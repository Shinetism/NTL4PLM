2022-03-20 21:55:32,252 - INFO - allennlp.common.params - random_seed = 13
2022-03-20 21:55:32,260 - INFO - allennlp.common.params - numpy_seed = 13
2022-03-20 21:55:32,261 - INFO - allennlp.common.params - pytorch_seed = 13
2022-03-20 21:55:32,265 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-20 21:55:32,267 - INFO - allennlp.common.params - type = default
2022-03-20 21:55:32,270 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-20 21:55:32,272 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-20 21:55:32,273 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-20 21:55:32,274 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-20 21:55:32,276 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-20 21:55:32,277 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-20 21:55:32,278 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-20 21:55:44,943 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-20 21:55:44,949 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-20 21:55:44,951 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-20 21:55:44,952 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-20 21:55:44,954 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-20 21:55:44,955 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-20 21:55:44,957 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-20 21:55:44,959 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-20 21:55:44,961 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-20 21:55:44,963 - INFO - allennlp.common.params - train_data_path = datasets/rct-20k/train.jsonl
2022-03-20 21:55:44,965 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f70f60920d0>
2022-03-20 21:55:44,967 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-20 21:55:44,969 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-20 21:55:44,971 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-20 21:55:44,972 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-20 21:55:44,974 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-20 21:55:44,975 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-20 21:55:44,977 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-20 21:55:44,978 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-20 21:55:44,981 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-20 21:55:44,982 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-20 21:55:44,984 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-20 21:55:44,985 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-20 21:55:44,987 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-20 21:55:44,988 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-20 21:55:44,990 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-20 21:55:44,993 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-20 21:55:44,994 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-20 21:55:44,996 - INFO - allennlp.common.params - validation_data_path = datasets/rct-20k/dev.jsonl
2022-03-20 21:55:44,997 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-20 21:55:44,999 - INFO - allennlp.common.params - test_data_path = datasets/rct-20k/test.jsonl
2022-03-20 21:55:45,000 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-20 21:55:45,001 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-20 21:55:45,003 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-20 21:55:45,005 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-20 21:55:45,006 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-20 21:55:45,008 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-20 21:55:45,009 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-20 21:55:45,011 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-20 21:55:45,012 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-20 21:55:45,014 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-20 21:55:45,015 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-20 21:55:45,017 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-20 21:55:45,018 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-20 21:55:45,020 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-20 21:55:45,021 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-20 21:55:45,023 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-20 21:55:45,026 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-20 21:55:55,118 - INFO - tqdm - loading instances: 35399it [00:10, 4270.41it/s]
2022-03-20 21:56:05,205 - INFO - tqdm - loading instances: 71452it [00:20, 4319.00it/s]
2022-03-20 21:56:15,277 - INFO - tqdm - loading instances: 105784it [00:30, 3495.81it/s]
2022-03-20 21:56:25,330 - INFO - tqdm - loading instances: 142316it [00:40, 4203.23it/s]
2022-03-20 21:56:35,420 - INFO - tqdm - loading instances: 177511it [00:50, 4300.80it/s]
2022-03-20 21:56:36,035 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-20 21:56:36,041 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-20 21:56:36,043 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-20 21:56:36,044 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-20 21:56:36,046 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-20 21:56:36,048 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-20 21:56:36,049 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-20 21:56:36,051 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-20 21:56:36,052 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-20 21:56:36,054 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-20 21:56:36,055 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-20 21:56:36,057 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-20 21:56:36,058 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-20 21:56:36,060 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-20 21:56:36,062 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-20 21:56:45,736 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-20 21:56:45,742 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-20 21:56:45,745 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-20 21:56:45,747 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-20 21:56:45,749 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-20 21:56:45,751 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-20 21:56:45,752 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-20 21:56:45,754 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-20 21:56:45,758 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-20 21:56:45,760 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-20 21:56:45,761 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-20 21:56:45,762 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-20 21:56:45,764 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-20 21:56:45,765 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-20 21:56:45,767 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-20 21:56:52,887 - INFO - allennlp.common.params - type = from_instances
2022-03-20 21:56:52,893 - INFO - allennlp.common.params - min_count = None
2022-03-20 21:56:52,895 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-20 21:56:52,896 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-20 21:56:52,898 - INFO - allennlp.common.params - pretrained_files = None
2022-03-20 21:56:52,899 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-20 21:56:52,901 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-20 21:56:52,903 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-20 21:56:52,904 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-20 21:56:52,906 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-20 21:56:52,907 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-20 21:56:52,909 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-20 21:56:54,127 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-20 21:56:54,133 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-20 21:56:54,135 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-20 21:56:54,136 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-20 21:56:54,138 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-20 21:56:54,139 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-20 21:56:54,140 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-20 21:56:54,142 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-20 21:56:54,143 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-20 21:56:54,145 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-20 21:56:54,146 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-20 21:56:54,147 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-20 21:56:54,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-20 21:56:59,792 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-20 21:56:59,798 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-20 21:56:59,801 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-20 21:56:59,803 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-20 21:56:59,804 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-20 21:56:59,805 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-20 21:56:59,807 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-20 21:56:59,808 - INFO - allennlp.common.params - type = tanh
2022-03-20 21:56:59,810 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-20 21:56:59,816 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-20 21:56:59,817 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-20 21:56:59,819 - INFO - allennlp.common.params - model.num_labels = None
2022-03-20 21:56:59,820 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-20 21:56:59,822 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f72660eb350>
2022-03-20 21:56:59,823 - INFO - allennlp.common.params - model.regularizer = None
2022-03-20 21:56:59,824 - INFO - allennlp.common.params - model.track_weights = False
2022-03-20 21:56:59,826 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-20 21:56:59,827 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-20 21:56:59,830 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-20 21:56:59,831 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-20 21:56:59,833 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-20 21:56:59,834 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-20 21:56:59,835 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-20 21:56:59,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-20 21:56:59,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-20 21:56:59,841 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-20 21:56:59,842 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-20 21:56:59,844 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-20 21:56:59,845 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-20 21:56:59,847 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-20 21:56:59,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-20 21:56:59,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-20 21:56:59,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-20 21:56:59,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-20 21:56:59,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-20 21:56:59,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-20 21:56:59,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-20 21:56:59,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-20 21:56:59,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-20 21:56:59,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-20 21:56:59,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-20 21:56:59,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-20 21:56:59,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-20 21:56:59,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-20 21:56:59,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-20 21:56:59,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-20 21:56:59,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-20 21:56:59,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-20 21:56:59,875 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-20 21:56:59,876 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-20 21:56:59,877 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-20 21:56:59,879 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-20 21:56:59,880 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-20 21:56:59,881 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-20 21:56:59,883 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-20 21:56:59,884 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-20 21:56:59,886 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-20 21:56:59,887 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-20 21:56:59,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-20 21:56:59,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-20 21:56:59,892 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-20 21:56:59,893 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-20 21:56:59,895 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-20 21:56:59,897 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-20 21:56:59,899 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-20 21:56:59,900 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-20 21:56:59,901 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-20 21:56:59,902 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-20 21:56:59,905 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-20 21:56:59,906 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-20 21:56:59,908 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-20 21:56:59,909 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-20 21:56:59,910 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-20 21:56:59,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-20 21:56:59,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-20 21:56:59,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-20 21:56:59,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-20 21:56:59,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-20 21:56:59,918 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-20 21:56:59,920 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-20 21:56:59,921 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-20 21:56:59,923 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-20 21:56:59,924 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-20 21:56:59,926 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-20 21:56:59,927 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-20 21:56:59,929 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-20 21:56:59,931 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-20 21:56:59,932 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-20 21:56:59,933 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-20 21:56:59,934 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-20 21:56:59,936 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-20 21:56:59,937 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-20 21:56:59,939 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-20 21:56:59,940 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-20 21:56:59,941 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-20 21:56:59,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-20 21:56:59,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-20 21:56:59,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-20 21:56:59,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-20 21:56:59,952 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-20 21:56:59,953 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-20 21:56:59,954 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-20 21:56:59,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-20 21:56:59,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-20 21:56:59,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-20 21:56:59,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-20 21:56:59,962 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-20 21:56:59,963 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-20 21:56:59,965 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-20 21:56:59,967 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-20 21:56:59,968 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-20 21:56:59,970 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-20 21:56:59,971 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-20 21:56:59,972 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-20 21:56:59,973 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-20 21:56:59,975 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-20 21:56:59,976 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-20 21:56:59,977 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-20 21:56:59,979 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-20 21:56:59,980 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-20 21:56:59,981 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-20 21:56:59,983 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-20 21:56:59,984 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-20 21:56:59,985 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-20 21:56:59,987 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-20 21:56:59,988 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-20 21:56:59,989 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-20 21:56:59,991 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-20 21:56:59,992 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-20 21:56:59,993 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-20 21:56:59,995 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-20 21:56:59,996 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-20 21:56:59,998 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-20 21:56:59,999 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-20 21:57:00,001 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-20 21:57:00,003 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-20 21:57:00,004 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-20 21:57:00,006 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-20 21:57:00,007 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-20 21:57:00,009 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-20 21:57:00,010 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-20 21:57:00,012 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-20 21:57:00,013 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-20 21:57:00,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-20 21:57:00,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-20 21:57:00,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-20 21:57:00,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-20 21:57:00,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-20 21:57:00,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-20 21:57:00,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-20 21:57:00,024 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-20 21:57:00,025 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-20 21:57:00,026 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-20 21:57:00,028 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-20 21:57:00,029 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-20 21:57:00,031 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-20 21:57:00,032 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-20 21:57:00,033 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-20 21:57:00,038 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-20 21:57:00,040 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-20 21:57:00,042 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-20 21:57:00,043 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-20 21:57:00,045 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-20 21:57:00,046 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-20 21:57:00,048 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-20 21:57:00,049 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-20 21:57:00,051 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-20 21:57:00,052 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-20 21:57:00,055 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-20 21:57:00,057 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-20 21:57:00,058 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-20 21:57:00,059 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-20 21:57:00,061 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-20 21:57:00,062 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-20 21:57:00,064 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-20 21:57:00,065 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-20 21:57:00,067 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-20 21:57:00,068 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-20 21:57:00,069 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-20 21:57:00,071 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-20 21:57:00,073 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-20 21:57:00,074 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-20 21:57:00,075 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-20 21:57:00,078 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-20 21:57:00,079 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-20 21:57:00,081 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-20 21:57:00,082 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-20 21:57:00,084 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-20 21:57:00,085 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-20 21:57:00,086 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-20 21:57:00,088 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-20 21:57:00,089 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-20 21:57:00,090 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-20 21:57:00,092 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-20 21:57:00,093 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-20 21:57:00,094 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-20 21:57:00,096 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-20 21:57:00,097 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-20 21:57:00,099 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-20 21:57:00,100 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-20 21:57:00,101 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-20 21:57:00,103 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-20 21:57:00,104 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-20 21:57:00,105 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-20 21:57:00,107 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-20 21:57:00,108 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-20 21:57:00,109 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-20 21:57:00,111 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-20 21:57:00,113 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-20 21:57:00,114 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-20 21:57:00,116 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-20 21:57:00,117 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-20 21:57:00,118 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-20 21:57:00,120 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-20 21:57:00,121 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-20 21:57:00,123 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-20 21:57:00,124 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-20 21:57:00,125 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-20 21:57:00,127 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-20 21:57:00,128 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-20 21:57:00,129 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-20 21:57:00,131 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-20 21:57:08,764 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-20 21:57:08,771 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-20 21:57:08,772 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-20 21:57:08,774 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-20 21:57:08,776 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-20 21:57:08,777 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-20 21:57:08,779 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-20 21:57:08,780 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-20 21:57:08,782 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-20 21:57:08,784 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-20 21:57:08,785 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-20 21:57:08,787 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-20 21:57:08,789 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-20 21:57:08,790 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-20 21:57:08,792 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-20 21:57:08,793 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-20 21:57:08,795 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-20 21:57:16,215 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-20 21:57:16,222 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-20 21:57:16,224 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-20 21:57:16,227 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-20 21:57:16,228 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-20 21:57:16,230 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-20 21:57:16,234 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-20 21:57:16,236 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias'], {'weight_decay': 0}
2022-03-20 21:57:16,239 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight'], {}
2022-03-20 21:57:16,242 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-20 21:57:16,244 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125240069
2022-03-20 21:57:16,246 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-20 21:57:16,249 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-20 21:57:16,250 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-20 21:57:16,252 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-20 21:57:16,254 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-20 21:57:16,255 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-20 21:57:16,257 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-20 21:57:16,259 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-20 21:57:16,261 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-20 21:57:16,262 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-20 21:57:16,264 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-20 21:57:16,266 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-20 21:57:16,267 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-20 21:57:16,269 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-20 21:57:16,271 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-20 21:57:16,272 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-20 21:57:16,274 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-20 21:57:16,278 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-20 21:57:16,279 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-20 21:57:16,281 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-20 21:57:16,282 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-20 21:57:16,284 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-20 21:57:16,286 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-20 21:57:16,287 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-20 21:57:16,289 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-20 21:57:16,290 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-20 21:57:16,292 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-20 21:57:16,293 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-20 21:57:16,295 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-20 21:57:16,296 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-20 21:57:16,298 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-20 21:57:16,299 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-20 21:57:16,301 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-20 21:57:16,302 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-20 21:57:16,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-20 21:57:16,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-20 21:57:16,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-20 21:57:16,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-20 21:57:16,309 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-20 21:57:16,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-20 21:57:16,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-20 21:57:16,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-20 21:57:16,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-20 21:57:16,317 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-20 21:57:16,318 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-20 21:57:16,319 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-20 21:57:16,321 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-20 21:57:16,322 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-20 21:57:16,324 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-20 21:57:16,325 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-20 21:57:16,326 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-20 21:57:16,328 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-20 21:57:16,329 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-20 21:57:16,331 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-20 21:57:16,332 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-20 21:57:16,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-20 21:57:16,336 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-20 21:57:16,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-20 21:57:16,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-20 21:57:16,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-20 21:57:16,342 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-20 21:57:16,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-20 21:57:16,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-20 21:57:16,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-20 21:57:16,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-20 21:57:16,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-20 21:57:16,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-20 21:57:16,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-20 21:57:16,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-20 21:57:16,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-20 21:57:16,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-20 21:57:16,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-20 21:57:16,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-20 21:57:16,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-20 21:57:16,365 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-20 21:57:16,367 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-20 21:57:16,368 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-20 21:57:16,370 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-20 21:57:16,371 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-20 21:57:16,373 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-20 21:57:16,374 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-20 21:57:16,375 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-20 21:57:16,377 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-20 21:57:16,379 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-20 21:57:16,380 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-20 21:57:16,382 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-20 21:57:16,383 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-20 21:57:16,385 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-20 21:57:16,386 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-20 21:57:16,388 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-20 21:57:16,390 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-20 21:57:16,391 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-20 21:57:16,393 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-20 21:57:16,395 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-20 21:57:16,396 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-20 21:57:16,399 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-20 21:57:16,400 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-20 21:57:16,402 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-20 21:57:16,403 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-20 21:57:16,404 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-20 21:57:16,406 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-20 21:57:16,407 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-20 21:57:16,408 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-20 21:57:16,410 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-20 21:57:16,411 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-20 21:57:16,413 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-20 21:57:16,414 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-20 21:57:16,415 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-20 21:57:16,417 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-20 21:57:16,418 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-20 21:57:16,419 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-20 21:57:16,421 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-20 21:57:16,422 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-20 21:57:16,423 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-20 21:57:16,425 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-20 21:57:16,426 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-20 21:57:16,427 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-20 21:57:16,430 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-20 21:57:16,431 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-20 21:57:16,433 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-20 21:57:16,435 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-20 21:57:16,436 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-20 21:57:16,437 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-20 21:57:16,439 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-20 21:57:16,440 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-20 21:57:16,441 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-20 21:57:16,443 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-20 21:57:16,444 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-20 21:57:16,445 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-20 21:57:16,447 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-20 21:57:16,448 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-20 21:57:16,449 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-20 21:57:16,450 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-20 21:57:16,452 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-20 21:57:16,453 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-20 21:57:16,454 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-20 21:57:16,456 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-20 21:57:16,457 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-20 21:57:16,458 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-20 21:57:16,461 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-20 21:57:16,462 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-20 21:57:16,463 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-20 21:57:16,465 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-20 21:57:16,466 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-20 21:57:16,467 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-20 21:57:16,469 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-20 21:57:16,471 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-20 21:57:16,472 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-20 21:57:16,473 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-20 21:57:16,475 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-20 21:57:16,476 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-20 21:57:16,477 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-20 21:57:16,478 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-20 21:57:16,480 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-20 21:57:16,481 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-20 21:57:16,482 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-20 21:57:16,483 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-20 21:57:16,485 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-20 21:57:16,486 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-20 21:57:16,487 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-20 21:57:16,489 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-20 21:57:16,490 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-20 21:57:16,491 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-20 21:57:16,492 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-20 21:57:16,494 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-20 21:57:16,495 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-20 21:57:16,496 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-20 21:57:16,498 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-20 21:57:16,499 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-20 21:57:16,500 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-20 21:57:16,501 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-20 21:57:16,503 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-20 21:57:16,505 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-20 21:57:16,506 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-20 21:57:16,507 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-20 21:57:16,509 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-20 21:57:16,510 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-20 21:57:16,511 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-20 21:57:16,513 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-20 21:57:16,514 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-20 21:57:16,515 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-20 21:57:16,517 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-20 21:57:16,518 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-20 21:57:16,519 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-20 21:57:16,521 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-20 21:57:16,522 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-20 21:57:16,523 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-20 21:57:16,525 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-20 21:57:16,526 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-20 21:57:16,528 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-20 21:57:16,529 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-20 21:57:16,530 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-20 21:57:16,532 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-20 21:57:16,533 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-20 21:57:16,534 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-20 21:57:16,536 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-20 21:57:16,537 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-20 21:57:16,538 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-20 21:57:16,541 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-20 21:57:16,542 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-20 21:57:16,543 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-20 21:57:16,545 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-20 21:57:16,546 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-20 21:57:16,547 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-20 21:57:16,549 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-20 21:57:16,550 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-20 21:57:16,552 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-20 21:57:16,553 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-20 21:57:16,555 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-20 21:57:16,556 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-20 21:57:16,558 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-20 21:57:16,562 - INFO - allennlp.training.trainer - Beginning training.
2022-03-20 21:57:16,564 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-20 21:57:16,565 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.3G
2022-03-20 21:57:16,567 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 21:57:16,569 - INFO - allennlp.training.trainer - Training
2022-03-20 21:57:16,570 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-20 21:57:16,755 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-20 21:57:16,757 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-20 21:57:26,762 - INFO - tqdm - f1: 0.3643, accuracy: 0.5542, batch_loss: 0.9110, loss: 1.0954 ||:   1%|          | 68/11253 [00:10<41:48,  4.46it/s]
2022-03-20 21:57:36,831 - INFO - tqdm - f1: 0.5664, accuracy: 0.6801, batch_loss: 0.4446, loss: 0.8296 ||:   2%|1         | 170/11253 [00:20<41:34,  4.44it/s]
2022-03-20 21:57:47,044 - INFO - tqdm - f1: 0.6336, accuracy: 0.7259, batch_loss: 0.8743, loss: 0.7250 ||:   2%|2         | 272/11253 [00:30<41:33,  4.40it/s]
2022-03-20 21:57:57,315 - INFO - tqdm - f1: 0.6639, accuracy: 0.7503, batch_loss: 0.3674, loss: 0.6610 ||:   3%|3         | 372/11253 [00:40<41:25,  4.38it/s]
2022-03-20 21:58:07,608 - INFO - tqdm - f1: 0.6872, accuracy: 0.7661, batch_loss: 0.7218, loss: 0.6216 ||:   4%|4         | 470/11253 [00:51<43:05,  4.17it/s]
2022-03-20 21:58:17,994 - INFO - tqdm - f1: 0.7037, accuracy: 0.7786, batch_loss: 0.5046, loss: 0.5905 ||:   5%|5         | 574/11253 [01:01<39:58,  4.45it/s]
2022-03-20 21:58:28,049 - INFO - tqdm - f1: 0.7127, accuracy: 0.7863, batch_loss: 0.3644, loss: 0.5723 ||:   6%|6         | 676/11253 [01:11<31:47,  5.55it/s]
2022-03-20 21:58:38,360 - INFO - tqdm - f1: 0.7195, accuracy: 0.7921, batch_loss: 0.5538, loss: 0.5579 ||:   7%|6         | 782/11253 [01:21<38:32,  4.53it/s]
2022-03-20 21:58:48,541 - INFO - tqdm - f1: 0.7255, accuracy: 0.7961, batch_loss: 0.2651, loss: 0.5489 ||:   8%|7         | 884/11253 [01:31<39:42,  4.35it/s]
2022-03-20 21:58:58,915 - INFO - tqdm - f1: 0.7293, accuracy: 0.7994, batch_loss: 0.3250, loss: 0.5415 ||:   9%|8         | 986/11253 [01:42<39:53,  4.29it/s]
2022-03-20 21:59:09,048 - INFO - tqdm - f1: 0.7338, accuracy: 0.8037, batch_loss: 0.3806, loss: 0.5337 ||:  10%|9         | 1086/11253 [01:52<39:42,  4.27it/s]
2022-03-20 21:59:19,096 - INFO - tqdm - f1: 0.7375, accuracy: 0.8065, batch_loss: 0.2849, loss: 0.5275 ||:  11%|#         | 1186/11253 [02:02<37:43,  4.45it/s]
2022-03-20 21:59:29,229 - INFO - tqdm - f1: 0.7413, accuracy: 0.8092, batch_loss: 0.7910, loss: 0.5192 ||:  11%|#1        | 1288/11253 [02:12<36:41,  4.53it/s]
2022-03-20 21:59:39,610 - INFO - tqdm - f1: 0.7434, accuracy: 0.8110, batch_loss: 0.9710, loss: 0.5140 ||:  12%|#2        | 1390/11253 [02:23<37:04,  4.43it/s]
2022-03-20 21:59:50,457 - INFO - tqdm - f1: 0.7444, accuracy: 0.8129, batch_loss: 0.3933, loss: 0.5077 ||:  13%|#3        | 1494/11253 [02:33<38:43,  4.20it/s]
2022-03-20 22:00:00,832 - INFO - tqdm - f1: 0.7455, accuracy: 0.8139, batch_loss: 0.1972, loss: 0.5056 ||:  14%|#4        | 1586/11253 [02:44<37:26,  4.30it/s]
2022-03-20 22:00:11,195 - INFO - tqdm - f1: 0.7464, accuracy: 0.8140, batch_loss: 0.5709, loss: 0.5063 ||:  15%|#4        | 1671/11253 [02:54<42:03,  3.80it/s]
2022-03-20 22:00:21,900 - INFO - tqdm - f1: 0.7478, accuracy: 0.8148, batch_loss: 0.3942, loss: 0.5034 ||:  16%|#5        | 1756/11253 [03:05<39:01,  4.06it/s]
2022-03-20 22:00:32,356 - INFO - tqdm - f1: 0.7491, accuracy: 0.8159, batch_loss: 0.3424, loss: 0.5003 ||:  16%|#6        | 1854/11253 [03:15<35:11,  4.45it/s]
2022-03-20 22:00:42,507 - INFO - tqdm - f1: 0.7501, accuracy: 0.8170, batch_loss: 1.1032, loss: 0.4974 ||:  17%|#7        | 1951/11253 [03:25<35:53,  4.32it/s]
2022-03-20 22:00:53,308 - INFO - tqdm - f1: 0.7518, accuracy: 0.8183, batch_loss: 0.3798, loss: 0.4934 ||:  18%|#8        | 2047/11253 [03:36<36:21,  4.22it/s]
2022-03-20 22:01:03,526 - INFO - tqdm - f1: 0.7533, accuracy: 0.8195, batch_loss: 0.4086, loss: 0.4901 ||:  19%|#9        | 2141/11253 [03:46<23:19,  6.51it/s]
2022-03-20 22:01:14,673 - INFO - tqdm - f1: 0.7542, accuracy: 0.8198, batch_loss: 0.3318, loss: 0.4894 ||:  20%|#9        | 2229/11253 [03:58<34:59,  4.30it/s]
2022-03-20 22:01:24,797 - INFO - tqdm - f1: 0.7554, accuracy: 0.8209, batch_loss: 0.4334, loss: 0.4863 ||:  21%|##        | 2315/11253 [04:08<38:19,  3.89it/s]
2022-03-20 22:01:35,638 - INFO - tqdm - f1: 0.7567, accuracy: 0.8221, batch_loss: 1.0498, loss: 0.4831 ||:  21%|##1       | 2410/11253 [04:19<34:36,  4.26it/s]
2022-03-20 22:01:46,115 - INFO - tqdm - f1: 0.7577, accuracy: 0.8231, batch_loss: 0.0273, loss: 0.4803 ||:  22%|##2       | 2496/11253 [04:29<35:28,  4.11it/s]
2022-03-20 22:01:57,234 - INFO - tqdm - f1: 0.7588, accuracy: 0.8241, batch_loss: 0.7570, loss: 0.4778 ||:  23%|##3       | 2590/11253 [04:40<36:05,  4.00it/s]
2022-03-20 22:02:07,625 - INFO - tqdm - f1: 0.7599, accuracy: 0.8255, batch_loss: 0.5094, loss: 0.4748 ||:  24%|##3       | 2681/11253 [04:51<33:42,  4.24it/s]
2022-03-20 22:02:17,695 - INFO - tqdm - f1: 0.7606, accuracy: 0.8260, batch_loss: 0.8068, loss: 0.4741 ||:  25%|##4       | 2768/11253 [05:01<31:23,  4.50it/s]
2022-03-20 22:02:27,813 - INFO - tqdm - f1: 0.7621, accuracy: 0.8268, batch_loss: 0.7936, loss: 0.4728 ||:  25%|##5       | 2860/11253 [05:11<26:33,  5.27it/s]
2022-03-20 22:02:38,378 - INFO - tqdm - f1: 0.7631, accuracy: 0.8277, batch_loss: 0.1200, loss: 0.4702 ||:  26%|##6       | 2950/11253 [05:21<33:20,  4.15it/s]
2022-03-20 22:02:48,456 - INFO - tqdm - f1: 0.7642, accuracy: 0.8285, batch_loss: 0.2794, loss: 0.4690 ||:  27%|##6       | 3036/11253 [05:31<34:06,  4.02it/s]
2022-03-20 22:02:58,683 - INFO - tqdm - f1: 0.7648, accuracy: 0.8290, batch_loss: 0.2505, loss: 0.4678 ||:  28%|##7       | 3127/11253 [05:42<32:25,  4.18it/s]
2022-03-20 22:03:08,746 - INFO - tqdm - f1: 0.7652, accuracy: 0.8295, batch_loss: 0.2806, loss: 0.4664 ||:  29%|##8       | 3210/11253 [05:52<30:56,  4.33it/s]
2022-03-20 22:03:19,246 - INFO - tqdm - f1: 0.7651, accuracy: 0.8294, batch_loss: 0.1383, loss: 0.4662 ||:  29%|##9       | 3294/11253 [06:02<33:43,  3.93it/s]
2022-03-20 22:03:29,931 - INFO - tqdm - f1: 0.7655, accuracy: 0.8299, batch_loss: 0.6822, loss: 0.4649 ||:  30%|###       | 3384/11253 [06:13<30:36,  4.28it/s]
2022-03-20 22:03:40,685 - INFO - tqdm - f1: 0.7667, accuracy: 0.8308, batch_loss: 0.6699, loss: 0.4627 ||:  31%|###       | 3481/11253 [06:24<31:17,  4.14it/s]
2022-03-20 22:03:50,692 - INFO - tqdm - f1: 0.7683, accuracy: 0.8319, batch_loss: 0.1367, loss: 0.4601 ||:  32%|###1      | 3573/11253 [06:34<30:11,  4.24it/s]
2022-03-20 22:04:01,281 - INFO - tqdm - f1: 0.7688, accuracy: 0.8325, batch_loss: 0.3473, loss: 0.4582 ||:  33%|###2      | 3663/11253 [06:44<28:56,  4.37it/s]
2022-03-20 22:04:11,727 - INFO - tqdm - f1: 0.7691, accuracy: 0.8328, batch_loss: 0.4777, loss: 0.4565 ||:  33%|###3      | 3747/11253 [06:55<32:02,  3.90it/s]
2022-03-20 22:04:22,281 - INFO - tqdm - f1: 0.7688, accuracy: 0.8329, batch_loss: 0.5059, loss: 0.4557 ||:  34%|###4      | 3842/11253 [07:05<28:35,  4.32it/s]
2022-03-20 22:04:32,959 - INFO - tqdm - f1: 0.7693, accuracy: 0.8333, batch_loss: 0.4111, loss: 0.4548 ||:  35%|###4      | 3920/11253 [07:16<32:16,  3.79it/s]
2022-03-20 22:04:43,712 - INFO - tqdm - f1: 0.7697, accuracy: 0.8337, batch_loss: 0.3864, loss: 0.4534 ||:  36%|###5      | 4012/11253 [07:27<27:22,  4.41it/s]
2022-03-20 22:04:54,321 - INFO - tqdm - f1: 0.7706, accuracy: 0.8346, batch_loss: 0.2586, loss: 0.4516 ||:  36%|###6      | 4106/11253 [07:37<28:37,  4.16it/s]
2022-03-20 22:05:04,813 - INFO - tqdm - f1: 0.7715, accuracy: 0.8353, batch_loss: 0.1759, loss: 0.4503 ||:  37%|###7      | 4204/11253 [07:48<27:13,  4.32it/s]
2022-03-20 22:05:15,131 - INFO - tqdm - f1: 0.7717, accuracy: 0.8355, batch_loss: 0.1449, loss: 0.4500 ||:  38%|###8      | 4300/11253 [07:58<28:07,  4.12it/s]
2022-03-20 22:05:25,517 - INFO - tqdm - f1: 0.7726, accuracy: 0.8362, batch_loss: 0.4133, loss: 0.4484 ||:  39%|###9      | 4396/11253 [08:08<27:00,  4.23it/s]
2022-03-20 22:05:36,281 - INFO - tqdm - f1: 0.7733, accuracy: 0.8369, batch_loss: 0.0901, loss: 0.4470 ||:  40%|###9      | 4481/11253 [08:19<38:57,  2.90it/s]
2022-03-20 22:05:46,996 - INFO - tqdm - f1: 0.7737, accuracy: 0.8375, batch_loss: 0.3596, loss: 0.4459 ||:  41%|####      | 4568/11253 [08:30<27:08,  4.10it/s]
2022-03-20 22:05:57,049 - INFO - tqdm - f1: 0.7738, accuracy: 0.8378, batch_loss: 0.4625, loss: 0.4450 ||:  41%|####1     | 4660/11253 [08:40<10:18, 10.66it/s]
2022-03-20 22:06:07,079 - INFO - tqdm - f1: 0.7746, accuracy: 0.8383, batch_loss: 0.3281, loss: 0.4436 ||:  42%|####2     | 4746/11253 [08:50<10:42, 10.13it/s]
2022-03-20 22:06:17,130 - INFO - tqdm - f1: 0.7746, accuracy: 0.8384, batch_loss: 0.1633, loss: 0.4434 ||:  43%|####2     | 4822/11253 [09:00<20:48,  5.15it/s]
2022-03-20 22:06:27,864 - INFO - tqdm - f1: 0.7751, accuracy: 0.8389, batch_loss: 0.1199, loss: 0.4420 ||:  44%|####3     | 4907/11253 [09:11<26:25,  4.00it/s]
2022-03-20 22:06:37,945 - INFO - tqdm - f1: 0.7753, accuracy: 0.8390, batch_loss: 0.4174, loss: 0.4416 ||:  44%|####4     | 4997/11253 [09:21<19:45,  5.28it/s]
2022-03-20 22:06:48,514 - INFO - tqdm - f1: 0.7758, accuracy: 0.8396, batch_loss: 0.7547, loss: 0.4401 ||:  45%|####5     | 5097/11253 [09:31<23:38,  4.34it/s]
2022-03-20 22:06:58,604 - INFO - tqdm - f1: 0.7765, accuracy: 0.8401, batch_loss: 0.2719, loss: 0.4390 ||:  46%|####6     | 5191/11253 [09:42<08:56, 11.30it/s]
2022-03-20 22:07:08,732 - INFO - tqdm - f1: 0.7769, accuracy: 0.8402, batch_loss: 0.4268, loss: 0.4385 ||:  47%|####6     | 5285/11253 [09:52<07:10, 13.87it/s]
2022-03-20 22:07:18,782 - INFO - tqdm - f1: 0.7768, accuracy: 0.8403, batch_loss: 0.1694, loss: 0.4383 ||:  48%|####7     | 5381/11253 [10:02<07:03, 13.88it/s]
2022-03-20 22:07:28,874 - INFO - tqdm - f1: 0.7769, accuracy: 0.8405, batch_loss: 0.2931, loss: 0.4374 ||:  49%|####8     | 5475/11253 [10:12<06:29, 14.85it/s]
2022-03-20 22:07:39,041 - INFO - tqdm - f1: 0.7770, accuracy: 0.8407, batch_loss: 0.2048, loss: 0.4369 ||:  50%|####9     | 5573/11253 [10:22<07:57, 11.90it/s]
2022-03-20 22:07:49,056 - INFO - tqdm - f1: 0.7773, accuracy: 0.8411, batch_loss: 0.4675, loss: 0.4365 ||:  50%|#####     | 5663/11253 [10:32<08:09, 11.41it/s]
2022-03-20 22:07:59,203 - INFO - tqdm - f1: 0.7776, accuracy: 0.8413, batch_loss: 0.4392, loss: 0.4357 ||:  51%|#####1    | 5759/11253 [10:42<07:32, 12.15it/s]
2022-03-20 22:08:09,282 - INFO - tqdm - f1: 0.7778, accuracy: 0.8415, batch_loss: 0.4658, loss: 0.4355 ||:  52%|#####1    | 5851/11253 [10:52<07:56, 11.34it/s]
2022-03-20 22:08:19,300 - INFO - tqdm - f1: 0.7780, accuracy: 0.8416, batch_loss: 0.2148, loss: 0.4346 ||:  53%|#####2    | 5938/11253 [11:02<08:44, 10.14it/s]
2022-03-20 22:08:29,360 - INFO - tqdm - f1: 0.7785, accuracy: 0.8419, batch_loss: 0.4171, loss: 0.4342 ||:  54%|#####3    | 6032/11253 [11:12<08:22, 10.39it/s]
2022-03-20 22:08:39,394 - INFO - tqdm - f1: 0.7791, accuracy: 0.8421, batch_loss: 0.5528, loss: 0.4340 ||:  54%|#####4    | 6124/11253 [11:22<11:02,  7.74it/s]
2022-03-20 22:08:49,465 - INFO - tqdm - f1: 0.7797, accuracy: 0.8425, batch_loss: 0.3742, loss: 0.4328 ||:  55%|#####5    | 6218/11253 [11:32<10:47,  7.78it/s]
2022-03-20 22:08:59,575 - INFO - tqdm - f1: 0.7801, accuracy: 0.8429, batch_loss: 0.1329, loss: 0.4322 ||:  56%|#####6    | 6310/11253 [11:43<09:15,  8.90it/s]
2022-03-20 22:09:09,669 - INFO - tqdm - f1: 0.7803, accuracy: 0.8431, batch_loss: 0.4143, loss: 0.4317 ||:  57%|#####6    | 6404/11253 [11:53<18:11,  4.44it/s]
2022-03-20 22:09:19,930 - INFO - tqdm - f1: 0.7810, accuracy: 0.8435, batch_loss: 0.5038, loss: 0.4307 ||:  58%|#####7    | 6498/11253 [12:03<18:16,  4.34it/s]
2022-03-20 22:09:30,114 - INFO - tqdm - f1: 0.7811, accuracy: 0.8437, batch_loss: 0.4287, loss: 0.4306 ||:  59%|#####8    | 6590/11253 [12:13<17:30,  4.44it/s]
2022-03-20 22:09:40,476 - INFO - tqdm - f1: 0.7813, accuracy: 0.8439, batch_loss: 0.1615, loss: 0.4296 ||:  59%|#####9    | 6692/11253 [12:23<16:44,  4.54it/s]
2022-03-20 22:09:51,281 - INFO - tqdm - f1: 0.7816, accuracy: 0.8443, batch_loss: 0.5222, loss: 0.4284 ||:  60%|######    | 6800/11253 [12:34<15:49,  4.69it/s]
2022-03-20 22:10:01,336 - INFO - tqdm - f1: 0.7817, accuracy: 0.8445, batch_loss: 0.2104, loss: 0.4277 ||:  61%|######1   | 6896/11253 [12:44<16:10,  4.49it/s]
2022-03-20 22:10:11,359 - INFO - tqdm - f1: 0.7821, accuracy: 0.8447, batch_loss: 0.4055, loss: 0.4270 ||:  62%|######2   | 6998/11253 [12:54<15:30,  4.57it/s]
2022-03-20 22:10:21,694 - INFO - tqdm - f1: 0.7822, accuracy: 0.8449, batch_loss: 0.6385, loss: 0.4263 ||:  63%|######3   | 7102/11253 [13:05<15:31,  4.46it/s]
2022-03-20 22:10:31,866 - INFO - tqdm - f1: 0.7824, accuracy: 0.8452, batch_loss: 0.1708, loss: 0.4256 ||:  64%|######3   | 7200/11253 [13:15<15:15,  4.43it/s]
2022-03-20 22:10:41,928 - INFO - tqdm - f1: 0.7827, accuracy: 0.8454, batch_loss: 0.2780, loss: 0.4248 ||:  65%|######4   | 7304/11253 [13:25<14:13,  4.62it/s]
2022-03-20 22:10:51,967 - INFO - tqdm - f1: 0.7829, accuracy: 0.8455, batch_loss: 0.6215, loss: 0.4242 ||:  66%|######5   | 7404/11253 [13:35<14:19,  4.48it/s]
2022-03-20 22:11:02,348 - INFO - tqdm - f1: 0.7833, accuracy: 0.8459, batch_loss: 0.1807, loss: 0.4235 ||:  67%|######6   | 7510/11253 [13:45<13:29,  4.62it/s]
2022-03-20 22:11:12,823 - INFO - tqdm - f1: 0.7835, accuracy: 0.8461, batch_loss: 0.6039, loss: 0.4230 ||:  68%|######7   | 7612/11253 [13:56<13:43,  4.42it/s]
2022-03-20 22:11:22,845 - INFO - tqdm - f1: 0.7836, accuracy: 0.8463, batch_loss: 0.4940, loss: 0.4225 ||:  68%|######8   | 7702/11253 [14:06<13:52,  4.26it/s]
2022-03-20 22:11:33,035 - INFO - tqdm - f1: 0.7838, accuracy: 0.8465, batch_loss: 0.9502, loss: 0.4217 ||:  69%|######9   | 7800/11253 [14:16<13:32,  4.25it/s]
2022-03-20 22:11:43,497 - INFO - tqdm - f1: 0.7837, accuracy: 0.8466, batch_loss: 0.5899, loss: 0.4212 ||:  70%|#######   | 7906/11253 [14:26<12:16,  4.54it/s]
2022-03-20 22:11:53,849 - INFO - tqdm - f1: 0.7839, accuracy: 0.8469, batch_loss: 0.6044, loss: 0.4208 ||:  71%|#######1  | 8012/11253 [14:37<11:55,  4.53it/s]
2022-03-20 22:12:04,137 - INFO - tqdm - f1: 0.7845, accuracy: 0.8472, batch_loss: 0.0277, loss: 0.4204 ||:  72%|#######2  | 8114/11253 [14:47<11:49,  4.42it/s]
2022-03-20 22:12:14,226 - INFO - tqdm - f1: 0.7848, accuracy: 0.8475, batch_loss: 0.2678, loss: 0.4197 ||:  73%|#######3  | 8216/11253 [14:57<11:05,  4.57it/s]
2022-03-20 22:12:24,703 - INFO - tqdm - f1: 0.7847, accuracy: 0.8476, batch_loss: 0.8528, loss: 0.4196 ||:  74%|#######3  | 8322/11253 [15:08<11:15,  4.34it/s]
2022-03-20 22:12:35,098 - INFO - tqdm - f1: 0.7847, accuracy: 0.8476, batch_loss: 0.2189, loss: 0.4191 ||:  75%|#######4  | 8424/11253 [15:18<10:52,  4.34it/s]
2022-03-20 22:12:45,428 - INFO - tqdm - f1: 0.7847, accuracy: 0.8477, batch_loss: 0.1412, loss: 0.4188 ||:  76%|#######5  | 8530/11253 [15:28<10:09,  4.47it/s]
2022-03-20 22:12:55,603 - INFO - tqdm - f1: 0.7851, accuracy: 0.8480, batch_loss: 0.2064, loss: 0.4180 ||:  77%|#######6  | 8632/11253 [15:39<09:45,  4.48it/s]
2022-03-20 22:13:05,941 - INFO - tqdm - f1: 0.7853, accuracy: 0.8481, batch_loss: 0.8683, loss: 0.4176 ||:  78%|#######7  | 8738/11253 [15:49<09:49,  4.26it/s]
2022-03-20 22:13:16,297 - INFO - tqdm - f1: 0.7854, accuracy: 0.8483, batch_loss: 0.5392, loss: 0.4170 ||:  79%|#######8  | 8844/11253 [15:59<08:46,  4.58it/s]
2022-03-20 22:13:26,523 - INFO - tqdm - f1: 0.7855, accuracy: 0.8484, batch_loss: 0.1026, loss: 0.4165 ||:  79%|#######9  | 8946/11253 [16:09<08:23,  4.58it/s]
2022-03-20 22:13:36,623 - INFO - tqdm - f1: 0.7855, accuracy: 0.8485, batch_loss: 0.2665, loss: 0.4164 ||:  80%|########  | 9046/11253 [16:20<08:18,  4.43it/s]
2022-03-20 22:13:46,635 - INFO - tqdm - f1: 0.7857, accuracy: 0.8486, batch_loss: 0.2089, loss: 0.4162 ||:  81%|########1 | 9152/11253 [16:30<05:45,  6.08it/s]
2022-03-20 22:13:57,240 - INFO - tqdm - f1: 0.7858, accuracy: 0.8487, batch_loss: 0.3638, loss: 0.4160 ||:  82%|########2 | 9254/11253 [16:40<07:26,  4.48it/s]
2022-03-20 22:14:07,562 - INFO - tqdm - f1: 0.7859, accuracy: 0.8488, batch_loss: 1.0060, loss: 0.4159 ||:  83%|########3 | 9356/11253 [16:50<07:24,  4.26it/s]
2022-03-20 22:14:17,832 - INFO - tqdm - f1: 0.7860, accuracy: 0.8488, batch_loss: 0.7171, loss: 0.4158 ||:  84%|########4 | 9462/11253 [17:01<06:43,  4.44it/s]
2022-03-20 22:14:27,850 - INFO - tqdm - f1: 0.7862, accuracy: 0.8489, batch_loss: 0.4920, loss: 0.4156 ||:  85%|########5 | 9568/11253 [17:11<02:03, 13.59it/s]
2022-03-20 22:14:37,934 - INFO - tqdm - f1: 0.7863, accuracy: 0.8491, batch_loss: 0.7343, loss: 0.4150 ||:  86%|########5 | 9664/11253 [17:21<01:50, 14.41it/s]
2022-03-20 22:14:47,938 - INFO - tqdm - f1: 0.7865, accuracy: 0.8492, batch_loss: 0.9562, loss: 0.4148 ||:  87%|########6 | 9760/11253 [17:31<02:28, 10.03it/s]
2022-03-20 22:14:58,054 - INFO - tqdm - f1: 0.7865, accuracy: 0.8492, batch_loss: 0.5340, loss: 0.4148 ||:  88%|########7 | 9858/11253 [17:41<02:09, 10.76it/s]
2022-03-20 22:15:08,194 - INFO - tqdm - f1: 0.7867, accuracy: 0.8494, batch_loss: 0.4287, loss: 0.4148 ||:  88%|########8 | 9958/11253 [17:51<02:41,  8.01it/s]
2022-03-20 22:15:18,217 - INFO - tqdm - f1: 0.7867, accuracy: 0.8494, batch_loss: 0.4004, loss: 0.4147 ||:  89%|########9 | 10056/11253 [18:01<02:56,  6.77it/s]
2022-03-20 22:15:28,575 - INFO - tqdm - f1: 0.7867, accuracy: 0.8494, batch_loss: 0.2974, loss: 0.4145 ||:  90%|######### | 10162/11253 [18:12<03:21,  5.42it/s]
2022-03-20 22:15:38,578 - INFO - tqdm - f1: 0.7868, accuracy: 0.8496, batch_loss: 0.3616, loss: 0.4142 ||:  91%|#########1| 10250/11253 [18:22<01:09, 14.37it/s]
2022-03-20 22:15:48,603 - INFO - tqdm - f1: 0.7871, accuracy: 0.8498, batch_loss: 0.3991, loss: 0.4138 ||:  92%|#########1| 10348/11253 [18:32<01:07, 13.35it/s]
2022-03-20 22:15:58,604 - INFO - tqdm - f1: 0.7873, accuracy: 0.8499, batch_loss: 0.6230, loss: 0.4136 ||:  93%|#########2| 10444/11253 [18:42<01:19, 10.17it/s]
2022-03-20 22:16:08,714 - INFO - tqdm - f1: 0.7872, accuracy: 0.8499, batch_loss: 0.2064, loss: 0.4136 ||:  94%|#########3| 10544/11253 [18:52<01:07, 10.53it/s]
2022-03-20 22:16:18,760 - INFO - tqdm - f1: 0.7874, accuracy: 0.8501, batch_loss: 0.3456, loss: 0.4130 ||:  95%|#########4| 10644/11253 [19:02<00:58, 10.43it/s]
2022-03-20 22:16:28,807 - INFO - tqdm - f1: 0.7876, accuracy: 0.8503, batch_loss: 0.9017, loss: 0.4127 ||:  95%|#########5| 10744/11253 [19:12<00:47, 10.62it/s]
2022-03-20 22:16:38,878 - INFO - tqdm - f1: 0.7879, accuracy: 0.8505, batch_loss: 0.2072, loss: 0.4123 ||:  96%|#########6| 10842/11253 [19:22<00:44,  9.18it/s]
2022-03-20 22:16:48,977 - INFO - tqdm - f1: 0.7880, accuracy: 0.8506, batch_loss: 0.2753, loss: 0.4119 ||:  97%|#########7| 10942/11253 [19:32<00:38,  8.01it/s]
2022-03-20 22:16:58,980 - INFO - tqdm - f1: 0.7882, accuracy: 0.8507, batch_loss: 0.5565, loss: 0.4117 ||:  98%|#########8| 11042/11253 [19:42<00:25,  8.21it/s]
2022-03-20 22:17:09,059 - INFO - tqdm - f1: 0.7882, accuracy: 0.8507, batch_loss: 0.6781, loss: 0.4116 ||:  99%|#########9| 11144/11253 [19:52<00:13,  7.97it/s]
2022-03-20 22:17:13,937 - INFO - tqdm - f1: 0.7884, accuracy: 0.8508, batch_loss: 0.6546, loss: 0.4114 ||: 100%|#########9| 11198/11253 [19:57<00:03, 14.25it/s]
2022-03-20 22:17:14,073 - INFO - tqdm - f1: 0.7884, accuracy: 0.8508, batch_loss: 0.6797, loss: 0.4114 ||: 100%|#########9| 11200/11253 [19:57<00:03, 14.39it/s]
2022-03-20 22:17:14,213 - INFO - tqdm - f1: 0.7883, accuracy: 0.8508, batch_loss: 0.4210, loss: 0.4114 ||: 100%|#########9| 11202/11253 [19:57<00:03, 14.36it/s]
2022-03-20 22:17:15,361 - INFO - tqdm - f1: 0.7884, accuracy: 0.8508, batch_loss: 0.3480, loss: 0.4114 ||: 100%|#########9| 11204/11253 [19:58<00:10,  4.53it/s]
2022-03-20 22:17:15,515 - INFO - tqdm - f1: 0.7884, accuracy: 0.8508, batch_loss: 0.2379, loss: 0.4114 ||: 100%|#########9| 11206/11253 [19:58<00:08,  5.62it/s]
2022-03-20 22:17:15,658 - INFO - tqdm - f1: 0.7884, accuracy: 0.8508, batch_loss: 0.6865, loss: 0.4114 ||: 100%|#########9| 11208/11253 [19:59<00:06,  6.86it/s]
2022-03-20 22:17:15,802 - INFO - tqdm - f1: 0.7884, accuracy: 0.8508, batch_loss: 0.3773, loss: 0.4114 ||: 100%|#########9| 11210/11253 [19:59<00:05,  8.08it/s]
2022-03-20 22:17:15,946 - INFO - tqdm - f1: 0.7884, accuracy: 0.8508, batch_loss: 0.2039, loss: 0.4114 ||: 100%|#########9| 11212/11253 [19:59<00:04,  9.24it/s]
2022-03-20 22:17:16,091 - INFO - tqdm - f1: 0.7884, accuracy: 0.8508, batch_loss: 0.7421, loss: 0.4114 ||: 100%|#########9| 11214/11253 [19:59<00:03, 10.26it/s]
2022-03-20 22:17:16,223 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.0346, loss: 0.4113 ||: 100%|#########9| 11216/11253 [19:59<00:03, 11.35it/s]
2022-03-20 22:17:16,361 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.4155, loss: 0.4113 ||: 100%|#########9| 11218/11253 [19:59<00:02, 12.14it/s]
2022-03-20 22:17:16,497 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.3803, loss: 0.4113 ||: 100%|#########9| 11220/11253 [19:59<00:02, 12.82it/s]
2022-03-20 22:17:16,638 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.2599, loss: 0.4113 ||: 100%|#########9| 11222/11253 [20:00<00:02, 13.20it/s]
2022-03-20 22:17:16,803 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.1738, loss: 0.4112 ||: 100%|#########9| 11224/11253 [20:00<00:02, 12.86it/s]
2022-03-20 22:17:16,970 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.3549, loss: 0.4112 ||: 100%|#########9| 11226/11253 [20:00<00:02, 12.57it/s]
2022-03-20 22:17:17,102 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.5202, loss: 0.4112 ||: 100%|#########9| 11228/11253 [20:00<00:01, 13.25it/s]
2022-03-20 22:17:17,240 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.3444, loss: 0.4112 ||: 100%|#########9| 11230/11253 [20:00<00:01, 13.61it/s]
2022-03-20 22:17:17,360 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.6706, loss: 0.4113 ||: 100%|#########9| 11232/11253 [20:00<00:01, 14.41it/s]
2022-03-20 22:17:17,484 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.2827, loss: 0.4112 ||: 100%|#########9| 11234/11253 [20:00<00:01, 14.87it/s]
2022-03-20 22:17:18,649 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.2467, loss: 0.4112 ||: 100%|#########9| 11236/11253 [20:02<00:03,  4.51it/s]
2022-03-20 22:17:18,814 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.5624, loss: 0.4112 ||: 100%|#########9| 11238/11253 [20:02<00:02,  5.55it/s]
2022-03-20 22:17:18,971 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.3804, loss: 0.4112 ||: 100%|#########9| 11240/11253 [20:02<00:01,  6.68it/s]
2022-03-20 22:17:19,120 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.3610, loss: 0.4112 ||: 100%|#########9| 11242/11253 [20:02<00:01,  7.87it/s]
2022-03-20 22:17:19,265 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.2902, loss: 0.4112 ||: 100%|#########9| 11244/11253 [20:02<00:00,  9.04it/s]
2022-03-20 22:17:19,413 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.6371, loss: 0.4111 ||: 100%|#########9| 11246/11253 [20:02<00:00, 10.03it/s]
2022-03-20 22:17:19,556 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.8892, loss: 0.4112 ||: 100%|#########9| 11248/11253 [20:02<00:00, 10.97it/s]
2022-03-20 22:17:19,698 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.3537, loss: 0.4112 ||: 100%|#########9| 11250/11253 [20:03<00:00, 11.74it/s]
2022-03-20 22:17:19,837 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.3288, loss: 0.4112 ||: 100%|#########9| 11252/11253 [20:03<00:00, 12.43it/s]
2022-03-20 22:17:20,024 - INFO - tqdm - f1: 0.7884, accuracy: 0.8509, batch_loss: 0.3101, loss: 0.4112 ||: 100%|##########| 11253/11253 [20:03<00:00,  9.35it/s]
2022-03-20 22:17:20,032 - INFO - allennlp.training.trainer - Validating
2022-03-20 22:17:20,035 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-20 22:17:20,083 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-20 22:17:20,085 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-20 22:17:30,156 - INFO - tqdm - f1: 0.8006, accuracy: 0.8645, batch_loss: 0.4358, loss: 0.3766 ||:  14%|#4        | 273/1889 [00:10<00:43, 37.54it/s]
2022-03-20 22:17:40,185 - INFO - tqdm - f1: 0.8037, accuracy: 0.8647, batch_loss: 0.1372, loss: 0.3729 ||:  29%|##9       | 551/1889 [00:20<00:36, 37.10it/s]
2022-03-20 22:17:50,195 - INFO - tqdm - f1: 0.8063, accuracy: 0.8670, batch_loss: 0.6953, loss: 0.3689 ||:  44%|####3     | 824/1889 [00:30<00:27, 38.41it/s]
2022-03-20 22:18:00,341 - INFO - tqdm - f1: 0.8087, accuracy: 0.8678, batch_loss: 0.2518, loss: 0.3676 ||:  58%|#####8    | 1102/1889 [00:40<00:21, 36.23it/s]
2022-03-20 22:18:10,377 - INFO - tqdm - f1: 0.8097, accuracy: 0.8687, batch_loss: 0.0980, loss: 0.3660 ||:  73%|#######2  | 1378/1889 [00:50<00:13, 37.93it/s]
2022-03-20 22:18:20,384 - INFO - tqdm - f1: 0.8099, accuracy: 0.8685, batch_loss: 1.0114, loss: 0.3663 ||:  87%|########7 | 1648/1889 [01:00<00:06, 39.31it/s]
2022-03-20 22:18:28,628 - INFO - tqdm - f1: 0.8108, accuracy: 0.8700, batch_loss: 0.0893, loss: 0.3639 ||: 100%|#########9| 1881/1889 [01:08<00:00, 38.45it/s]
2022-03-20 22:18:28,743 - INFO - tqdm - f1: 0.8106, accuracy: 0.8698, batch_loss: 0.8793, loss: 0.3643 ||: 100%|#########9| 1886/1889 [01:08<00:00, 39.91it/s]
2022-03-20 22:18:28,815 - INFO - tqdm - f1: 0.8106, accuracy: 0.8698, batch_loss: 0.3361, loss: 0.3645 ||: 100%|##########| 1889/1889 [01:08<00:00, 27.47it/s]
2022-03-20 22:18:28,828 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct-20k_base_hyper_small_seed_13/best.th'.
2022-03-20 22:18:31,085 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 22:18:31,087 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.851  |     0.870
2022-03-20 22:18:31,088 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.788  |     0.811
2022-03-20 22:18:31,089 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 22:18:31,091 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.411  |     0.364
2022-03-20 22:18:31,092 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8469.074  |       N/A
2022-03-20 22:18:31,093 - INFO - allennlp.training.trainer - Epoch duration: 0:21:14.529668
2022-03-20 22:18:31,096 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:11:10
2022-03-20 22:18:31,097 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-20 22:18:31,098 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-20 22:18:31,100 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 22:18:31,103 - INFO - allennlp.training.trainer - Training
2022-03-20 22:18:31,105 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-20 22:18:41,213 - INFO - tqdm - f1: 0.8284, accuracy: 0.8865, batch_loss: 0.3999, loss: 0.3375 ||:   1%|          | 87/11253 [00:10<14:03, 13.23it/s]
2022-03-20 22:18:51,284 - INFO - tqdm - f1: 0.8290, accuracy: 0.8858, batch_loss: 0.2721, loss: 0.3221 ||:   2%|1         | 191/11253 [00:20<12:53, 14.30it/s]
2022-03-20 22:19:01,301 - INFO - tqdm - f1: 0.8193, accuracy: 0.8793, batch_loss: 0.2489, loss: 0.3360 ||:   3%|2         | 293/11253 [00:30<13:13, 13.80it/s]
2022-03-20 22:19:11,317 - INFO - tqdm - f1: 0.8186, accuracy: 0.8799, batch_loss: 0.3825, loss: 0.3312 ||:   3%|3         | 393/11253 [00:40<13:59, 12.94it/s]
2022-03-20 22:19:21,424 - INFO - tqdm - f1: 0.8180, accuracy: 0.8799, batch_loss: 0.7171, loss: 0.3278 ||:   4%|4         | 495/11253 [00:50<12:22, 14.50it/s]
2022-03-20 22:19:31,489 - INFO - tqdm - f1: 0.8181, accuracy: 0.8782, batch_loss: 0.1655, loss: 0.3307 ||:   5%|5         | 597/11253 [01:00<13:24, 13.25it/s]
2022-03-20 22:19:41,580 - INFO - tqdm - f1: 0.8196, accuracy: 0.8780, batch_loss: 0.2585, loss: 0.3342 ||:   6%|6         | 699/11253 [01:10<12:39, 13.89it/s]
2022-03-20 22:19:51,642 - INFO - tqdm - f1: 0.8199, accuracy: 0.8771, batch_loss: 0.1963, loss: 0.3364 ||:   7%|7         | 801/11253 [01:20<12:32, 13.90it/s]
2022-03-20 22:20:01,776 - INFO - tqdm - f1: 0.8205, accuracy: 0.8780, batch_loss: 0.3313, loss: 0.3340 ||:   8%|8         | 905/11253 [01:30<12:37, 13.66it/s]
2022-03-20 22:20:11,907 - INFO - tqdm - f1: 0.8213, accuracy: 0.8774, batch_loss: 0.4533, loss: 0.3357 ||:   9%|8         | 1009/11253 [01:40<12:26, 13.73it/s]
2022-03-20 22:20:22,000 - INFO - tqdm - f1: 0.8228, accuracy: 0.8787, batch_loss: 0.3910, loss: 0.3335 ||:  10%|9         | 1111/11253 [01:50<12:06, 13.96it/s]
2022-03-20 22:20:32,056 - INFO - tqdm - f1: 0.8205, accuracy: 0.8775, batch_loss: 0.3026, loss: 0.3367 ||:  11%|#         | 1211/11253 [02:00<12:19, 13.58it/s]
2022-03-20 22:20:42,111 - INFO - tqdm - f1: 0.8185, accuracy: 0.8761, batch_loss: 0.6432, loss: 0.3398 ||:  12%|#1        | 1311/11253 [02:11<12:34, 13.17it/s]
2022-03-20 22:20:52,242 - INFO - tqdm - f1: 0.8178, accuracy: 0.8752, batch_loss: 0.1869, loss: 0.3418 ||:  13%|#2        | 1411/11253 [02:21<14:28, 11.34it/s]
2022-03-20 22:21:02,261 - INFO - tqdm - f1: 0.8180, accuracy: 0.8755, batch_loss: 0.4033, loss: 0.3426 ||:  13%|#3        | 1511/11253 [02:31<13:44, 11.81it/s]
2022-03-20 22:21:12,379 - INFO - tqdm - f1: 0.8185, accuracy: 0.8754, batch_loss: 0.6743, loss: 0.3426 ||:  14%|#4        | 1613/11253 [02:41<12:32, 12.80it/s]
2022-03-20 22:21:22,484 - INFO - tqdm - f1: 0.8186, accuracy: 0.8751, batch_loss: 0.2652, loss: 0.3441 ||:  15%|#5        | 1715/11253 [02:51<12:39, 12.56it/s]
2022-03-20 22:21:32,591 - INFO - tqdm - f1: 0.8187, accuracy: 0.8751, batch_loss: 0.3979, loss: 0.3455 ||:  16%|#6        | 1817/11253 [03:01<11:58, 13.14it/s]
2022-03-20 22:21:42,636 - INFO - tqdm - f1: 0.8187, accuracy: 0.8757, batch_loss: 0.4502, loss: 0.3435 ||:  17%|#7        | 1919/11253 [03:11<11:06, 14.00it/s]
2022-03-20 22:21:52,645 - INFO - tqdm - f1: 0.8192, accuracy: 0.8760, batch_loss: 0.2030, loss: 0.3430 ||:  18%|#7        | 2017/11253 [03:21<13:03, 11.79it/s]
2022-03-20 22:22:02,683 - INFO - tqdm - f1: 0.8189, accuracy: 0.8756, batch_loss: 0.7699, loss: 0.3434 ||:  19%|#8        | 2119/11253 [03:31<11:27, 13.28it/s]
2022-03-20 22:22:12,700 - INFO - tqdm - f1: 0.8189, accuracy: 0.8759, batch_loss: 0.0601, loss: 0.3425 ||:  20%|#9        | 2219/11253 [03:41<12:24, 12.13it/s]
2022-03-20 22:22:22,803 - INFO - tqdm - f1: 0.8190, accuracy: 0.8759, batch_loss: 0.0917, loss: 0.3429 ||:  21%|##        | 2319/11253 [03:51<12:13, 12.19it/s]
2022-03-20 22:22:32,810 - INFO - tqdm - f1: 0.8188, accuracy: 0.8754, batch_loss: 0.2830, loss: 0.3437 ||:  21%|##1       | 2419/11253 [04:01<11:39, 12.62it/s]
2022-03-20 22:22:42,884 - INFO - tqdm - f1: 0.8191, accuracy: 0.8751, batch_loss: 0.2032, loss: 0.3440 ||:  22%|##2       | 2519/11253 [04:11<11:34, 12.58it/s]
2022-03-20 22:22:52,916 - INFO - tqdm - f1: 0.8196, accuracy: 0.8753, batch_loss: 0.1889, loss: 0.3440 ||:  23%|##3       | 2619/11253 [04:21<12:18, 11.70it/s]
2022-03-20 22:23:03,004 - INFO - tqdm - f1: 0.8191, accuracy: 0.8752, batch_loss: 0.2616, loss: 0.3443 ||:  24%|##4       | 2719/11253 [04:31<11:29, 12.37it/s]
2022-03-20 22:23:13,070 - INFO - tqdm - f1: 0.8193, accuracy: 0.8754, batch_loss: 0.3991, loss: 0.3446 ||:  25%|##5       | 2821/11253 [04:41<10:57, 12.82it/s]
2022-03-20 22:23:23,182 - INFO - tqdm - f1: 0.8196, accuracy: 0.8756, batch_loss: 0.2774, loss: 0.3443 ||:  26%|##5       | 2923/11253 [04:52<11:04, 12.54it/s]
2022-03-20 22:23:33,224 - INFO - tqdm - f1: 0.8199, accuracy: 0.8759, batch_loss: 0.1633, loss: 0.3446 ||:  27%|##6       | 3025/11253 [05:02<11:31, 11.90it/s]
2022-03-20 22:23:43,238 - INFO - tqdm - f1: 0.8198, accuracy: 0.8759, batch_loss: 0.1314, loss: 0.3442 ||:  28%|##7       | 3125/11253 [05:12<11:56, 11.35it/s]
2022-03-20 22:23:53,310 - INFO - tqdm - f1: 0.8208, accuracy: 0.8767, batch_loss: 0.7262, loss: 0.3429 ||:  29%|##8       | 3225/11253 [05:22<11:39, 11.48it/s]
2022-03-20 22:24:03,333 - INFO - tqdm - f1: 0.8202, accuracy: 0.8765, batch_loss: 0.1449, loss: 0.3426 ||:  30%|##9       | 3329/11253 [05:32<12:04, 10.93it/s]
2022-03-20 22:24:13,403 - INFO - tqdm - f1: 0.8195, accuracy: 0.8761, batch_loss: 0.2277, loss: 0.3434 ||:  31%|###       | 3433/11253 [05:42<13:21,  9.75it/s]
2022-03-20 22:24:23,520 - INFO - tqdm - f1: 0.8198, accuracy: 0.8761, batch_loss: 0.1595, loss: 0.3432 ||:  31%|###1      | 3537/11253 [05:52<15:17,  8.41it/s]
2022-03-20 22:24:33,548 - INFO - tqdm - f1: 0.8200, accuracy: 0.8762, batch_loss: 0.3007, loss: 0.3436 ||:  32%|###2      | 3639/11253 [06:02<15:09,  8.38it/s]
2022-03-20 22:24:43,648 - INFO - tqdm - f1: 0.8199, accuracy: 0.8761, batch_loss: 0.1820, loss: 0.3436 ||:  33%|###3      | 3743/11253 [06:12<14:50,  8.43it/s]
2022-03-20 22:24:53,686 - INFO - tqdm - f1: 0.8199, accuracy: 0.8762, batch_loss: 0.0834, loss: 0.3431 ||:  34%|###4      | 3843/11253 [06:22<22:18,  5.54it/s]
2022-03-20 22:25:03,783 - INFO - tqdm - f1: 0.8207, accuracy: 0.8766, batch_loss: 0.3797, loss: 0.3421 ||:  35%|###5      | 3945/11253 [06:32<22:02,  5.53it/s]
2022-03-20 22:25:13,798 - INFO - tqdm - f1: 0.8204, accuracy: 0.8766, batch_loss: 0.4000, loss: 0.3422 ||:  36%|###5      | 4047/11253 [06:42<21:22,  5.62it/s]
2022-03-20 22:25:23,894 - INFO - tqdm - f1: 0.8201, accuracy: 0.8764, batch_loss: 0.4171, loss: 0.3422 ||:  37%|###6      | 4149/11253 [06:52<21:27,  5.52it/s]
2022-03-20 22:25:34,016 - INFO - tqdm - f1: 0.8199, accuracy: 0.8762, batch_loss: 0.8723, loss: 0.3423 ||:  38%|###7      | 4253/11253 [07:02<25:12,  4.63it/s]
2022-03-20 22:25:44,125 - INFO - tqdm - f1: 0.8198, accuracy: 0.8761, batch_loss: 0.4867, loss: 0.3428 ||:  39%|###8      | 4355/11253 [07:13<26:04,  4.41it/s]
2022-03-20 22:25:54,226 - INFO - tqdm - f1: 0.8201, accuracy: 0.8763, batch_loss: 0.2512, loss: 0.3423 ||:  40%|###9      | 4457/11253 [07:23<19:46,  5.73it/s]
2022-03-20 22:26:04,322 - INFO - tqdm - f1: 0.8198, accuracy: 0.8763, batch_loss: 0.0314, loss: 0.3425 ||:  41%|####      | 4561/11253 [07:33<19:31,  5.71it/s]
2022-03-20 22:26:14,401 - INFO - tqdm - f1: 0.8199, accuracy: 0.8765, batch_loss: 0.2157, loss: 0.3417 ||:  41%|####1     | 4663/11253 [07:43<19:45,  5.56it/s]
2022-03-20 22:26:24,411 - INFO - tqdm - f1: 0.8200, accuracy: 0.8766, batch_loss: 0.3330, loss: 0.3419 ||:  42%|####2     | 4765/11253 [07:53<24:15,  4.46it/s]
2022-03-20 22:26:34,627 - INFO - tqdm - f1: 0.8200, accuracy: 0.8766, batch_loss: 0.2719, loss: 0.3418 ||:  43%|####3     | 4869/11253 [08:03<23:48,  4.47it/s]
2022-03-20 22:26:44,876 - INFO - tqdm - f1: 0.8198, accuracy: 0.8766, batch_loss: 0.4215, loss: 0.3416 ||:  44%|####4     | 4975/11253 [08:13<23:18,  4.49it/s]
2022-03-20 22:26:54,956 - INFO - tqdm - f1: 0.8196, accuracy: 0.8765, batch_loss: 0.1066, loss: 0.3420 ||:  45%|####5     | 5079/11253 [08:23<22:42,  4.53it/s]
2022-03-20 22:27:05,020 - INFO - tqdm - f1: 0.8191, accuracy: 0.8762, batch_loss: 0.4545, loss: 0.3422 ||:  46%|####6     | 5181/11253 [08:33<22:13,  4.55it/s]
2022-03-20 22:27:15,515 - INFO - tqdm - f1: 0.8192, accuracy: 0.8761, batch_loss: 0.1041, loss: 0.3425 ||:  47%|####6     | 5285/11253 [08:44<22:13,  4.48it/s]
2022-03-20 22:27:26,034 - INFO - tqdm - f1: 0.8191, accuracy: 0.8761, batch_loss: 0.3488, loss: 0.3425 ||:  48%|####7     | 5393/11253 [08:54<22:30,  4.34it/s]
2022-03-20 22:27:36,055 - INFO - tqdm - f1: 0.8190, accuracy: 0.8760, batch_loss: 0.1038, loss: 0.3425 ||:  49%|####8     | 5495/11253 [09:04<21:29,  4.47it/s]
2022-03-20 22:27:46,361 - INFO - tqdm - f1: 0.8189, accuracy: 0.8758, batch_loss: 0.1923, loss: 0.3429 ||:  50%|####9     | 5599/11253 [09:15<21:14,  4.43it/s]
2022-03-20 22:27:56,533 - INFO - tqdm - f1: 0.8187, accuracy: 0.8757, batch_loss: 0.2335, loss: 0.3428 ||:  51%|#####     | 5701/11253 [09:25<21:24,  4.32it/s]
2022-03-20 22:28:06,657 - INFO - tqdm - f1: 0.8189, accuracy: 0.8758, batch_loss: 0.3381, loss: 0.3427 ||:  52%|#####1    | 5803/11253 [09:35<20:09,  4.51it/s]
2022-03-20 22:28:16,726 - INFO - tqdm - f1: 0.8188, accuracy: 0.8757, batch_loss: 0.2775, loss: 0.3429 ||:  52%|#####2    | 5903/11253 [09:45<20:34,  4.34it/s]
2022-03-20 22:28:26,836 - INFO - tqdm - f1: 0.8187, accuracy: 0.8757, batch_loss: 0.4398, loss: 0.3432 ||:  53%|#####3    | 6005/11253 [09:55<19:19,  4.53it/s]
2022-03-20 22:28:36,902 - INFO - tqdm - f1: 0.8185, accuracy: 0.8755, batch_loss: 0.7085, loss: 0.3436 ||:  54%|#####4    | 6109/11253 [10:05<19:11,  4.47it/s]
2022-03-20 22:28:47,024 - INFO - tqdm - f1: 0.8186, accuracy: 0.8756, batch_loss: 0.1792, loss: 0.3437 ||:  55%|#####5    | 6211/11253 [10:15<15:14,  5.51it/s]
2022-03-20 22:28:57,091 - INFO - tqdm - f1: 0.8185, accuracy: 0.8756, batch_loss: 0.4176, loss: 0.3435 ||:  56%|#####6    | 6313/11253 [10:25<14:51,  5.54it/s]
2022-03-20 22:29:07,096 - INFO - tqdm - f1: 0.8183, accuracy: 0.8756, batch_loss: 0.7553, loss: 0.3437 ||:  57%|#####6    | 6413/11253 [10:35<14:23,  5.61it/s]
2022-03-20 22:29:17,316 - INFO - tqdm - f1: 0.8183, accuracy: 0.8757, batch_loss: 0.3518, loss: 0.3435 ||:  58%|#####7    | 6519/11253 [10:46<17:42,  4.45it/s]
2022-03-20 22:29:27,338 - INFO - tqdm - f1: 0.8184, accuracy: 0.8757, batch_loss: 0.2218, loss: 0.3433 ||:  59%|#####8    | 6619/11253 [10:56<17:36,  4.39it/s]
2022-03-20 22:29:37,523 - INFO - tqdm - f1: 0.8183, accuracy: 0.8756, batch_loss: 0.4342, loss: 0.3437 ||:  60%|#####9    | 6723/11253 [11:06<16:39,  4.53it/s]
2022-03-20 22:29:47,715 - INFO - tqdm - f1: 0.8184, accuracy: 0.8757, batch_loss: 0.0106, loss: 0.3432 ||:  61%|######    | 6825/11253 [11:16<17:10,  4.30it/s]
2022-03-20 22:29:57,764 - INFO - tqdm - f1: 0.8183, accuracy: 0.8758, batch_loss: 0.7031, loss: 0.3429 ||:  62%|######1   | 6927/11253 [11:26<16:08,  4.47it/s]
2022-03-20 22:30:08,108 - INFO - tqdm - f1: 0.8182, accuracy: 0.8758, batch_loss: 0.3351, loss: 0.3429 ||:  62%|######2   | 7033/11253 [11:37<15:36,  4.50it/s]
2022-03-20 22:30:18,141 - INFO - tqdm - f1: 0.8182, accuracy: 0.8760, batch_loss: 0.8169, loss: 0.3427 ||:  63%|######3   | 7135/11253 [11:47<15:35,  4.40it/s]
2022-03-20 22:30:28,371 - INFO - tqdm - f1: 0.8181, accuracy: 0.8759, batch_loss: 0.3808, loss: 0.3430 ||:  64%|######4   | 7239/11253 [11:57<14:58,  4.47it/s]
2022-03-20 22:30:38,789 - INFO - tqdm - f1: 0.8181, accuracy: 0.8758, batch_loss: 0.2849, loss: 0.3431 ||:  65%|######5   | 7347/11253 [12:07<14:42,  4.42it/s]
2022-03-20 22:30:48,797 - INFO - tqdm - f1: 0.8181, accuracy: 0.8758, batch_loss: 0.2417, loss: 0.3430 ||:  66%|######6   | 7449/11253 [12:17<13:51,  4.57it/s]
2022-03-20 22:30:58,899 - INFO - tqdm - f1: 0.8178, accuracy: 0.8758, batch_loss: 0.1968, loss: 0.3430 ||:  67%|######7   | 7553/11253 [12:27<14:02,  4.39it/s]
2022-03-20 22:31:09,097 - INFO - tqdm - f1: 0.8177, accuracy: 0.8758, batch_loss: 0.4960, loss: 0.3427 ||:  68%|######8   | 7657/11253 [12:37<13:35,  4.41it/s]
2022-03-20 22:31:19,187 - INFO - tqdm - f1: 0.8179, accuracy: 0.8760, batch_loss: 0.5909, loss: 0.3425 ||:  69%|######8   | 7757/11253 [12:48<10:31,  5.54it/s]
2022-03-20 22:31:29,357 - INFO - tqdm - f1: 0.8176, accuracy: 0.8757, batch_loss: 0.4588, loss: 0.3432 ||:  70%|######9   | 7859/11253 [12:58<13:06,  4.32it/s]
2022-03-20 22:31:39,568 - INFO - tqdm - f1: 0.8176, accuracy: 0.8758, batch_loss: 0.3300, loss: 0.3429 ||:  71%|#######   | 7963/11253 [13:08<12:28,  4.39it/s]
2022-03-20 22:31:49,969 - INFO - tqdm - f1: 0.8176, accuracy: 0.8757, batch_loss: 0.3132, loss: 0.3427 ||:  72%|#######1  | 8069/11253 [13:18<12:07,  4.37it/s]
2022-03-20 22:32:00,167 - INFO - tqdm - f1: 0.8174, accuracy: 0.8757, batch_loss: 0.8715, loss: 0.3428 ||:  73%|#######2  | 8173/11253 [13:29<11:42,  4.38it/s]
2022-03-20 22:32:10,297 - INFO - tqdm - f1: 0.8175, accuracy: 0.8757, batch_loss: 0.1344, loss: 0.3429 ||:  74%|#######3  | 8275/11253 [13:39<08:45,  5.67it/s]
2022-03-20 22:32:20,415 - INFO - tqdm - f1: 0.8175, accuracy: 0.8756, batch_loss: 0.0671, loss: 0.3433 ||:  74%|#######4  | 8377/11253 [13:49<08:36,  5.57it/s]
2022-03-20 22:32:30,516 - INFO - tqdm - f1: 0.8175, accuracy: 0.8757, batch_loss: 0.2981, loss: 0.3430 ||:  75%|#######5  | 8477/11253 [13:59<08:07,  5.70it/s]
2022-03-20 22:32:40,633 - INFO - tqdm - f1: 0.8176, accuracy: 0.8757, batch_loss: 0.2292, loss: 0.3428 ||:  76%|#######6  | 8577/11253 [14:09<08:15,  5.41it/s]
2022-03-20 22:32:50,670 - INFO - tqdm - f1: 0.8176, accuracy: 0.8757, batch_loss: 0.2213, loss: 0.3430 ||:  77%|#######7  | 8677/11253 [14:19<07:43,  5.55it/s]
2022-03-20 22:33:00,707 - INFO - tqdm - f1: 0.8174, accuracy: 0.8756, batch_loss: 0.2245, loss: 0.3431 ||:  78%|#######7  | 8777/11253 [14:29<07:20,  5.62it/s]
2022-03-20 22:33:10,874 - INFO - tqdm - f1: 0.8173, accuracy: 0.8756, batch_loss: 0.3159, loss: 0.3432 ||:  79%|#######8  | 8881/11253 [14:39<08:57,  4.42it/s]
2022-03-20 22:33:21,040 - INFO - tqdm - f1: 0.8172, accuracy: 0.8755, batch_loss: 0.1960, loss: 0.3431 ||:  80%|#######9  | 8985/11253 [14:49<08:33,  4.42it/s]
2022-03-20 22:33:31,175 - INFO - tqdm - f1: 0.8168, accuracy: 0.8752, batch_loss: 0.2839, loss: 0.3435 ||:  81%|########  | 9085/11253 [15:00<06:26,  5.60it/s]
2022-03-20 22:33:41,279 - INFO - tqdm - f1: 0.8166, accuracy: 0.8751, batch_loss: 0.3097, loss: 0.3436 ||:  82%|########1 | 9185/11253 [15:10<04:58,  6.94it/s]
2022-03-20 22:33:51,393 - INFO - tqdm - f1: 0.8167, accuracy: 0.8752, batch_loss: 0.2197, loss: 0.3435 ||:  83%|########2 | 9287/11253 [15:20<04:52,  6.72it/s]
2022-03-20 22:34:01,421 - INFO - tqdm - f1: 0.8166, accuracy: 0.8751, batch_loss: 0.1277, loss: 0.3435 ||:  83%|########3 | 9389/11253 [15:30<04:31,  6.87it/s]
2022-03-20 22:34:11,506 - INFO - tqdm - f1: 0.8165, accuracy: 0.8751, batch_loss: 0.3211, loss: 0.3437 ||:  84%|########4 | 9493/11253 [15:40<04:17,  6.84it/s]
2022-03-20 22:34:21,617 - INFO - tqdm - f1: 0.8166, accuracy: 0.8752, batch_loss: 0.3875, loss: 0.3436 ||:  85%|########5 | 9595/11253 [15:50<04:00,  6.89it/s]
2022-03-20 22:34:31,643 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.3228, loss: 0.3438 ||:  86%|########6 | 9697/11253 [16:00<02:43,  9.52it/s]
2022-03-20 22:34:41,766 - INFO - tqdm - f1: 0.8165, accuracy: 0.8750, batch_loss: 0.3804, loss: 0.3441 ||:  87%|########7 | 9797/11253 [16:10<02:24, 10.08it/s]
2022-03-20 22:34:51,793 - INFO - tqdm - f1: 0.8166, accuracy: 0.8751, batch_loss: 0.3529, loss: 0.3440 ||:  88%|########7 | 9895/11253 [16:20<02:49,  8.00it/s]
2022-03-20 22:35:01,819 - INFO - tqdm - f1: 0.8165, accuracy: 0.8751, batch_loss: 0.6653, loss: 0.3440 ||:  89%|########8 | 9993/11253 [16:30<02:15,  9.33it/s]
2022-03-20 22:35:11,942 - INFO - tqdm - f1: 0.8166, accuracy: 0.8751, batch_loss: 0.2279, loss: 0.3436 ||:  90%|########9 | 10095/11253 [16:40<02:22,  8.14it/s]
2022-03-20 22:35:21,966 - INFO - tqdm - f1: 0.8168, accuracy: 0.8752, batch_loss: 0.1910, loss: 0.3434 ||:  91%|######### | 10195/11253 [16:50<02:36,  6.78it/s]
2022-03-20 22:35:32,076 - INFO - tqdm - f1: 0.8169, accuracy: 0.8753, batch_loss: 0.6691, loss: 0.3431 ||:  92%|#########1| 10304/11253 [17:00<01:22, 11.45it/s]
2022-03-20 22:35:42,235 - INFO - tqdm - f1: 0.8169, accuracy: 0.8753, batch_loss: 0.3138, loss: 0.3432 ||:  92%|#########2| 10407/11253 [17:11<01:22, 10.25it/s]
2022-03-20 22:35:52,331 - INFO - tqdm - f1: 0.8168, accuracy: 0.8752, batch_loss: 0.1957, loss: 0.3433 ||:  93%|#########3| 10509/11253 [17:21<01:08, 10.82it/s]
2022-03-20 22:36:02,440 - INFO - tqdm - f1: 0.8168, accuracy: 0.8752, batch_loss: 0.3178, loss: 0.3434 ||:  94%|#########4| 10620/11253 [17:31<00:46, 13.70it/s]
2022-03-20 22:36:12,568 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.5840, loss: 0.3435 ||:  96%|#########5| 10752/11253 [17:41<00:34, 14.36it/s]
2022-03-20 22:36:22,718 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.4805, loss: 0.3438 ||:  97%|#########6| 10884/11253 [17:51<00:28, 13.05it/s]
2022-03-20 22:36:32,817 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.1551, loss: 0.3438 ||:  98%|#########7| 11018/11253 [18:01<00:19, 12.22it/s]
2022-03-20 22:36:42,987 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.7051, loss: 0.3439 ||:  99%|#########9| 11150/11253 [18:11<00:08, 12.16it/s]
2022-03-20 22:36:47,424 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.2181, loss: 0.3438 ||: 100%|#########9| 11197/11253 [18:16<00:05,  9.72it/s]
2022-03-20 22:36:47,574 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.3279, loss: 0.3438 ||: 100%|#########9| 11199/11253 [18:16<00:04, 10.83it/s]
2022-03-20 22:36:47,719 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.9520, loss: 0.3439 ||: 100%|#########9| 11201/11253 [18:16<00:04, 11.71it/s]
2022-03-20 22:36:47,947 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.2835, loss: 0.3439 ||: 100%|#########9| 11203/11253 [18:16<00:04, 10.54it/s]
2022-03-20 22:36:48,211 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.2499, loss: 0.3439 ||: 100%|#########9| 11205/11253 [18:17<00:05,  9.36it/s]
2022-03-20 22:36:48,317 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.7439, loss: 0.3439 ||: 100%|#########9| 11206/11253 [18:17<00:05,  9.38it/s]
2022-03-20 22:36:48,468 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.2564, loss: 0.3439 ||: 100%|#########9| 11208/11253 [18:17<00:04, 10.43it/s]
2022-03-20 22:36:48,665 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.0565, loss: 0.3439 ||: 100%|#########9| 11210/11253 [18:17<00:04, 10.33it/s]
2022-03-20 22:36:48,861 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.2510, loss: 0.3438 ||: 100%|#########9| 11212/11253 [18:17<00:03, 10.29it/s]
2022-03-20 22:36:49,047 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.5991, loss: 0.3439 ||: 100%|#########9| 11214/11253 [18:17<00:03, 10.44it/s]
2022-03-20 22:36:49,256 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.2873, loss: 0.3438 ||: 100%|#########9| 11216/11253 [18:18<00:03, 10.16it/s]
2022-03-20 22:36:49,440 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.4947, loss: 0.3439 ||: 100%|#########9| 11218/11253 [18:18<00:03, 10.36it/s]
2022-03-20 22:36:49,680 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.2454, loss: 0.3438 ||: 100%|#########9| 11220/11253 [18:18<00:03,  9.65it/s]
2022-03-20 22:36:49,799 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.2472, loss: 0.3438 ||: 100%|#########9| 11221/11253 [18:18<00:03,  9.39it/s]
2022-03-20 22:36:49,951 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.2238, loss: 0.3438 ||: 100%|#########9| 11222/11253 [18:18<00:03,  8.68it/s]
2022-03-20 22:36:50,050 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.2606, loss: 0.3438 ||: 100%|#########9| 11223/11253 [18:18<00:03,  8.93it/s]
2022-03-20 22:36:50,270 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.1642, loss: 0.3438 ||: 100%|#########9| 11225/11253 [18:19<00:03,  9.01it/s]
2022-03-20 22:36:50,390 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.1867, loss: 0.3438 ||: 100%|#########9| 11226/11253 [18:19<00:03,  8.81it/s]
2022-03-20 22:36:50,564 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.8230, loss: 0.3438 ||: 100%|#########9| 11228/11253 [18:19<00:02,  9.69it/s]
2022-03-20 22:36:50,668 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.4037, loss: 0.3438 ||: 100%|#########9| 11229/11253 [18:19<00:02,  9.68it/s]
2022-03-20 22:36:50,876 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.2089, loss: 0.3438 ||: 100%|#########9| 11231/11253 [18:19<00:02,  9.72it/s]
2022-03-20 22:36:51,061 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.5393, loss: 0.3438 ||: 100%|#########9| 11233/11253 [18:19<00:01, 10.01it/s]
2022-03-20 22:36:51,166 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.2700, loss: 0.3438 ||: 100%|#########9| 11234/11253 [18:20<00:01,  9.91it/s]
2022-03-20 22:36:51,341 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.4968, loss: 0.3438 ||: 100%|#########9| 11236/11253 [18:20<00:01, 10.50it/s]
2022-03-20 22:36:51,484 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.3435, loss: 0.3438 ||: 100%|#########9| 11238/11253 [18:20<00:01, 11.38it/s]
2022-03-20 22:36:51,664 - INFO - tqdm - f1: 0.8167, accuracy: 0.8750, batch_loss: 0.3826, loss: 0.3438 ||: 100%|#########9| 11240/11253 [18:20<00:01, 11.29it/s]
2022-03-20 22:36:51,869 - INFO - tqdm - f1: 0.8168, accuracy: 0.8750, batch_loss: 0.0944, loss: 0.3438 ||: 100%|#########9| 11242/11253 [18:20<00:01, 10.75it/s]
2022-03-20 22:36:52,061 - INFO - tqdm - f1: 0.8168, accuracy: 0.8750, batch_loss: 0.0510, loss: 0.3438 ||: 100%|#########9| 11244/11253 [18:20<00:00, 10.64it/s]
2022-03-20 22:36:52,296 - INFO - tqdm - f1: 0.8168, accuracy: 0.8750, batch_loss: 0.1980, loss: 0.3438 ||: 100%|#########9| 11246/11253 [18:21<00:00,  9.87it/s]
2022-03-20 22:36:52,475 - INFO - tqdm - f1: 0.8168, accuracy: 0.8750, batch_loss: 0.3703, loss: 0.3438 ||: 100%|#########9| 11248/11253 [18:21<00:00, 10.25it/s]
2022-03-20 22:36:52,694 - INFO - tqdm - f1: 0.8168, accuracy: 0.8750, batch_loss: 0.4383, loss: 0.3438 ||: 100%|#########9| 11250/11253 [18:21<00:00,  9.89it/s]
2022-03-20 22:36:52,952 - INFO - tqdm - f1: 0.8168, accuracy: 0.8750, batch_loss: 0.1998, loss: 0.3437 ||: 100%|#########9| 11252/11253 [18:21<00:00,  9.12it/s]
2022-03-20 22:36:53,073 - INFO - tqdm - f1: 0.8168, accuracy: 0.8750, batch_loss: 0.2121, loss: 0.3437 ||: 100%|##########| 11253/11253 [18:21<00:00,  8.96it/s]
2022-03-20 22:36:53,148 - INFO - tqdm - f1: 0.8168, accuracy: 0.8750, batch_loss: 0.2121, loss: 0.3437 ||: 100%|##########| 11253/11253 [18:22<00:00, 10.21it/s]
2022-03-20 22:36:53,160 - INFO - allennlp.training.trainer - Validating
2022-03-20 22:36:53,163 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-20 22:37:03,198 - INFO - tqdm - f1: 0.8147, accuracy: 0.8680, batch_loss: 0.2801, loss: 0.3809 ||:   9%|8         | 170/1889 [00:10<01:19, 21.59it/s]
2022-03-20 22:37:13,305 - INFO - tqdm - f1: 0.8210, accuracy: 0.8773, batch_loss: 0.3254, loss: 0.3598 ||:  25%|##4       | 466/1889 [00:20<00:46, 30.40it/s]
2022-03-20 22:37:23,368 - INFO - tqdm - f1: 0.8173, accuracy: 0.8748, batch_loss: 0.1008, loss: 0.3599 ||:  40%|####      | 761/1889 [00:30<00:32, 35.06it/s]
2022-03-20 22:37:33,388 - INFO - tqdm - f1: 0.8166, accuracy: 0.8741, batch_loss: 0.3001, loss: 0.3600 ||:  56%|#####5    | 1049/1889 [00:40<00:24, 34.97it/s]
2022-03-20 22:37:43,443 - INFO - tqdm - f1: 0.8167, accuracy: 0.8745, batch_loss: 0.6769, loss: 0.3589 ||:  71%|#######1  | 1345/1889 [00:50<00:15, 34.76it/s]
2022-03-20 22:37:53,477 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.3913, loss: 0.3579 ||:  82%|########1 | 1542/1889 [01:00<00:20, 17.26it/s]
2022-03-20 22:38:03,576 - INFO - tqdm - f1: 0.8164, accuracy: 0.8747, batch_loss: 0.3451, loss: 0.3574 ||:  90%|######### | 1709/1889 [01:10<00:10, 17.37it/s]
2022-03-20 22:38:10,622 - INFO - tqdm - f1: 0.8170, accuracy: 0.8747, batch_loss: 0.1665, loss: 0.3580 ||: 100%|#########9| 1883/1889 [01:17<00:00, 36.47it/s]
2022-03-20 22:38:10,881 - INFO - tqdm - f1: 0.8170, accuracy: 0.8748, batch_loss: 0.2731, loss: 0.3579 ||: 100%|#########9| 1887/1889 [01:17<00:00, 27.20it/s]
2022-03-20 22:38:10,971 - INFO - tqdm - f1: 0.8171, accuracy: 0.8748, batch_loss: 0.0662, loss: 0.3577 ||: 100%|##########| 1889/1889 [01:17<00:00, 24.28it/s]
2022-03-20 22:38:10,987 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct-20k_base_hyper_small_seed_13/best.th'.
2022-03-20 22:38:13,179 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 22:38:13,181 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.875  |     0.875
2022-03-20 22:38:13,182 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.817  |     0.817
2022-03-20 22:38:13,184 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 22:38:13,185 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.344  |     0.358
2022-03-20 22:38:13,186 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8644.543  |       N/A
2022-03-20 22:38:13,187 - INFO - allennlp.training.trainer - Epoch duration: 0:19:42.090530
2022-03-20 22:38:13,189 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:43:46
2022-03-20 22:38:13,190 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-20 22:38:13,192 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-20 22:38:13,194 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 22:38:13,197 - INFO - allennlp.training.trainer - Training
2022-03-20 22:38:13,199 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-20 22:38:23,275 - INFO - tqdm - f1: 0.8434, accuracy: 0.9038, batch_loss: 0.1435, loss: 0.2787 ||:   0%|          | 39/11253 [00:10<14:33, 12.83it/s]
2022-03-20 22:38:33,379 - INFO - tqdm - f1: 0.8180, accuracy: 0.8873, batch_loss: 0.5369, loss: 0.3121 ||:   2%|1         | 173/11253 [00:20<14:16, 12.93it/s]
2022-03-20 22:38:43,400 - INFO - tqdm - f1: 0.8235, accuracy: 0.8852, batch_loss: 0.0974, loss: 0.3162 ||:   3%|2         | 313/11253 [00:30<12:21, 14.75it/s]
2022-03-20 22:38:53,490 - INFO - tqdm - f1: 0.8277, accuracy: 0.8857, batch_loss: 0.1941, loss: 0.3179 ||:   4%|3         | 427/11253 [00:40<53:16,  3.39it/s]
2022-03-20 22:39:03,676 - INFO - tqdm - f1: 0.8310, accuracy: 0.8893, batch_loss: 0.1956, loss: 0.3094 ||:   5%|4         | 529/11253 [00:50<16:35, 10.77it/s]
2022-03-20 22:39:13,778 - INFO - tqdm - f1: 0.8331, accuracy: 0.8902, batch_loss: 0.2162, loss: 0.3077 ||:   6%|5         | 643/11253 [01:00<13:49, 12.79it/s]
2022-03-20 22:39:23,927 - INFO - tqdm - f1: 0.8342, accuracy: 0.8911, batch_loss: 0.2863, loss: 0.3048 ||:   7%|6         | 746/11253 [01:10<17:21, 10.08it/s]
2022-03-20 22:39:34,028 - INFO - tqdm - f1: 0.8352, accuracy: 0.8909, batch_loss: 0.5103, loss: 0.3066 ||:   7%|7         | 841/11253 [01:20<22:33,  7.70it/s]
2022-03-20 22:39:44,966 - INFO - tqdm - f1: 0.8355, accuracy: 0.8911, batch_loss: 0.2713, loss: 0.3056 ||:   8%|8         | 937/11253 [01:31<39:50,  4.31it/s]
2022-03-20 22:39:55,116 - INFO - tqdm - f1: 0.8366, accuracy: 0.8917, batch_loss: 0.3977, loss: 0.3049 ||:   9%|9         | 1045/11253 [01:41<12:18, 13.82it/s]
2022-03-20 22:40:05,174 - INFO - tqdm - f1: 0.8364, accuracy: 0.8919, batch_loss: 0.2511, loss: 0.3031 ||:  10%|#         | 1135/11253 [01:51<16:31, 10.20it/s]
2022-03-20 22:40:15,292 - INFO - tqdm - f1: 0.8366, accuracy: 0.8923, batch_loss: 0.3502, loss: 0.3010 ||:  11%|#         | 1233/11253 [02:02<15:46, 10.59it/s]
2022-03-20 22:40:25,361 - INFO - tqdm - f1: 0.8351, accuracy: 0.8911, batch_loss: 0.0503, loss: 0.3022 ||:  12%|#1        | 1335/11253 [02:12<15:52, 10.41it/s]
2022-03-20 22:40:35,466 - INFO - tqdm - f1: 0.8368, accuracy: 0.8918, batch_loss: 0.1535, loss: 0.3008 ||:  13%|#2        | 1437/11253 [02:22<15:08, 10.80it/s]
2022-03-20 22:40:45,502 - INFO - tqdm - f1: 0.8361, accuracy: 0.8913, batch_loss: 0.1784, loss: 0.3013 ||:  14%|#3        | 1537/11253 [02:32<15:34, 10.39it/s]
2022-03-20 22:40:55,624 - INFO - tqdm - f1: 0.8359, accuracy: 0.8916, batch_loss: 0.5504, loss: 0.3008 ||:  15%|#4        | 1637/11253 [02:42<13:52, 11.55it/s]
2022-03-20 22:41:05,740 - INFO - tqdm - f1: 0.8353, accuracy: 0.8906, batch_loss: 0.6145, loss: 0.3018 ||:  15%|#5        | 1739/11253 [02:52<13:34, 11.67it/s]
2022-03-20 22:41:15,755 - INFO - tqdm - f1: 0.8356, accuracy: 0.8911, batch_loss: 0.0067, loss: 0.3010 ||:  16%|#6        | 1839/11253 [03:02<15:12, 10.32it/s]
2022-03-20 22:41:25,757 - INFO - tqdm - f1: 0.8354, accuracy: 0.8910, batch_loss: 0.2899, loss: 0.3011 ||:  17%|#7        | 1937/11253 [03:12<16:48,  9.24it/s]
2022-03-20 22:41:35,866 - INFO - tqdm - f1: 0.8359, accuracy: 0.8913, batch_loss: 0.5782, loss: 0.3020 ||:  18%|#8        | 2037/11253 [03:22<19:21,  7.93it/s]
2022-03-20 22:41:45,964 - INFO - tqdm - f1: 0.8359, accuracy: 0.8909, batch_loss: 0.1001, loss: 0.3031 ||:  19%|#9        | 2139/11253 [03:32<16:00,  9.48it/s]
2022-03-20 22:41:56,102 - INFO - tqdm - f1: 0.8349, accuracy: 0.8901, batch_loss: 0.2805, loss: 0.3047 ||:  20%|#9        | 2243/11253 [03:42<16:17,  9.22it/s]
2022-03-20 22:42:06,264 - INFO - tqdm - f1: 0.8344, accuracy: 0.8901, batch_loss: 0.2708, loss: 0.3048 ||:  21%|##        | 2358/11253 [03:53<13:06, 11.32it/s]
2022-03-20 22:42:16,354 - INFO - tqdm - f1: 0.8351, accuracy: 0.8905, batch_loss: 0.6326, loss: 0.3038 ||:  22%|##1       | 2455/11253 [04:03<15:31,  9.45it/s]
2022-03-20 22:42:26,548 - INFO - tqdm - f1: 0.8358, accuracy: 0.8904, batch_loss: 0.2324, loss: 0.3047 ||:  23%|##2       | 2553/11253 [04:13<15:11,  9.55it/s]
2022-03-20 22:42:36,712 - INFO - tqdm - f1: 0.8352, accuracy: 0.8903, batch_loss: 0.1472, loss: 0.3044 ||:  23%|##3       | 2624/11253 [04:23<23:10,  6.20it/s]
2022-03-20 22:42:46,823 - INFO - tqdm - f1: 0.8354, accuracy: 0.8904, batch_loss: 0.1573, loss: 0.3040 ||:  24%|##3       | 2692/11253 [04:33<21:55,  6.51it/s]
2022-03-20 22:42:56,837 - INFO - tqdm - f1: 0.8351, accuracy: 0.8902, batch_loss: 0.4239, loss: 0.3045 ||:  25%|##4       | 2758/11253 [04:43<23:46,  5.96it/s]
2022-03-20 22:43:06,890 - INFO - tqdm - f1: 0.8358, accuracy: 0.8906, batch_loss: 0.1067, loss: 0.3038 ||:  25%|##5       | 2824/11253 [04:53<21:07,  6.65it/s]
2022-03-20 22:43:17,082 - INFO - tqdm - f1: 0.8352, accuracy: 0.8903, batch_loss: 0.7218, loss: 0.3039 ||:  26%|##5       | 2889/11253 [05:03<24:07,  5.78it/s]
2022-03-20 22:43:27,156 - INFO - tqdm - f1: 0.8352, accuracy: 0.8903, batch_loss: 0.2295, loss: 0.3037 ||:  26%|##6       | 2957/11253 [05:13<19:56,  6.93it/s]
2022-03-20 22:43:37,190 - INFO - tqdm - f1: 0.8344, accuracy: 0.8898, batch_loss: 0.6329, loss: 0.3045 ||:  27%|##6       | 3029/11253 [05:23<13:42, 10.00it/s]
2022-03-20 22:43:47,310 - INFO - tqdm - f1: 0.8352, accuracy: 0.8900, batch_loss: 0.4895, loss: 0.3040 ||:  28%|##7       | 3140/11253 [05:34<12:03, 11.21it/s]
2022-03-20 22:43:57,528 - INFO - tqdm - f1: 0.8360, accuracy: 0.8902, batch_loss: 0.5178, loss: 0.3042 ||:  29%|##8       | 3250/11253 [05:44<13:14, 10.08it/s]
2022-03-20 22:44:07,643 - INFO - tqdm - f1: 0.8363, accuracy: 0.8903, batch_loss: 0.0167, loss: 0.3038 ||:  29%|##9       | 3318/11253 [05:54<22:47,  5.80it/s]
2022-03-20 22:44:17,712 - INFO - tqdm - f1: 0.8360, accuracy: 0.8900, batch_loss: 0.4013, loss: 0.3044 ||:  30%|###       | 3383/11253 [06:04<19:03,  6.88it/s]
2022-03-20 22:44:27,779 - INFO - tqdm - f1: 0.8360, accuracy: 0.8900, batch_loss: 0.5033, loss: 0.3047 ||:  31%|###       | 3449/11253 [06:14<21:43,  5.99it/s]
2022-03-20 22:44:37,794 - INFO - tqdm - f1: 0.8359, accuracy: 0.8901, batch_loss: 0.3691, loss: 0.3048 ||:  31%|###1      | 3517/11253 [06:24<19:45,  6.52it/s]
2022-03-20 22:44:47,969 - INFO - tqdm - f1: 0.8359, accuracy: 0.8900, batch_loss: 0.2350, loss: 0.3053 ||:  32%|###1      | 3583/11253 [06:34<21:32,  5.94it/s]
2022-03-20 22:44:58,102 - INFO - tqdm - f1: 0.8360, accuracy: 0.8902, batch_loss: 0.5524, loss: 0.3049 ||:  32%|###2      | 3649/11253 [06:44<18:40,  6.78it/s]
2022-03-20 22:45:08,181 - INFO - tqdm - f1: 0.8359, accuracy: 0.8901, batch_loss: 0.3448, loss: 0.3051 ||:  33%|###3      | 3722/11253 [06:54<12:50,  9.77it/s]
2022-03-20 22:45:18,182 - INFO - tqdm - f1: 0.8362, accuracy: 0.8902, batch_loss: 0.1621, loss: 0.3051 ||:  34%|###4      | 3831/11253 [07:04<10:11, 12.13it/s]
2022-03-20 22:45:28,276 - INFO - tqdm - f1: 0.8361, accuracy: 0.8900, batch_loss: 0.4113, loss: 0.3057 ||:  35%|###4      | 3924/11253 [07:15<20:17,  6.02it/s]
2022-03-20 22:45:38,420 - INFO - tqdm - f1: 0.8362, accuracy: 0.8901, batch_loss: 0.4031, loss: 0.3056 ||:  35%|###5      | 3990/11253 [07:25<19:08,  6.32it/s]
2022-03-20 22:45:48,550 - INFO - tqdm - f1: 0.8363, accuracy: 0.8902, batch_loss: 0.4886, loss: 0.3052 ||:  36%|###6      | 4055/11253 [07:35<17:59,  6.67it/s]
2022-03-20 22:45:58,612 - INFO - tqdm - f1: 0.8362, accuracy: 0.8901, batch_loss: 0.2131, loss: 0.3053 ||:  37%|###6      | 4116/11253 [07:45<21:49,  5.45it/s]
2022-03-20 22:46:08,626 - INFO - tqdm - f1: 0.8361, accuracy: 0.8902, batch_loss: 0.2952, loss: 0.3054 ||:  37%|###7      | 4181/11253 [07:55<16:25,  7.17it/s]
2022-03-20 22:46:18,699 - INFO - tqdm - f1: 0.8357, accuracy: 0.8901, batch_loss: 0.1764, loss: 0.3053 ||:  38%|###7      | 4248/11253 [08:05<16:42,  6.99it/s]
2022-03-20 22:46:28,747 - INFO - tqdm - f1: 0.8357, accuracy: 0.8901, batch_loss: 0.2988, loss: 0.3053 ||:  38%|###8      | 4313/11253 [08:15<18:09,  6.37it/s]
2022-03-20 22:46:38,755 - INFO - tqdm - f1: 0.8361, accuracy: 0.8904, batch_loss: 0.3422, loss: 0.3046 ||:  39%|###9      | 4403/11253 [08:25<10:52, 10.49it/s]
2022-03-20 22:46:48,756 - INFO - tqdm - f1: 0.8364, accuracy: 0.8907, batch_loss: 0.6053, loss: 0.3038 ||:  40%|####      | 4513/11253 [08:35<09:33, 11.76it/s]
2022-03-20 22:46:59,143 - INFO - tqdm - f1: 0.8366, accuracy: 0.8909, batch_loss: 0.0278, loss: 0.3033 ||:  41%|####      | 4585/11253 [08:45<26:16,  4.23it/s]
2022-03-20 22:47:09,235 - INFO - tqdm - f1: 0.8364, accuracy: 0.8906, batch_loss: 0.2999, loss: 0.3042 ||:  42%|####1     | 4692/11253 [08:56<09:07, 11.98it/s]
2022-03-20 22:47:19,280 - INFO - tqdm - f1: 0.8366, accuracy: 0.8907, batch_loss: 0.3290, loss: 0.3041 ||:  43%|####2     | 4797/11253 [09:06<12:15,  8.78it/s]
2022-03-20 22:47:29,421 - INFO - tqdm - f1: 0.8364, accuracy: 0.8906, batch_loss: 0.3483, loss: 0.3042 ||:  44%|####3     | 4896/11253 [09:16<10:06, 10.49it/s]
2022-03-20 22:47:39,620 - INFO - tqdm - f1: 0.8363, accuracy: 0.8907, batch_loss: 0.1768, loss: 0.3043 ||:  44%|####4     | 4994/11253 [09:26<11:12,  9.31it/s]
2022-03-20 22:47:49,866 - INFO - tqdm - f1: 0.8360, accuracy: 0.8905, batch_loss: 0.2654, loss: 0.3047 ||:  45%|####5     | 5095/11253 [09:36<24:11,  4.24it/s]
2022-03-20 22:48:00,418 - INFO - tqdm - f1: 0.8358, accuracy: 0.8905, batch_loss: 0.1561, loss: 0.3048 ||:  46%|####6     | 5203/11253 [09:47<23:01,  4.38it/s]
2022-03-20 22:48:10,912 - INFO - tqdm - f1: 0.8359, accuracy: 0.8903, batch_loss: 0.5777, loss: 0.3052 ||:  47%|####7     | 5307/11253 [09:57<22:14,  4.45it/s]
2022-03-20 22:48:21,618 - INFO - tqdm - f1: 0.8358, accuracy: 0.8901, batch_loss: 0.4229, loss: 0.3060 ||:  48%|####8     | 5413/11253 [10:08<22:17,  4.37it/s]
2022-03-20 22:48:31,731 - INFO - tqdm - f1: 0.8361, accuracy: 0.8902, batch_loss: 0.4396, loss: 0.3058 ||:  49%|####9     | 5515/11253 [10:18<21:40,  4.41it/s]
2022-03-20 22:48:42,346 - INFO - tqdm - f1: 0.8359, accuracy: 0.8900, batch_loss: 0.1210, loss: 0.3058 ||:  50%|####9     | 5619/11253 [10:29<21:57,  4.28it/s]
2022-03-20 22:48:52,582 - INFO - tqdm - f1: 0.8359, accuracy: 0.8900, batch_loss: 0.2719, loss: 0.3059 ||:  51%|#####     | 5721/11253 [10:39<21:01,  4.39it/s]
2022-03-20 22:49:03,629 - INFO - tqdm - f1: 0.8363, accuracy: 0.8901, batch_loss: 0.3743, loss: 0.3058 ||:  52%|#####1    | 5833/11253 [10:50<21:04,  4.29it/s]
2022-03-20 22:49:14,139 - INFO - tqdm - f1: 0.8365, accuracy: 0.8901, batch_loss: 0.0413, loss: 0.3056 ||:  53%|#####2    | 5937/11253 [11:00<20:29,  4.33it/s]
2022-03-20 22:49:24,188 - INFO - tqdm - f1: 0.8366, accuracy: 0.8901, batch_loss: 0.2417, loss: 0.3059 ||:  54%|#####3    | 6039/11253 [11:10<15:15,  5.70it/s]
2022-03-20 22:49:34,233 - INFO - tqdm - f1: 0.8366, accuracy: 0.8900, batch_loss: 0.4002, loss: 0.3063 ||:  55%|#####4    | 6141/11253 [11:21<14:43,  5.79it/s]
2022-03-20 22:49:44,268 - INFO - tqdm - f1: 0.8364, accuracy: 0.8898, batch_loss: 0.3100, loss: 0.3066 ||:  55%|#####5    | 6241/11253 [11:31<15:01,  5.56it/s]
2022-03-20 22:49:54,394 - INFO - tqdm - f1: 0.8361, accuracy: 0.8898, batch_loss: 0.6318, loss: 0.3066 ||:  56%|#####6    | 6345/11253 [11:41<11:54,  6.87it/s]
2022-03-20 22:50:04,490 - INFO - tqdm - f1: 0.8359, accuracy: 0.8898, batch_loss: 0.6475, loss: 0.3064 ||:  57%|#####7    | 6447/11253 [11:51<09:40,  8.27it/s]
2022-03-20 22:50:14,604 - INFO - tqdm - f1: 0.8354, accuracy: 0.8894, batch_loss: 0.1396, loss: 0.3070 ||:  58%|#####8    | 6549/11253 [12:01<08:30,  9.21it/s]
2022-03-20 22:50:24,736 - INFO - tqdm - f1: 0.8350, accuracy: 0.8893, batch_loss: 0.4328, loss: 0.3068 ||:  59%|#####9    | 6651/11253 [12:11<07:27, 10.28it/s]
2022-03-20 22:50:34,752 - INFO - tqdm - f1: 0.8349, accuracy: 0.8894, batch_loss: 0.1914, loss: 0.3066 ||:  60%|#####9    | 6751/11253 [12:21<07:59,  9.39it/s]
2022-03-20 22:50:44,871 - INFO - tqdm - f1: 0.8351, accuracy: 0.8896, batch_loss: 0.2815, loss: 0.3061 ||:  61%|######    | 6851/11253 [12:31<07:02, 10.41it/s]
2022-03-20 22:50:54,884 - INFO - tqdm - f1: 0.8351, accuracy: 0.8896, batch_loss: 0.6905, loss: 0.3061 ||:  62%|######1   | 6951/11253 [12:41<07:43,  9.28it/s]
2022-03-20 22:51:04,953 - INFO - tqdm - f1: 0.8350, accuracy: 0.8897, batch_loss: 0.1359, loss: 0.3057 ||:  63%|######2   | 7051/11253 [12:51<07:24,  9.45it/s]
2022-03-20 22:51:14,954 - INFO - tqdm - f1: 0.8350, accuracy: 0.8897, batch_loss: 0.2685, loss: 0.3058 ||:  64%|######3   | 7153/11253 [13:01<08:13,  8.32it/s]
2022-03-20 22:51:25,082 - INFO - tqdm - f1: 0.8349, accuracy: 0.8896, batch_loss: 0.2504, loss: 0.3057 ||:  64%|######4   | 7255/11253 [13:11<09:41,  6.87it/s]
2022-03-20 22:51:35,106 - INFO - tqdm - f1: 0.8350, accuracy: 0.8897, batch_loss: 0.0716, loss: 0.3055 ||:  65%|######5   | 7357/11253 [13:21<11:41,  5.55it/s]
2022-03-20 22:51:45,217 - INFO - tqdm - f1: 0.8351, accuracy: 0.8898, batch_loss: 0.2265, loss: 0.3054 ||:  66%|######6   | 7461/11253 [13:32<09:04,  6.97it/s]
2022-03-20 22:51:55,218 - INFO - tqdm - f1: 0.8350, accuracy: 0.8897, batch_loss: 0.5285, loss: 0.3057 ||:  67%|######7   | 7563/11253 [13:42<13:31,  4.55it/s]
2022-03-20 22:52:05,355 - INFO - tqdm - f1: 0.8350, accuracy: 0.8897, batch_loss: 0.4785, loss: 0.3058 ||:  68%|######8   | 7665/11253 [13:52<13:19,  4.49it/s]
2022-03-20 22:52:15,633 - INFO - tqdm - f1: 0.8346, accuracy: 0.8895, batch_loss: 0.4651, loss: 0.3060 ||:  69%|######9   | 7769/11253 [14:02<10:43,  5.41it/s]
2022-03-20 22:52:25,675 - INFO - tqdm - f1: 0.8348, accuracy: 0.8895, batch_loss: 0.1580, loss: 0.3064 ||:  70%|######9   | 7871/11253 [14:12<10:07,  5.57it/s]
2022-03-20 22:52:35,847 - INFO - tqdm - f1: 0.8347, accuracy: 0.8894, batch_loss: 0.1713, loss: 0.3065 ||:  71%|#######   | 7973/11253 [14:22<12:14,  4.46it/s]
2022-03-20 22:52:46,014 - INFO - tqdm - f1: 0.8348, accuracy: 0.8896, batch_loss: 0.1592, loss: 0.3059 ||:  72%|#######1  | 8075/11253 [14:32<11:50,  4.47it/s]
2022-03-20 22:52:56,444 - INFO - tqdm - f1: 0.8349, accuracy: 0.8895, batch_loss: 1.2818, loss: 0.3061 ||:  73%|#######2  | 8179/11253 [14:43<11:38,  4.40it/s]
2022-03-20 22:53:06,508 - INFO - tqdm - f1: 0.8349, accuracy: 0.8894, batch_loss: 0.2171, loss: 0.3060 ||:  74%|#######3  | 8285/11253 [14:53<04:26, 11.12it/s]
2022-03-20 22:53:16,560 - INFO - tqdm - f1: 0.8344, accuracy: 0.8892, batch_loss: 0.2429, loss: 0.3062 ||:  75%|#######4  | 8388/11253 [15:03<05:26,  8.77it/s]
2022-03-20 22:53:26,618 - INFO - tqdm - f1: 0.8345, accuracy: 0.8892, batch_loss: 0.2968, loss: 0.3062 ||:  75%|#######5  | 8483/11253 [15:13<04:47,  9.64it/s]
2022-03-20 22:53:36,632 - INFO - tqdm - f1: 0.8344, accuracy: 0.8893, batch_loss: 0.4165, loss: 0.3061 ||:  76%|#######6  | 8563/11253 [15:23<05:57,  7.52it/s]
2022-03-20 22:53:46,657 - INFO - tqdm - f1: 0.8343, accuracy: 0.8893, batch_loss: 0.4570, loss: 0.3062 ||:  77%|#######6  | 8632/11253 [15:33<06:12,  7.04it/s]
2022-03-20 22:53:56,719 - INFO - tqdm - f1: 0.8343, accuracy: 0.8892, batch_loss: 0.2772, loss: 0.3061 ||:  77%|#######7  | 8700/11253 [15:43<06:03,  7.02it/s]
2022-03-20 22:54:06,816 - INFO - tqdm - f1: 0.8343, accuracy: 0.8892, batch_loss: 0.1070, loss: 0.3061 ||:  78%|#######7  | 8767/11253 [15:53<07:04,  5.85it/s]
2022-03-20 22:54:16,907 - INFO - tqdm - f1: 0.8341, accuracy: 0.8890, batch_loss: 0.0999, loss: 0.3063 ||:  79%|#######8  | 8834/11253 [16:03<06:31,  6.18it/s]
2022-03-20 22:54:26,920 - INFO - tqdm - f1: 0.8341, accuracy: 0.8889, batch_loss: 0.3753, loss: 0.3065 ||:  79%|#######9  | 8902/11253 [16:13<05:48,  6.74it/s]
2022-03-20 22:54:37,030 - INFO - tqdm - f1: 0.8341, accuracy: 0.8889, batch_loss: 0.2641, loss: 0.3066 ||:  80%|#######9  | 8969/11253 [16:23<04:53,  7.78it/s]
2022-03-20 22:54:47,043 - INFO - tqdm - f1: 0.8340, accuracy: 0.8889, batch_loss: 0.1992, loss: 0.3063 ||:  81%|########  | 9061/11253 [16:33<03:49,  9.57it/s]
2022-03-20 22:54:57,064 - INFO - tqdm - f1: 0.8340, accuracy: 0.8889, batch_loss: 0.4421, loss: 0.3064 ||:  81%|########1 | 9162/11253 [16:43<03:39,  9.53it/s]
2022-03-20 22:55:07,137 - INFO - tqdm - f1: 0.8341, accuracy: 0.8890, batch_loss: 0.1574, loss: 0.3063 ||:  82%|########2 | 9255/11253 [16:53<04:50,  6.87it/s]
2022-03-20 22:55:17,378 - INFO - tqdm - f1: 0.8340, accuracy: 0.8889, batch_loss: 0.2195, loss: 0.3063 ||:  83%|########2 | 9323/11253 [17:04<04:26,  7.24it/s]
2022-03-20 22:55:27,433 - INFO - tqdm - f1: 0.8342, accuracy: 0.8889, batch_loss: 0.0083, loss: 0.3063 ||:  83%|########3 | 9387/11253 [17:14<05:10,  6.02it/s]
2022-03-20 22:55:37,483 - INFO - tqdm - f1: 0.8341, accuracy: 0.8889, batch_loss: 0.6872, loss: 0.3061 ||:  84%|########4 | 9454/11253 [17:24<03:59,  7.50it/s]
2022-03-20 22:55:47,557 - INFO - tqdm - f1: 0.8342, accuracy: 0.8889, batch_loss: 0.0138, loss: 0.3062 ||:  85%|########4 | 9521/11253 [17:34<04:29,  6.43it/s]
2022-03-20 22:55:57,610 - INFO - tqdm - f1: 0.8342, accuracy: 0.8889, batch_loss: 0.1818, loss: 0.3062 ||:  85%|########5 | 9585/11253 [17:44<04:02,  6.87it/s]
2022-03-20 22:56:07,615 - INFO - tqdm - f1: 0.8340, accuracy: 0.8889, batch_loss: 0.2152, loss: 0.3063 ||:  86%|########5 | 9649/11253 [17:54<04:30,  5.93it/s]
2022-03-20 22:56:17,789 - INFO - tqdm - f1: 0.8339, accuracy: 0.8889, batch_loss: 0.6969, loss: 0.3061 ||:  87%|########6 | 9738/11253 [18:04<02:34,  9.82it/s]
2022-03-20 22:56:27,808 - INFO - tqdm - f1: 0.8341, accuracy: 0.8889, batch_loss: 0.2922, loss: 0.3061 ||:  87%|########7 | 9842/11253 [18:14<02:23,  9.81it/s]
2022-03-20 22:56:37,907 - INFO - tqdm - f1: 0.8342, accuracy: 0.8890, batch_loss: 0.6745, loss: 0.3062 ||:  88%|########8 | 9932/11253 [18:24<03:17,  6.69it/s]
2022-03-20 22:56:48,031 - INFO - tqdm - f1: 0.8341, accuracy: 0.8889, batch_loss: 0.1214, loss: 0.3064 ||:  89%|########8 | 10000/11253 [18:34<02:57,  7.05it/s]
2022-03-20 22:56:58,081 - INFO - tqdm - f1: 0.8344, accuracy: 0.8890, batch_loss: 0.2510, loss: 0.3063 ||:  89%|########9 | 10065/11253 [18:44<02:50,  6.98it/s]
2022-03-20 22:57:08,184 - INFO - tqdm - f1: 0.8344, accuracy: 0.8890, batch_loss: 0.2035, loss: 0.3063 ||:  90%|######### | 10133/11253 [18:54<02:33,  7.28it/s]
2022-03-20 22:57:18,315 - INFO - tqdm - f1: 0.8343, accuracy: 0.8890, batch_loss: 0.1097, loss: 0.3063 ||:  91%|######### | 10201/11253 [19:05<02:30,  6.98it/s]
2022-03-20 22:57:28,444 - INFO - tqdm - f1: 0.8343, accuracy: 0.8889, batch_loss: 0.4695, loss: 0.3064 ||:  91%|#########1| 10267/11253 [19:15<02:30,  6.53it/s]
2022-03-20 22:57:38,546 - INFO - tqdm - f1: 0.8342, accuracy: 0.8888, batch_loss: 0.2791, loss: 0.3066 ||:  92%|#########1| 10333/11253 [19:25<02:46,  5.54it/s]
2022-03-20 22:57:48,650 - INFO - tqdm - f1: 0.8339, accuracy: 0.8886, batch_loss: 0.3861, loss: 0.3070 ||:  93%|#########2| 10427/11253 [19:35<01:12, 11.40it/s]
2022-03-20 22:57:58,759 - INFO - tqdm - f1: 0.8339, accuracy: 0.8887, batch_loss: 1.0100, loss: 0.3069 ||:  94%|#########3| 10530/11253 [19:45<01:10, 10.20it/s]
2022-03-20 22:58:08,816 - INFO - tqdm - f1: 0.8339, accuracy: 0.8887, batch_loss: 0.1777, loss: 0.3070 ||:  94%|#########4| 10590/11253 [19:55<02:51,  3.87it/s]
2022-03-20 22:58:18,888 - INFO - tqdm - f1: 0.8339, accuracy: 0.8887, batch_loss: 0.4099, loss: 0.3071 ||:  95%|#########5| 10702/11253 [20:05<00:48, 11.36it/s]
2022-03-20 22:58:29,016 - INFO - tqdm - f1: 0.8337, accuracy: 0.8886, batch_loss: 0.0701, loss: 0.3075 ||:  96%|#########5| 10797/11253 [20:15<01:04,  7.07it/s]
2022-03-20 22:58:39,022 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.1365, loss: 0.3073 ||:  97%|#########6| 10875/11253 [20:25<00:54,  6.98it/s]
2022-03-20 22:58:49,202 - INFO - tqdm - f1: 0.8339, accuracy: 0.8887, batch_loss: 0.1497, loss: 0.3073 ||:  97%|#########7| 10961/11253 [20:36<00:32,  8.91it/s]
2022-03-20 22:58:59,209 - INFO - tqdm - f1: 0.8340, accuracy: 0.8887, batch_loss: 0.4817, loss: 0.3075 ||:  98%|#########8| 11062/11253 [20:46<00:14, 13.28it/s]
2022-03-20 22:59:09,278 - INFO - tqdm - f1: 0.8340, accuracy: 0.8888, batch_loss: 0.3850, loss: 0.3072 ||:  99%|#########9| 11162/11253 [20:56<00:06, 14.62it/s]
2022-03-20 22:59:13,128 - INFO - tqdm - f1: 0.8339, accuracy: 0.8887, batch_loss: 0.3453, loss: 0.3073 ||: 100%|#########9| 11198/11253 [20:59<00:04, 13.21it/s]
2022-03-20 22:59:13,279 - INFO - tqdm - f1: 0.8339, accuracy: 0.8887, batch_loss: 0.1226, loss: 0.3073 ||: 100%|#########9| 11200/11253 [21:00<00:04, 13.23it/s]
2022-03-20 22:59:14,474 - INFO - tqdm - f1: 0.8339, accuracy: 0.8887, batch_loss: 0.5155, loss: 0.3073 ||: 100%|#########9| 11202/11253 [21:01<00:11,  4.31it/s]
2022-03-20 22:59:14,632 - INFO - tqdm - f1: 0.8339, accuracy: 0.8887, batch_loss: 0.2635, loss: 0.3073 ||: 100%|#########9| 11204/11253 [21:01<00:09,  5.37it/s]
2022-03-20 22:59:14,784 - INFO - tqdm - f1: 0.8339, accuracy: 0.8887, batch_loss: 0.5174, loss: 0.3073 ||: 100%|#########9| 11206/11253 [21:01<00:07,  6.53it/s]
2022-03-20 22:59:14,951 - INFO - tqdm - f1: 0.8339, accuracy: 0.8887, batch_loss: 0.7032, loss: 0.3074 ||: 100%|#########9| 11208/11253 [21:01<00:05,  7.56it/s]
2022-03-20 22:59:15,093 - INFO - tqdm - f1: 0.8339, accuracy: 0.8886, batch_loss: 0.4377, loss: 0.3074 ||: 100%|#########9| 11210/11253 [21:01<00:04,  8.78it/s]
2022-03-20 22:59:15,235 - INFO - tqdm - f1: 0.8338, accuracy: 0.8886, batch_loss: 0.3957, loss: 0.3074 ||: 100%|#########9| 11212/11253 [21:02<00:04,  9.90it/s]
2022-03-20 22:59:15,374 - INFO - tqdm - f1: 0.8339, accuracy: 0.8887, batch_loss: 0.1542, loss: 0.3074 ||: 100%|#########9| 11214/11253 [21:02<00:03, 10.92it/s]
2022-03-20 22:59:15,515 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.1913, loss: 0.3074 ||: 100%|#########9| 11216/11253 [21:02<00:03, 11.74it/s]
2022-03-20 22:59:15,660 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.0452, loss: 0.3074 ||: 100%|#########9| 11218/11253 [21:02<00:02, 12.28it/s]
2022-03-20 22:59:15,797 - INFO - tqdm - f1: 0.8338, accuracy: 0.8886, batch_loss: 0.3535, loss: 0.3074 ||: 100%|#########9| 11220/11253 [21:02<00:02, 12.88it/s]
2022-03-20 22:59:15,950 - INFO - tqdm - f1: 0.8338, accuracy: 0.8886, batch_loss: 0.6091, loss: 0.3074 ||: 100%|#########9| 11222/11253 [21:02<00:02, 12.96it/s]
2022-03-20 22:59:16,101 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.0989, loss: 0.3074 ||: 100%|#########9| 11224/11253 [21:02<00:02, 13.03it/s]
2022-03-20 22:59:16,243 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.2935, loss: 0.3073 ||: 100%|#########9| 11226/11253 [21:03<00:02, 13.33it/s]
2022-03-20 22:59:16,381 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.0994, loss: 0.3073 ||: 100%|#########9| 11228/11253 [21:03<00:01, 13.66it/s]
2022-03-20 22:59:16,536 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.3473, loss: 0.3073 ||: 100%|#########9| 11230/11253 [21:03<00:01, 13.42it/s]
2022-03-20 22:59:16,676 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.2283, loss: 0.3073 ||: 100%|#########9| 11232/11253 [21:03<00:01, 13.68it/s]
2022-03-20 22:59:16,803 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.4925, loss: 0.3073 ||: 100%|#########9| 11234/11253 [21:03<00:01, 14.23it/s]
2022-03-20 22:59:17,968 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.1953, loss: 0.3073 ||: 100%|#########9| 11236/11253 [21:04<00:03,  4.47it/s]
2022-03-20 22:59:18,123 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.0429, loss: 0.3072 ||: 100%|#########9| 11238/11253 [21:04<00:02,  5.56it/s]
2022-03-20 22:59:18,281 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.1704, loss: 0.3072 ||: 100%|#########9| 11240/11253 [21:05<00:01,  6.68it/s]
2022-03-20 22:59:18,427 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.0502, loss: 0.3072 ||: 100%|#########9| 11242/11253 [21:05<00:01,  7.89it/s]
2022-03-20 22:59:18,570 - INFO - tqdm - f1: 0.8339, accuracy: 0.8887, batch_loss: 0.1780, loss: 0.3072 ||: 100%|#########9| 11244/11253 [21:05<00:00,  9.08it/s]
2022-03-20 22:59:18,709 - INFO - tqdm - f1: 0.8339, accuracy: 0.8887, batch_loss: 0.5112, loss: 0.3072 ||: 100%|#########9| 11246/11253 [21:05<00:00, 10.21it/s]
2022-03-20 22:59:18,850 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.5672, loss: 0.3072 ||: 100%|#########9| 11248/11253 [21:05<00:00, 11.16it/s]
2022-03-20 22:59:18,996 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.7443, loss: 0.3072 ||: 100%|#########9| 11250/11253 [21:05<00:00, 11.81it/s]
2022-03-20 22:59:19,137 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.2545, loss: 0.3072 ||: 100%|#########9| 11252/11253 [21:05<00:00, 12.43it/s]
2022-03-20 22:59:19,281 - INFO - tqdm - f1: 0.8338, accuracy: 0.8887, batch_loss: 0.1074, loss: 0.3072 ||: 100%|##########| 11253/11253 [21:06<00:00,  8.89it/s]
2022-03-20 22:59:19,289 - INFO - allennlp.training.trainer - Validating
2022-03-20 22:59:19,291 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-20 22:59:29,387 - INFO - tqdm - f1: 0.8161, accuracy: 0.8668, batch_loss: 0.5514, loss: 0.3917 ||:  15%|#4        | 275/1889 [00:10<00:43, 36.97it/s]
2022-03-20 22:59:39,459 - INFO - tqdm - f1: 0.8153, accuracy: 0.8678, batch_loss: 0.9009, loss: 0.3972 ||:  29%|##8       | 547/1889 [00:20<00:35, 37.78it/s]
2022-03-20 22:59:49,521 - INFO - tqdm - f1: 0.8173, accuracy: 0.8695, batch_loss: 0.0979, loss: 0.3942 ||:  41%|####1     | 775/1889 [00:30<00:59, 18.88it/s]
2022-03-20 22:59:59,578 - INFO - tqdm - f1: 0.8160, accuracy: 0.8686, batch_loss: 0.9493, loss: 0.3973 ||:  52%|#####2    | 991/1889 [00:40<00:54, 16.51it/s]
2022-03-20 23:00:09,599 - INFO - tqdm - f1: 0.8150, accuracy: 0.8675, batch_loss: 0.1116, loss: 0.3999 ||:  61%|######    | 1151/1889 [00:50<00:43, 17.10it/s]
2022-03-20 23:00:19,770 - INFO - tqdm - f1: 0.8149, accuracy: 0.8681, batch_loss: 0.7325, loss: 0.3960 ||:  69%|######8   | 1299/1889 [01:00<01:00,  9.78it/s]
2022-03-20 23:00:29,892 - INFO - tqdm - f1: 0.8149, accuracy: 0.8688, batch_loss: 0.0194, loss: 0.3937 ||:  73%|#######3  | 1388/1889 [01:10<01:01,  8.20it/s]
2022-03-20 23:00:39,993 - INFO - tqdm - f1: 0.8158, accuracy: 0.8697, batch_loss: 0.1262, loss: 0.3902 ||:  78%|#######8  | 1474/1889 [01:20<00:52,  7.92it/s]
2022-03-20 23:00:50,128 - INFO - tqdm - f1: 0.8155, accuracy: 0.8695, batch_loss: 0.1440, loss: 0.3901 ||:  83%|########2 | 1561/1889 [01:30<00:36,  9.09it/s]
2022-03-20 23:01:00,142 - INFO - tqdm - f1: 0.8160, accuracy: 0.8697, batch_loss: 0.7611, loss: 0.3903 ||:  87%|########7 | 1648/1889 [01:40<00:30,  7.84it/s]
2022-03-20 23:01:10,152 - INFO - tqdm - f1: 0.8161, accuracy: 0.8701, batch_loss: 0.5229, loss: 0.3882 ||:  92%|#########1| 1734/1889 [01:50<00:19,  7.96it/s]
2022-03-20 23:01:20,223 - INFO - tqdm - f1: 0.8154, accuracy: 0.8702, batch_loss: 0.5898, loss: 0.3882 ||:  96%|#########6| 1820/1889 [02:00<00:08,  7.74it/s]
2022-03-20 23:01:26,494 - INFO - tqdm - f1: 0.8157, accuracy: 0.8706, batch_loss: 0.3134, loss: 0.3865 ||: 100%|#########9| 1881/1889 [02:07<00:00, 11.42it/s]
2022-03-20 23:01:26,710 - INFO - tqdm - f1: 0.8158, accuracy: 0.8707, batch_loss: 0.1150, loss: 0.3864 ||: 100%|#########9| 1883/1889 [02:07<00:00, 10.65it/s]
2022-03-20 23:01:26,866 - INFO - tqdm - f1: 0.8159, accuracy: 0.8708, batch_loss: 0.1804, loss: 0.3861 ||: 100%|#########9| 1885/1889 [02:07<00:00, 11.24it/s]
2022-03-20 23:01:27,064 - INFO - tqdm - f1: 0.8160, accuracy: 0.8708, batch_loss: 0.5645, loss: 0.3861 ||: 100%|#########9| 1887/1889 [02:07<00:00, 10.86it/s]
2022-03-20 23:01:27,168 - INFO - tqdm - f1: 0.8159, accuracy: 0.8707, batch_loss: 0.5213, loss: 0.3862 ||: 100%|##########| 1889/1889 [02:07<00:00, 14.77it/s]
2022-03-20 23:01:27,191 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 23:01:27,193 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.889  |     0.871
2022-03-20 23:01:27,195 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.834  |     0.816
2022-03-20 23:01:27,197 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 23:01:27,199 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.307  |     0.386
2022-03-20 23:01:27,202 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8644.559  |       N/A
2022-03-20 23:01:27,204 - INFO - allennlp.training.trainer - Epoch duration: 0:23:14.013735
2022-03-20 23:01:27,206 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:29:44
2022-03-20 23:01:27,209 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-20 23:01:27,211 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-20 23:01:27,214 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 23:01:27,217 - INFO - allennlp.training.trainer - Training
2022-03-20 23:01:27,220 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-20 23:01:37,276 - INFO - tqdm - f1: 0.8423, accuracy: 0.8893, batch_loss: 0.0752, loss: 0.2903 ||:   1%|          | 92/11253 [00:10<16:24, 11.34it/s]
2022-03-20 23:01:47,390 - INFO - tqdm - f1: 0.8461, accuracy: 0.8964, batch_loss: 0.0570, loss: 0.2743 ||:   2%|1         | 196/11253 [00:20<18:13, 10.11it/s]
2022-03-20 23:01:57,390 - INFO - tqdm - f1: 0.8483, accuracy: 0.9011, batch_loss: 0.1146, loss: 0.2621 ||:   2%|2         | 273/11253 [00:30<28:33,  6.41it/s]
2022-03-20 23:02:07,449 - INFO - tqdm - f1: 0.8464, accuracy: 0.8989, batch_loss: 0.3244, loss: 0.2715 ||:   3%|2         | 337/11253 [00:40<30:07,  6.04it/s]
2022-03-20 23:02:17,456 - INFO - tqdm - f1: 0.8451, accuracy: 0.8981, batch_loss: 0.4647, loss: 0.2754 ||:   4%|3         | 403/11253 [00:50<26:59,  6.70it/s]
2022-03-20 23:02:27,585 - INFO - tqdm - f1: 0.8442, accuracy: 0.8984, batch_loss: 0.2273, loss: 0.2730 ||:   4%|4         | 470/11253 [01:00<28:26,  6.32it/s]
2022-03-20 23:02:37,597 - INFO - tqdm - f1: 0.8446, accuracy: 0.8985, batch_loss: 0.2047, loss: 0.2756 ||:   5%|4         | 533/11253 [01:10<30:16,  5.90it/s]
2022-03-20 23:02:47,705 - INFO - tqdm - f1: 0.8459, accuracy: 0.8991, batch_loss: 0.1086, loss: 0.2743 ||:   5%|5         | 598/11253 [01:20<30:33,  5.81it/s]
2022-03-20 23:02:57,843 - INFO - tqdm - f1: 0.8464, accuracy: 0.8998, batch_loss: 0.0784, loss: 0.2758 ||:   6%|5         | 664/11253 [01:30<29:34,  5.97it/s]
2022-03-20 23:03:07,878 - INFO - tqdm - f1: 0.8486, accuracy: 0.9004, batch_loss: 0.5242, loss: 0.2752 ||:   7%|6         | 761/11253 [01:40<16:35, 10.53it/s]
2022-03-20 23:03:18,048 - INFO - tqdm - f1: 0.8493, accuracy: 0.9012, batch_loss: 0.4118, loss: 0.2745 ||:   8%|7         | 868/11253 [01:50<16:35, 10.43it/s]
2022-03-20 23:03:28,142 - INFO - tqdm - f1: 0.8497, accuracy: 0.9011, batch_loss: 0.1980, loss: 0.2752 ||:   8%|8         | 935/11253 [02:00<24:05,  7.14it/s]
2022-03-20 23:03:38,326 - INFO - tqdm - f1: 0.8491, accuracy: 0.9014, batch_loss: 0.2015, loss: 0.2750 ||:   9%|8         | 1003/11253 [02:11<27:45,  6.16it/s]
2022-03-20 23:03:48,437 - INFO - tqdm - f1: 0.8490, accuracy: 0.9017, batch_loss: 0.6034, loss: 0.2739 ||:   9%|9         | 1069/11253 [02:21<26:37,  6.38it/s]
2022-03-20 23:03:58,473 - INFO - tqdm - f1: 0.8481, accuracy: 0.9010, batch_loss: 0.1044, loss: 0.2752 ||:  10%|#         | 1137/11253 [02:31<23:08,  7.29it/s]
2022-03-20 23:04:08,555 - INFO - tqdm - f1: 0.8478, accuracy: 0.9009, batch_loss: 0.7891, loss: 0.2763 ||:  11%|#         | 1201/11253 [02:41<29:30,  5.68it/s]
2022-03-20 23:04:18,632 - INFO - tqdm - f1: 0.8499, accuracy: 0.9022, batch_loss: 0.0540, loss: 0.2731 ||:  11%|#1        | 1267/11253 [02:51<25:49,  6.44it/s]
2022-03-20 23:04:28,747 - INFO - tqdm - f1: 0.8492, accuracy: 0.9020, batch_loss: 0.4265, loss: 0.2727 ||:  12%|#1        | 1342/11253 [03:01<16:03, 10.28it/s]
2022-03-20 23:04:38,870 - INFO - tqdm - f1: 0.8486, accuracy: 0.9016, batch_loss: 0.3135, loss: 0.2723 ||:  13%|#2        | 1444/11253 [03:11<16:24,  9.97it/s]
2022-03-20 23:04:48,882 - INFO - tqdm - f1: 0.8488, accuracy: 0.9018, batch_loss: 0.2797, loss: 0.2715 ||:  14%|#3        | 1541/11253 [03:21<25:30,  6.34it/s]
2022-03-20 23:04:58,977 - INFO - tqdm - f1: 0.8484, accuracy: 0.9018, batch_loss: 0.0088, loss: 0.2713 ||:  14%|#4        | 1601/11253 [03:31<19:37,  8.20it/s]
2022-03-20 23:05:09,008 - INFO - tqdm - f1: 0.8491, accuracy: 0.9023, batch_loss: 0.1294, loss: 0.2705 ||:  15%|#5        | 1714/11253 [03:41<16:46,  9.48it/s]
2022-03-20 23:05:19,010 - INFO - tqdm - f1: 0.8495, accuracy: 0.9025, batch_loss: 0.4193, loss: 0.2712 ||:  16%|#6        | 1822/11253 [03:51<14:51, 10.58it/s]
2022-03-20 23:05:29,106 - INFO - tqdm - f1: 0.8495, accuracy: 0.9025, batch_loss: 0.2720, loss: 0.2701 ||:  17%|#7        | 1921/11253 [04:01<17:31,  8.88it/s]
2022-03-20 23:05:39,469 - INFO - tqdm - f1: 0.8494, accuracy: 0.9022, batch_loss: 0.2323, loss: 0.2707 ||:  18%|#7        | 2021/11253 [04:12<19:11,  8.02it/s]
2022-03-20 23:05:49,557 - INFO - tqdm - f1: 0.8495, accuracy: 0.9025, batch_loss: 0.2313, loss: 0.2698 ||:  19%|#8        | 2108/11253 [04:22<27:15,  5.59it/s]
2022-03-20 23:05:59,587 - INFO - tqdm - f1: 0.8483, accuracy: 0.9018, batch_loss: 0.1230, loss: 0.2708 ||:  20%|#9        | 2208/11253 [04:32<26:18,  5.73it/s]
2022-03-20 23:06:10,166 - INFO - tqdm - f1: 0.8487, accuracy: 0.9018, batch_loss: 0.2876, loss: 0.2704 ||:  21%|##        | 2310/11253 [04:42<33:32,  4.44it/s]
2022-03-20 23:06:20,332 - INFO - tqdm - f1: 0.8489, accuracy: 0.9018, batch_loss: 0.1043, loss: 0.2699 ||:  21%|##1       | 2410/11253 [04:53<33:38,  4.38it/s]
2022-03-20 23:06:30,348 - INFO - tqdm - f1: 0.8493, accuracy: 0.9021, batch_loss: 0.0472, loss: 0.2689 ||:  22%|##2       | 2510/11253 [05:03<32:37,  4.47it/s]
2022-03-20 23:06:40,698 - INFO - tqdm - f1: 0.8494, accuracy: 0.9023, batch_loss: 0.1961, loss: 0.2684 ||:  23%|##3       | 2614/11253 [05:13<32:14,  4.47it/s]
2022-03-20 23:06:50,811 - INFO - tqdm - f1: 0.8496, accuracy: 0.9022, batch_loss: 0.0785, loss: 0.2683 ||:  24%|##4       | 2716/11253 [05:23<20:59,  6.78it/s]
2022-03-20 23:07:00,903 - INFO - tqdm - f1: 0.8498, accuracy: 0.9023, batch_loss: 0.1361, loss: 0.2680 ||:  25%|##5       | 2816/11253 [05:33<20:37,  6.82it/s]
2022-03-20 23:07:11,028 - INFO - tqdm - f1: 0.8506, accuracy: 0.9028, batch_loss: 0.2296, loss: 0.2674 ||:  26%|##5       | 2916/11253 [05:43<25:02,  5.55it/s]
2022-03-20 23:07:21,132 - INFO - tqdm - f1: 0.8513, accuracy: 0.9029, batch_loss: 0.0677, loss: 0.2675 ||:  27%|##6       | 3018/11253 [05:53<31:37,  4.34it/s]
2022-03-20 23:07:31,254 - INFO - tqdm - f1: 0.8516, accuracy: 0.9028, batch_loss: 0.4554, loss: 0.2687 ||:  28%|##7       | 3123/11253 [06:04<11:43, 11.56it/s]
2022-03-20 23:07:41,327 - INFO - tqdm - f1: 0.8524, accuracy: 0.9033, batch_loss: 0.5206, loss: 0.2680 ||:  29%|##8       | 3227/11253 [06:14<14:51,  9.00it/s]
2022-03-20 23:07:51,362 - INFO - tqdm - f1: 0.8520, accuracy: 0.9031, batch_loss: 0.1685, loss: 0.2683 ||:  29%|##9       | 3317/11253 [06:24<13:47,  9.59it/s]
2022-03-20 23:08:01,489 - INFO - tqdm - f1: 0.8518, accuracy: 0.9029, batch_loss: 0.2009, loss: 0.2688 ||:  30%|###       | 3392/11253 [06:34<18:59,  6.90it/s]
2022-03-20 23:08:11,642 - INFO - tqdm - f1: 0.8515, accuracy: 0.9027, batch_loss: 0.2084, loss: 0.2693 ||:  31%|###       | 3462/11253 [06:44<19:10,  6.77it/s]
2022-03-20 23:08:21,776 - INFO - tqdm - f1: 0.8512, accuracy: 0.9025, batch_loss: 0.1290, loss: 0.2698 ||:  31%|###1      | 3532/11253 [06:54<18:08,  7.09it/s]
2022-03-20 23:08:31,820 - INFO - tqdm - f1: 0.8513, accuracy: 0.9023, batch_loss: 0.1437, loss: 0.2703 ||:  32%|###1      | 3599/11253 [07:04<17:50,  7.15it/s]
2022-03-20 23:08:41,887 - INFO - tqdm - f1: 0.8516, accuracy: 0.9025, batch_loss: 0.3438, loss: 0.2699 ||:  33%|###2      | 3664/11253 [07:14<19:07,  6.61it/s]
2022-03-20 23:08:51,901 - INFO - tqdm - f1: 0.8517, accuracy: 0.9026, batch_loss: 0.3729, loss: 0.2699 ||:  33%|###3      | 3729/11253 [07:24<21:42,  5.78it/s]
2022-03-20 23:09:01,981 - INFO - tqdm - f1: 0.8515, accuracy: 0.9024, batch_loss: 0.1307, loss: 0.2700 ||:  34%|###3      | 3792/11253 [07:34<19:19,  6.44it/s]
2022-03-20 23:09:12,006 - INFO - tqdm - f1: 0.8515, accuracy: 0.9023, batch_loss: 0.3260, loss: 0.2702 ||:  34%|###4      | 3874/11253 [07:44<11:43, 10.49it/s]
2022-03-20 23:09:22,216 - INFO - tqdm - f1: 0.8516, accuracy: 0.9024, batch_loss: 0.1328, loss: 0.2700 ||:  35%|###5      | 3976/11253 [07:54<12:02, 10.07it/s]
2022-03-20 23:09:32,236 - INFO - tqdm - f1: 0.8507, accuracy: 0.9021, batch_loss: 0.2608, loss: 0.2702 ||:  36%|###6      | 4070/11253 [08:05<18:02,  6.64it/s]
2022-03-20 23:09:42,343 - INFO - tqdm - f1: 0.8504, accuracy: 0.9019, batch_loss: 0.7344, loss: 0.2711 ||:  37%|###6      | 4138/11253 [08:15<20:19,  5.84it/s]
2022-03-20 23:09:52,466 - INFO - tqdm - f1: 0.8509, accuracy: 0.9019, batch_loss: 0.0954, loss: 0.2714 ||:  37%|###7      | 4203/11253 [08:25<17:29,  6.72it/s]
2022-03-20 23:10:02,578 - INFO - tqdm - f1: 0.8506, accuracy: 0.9018, batch_loss: 0.2238, loss: 0.2716 ||:  38%|###7      | 4266/11253 [08:35<18:26,  6.31it/s]
2022-03-20 23:10:12,611 - INFO - tqdm - f1: 0.8508, accuracy: 0.9019, batch_loss: 0.2591, loss: 0.2714 ||:  38%|###8      | 4330/11253 [08:45<18:47,  6.14it/s]
2022-03-20 23:10:22,710 - INFO - tqdm - f1: 0.8508, accuracy: 0.9019, batch_loss: 0.1562, loss: 0.2714 ||:  39%|###9      | 4394/11253 [08:55<17:47,  6.42it/s]
2022-03-20 23:10:32,787 - INFO - tqdm - f1: 0.8509, accuracy: 0.9019, batch_loss: 0.1412, loss: 0.2715 ||:  40%|###9      | 4458/11253 [09:05<19:14,  5.89it/s]
2022-03-20 23:10:42,829 - INFO - tqdm - f1: 0.8507, accuracy: 0.9017, batch_loss: 0.0655, loss: 0.2713 ||:  40%|####      | 4535/11253 [09:15<11:30,  9.72it/s]
2022-03-20 23:10:52,849 - INFO - tqdm - f1: 0.8503, accuracy: 0.9016, batch_loss: 0.0123, loss: 0.2713 ||:  41%|####1     | 4635/11253 [09:25<11:30,  9.59it/s]
2022-03-20 23:11:02,884 - INFO - tqdm - f1: 0.8501, accuracy: 0.9014, batch_loss: 0.4106, loss: 0.2717 ||:  42%|####1     | 4721/11253 [09:35<16:46,  6.49it/s]
2022-03-20 23:11:12,997 - INFO - tqdm - f1: 0.8498, accuracy: 0.9012, batch_loss: 0.3212, loss: 0.2720 ||:  43%|####2     | 4788/11253 [09:45<15:54,  6.77it/s]
2022-03-20 23:11:23,018 - INFO - tqdm - f1: 0.8499, accuracy: 0.9013, batch_loss: 0.1572, loss: 0.2716 ||:  43%|####3     | 4853/11253 [09:55<15:51,  6.73it/s]
2022-03-20 23:11:33,113 - INFO - tqdm - f1: 0.8501, accuracy: 0.9012, batch_loss: 0.1863, loss: 0.2716 ||:  44%|####3     | 4918/11253 [10:05<15:17,  6.91it/s]
2022-03-20 23:11:43,232 - INFO - tqdm - f1: 0.8500, accuracy: 0.9012, batch_loss: 0.3282, loss: 0.2717 ||:  44%|####4     | 4984/11253 [10:16<15:33,  6.71it/s]
2022-03-20 23:11:53,247 - INFO - tqdm - f1: 0.8498, accuracy: 0.9011, batch_loss: 0.1252, loss: 0.2722 ||:  45%|####4     | 5049/11253 [10:26<16:02,  6.44it/s]
2022-03-20 23:12:03,253 - INFO - tqdm - f1: 0.8500, accuracy: 0.9011, batch_loss: 0.3996, loss: 0.2721 ||:  45%|####5     | 5112/11253 [10:36<18:32,  5.52it/s]
2022-03-20 23:12:13,462 - INFO - tqdm - f1: 0.8502, accuracy: 0.9013, batch_loss: 0.1643, loss: 0.2715 ||:  46%|####6     | 5203/11253 [10:46<10:18,  9.78it/s]
2022-03-20 23:12:23,482 - INFO - tqdm - f1: 0.8504, accuracy: 0.9014, batch_loss: 0.2205, loss: 0.2711 ||:  47%|####7     | 5306/11253 [10:56<09:51, 10.05it/s]
2022-03-20 23:12:33,605 - INFO - tqdm - f1: 0.8502, accuracy: 0.9013, batch_loss: 0.1847, loss: 0.2713 ||:  48%|####7     | 5368/11253 [11:06<12:20,  7.94it/s]
2022-03-20 23:12:43,659 - INFO - tqdm - f1: 0.8500, accuracy: 0.9012, batch_loss: 0.2700, loss: 0.2713 ||:  49%|####8     | 5482/11253 [11:16<08:46, 10.95it/s]
2022-03-20 23:12:53,733 - INFO - tqdm - f1: 0.8502, accuracy: 0.9013, batch_loss: 0.1537, loss: 0.2716 ||:  50%|####9     | 5582/11253 [11:26<11:45,  8.03it/s]
2022-03-20 23:13:03,850 - INFO - tqdm - f1: 0.8501, accuracy: 0.9013, batch_loss: 0.8116, loss: 0.2717 ||:  51%|#####     | 5683/11253 [11:36<08:50, 10.50it/s]
2022-03-20 23:13:13,969 - INFO - tqdm - f1: 0.8500, accuracy: 0.9011, batch_loss: 0.2290, loss: 0.2721 ||:  51%|#####1    | 5777/11253 [11:46<10:45,  8.49it/s]
2022-03-20 23:13:24,028 - INFO - tqdm - f1: 0.8495, accuracy: 0.9011, batch_loss: 0.1148, loss: 0.2722 ||:  52%|#####2    | 5880/11253 [11:56<06:36, 13.56it/s]
2022-03-20 23:13:34,111 - INFO - tqdm - f1: 0.8491, accuracy: 0.9008, batch_loss: 0.1704, loss: 0.2726 ||:  53%|#####3    | 5976/11253 [12:06<06:19, 13.92it/s]
2022-03-20 23:13:44,253 - INFO - tqdm - f1: 0.8488, accuracy: 0.9007, batch_loss: 0.2569, loss: 0.2729 ||:  54%|#####3    | 6076/11253 [12:17<06:38, 12.98it/s]
2022-03-20 23:13:54,280 - INFO - tqdm - f1: 0.8487, accuracy: 0.9005, batch_loss: 0.1088, loss: 0.2729 ||:  55%|#####4    | 6176/11253 [12:27<06:08, 13.78it/s]
2022-03-20 23:14:04,427 - INFO - tqdm - f1: 0.8487, accuracy: 0.9005, batch_loss: 0.1274, loss: 0.2728 ||:  56%|#####5    | 6278/11253 [12:37<06:16, 13.20it/s]
2022-03-20 23:14:14,468 - INFO - tqdm - f1: 0.8487, accuracy: 0.9007, batch_loss: 0.2861, loss: 0.2725 ||:  57%|#####6    | 6378/11253 [12:47<06:09, 13.18it/s]
2022-03-20 23:14:24,601 - INFO - tqdm - f1: 0.8487, accuracy: 0.9007, batch_loss: 0.2439, loss: 0.2727 ||:  58%|#####7    | 6480/11253 [12:57<05:52, 13.54it/s]
2022-03-20 23:14:34,648 - INFO - tqdm - f1: 0.8491, accuracy: 0.9010, batch_loss: 0.5147, loss: 0.2723 ||:  58%|#####8    | 6582/11253 [13:07<05:31, 14.08it/s]
2022-03-20 23:14:44,659 - INFO - tqdm - f1: 0.8489, accuracy: 0.9009, batch_loss: 0.4461, loss: 0.2724 ||:  59%|#####9    | 6680/11253 [13:17<05:43, 13.33it/s]
2022-03-20 23:14:54,777 - INFO - tqdm - f1: 0.8487, accuracy: 0.9008, batch_loss: 0.2587, loss: 0.2728 ||:  60%|######    | 6782/11253 [13:27<05:46, 12.89it/s]
2022-03-20 23:15:04,859 - INFO - tqdm - f1: 0.8485, accuracy: 0.9006, batch_loss: 0.6673, loss: 0.2731 ||:  61%|######1   | 6884/11253 [13:37<05:22, 13.55it/s]
2022-03-20 23:15:14,886 - INFO - tqdm - f1: 0.8482, accuracy: 0.9003, batch_loss: 0.4781, loss: 0.2739 ||:  62%|######2   | 6984/11253 [13:47<06:10, 11.51it/s]
2022-03-20 23:15:24,992 - INFO - tqdm - f1: 0.8481, accuracy: 0.9002, batch_loss: 0.0655, loss: 0.2741 ||:  63%|######2   | 7084/11253 [13:57<05:22, 12.92it/s]
2022-03-20 23:15:35,076 - INFO - tqdm - f1: 0.8481, accuracy: 0.9002, batch_loss: 0.1083, loss: 0.2739 ||:  64%|######3   | 7186/11253 [14:07<05:35, 12.13it/s]
2022-03-20 23:15:45,132 - INFO - tqdm - f1: 0.8480, accuracy: 0.9002, batch_loss: 0.2718, loss: 0.2739 ||:  65%|######4   | 7286/11253 [14:17<06:14, 10.59it/s]
2022-03-20 23:15:55,203 - INFO - tqdm - f1: 0.8481, accuracy: 0.9002, batch_loss: 0.6495, loss: 0.2738 ||:  66%|######5   | 7386/11253 [14:27<07:50,  8.22it/s]
2022-03-20 23:16:05,301 - INFO - tqdm - f1: 0.8479, accuracy: 0.9002, batch_loss: 0.0231, loss: 0.2739 ||:  67%|######6   | 7486/11253 [14:38<14:20,  4.38it/s]
2022-03-20 23:16:15,403 - INFO - tqdm - f1: 0.8476, accuracy: 0.9000, batch_loss: 0.2288, loss: 0.2741 ||:  67%|######7   | 7586/11253 [14:48<10:57,  5.58it/s]
2022-03-20 23:16:25,475 - INFO - tqdm - f1: 0.8476, accuracy: 0.9000, batch_loss: 0.3374, loss: 0.2745 ||:  68%|######8   | 7688/11253 [14:58<13:31,  4.39it/s]
2022-03-20 23:16:35,757 - INFO - tqdm - f1: 0.8478, accuracy: 0.9002, batch_loss: 0.2377, loss: 0.2743 ||:  69%|######9   | 7792/11253 [15:08<12:51,  4.49it/s]
2022-03-20 23:16:46,025 - INFO - tqdm - f1: 0.8475, accuracy: 0.9000, batch_loss: 0.5196, loss: 0.2747 ||:  70%|#######   | 7896/11253 [15:18<12:47,  4.37it/s]
2022-03-20 23:16:56,120 - INFO - tqdm - f1: 0.8474, accuracy: 0.9000, batch_loss: 0.3897, loss: 0.2746 ||:  71%|#######1  | 7996/11253 [15:28<12:22,  4.38it/s]
2022-03-20 23:17:06,645 - INFO - tqdm - f1: 0.8472, accuracy: 0.8999, batch_loss: 0.2479, loss: 0.2744 ||:  72%|#######2  | 8104/11253 [15:39<11:43,  4.47it/s]
2022-03-20 23:17:16,937 - INFO - tqdm - f1: 0.8475, accuracy: 0.9000, batch_loss: 0.1801, loss: 0.2742 ||:  73%|#######2  | 8208/11253 [15:49<11:37,  4.37it/s]
2022-03-20 23:17:27,374 - INFO - tqdm - f1: 0.8475, accuracy: 0.9000, batch_loss: 0.2312, loss: 0.2743 ||:  74%|#######3  | 8314/11253 [16:00<10:58,  4.46it/s]
2022-03-20 23:17:37,613 - INFO - tqdm - f1: 0.8477, accuracy: 0.9000, batch_loss: 0.2241, loss: 0.2740 ||:  75%|#######4  | 8416/11253 [16:10<10:43,  4.41it/s]
2022-03-20 23:17:47,996 - INFO - tqdm - f1: 0.8478, accuracy: 0.9001, batch_loss: 0.0980, loss: 0.2740 ||:  76%|#######5  | 8520/11253 [16:20<10:12,  4.46it/s]
2022-03-20 23:17:58,044 - INFO - tqdm - f1: 0.8478, accuracy: 0.9001, batch_loss: 0.1688, loss: 0.2741 ||:  77%|#######6  | 8620/11253 [16:30<10:02,  4.37it/s]
2022-03-20 23:18:08,306 - INFO - tqdm - f1: 0.8479, accuracy: 0.9001, batch_loss: 0.2303, loss: 0.2743 ||:  78%|#######7  | 8724/11253 [16:41<09:28,  4.45it/s]
2022-03-20 23:18:18,378 - INFO - tqdm - f1: 0.8479, accuracy: 0.9002, batch_loss: 0.2723, loss: 0.2742 ||:  78%|#######8  | 8824/11253 [16:51<09:14,  4.38it/s]
2022-03-20 23:18:28,388 - INFO - tqdm - f1: 0.8482, accuracy: 0.9003, batch_loss: 0.5033, loss: 0.2739 ||:  79%|#######9  | 8924/11253 [17:01<08:58,  4.33it/s]
2022-03-20 23:18:38,517 - INFO - tqdm - f1: 0.8482, accuracy: 0.9002, batch_loss: 0.1195, loss: 0.2739 ||:  80%|########  | 9026/11253 [17:11<08:34,  4.33it/s]
2022-03-20 23:18:48,539 - INFO - tqdm - f1: 0.8482, accuracy: 0.9002, batch_loss: 0.4172, loss: 0.2739 ||:  81%|########1 | 9126/11253 [17:21<08:02,  4.41it/s]
2022-03-20 23:18:58,700 - INFO - tqdm - f1: 0.8483, accuracy: 0.9003, batch_loss: 0.4652, loss: 0.2736 ||:  82%|########2 | 9228/11253 [17:31<07:31,  4.48it/s]
2022-03-20 23:19:08,925 - INFO - tqdm - f1: 0.8482, accuracy: 0.9003, batch_loss: 0.0780, loss: 0.2738 ||:  83%|########2 | 9328/11253 [17:41<07:21,  4.36it/s]
2022-03-20 23:19:19,005 - INFO - tqdm - f1: 0.8483, accuracy: 0.9002, batch_loss: 0.2691, loss: 0.2740 ||:  84%|########3 | 9438/11253 [17:51<02:37, 11.50it/s]
2022-03-20 23:19:29,088 - INFO - tqdm - f1: 0.8483, accuracy: 0.9003, batch_loss: 0.2256, loss: 0.2741 ||:  85%|########4 | 9551/11253 [18:01<02:35, 10.93it/s]
2022-03-20 23:19:39,300 - INFO - tqdm - f1: 0.8481, accuracy: 0.9002, batch_loss: 0.1205, loss: 0.2743 ||:  86%|########5 | 9646/11253 [18:12<02:37, 10.18it/s]
2022-03-20 23:19:49,386 - INFO - tqdm - f1: 0.8480, accuracy: 0.9001, batch_loss: 0.1156, loss: 0.2744 ||:  87%|########6 | 9736/11253 [18:22<03:16,  7.73it/s]
2022-03-20 23:19:59,398 - INFO - tqdm - f1: 0.8479, accuracy: 0.9001, batch_loss: 0.3293, loss: 0.2745 ||:  87%|########7 | 9803/11253 [18:32<03:19,  7.26it/s]
2022-03-20 23:20:09,497 - INFO - tqdm - f1: 0.8480, accuracy: 0.9001, batch_loss: 0.4680, loss: 0.2745 ||:  88%|########7 | 9867/11253 [18:42<03:21,  6.89it/s]
2022-03-20 23:20:19,612 - INFO - tqdm - f1: 0.8479, accuracy: 0.9001, batch_loss: 0.2101, loss: 0.2744 ||:  88%|########8 | 9932/11253 [18:52<03:30,  6.28it/s]
2022-03-20 23:20:29,798 - INFO - tqdm - f1: 0.8480, accuracy: 0.9000, batch_loss: 0.5218, loss: 0.2745 ||:  89%|########8 | 9998/11253 [19:02<03:28,  6.02it/s]
2022-03-20 23:20:39,918 - INFO - tqdm - f1: 0.8478, accuracy: 0.9000, batch_loss: 0.2221, loss: 0.2746 ||:  89%|########9 | 10062/11253 [19:12<03:14,  6.13it/s]
2022-03-20 23:20:50,101 - INFO - tqdm - f1: 0.8477, accuracy: 0.9000, batch_loss: 0.1340, loss: 0.2745 ||:  90%|########9 | 10126/11253 [19:22<03:09,  5.94it/s]
2022-03-20 23:21:00,119 - INFO - tqdm - f1: 0.8478, accuracy: 0.9001, batch_loss: 0.1420, loss: 0.2743 ||:  91%|######### | 10200/11253 [19:32<01:56,  9.05it/s]
2022-03-20 23:21:10,153 - INFO - tqdm - f1: 0.8478, accuracy: 0.9000, batch_loss: 0.3970, loss: 0.2745 ||:  92%|#########1| 10306/11253 [19:42<01:25, 11.01it/s]
2022-03-20 23:21:20,161 - INFO - tqdm - f1: 0.8476, accuracy: 0.8999, batch_loss: 0.1292, loss: 0.2744 ||:  93%|#########2| 10411/11253 [19:52<01:21, 10.36it/s]
2022-03-20 23:21:30,244 - INFO - tqdm - f1: 0.8477, accuracy: 0.8999, batch_loss: 0.7769, loss: 0.2744 ||:  93%|#########3| 10477/11253 [20:03<01:56,  6.67it/s]
2022-03-20 23:21:40,345 - INFO - tqdm - f1: 0.8476, accuracy: 0.8998, batch_loss: 0.4344, loss: 0.2746 ||:  94%|#########3| 10543/11253 [20:13<01:42,  6.95it/s]
2022-03-20 23:21:50,368 - INFO - tqdm - f1: 0.8475, accuracy: 0.8997, batch_loss: 0.2849, loss: 0.2748 ||:  94%|#########4| 10608/11253 [20:23<01:55,  5.58it/s]
2022-03-20 23:22:00,371 - INFO - tqdm - f1: 0.8475, accuracy: 0.8997, batch_loss: 0.0420, loss: 0.2750 ||:  95%|#########4| 10671/11253 [20:33<01:30,  6.42it/s]
2022-03-20 23:22:10,468 - INFO - tqdm - f1: 0.8475, accuracy: 0.8997, batch_loss: 0.0854, loss: 0.2749 ||:  95%|#########5| 10738/11253 [20:43<01:18,  6.56it/s]
2022-03-20 23:22:20,580 - INFO - tqdm - f1: 0.8475, accuracy: 0.8997, batch_loss: 0.2159, loss: 0.2751 ||:  96%|#########5| 10802/11253 [20:53<01:08,  6.59it/s]
2022-03-20 23:22:30,716 - INFO - tqdm - f1: 0.8475, accuracy: 0.8996, batch_loss: 0.0726, loss: 0.2751 ||:  97%|#########6| 10878/11253 [21:03<00:39,  9.52it/s]
2022-03-20 23:22:40,936 - INFO - tqdm - f1: 0.8473, accuracy: 0.8995, batch_loss: 0.6502, loss: 0.2755 ||:  98%|#########7| 10980/11253 [21:13<00:27,  9.96it/s]
2022-03-20 23:22:50,937 - INFO - tqdm - f1: 0.8472, accuracy: 0.8995, batch_loss: 0.5257, loss: 0.2755 ||:  98%|#########8| 11069/11253 [21:23<00:28,  6.55it/s]
2022-03-20 23:23:00,981 - INFO - tqdm - f1: 0.8471, accuracy: 0.8994, batch_loss: 0.2001, loss: 0.2758 ||:  99%|#########8| 11132/11253 [21:33<00:20,  5.83it/s]
2022-03-20 23:23:11,008 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.0641, loss: 0.2760 ||:  99%|#########9| 11194/11253 [21:43<00:09,  6.15it/s]
2022-03-20 23:23:11,525 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.1293, loss: 0.2760 ||: 100%|#########9| 11197/11253 [21:44<00:09,  6.07it/s]
2022-03-20 23:23:11,725 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.6595, loss: 0.2760 ||: 100%|#########9| 11198/11253 [21:44<00:09,  5.71it/s]
2022-03-20 23:23:11,928 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.3518, loss: 0.2761 ||: 100%|#########9| 11199/11253 [21:44<00:09,  5.44it/s]
2022-03-20 23:23:12,124 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.2919, loss: 0.2761 ||: 100%|#########9| 11200/11253 [21:44<00:09,  5.33it/s]
2022-03-20 23:23:12,288 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.6008, loss: 0.2761 ||: 100%|#########9| 11201/11253 [21:45<00:09,  5.54it/s]
2022-03-20 23:23:12,452 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.2412, loss: 0.2761 ||: 100%|#########9| 11202/11253 [21:45<00:08,  5.70it/s]
2022-03-20 23:23:12,601 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.3068, loss: 0.2761 ||: 100%|#########9| 11203/11253 [21:45<00:08,  5.97it/s]
2022-03-20 23:23:12,744 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.1575, loss: 0.2761 ||: 100%|#########9| 11204/11253 [21:45<00:07,  6.24it/s]
2022-03-20 23:23:12,921 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.4369, loss: 0.2761 ||: 100%|#########9| 11205/11253 [21:45<00:07,  6.05it/s]
2022-03-20 23:23:13,086 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.8455, loss: 0.2761 ||: 100%|#########9| 11206/11253 [21:45<00:07,  6.05it/s]
2022-03-20 23:23:13,225 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.3399, loss: 0.2761 ||: 100%|#########9| 11207/11253 [21:46<00:07,  6.36it/s]
2022-03-20 23:23:13,364 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.1260, loss: 0.2761 ||: 100%|#########9| 11208/11253 [21:46<00:06,  6.59it/s]
2022-03-20 23:23:13,504 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.0462, loss: 0.2761 ||: 100%|#########9| 11209/11253 [21:46<00:06,  6.74it/s]
2022-03-20 23:23:13,683 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.6359, loss: 0.2761 ||: 100%|#########9| 11210/11253 [21:46<00:06,  6.35it/s]
2022-03-20 23:23:13,899 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.2958, loss: 0.2761 ||: 100%|#########9| 11211/11253 [21:46<00:07,  5.71it/s]
2022-03-20 23:23:14,077 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.1751, loss: 0.2761 ||: 100%|#########9| 11212/11253 [21:46<00:07,  5.69it/s]
2022-03-20 23:23:14,213 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.1387, loss: 0.2761 ||: 100%|#########9| 11213/11253 [21:46<00:06,  6.10it/s]
2022-03-20 23:23:14,398 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.1895, loss: 0.2761 ||: 100%|#########9| 11214/11253 [21:47<00:06,  5.87it/s]
2022-03-20 23:23:14,572 - INFO - tqdm - f1: 0.8472, accuracy: 0.8993, batch_loss: 0.1814, loss: 0.2761 ||: 100%|#########9| 11215/11253 [21:47<00:06,  5.83it/s]
2022-03-20 23:23:14,736 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.2445, loss: 0.2761 ||: 100%|#########9| 11216/11253 [21:47<00:06,  5.91it/s]
2022-03-20 23:23:14,999 - INFO - tqdm - f1: 0.8471, accuracy: 0.8993, batch_loss: 0.1018, loss: 0.2761 ||: 100%|#########9| 11217/11253 [21:47<00:07,  5.07it/s]
2022-03-20 23:23:15,211 - INFO - tqdm - f1: 0.8472, accuracy: 0.8993, batch_loss: 0.1353, loss: 0.2761 ||: 100%|#########9| 11218/11253 [21:47<00:07,  4.96it/s]
2022-03-20 23:23:15,361 - INFO - tqdm - f1: 0.8472, accuracy: 0.8993, batch_loss: 0.5391, loss: 0.2761 ||: 100%|#########9| 11219/11253 [21:48<00:06,  5.38it/s]
2022-03-20 23:23:15,523 - INFO - tqdm - f1: 0.8472, accuracy: 0.8993, batch_loss: 0.1684, loss: 0.2761 ||: 100%|#########9| 11220/11253 [21:48<00:05,  5.59it/s]
2022-03-20 23:23:15,722 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.0889, loss: 0.2761 ||: 100%|#########9| 11221/11253 [21:48<00:05,  5.40it/s]
2022-03-20 23:23:15,854 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.1116, loss: 0.2761 ||: 100%|#########9| 11222/11253 [21:48<00:05,  5.91it/s]
2022-03-20 23:23:16,029 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.0136, loss: 0.2760 ||: 100%|#########9| 11223/11253 [21:48<00:05,  5.86it/s]
2022-03-20 23:23:16,235 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.6074, loss: 0.2761 ||: 100%|#########9| 11224/11253 [21:49<00:05,  5.52it/s]
2022-03-20 23:23:16,417 - INFO - tqdm - f1: 0.8472, accuracy: 0.8993, batch_loss: 0.2752, loss: 0.2761 ||: 100%|#########9| 11225/11253 [21:49<00:05,  5.51it/s]
2022-03-20 23:23:16,532 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.1788, loss: 0.2761 ||: 100%|#########9| 11226/11253 [21:49<00:04,  6.19it/s]
2022-03-20 23:23:16,723 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.2029, loss: 0.2761 ||: 100%|#########9| 11227/11253 [21:49<00:04,  5.87it/s]
2022-03-20 23:23:16,924 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.3031, loss: 0.2761 ||: 100%|#########9| 11228/11253 [21:49<00:04,  5.57it/s]
2022-03-20 23:23:17,052 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.1370, loss: 0.2760 ||: 100%|#########9| 11229/11253 [21:49<00:03,  6.09it/s]
2022-03-20 23:23:17,237 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.0816, loss: 0.2760 ||: 100%|#########9| 11230/11253 [21:50<00:03,  5.87it/s]
2022-03-20 23:23:17,459 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.2426, loss: 0.2760 ||: 100%|#########9| 11231/11253 [21:50<00:04,  5.38it/s]
2022-03-20 23:23:17,596 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.0850, loss: 0.2760 ||: 100%|#########9| 11232/11253 [21:50<00:03,  5.84it/s]
2022-03-20 23:23:17,778 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.3614, loss: 0.2760 ||: 100%|#########9| 11233/11253 [21:50<00:03,  5.73it/s]
2022-03-20 23:23:17,950 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.0265, loss: 0.2760 ||: 100%|#########9| 11234/11253 [21:50<00:03,  5.76it/s]
2022-03-20 23:23:18,169 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.2937, loss: 0.2760 ||: 100%|#########9| 11235/11253 [21:50<00:03,  5.34it/s]
2022-03-20 23:23:18,350 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.0947, loss: 0.2760 ||: 100%|#########9| 11236/11253 [21:51<00:03,  5.39it/s]
2022-03-20 23:23:18,508 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.0982, loss: 0.2760 ||: 100%|#########9| 11237/11253 [21:51<00:02,  5.65it/s]
2022-03-20 23:23:18,649 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.1429, loss: 0.2759 ||: 100%|#########9| 11238/11253 [21:51<00:02,  6.02it/s]
2022-03-20 23:23:18,849 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.2708, loss: 0.2759 ||: 100%|#########9| 11239/11253 [21:51<00:02,  5.70it/s]
2022-03-20 23:23:19,035 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.0695, loss: 0.2759 ||: 100%|#########9| 11240/11253 [21:51<00:02,  5.57it/s]
2022-03-20 23:23:19,182 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.1548, loss: 0.2759 ||: 100%|#########9| 11241/11253 [21:51<00:02,  5.89it/s]
2022-03-20 23:23:19,355 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.2789, loss: 0.2759 ||: 100%|#########9| 11242/11253 [21:52<00:01,  5.85it/s]
2022-03-20 23:23:19,556 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.0882, loss: 0.2759 ||: 100%|#########9| 11243/11253 [21:52<00:01,  5.56it/s]
2022-03-20 23:23:19,766 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.1100, loss: 0.2759 ||: 100%|#########9| 11244/11253 [21:52<00:01,  5.29it/s]
2022-03-20 23:23:19,902 - INFO - tqdm - f1: 0.8473, accuracy: 0.8994, batch_loss: 0.2933, loss: 0.2759 ||: 100%|#########9| 11245/11253 [21:52<00:01,  5.78it/s]
2022-03-20 23:23:20,075 - INFO - tqdm - f1: 0.8473, accuracy: 0.8994, batch_loss: 0.1564, loss: 0.2759 ||: 100%|#########9| 11246/11253 [21:52<00:01,  5.78it/s]
2022-03-20 23:23:20,212 - INFO - tqdm - f1: 0.8473, accuracy: 0.8994, batch_loss: 0.1718, loss: 0.2759 ||: 100%|#########9| 11247/11253 [21:52<00:00,  6.16it/s]
2022-03-20 23:23:20,378 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.5968, loss: 0.2759 ||: 100%|#########9| 11248/11253 [21:53<00:00,  6.12it/s]
2022-03-20 23:23:20,545 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.3067, loss: 0.2759 ||: 100%|#########9| 11249/11253 [21:53<00:00,  6.09it/s]
2022-03-20 23:23:20,744 - INFO - tqdm - f1: 0.8472, accuracy: 0.8994, batch_loss: 0.3179, loss: 0.2759 ||: 100%|#########9| 11250/11253 [21:53<00:00,  5.72it/s]
2022-03-20 23:23:20,940 - INFO - tqdm - f1: 0.8473, accuracy: 0.8994, batch_loss: 0.0693, loss: 0.2759 ||: 100%|#########9| 11251/11253 [21:53<00:00,  5.52it/s]
2022-03-20 23:23:21,061 - INFO - tqdm - f1: 0.8473, accuracy: 0.8994, batch_loss: 0.3211, loss: 0.2759 ||: 100%|#########9| 11252/11253 [21:53<00:00,  6.13it/s]
2022-03-20 23:23:21,192 - INFO - tqdm - f1: 0.8473, accuracy: 0.8994, batch_loss: 0.3829, loss: 0.2759 ||: 100%|##########| 11253/11253 [21:53<00:00,  6.51it/s]
2022-03-20 23:23:21,283 - INFO - tqdm - f1: 0.8473, accuracy: 0.8994, batch_loss: 0.3829, loss: 0.2759 ||: 100%|##########| 11253/11253 [21:54<00:00,  8.56it/s]
2022-03-20 23:23:21,291 - INFO - allennlp.training.trainer - Validating
2022-03-20 23:23:21,294 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-20 23:23:31,301 - INFO - tqdm - f1: 0.8336, accuracy: 0.8757, batch_loss: 0.5975, loss: 0.3804 ||:   5%|4         | 87/1889 [00:10<03:26,  8.74it/s]
2022-03-20 23:23:41,311 - INFO - tqdm - f1: 0.8272, accuracy: 0.8743, batch_loss: 0.7006, loss: 0.3898 ||:   9%|9         | 173/1889 [00:20<03:22,  8.45it/s]
2022-03-20 23:23:51,318 - INFO - tqdm - f1: 0.8334, accuracy: 0.8809, batch_loss: 0.4425, loss: 0.3601 ||:  14%|#3        | 263/1889 [00:30<03:19,  8.13it/s]
2022-03-20 23:24:01,324 - INFO - tqdm - f1: 0.8385, accuracy: 0.8838, batch_loss: 0.0087, loss: 0.3535 ||:  21%|##1       | 399/1889 [00:40<01:33, 15.85it/s]
2022-03-20 23:24:11,328 - INFO - tqdm - f1: 0.8331, accuracy: 0.8815, batch_loss: 0.0241, loss: 0.3568 ||:  28%|##7       | 523/1889 [00:50<01:51, 12.23it/s]
2022-03-20 23:24:21,355 - INFO - tqdm - f1: 0.8280, accuracy: 0.8788, batch_loss: 0.5876, loss: 0.3650 ||:  38%|###7      | 711/1889 [01:00<00:43, 27.28it/s]
2022-03-20 23:24:31,477 - INFO - tqdm - f1: 0.8257, accuracy: 0.8768, batch_loss: 0.0400, loss: 0.3678 ||:  49%|####8     | 918/1889 [01:10<00:49, 19.51it/s]
2022-03-20 23:24:41,618 - INFO - tqdm - f1: 0.8255, accuracy: 0.8781, batch_loss: 0.2576, loss: 0.3671 ||:  59%|#####8    | 1111/1889 [01:20<00:40, 19.12it/s]
2022-03-20 23:24:51,749 - INFO - tqdm - f1: 0.8235, accuracy: 0.8769, batch_loss: 0.3178, loss: 0.3703 ||:  69%|######8   | 1299/1889 [01:30<00:51, 11.42it/s]
2022-03-20 23:25:01,751 - INFO - tqdm - f1: 0.8228, accuracy: 0.8773, batch_loss: 0.3538, loss: 0.3689 ||:  80%|#######9  | 1509/1889 [01:40<00:10, 35.56it/s]
2022-03-20 23:25:11,780 - INFO - tqdm - f1: 0.8221, accuracy: 0.8768, batch_loss: 0.2624, loss: 0.3706 ||:  93%|#########2| 1755/1889 [01:50<00:05, 24.76it/s]
2022-03-20 23:25:15,959 - INFO - tqdm - f1: 0.8227, accuracy: 0.8775, batch_loss: 0.1202, loss: 0.3695 ||: 100%|#########9| 1880/1889 [01:54<00:00, 39.94it/s]
2022-03-20 23:25:16,125 - INFO - tqdm - f1: 0.8226, accuracy: 0.8774, batch_loss: 0.3903, loss: 0.3700 ||: 100%|#########9| 1885/1889 [01:54<00:00, 36.39it/s]
2022-03-20 23:25:16,249 - INFO - tqdm - f1: 0.8227, accuracy: 0.8774, batch_loss: 0.1068, loss: 0.3700 ||: 100%|##########| 1889/1889 [01:54<00:00, 35.29it/s]
2022-03-20 23:25:16,261 - INFO - tqdm - f1: 0.8227, accuracy: 0.8774, batch_loss: 0.1068, loss: 0.3700 ||: 100%|##########| 1889/1889 [01:54<00:00, 16.43it/s]
2022-03-20 23:25:16,275 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct-20k_base_hyper_small_seed_13/best.th'.
2022-03-20 23:25:18,783 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 23:25:18,785 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.899  |     0.877
2022-03-20 23:25:18,787 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.847  |     0.823
2022-03-20 23:25:18,788 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 23:25:18,790 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.276  |     0.370
2022-03-20 23:25:18,791 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8644.559  |       N/A
2022-03-20 23:25:18,793 - INFO - allennlp.training.trainer - Epoch duration: 0:23:51.584525
2022-03-20 23:25:18,795 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:12:03
2022-03-20 23:25:18,796 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-20 23:25:18,798 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-20 23:25:18,799 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 23:25:18,802 - INFO - allennlp.training.trainer - Training
2022-03-20 23:25:18,804 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-20 23:25:28,862 - INFO - tqdm - f1: 0.8627, accuracy: 0.9073, batch_loss: 0.3252, loss: 0.2773 ||:   1%|          | 87/11253 [00:10<26:41,  6.97it/s]
2022-03-20 23:25:38,869 - INFO - tqdm - f1: 0.8635, accuracy: 0.9084, batch_loss: 0.2108, loss: 0.2573 ||:   2%|1         | 187/11253 [00:20<33:26,  5.51it/s]
2022-03-20 23:25:49,023 - INFO - tqdm - f1: 0.8643, accuracy: 0.9091, batch_loss: 0.0727, loss: 0.2527 ||:   3%|2         | 291/11253 [00:30<41:13,  4.43it/s]
2022-03-20 23:25:59,068 - INFO - tqdm - f1: 0.8648, accuracy: 0.9092, batch_loss: 0.2338, loss: 0.2488 ||:   3%|3         | 393/11253 [00:40<40:09,  4.51it/s]
2022-03-20 23:26:09,158 - INFO - tqdm - f1: 0.8642, accuracy: 0.9106, batch_loss: 0.2004, loss: 0.2441 ||:   4%|4         | 495/11253 [00:50<32:32,  5.51it/s]
2022-03-20 23:26:19,175 - INFO - tqdm - f1: 0.8658, accuracy: 0.9111, batch_loss: 0.4545, loss: 0.2457 ||:   5%|5         | 595/11253 [01:00<31:14,  5.69it/s]
2022-03-20 23:26:29,205 - INFO - tqdm - f1: 0.8669, accuracy: 0.9114, batch_loss: 0.4145, loss: 0.2457 ||:   6%|6         | 697/11253 [01:10<30:47,  5.71it/s]
2022-03-20 23:26:39,224 - INFO - tqdm - f1: 0.8686, accuracy: 0.9136, batch_loss: 0.0295, loss: 0.2415 ||:   7%|7         | 799/11253 [01:20<25:36,  6.80it/s]
2022-03-20 23:26:49,320 - INFO - tqdm - f1: 0.8681, accuracy: 0.9135, batch_loss: 0.2190, loss: 0.2409 ||:   8%|8         | 901/11253 [01:30<21:20,  8.09it/s]
2022-03-20 23:26:59,362 - INFO - tqdm - f1: 0.8676, accuracy: 0.9138, batch_loss: 0.1097, loss: 0.2406 ||:   9%|8         | 1003/11253 [01:40<16:01, 10.66it/s]
2022-03-20 23:27:09,392 - INFO - tqdm - f1: 0.8659, accuracy: 0.9123, batch_loss: 0.0876, loss: 0.2435 ||:  10%|9         | 1103/11253 [01:50<14:35, 11.59it/s]
2022-03-20 23:27:19,395 - INFO - tqdm - f1: 0.8663, accuracy: 0.9124, batch_loss: 0.0303, loss: 0.2431 ||:  11%|#         | 1203/11253 [02:00<14:04, 11.89it/s]
2022-03-20 23:27:29,433 - INFO - tqdm - f1: 0.8661, accuracy: 0.9124, batch_loss: 0.1498, loss: 0.2419 ||:  12%|#1        | 1305/11253 [02:10<12:58, 12.77it/s]
2022-03-20 23:27:39,547 - INFO - tqdm - f1: 0.8659, accuracy: 0.9127, batch_loss: 0.1175, loss: 0.2399 ||:  13%|#2        | 1409/11253 [02:20<12:17, 13.34it/s]
2022-03-20 23:27:49,594 - INFO - tqdm - f1: 0.8648, accuracy: 0.9115, batch_loss: 0.4218, loss: 0.2414 ||:  13%|#3        | 1504/11253 [02:30<13:50, 11.74it/s]
2022-03-20 23:27:59,599 - INFO - tqdm - f1: 0.8638, accuracy: 0.9111, batch_loss: 0.0693, loss: 0.2423 ||:  14%|#4        | 1613/11253 [02:40<17:06,  9.39it/s]
2022-03-20 23:28:09,742 - INFO - tqdm - f1: 0.8637, accuracy: 0.9106, batch_loss: 0.4770, loss: 0.2435 ||:  15%|#5        | 1710/11253 [02:50<15:33, 10.23it/s]
2022-03-20 23:28:19,792 - INFO - tqdm - f1: 0.8641, accuracy: 0.9112, batch_loss: 0.0057, loss: 0.2424 ||:  16%|#5        | 1787/11253 [03:00<22:32,  7.00it/s]
2022-03-20 23:28:29,918 - INFO - tqdm - f1: 0.8639, accuracy: 0.9110, batch_loss: 0.3721, loss: 0.2438 ||:  16%|#6        | 1856/11253 [03:11<25:00,  6.26it/s]
2022-03-20 23:28:40,002 - INFO - tqdm - f1: 0.8634, accuracy: 0.9105, batch_loss: 0.2357, loss: 0.2443 ||:  17%|#7        | 1921/11253 [03:21<27:29,  5.66it/s]
2022-03-20 23:28:50,068 - INFO - tqdm - f1: 0.8630, accuracy: 0.9103, batch_loss: 0.0673, loss: 0.2445 ||:  18%|#7        | 1988/11253 [03:31<22:06,  6.98it/s]
2022-03-20 23:29:00,167 - INFO - tqdm - f1: 0.8628, accuracy: 0.9104, batch_loss: 0.2693, loss: 0.2441 ||:  18%|#8        | 2053/11253 [03:41<26:07,  5.87it/s]
2022-03-20 23:29:10,886 - INFO - tqdm - f1: 0.8632, accuracy: 0.9109, batch_loss: 0.3377, loss: 0.2435 ||:  19%|#8        | 2115/11253 [03:52<1:14:36,  2.04it/s]
2022-03-20 23:29:21,015 - INFO - tqdm - f1: 0.8627, accuracy: 0.9106, batch_loss: 0.2708, loss: 0.2432 ||:  19%|#9        | 2180/11253 [04:02<22:28,  6.73it/s]
2022-03-20 23:29:31,153 - INFO - tqdm - f1: 0.8626, accuracy: 0.9107, batch_loss: 0.1253, loss: 0.2436 ||:  20%|##        | 2265/11253 [04:12<15:40,  9.56it/s]
2022-03-20 23:29:41,304 - INFO - tqdm - f1: 0.8634, accuracy: 0.9112, batch_loss: 0.1662, loss: 0.2426 ||:  21%|##        | 2343/11253 [04:22<26:00,  5.71it/s]
2022-03-20 23:29:51,315 - INFO - tqdm - f1: 0.8630, accuracy: 0.9113, batch_loss: 0.0094, loss: 0.2423 ||:  21%|##1       | 2402/11253 [04:32<23:46,  6.20it/s]
2022-03-20 23:30:01,347 - INFO - tqdm - f1: 0.8632, accuracy: 0.9113, batch_loss: 0.3207, loss: 0.2426 ||:  22%|##1       | 2468/11253 [04:42<19:20,  7.57it/s]
2022-03-20 23:30:11,439 - INFO - tqdm - f1: 0.8630, accuracy: 0.9111, batch_loss: 0.4640, loss: 0.2436 ||:  22%|##2       | 2529/11253 [04:52<28:43,  5.06it/s]
2022-03-20 23:30:21,539 - INFO - tqdm - f1: 0.8630, accuracy: 0.9112, batch_loss: 0.2199, loss: 0.2431 ||:  23%|##3       | 2589/11253 [05:02<21:17,  6.78it/s]
2022-03-20 23:30:31,582 - INFO - tqdm - f1: 0.8632, accuracy: 0.9113, batch_loss: 0.2799, loss: 0.2427 ||:  24%|##3       | 2654/11253 [05:12<21:09,  6.78it/s]
2022-03-20 23:30:41,624 - INFO - tqdm - f1: 0.8635, accuracy: 0.9114, batch_loss: 0.0704, loss: 0.2429 ||:  24%|##4       | 2716/11253 [05:22<23:26,  6.07it/s]
2022-03-20 23:30:51,737 - INFO - tqdm - f1: 0.8635, accuracy: 0.9114, batch_loss: 0.4628, loss: 0.2432 ||:  25%|##4       | 2784/11253 [05:32<24:45,  5.70it/s]
2022-03-20 23:31:01,798 - INFO - tqdm - f1: 0.8642, accuracy: 0.9119, batch_loss: 0.4588, loss: 0.2421 ||:  25%|##5       | 2848/11253 [05:42<19:53,  7.04it/s]
2022-03-20 23:31:11,900 - INFO - tqdm - f1: 0.8643, accuracy: 0.9120, batch_loss: 0.3529, loss: 0.2422 ||:  26%|##5       | 2912/11253 [05:53<22:48,  6.10it/s]
2022-03-20 23:31:21,986 - INFO - tqdm - f1: 0.8640, accuracy: 0.9118, batch_loss: 0.0735, loss: 0.2428 ||:  26%|##6       | 2974/11253 [06:03<23:35,  5.85it/s]
2022-03-20 23:31:32,066 - INFO - tqdm - f1: 0.8644, accuracy: 0.9122, batch_loss: 0.0848, loss: 0.2418 ||:  27%|##6       | 3035/11253 [06:13<22:41,  6.04it/s]
2022-03-20 23:31:42,135 - INFO - tqdm - f1: 0.8642, accuracy: 0.9121, batch_loss: 0.2041, loss: 0.2420 ||:  28%|##7       | 3096/11253 [06:23<23:56,  5.68it/s]
2022-03-20 23:31:52,263 - INFO - tqdm - f1: 0.8640, accuracy: 0.9119, batch_loss: 0.0739, loss: 0.2421 ||:  28%|##8       | 3153/11253 [06:33<22:51,  5.91it/s]
2022-03-20 23:32:02,384 - INFO - tqdm - f1: 0.8638, accuracy: 0.9120, batch_loss: 0.0494, loss: 0.2419 ||:  29%|##8       | 3219/11253 [06:43<13:36,  9.84it/s]
2022-03-20 23:32:12,713 - INFO - tqdm - f1: 0.8637, accuracy: 0.9121, batch_loss: 0.2716, loss: 0.2417 ||:  29%|##9       | 3295/11253 [06:53<1:15:27,  1.76it/s]
2022-03-20 23:32:22,795 - INFO - tqdm - f1: 0.8640, accuracy: 0.9122, batch_loss: 0.1489, loss: 0.2411 ||:  30%|##9       | 3366/11253 [07:03<16:10,  8.12it/s]
2022-03-20 23:32:32,948 - INFO - tqdm - f1: 0.8643, accuracy: 0.9123, batch_loss: 0.0775, loss: 0.2407 ||:  31%|###       | 3446/11253 [07:14<17:30,  7.43it/s]
2022-03-20 23:32:42,955 - INFO - tqdm - f1: 0.8639, accuracy: 0.9122, batch_loss: 0.1378, loss: 0.2409 ||:  31%|###1      | 3519/11253 [07:24<19:11,  6.72it/s]
2022-03-20 23:32:53,018 - INFO - tqdm - f1: 0.8646, accuracy: 0.9126, batch_loss: 0.1557, loss: 0.2403 ||:  32%|###1      | 3586/11253 [07:34<18:27,  6.92it/s]
2022-03-20 23:33:03,123 - INFO - tqdm - f1: 0.8642, accuracy: 0.9123, batch_loss: 0.3925, loss: 0.2413 ||:  32%|###2      | 3657/11253 [07:44<17:16,  7.33it/s]
2022-03-20 23:33:13,173 - INFO - tqdm - f1: 0.8641, accuracy: 0.9124, batch_loss: 0.4108, loss: 0.2412 ||:  33%|###3      | 3720/11253 [07:54<14:40,  8.56it/s]
2022-03-20 23:33:23,426 - INFO - tqdm - f1: 0.8645, accuracy: 0.9127, batch_loss: 0.4098, loss: 0.2408 ||:  34%|###3      | 3785/11253 [08:04<16:23,  7.59it/s]
2022-03-20 23:33:33,428 - INFO - tqdm - f1: 0.8643, accuracy: 0.9127, batch_loss: 0.0256, loss: 0.2411 ||:  34%|###4      | 3847/11253 [08:14<15:54,  7.76it/s]
2022-03-20 23:33:43,485 - INFO - tqdm - f1: 0.8642, accuracy: 0.9127, batch_loss: 0.0548, loss: 0.2409 ||:  35%|###4      | 3916/11253 [08:24<14:24,  8.49it/s]
2022-03-20 23:33:53,562 - INFO - tqdm - f1: 0.8642, accuracy: 0.9127, batch_loss: 0.2171, loss: 0.2410 ||:  35%|###5      | 3983/11253 [08:34<14:05,  8.60it/s]
2022-03-20 23:34:03,618 - INFO - tqdm - f1: 0.8645, accuracy: 0.9129, batch_loss: 0.2932, loss: 0.2407 ||:  36%|###6      | 4054/11253 [08:44<13:34,  8.83it/s]
2022-03-20 23:34:13,731 - INFO - tqdm - f1: 0.8646, accuracy: 0.9130, batch_loss: 0.0845, loss: 0.2405 ||:  37%|###6      | 4121/11253 [08:54<15:03,  7.89it/s]
2022-03-20 23:34:24,058 - INFO - tqdm - f1: 0.8645, accuracy: 0.9128, batch_loss: 0.2398, loss: 0.2411 ||:  37%|###7      | 4187/11253 [09:05<31:19,  3.76it/s]
2022-03-20 23:34:34,230 - INFO - tqdm - f1: 0.8642, accuracy: 0.9128, batch_loss: 0.0784, loss: 0.2411 ||:  38%|###8      | 4283/11253 [09:15<10:21, 11.21it/s]
2022-03-20 23:34:44,337 - INFO - tqdm - f1: 0.8646, accuracy: 0.9131, batch_loss: 0.1458, loss: 0.2409 ||:  39%|###9      | 4395/11253 [09:25<11:52,  9.63it/s]
2022-03-20 23:34:54,427 - INFO - tqdm - f1: 0.8642, accuracy: 0.9128, batch_loss: 0.4398, loss: 0.2415 ||:  40%|###9      | 4485/11253 [09:35<11:30,  9.80it/s]
2022-03-20 23:35:04,538 - INFO - tqdm - f1: 0.8640, accuracy: 0.9128, batch_loss: 0.2884, loss: 0.2410 ||:  41%|####      | 4568/11253 [09:45<13:32,  8.23it/s]
2022-03-20 23:35:14,610 - INFO - tqdm - f1: 0.8638, accuracy: 0.9127, batch_loss: 0.7400, loss: 0.2411 ||:  41%|####1     | 4637/11253 [09:55<17:40,  6.24it/s]
2022-03-20 23:35:24,695 - INFO - tqdm - f1: 0.8636, accuracy: 0.9126, batch_loss: 0.0500, loss: 0.2415 ||:  42%|####1     | 4700/11253 [10:05<17:32,  6.22it/s]
2022-03-20 23:35:34,697 - INFO - tqdm - f1: 0.8637, accuracy: 0.9127, batch_loss: 0.1199, loss: 0.2414 ||:  42%|####2     | 4759/11253 [10:15<22:44,  4.76it/s]
2022-03-20 23:35:44,948 - INFO - tqdm - f1: 0.8636, accuracy: 0.9126, batch_loss: 0.2283, loss: 0.2415 ||:  43%|####2     | 4806/11253 [10:26<25:27,  4.22it/s]
2022-03-20 23:35:55,036 - INFO - tqdm - f1: 0.8638, accuracy: 0.9128, batch_loss: 0.1213, loss: 0.2413 ||:  43%|####3     | 4855/11253 [10:36<20:06,  5.30it/s]
2022-03-20 23:36:05,207 - INFO - tqdm - f1: 0.8639, accuracy: 0.9128, batch_loss: 0.0301, loss: 0.2411 ||:  44%|####3     | 4903/11253 [10:46<24:13,  4.37it/s]
2022-03-20 23:36:15,432 - INFO - tqdm - f1: 0.8638, accuracy: 0.9128, batch_loss: 0.3280, loss: 0.2413 ||:  44%|####3     | 4950/11253 [10:56<24:14,  4.33it/s]
2022-03-20 23:36:25,433 - INFO - tqdm - f1: 0.8638, accuracy: 0.9128, batch_loss: 0.4074, loss: 0.2411 ||:  44%|####4     | 5004/11253 [11:06<16:54,  6.16it/s]
2022-03-20 23:36:35,451 - INFO - tqdm - f1: 0.8640, accuracy: 0.9129, batch_loss: 0.2377, loss: 0.2411 ||:  45%|####5     | 5076/11253 [11:16<12:01,  8.56it/s]
2022-03-20 23:36:45,615 - INFO - tqdm - f1: 0.8640, accuracy: 0.9129, batch_loss: 0.2284, loss: 0.2410 ||:  46%|####5     | 5139/11253 [11:26<21:29,  4.74it/s]
2022-03-20 23:36:55,621 - INFO - tqdm - f1: 0.8640, accuracy: 0.9129, batch_loss: 0.1603, loss: 0.2410 ||:  46%|####6     | 5189/11253 [11:36<20:49,  4.85it/s]
2022-03-20 23:37:05,738 - INFO - tqdm - f1: 0.8642, accuracy: 0.9130, batch_loss: 0.3552, loss: 0.2407 ||:  47%|####6     | 5238/11253 [11:46<22:02,  4.55it/s]
2022-03-20 23:37:15,816 - INFO - tqdm - f1: 0.8640, accuracy: 0.9128, batch_loss: 0.1299, loss: 0.2409 ||:  47%|####6     | 5285/11253 [11:57<23:17,  4.27it/s]
2022-03-20 23:37:25,856 - INFO - tqdm - f1: 0.8637, accuracy: 0.9126, batch_loss: 0.2842, loss: 0.2410 ||:  47%|####7     | 5330/11253 [12:07<22:55,  4.31it/s]
2022-03-20 23:37:36,059 - INFO - tqdm - f1: 0.8638, accuracy: 0.9126, batch_loss: 0.0899, loss: 0.2413 ||:  48%|####7     | 5372/11253 [12:17<26:38,  3.68it/s]
2022-03-20 23:37:46,200 - INFO - tqdm - f1: 0.8639, accuracy: 0.9127, batch_loss: 0.1720, loss: 0.2415 ||:  48%|####8     | 5418/11253 [12:27<21:43,  4.47it/s]
2022-03-20 23:37:56,329 - INFO - tqdm - f1: 0.8636, accuracy: 0.9126, batch_loss: 0.7579, loss: 0.2417 ||:  49%|####8     | 5464/11253 [12:37<21:08,  4.56it/s]
2022-03-20 23:38:06,386 - INFO - tqdm - f1: 0.8635, accuracy: 0.9127, batch_loss: 0.3998, loss: 0.2415 ||:  49%|####9     | 5526/11253 [12:47<12:19,  7.74it/s]
2022-03-20 23:38:16,642 - INFO - tqdm - f1: 0.8633, accuracy: 0.9126, batch_loss: 0.3116, loss: 0.2416 ||:  50%|####9     | 5598/11253 [12:57<12:50,  7.34it/s]
2022-03-20 23:38:26,756 - INFO - tqdm - f1: 0.8630, accuracy: 0.9123, batch_loss: 0.1673, loss: 0.2422 ||:  50%|#####     | 5648/11253 [13:07<18:47,  4.97it/s]
2022-03-20 23:38:36,923 - INFO - tqdm - f1: 0.8628, accuracy: 0.9122, batch_loss: 0.2315, loss: 0.2425 ||:  51%|#####     | 5699/11253 [13:18<18:49,  4.92it/s]
2022-03-20 23:38:47,168 - INFO - tqdm - f1: 0.8627, accuracy: 0.9120, batch_loss: 0.4005, loss: 0.2429 ||:  51%|#####1    | 5747/11253 [13:28<21:21,  4.30it/s]
2022-03-20 23:38:57,291 - INFO - tqdm - f1: 0.8629, accuracy: 0.9121, batch_loss: 0.2703, loss: 0.2429 ||:  51%|#####1    | 5795/11253 [13:38<17:07,  5.31it/s]
2022-03-20 23:39:07,419 - INFO - tqdm - f1: 0.8632, accuracy: 0.9123, batch_loss: 0.1726, loss: 0.2424 ||:  52%|#####1    | 5841/11253 [13:48<22:40,  3.98it/s]
2022-03-20 23:39:17,425 - INFO - tqdm - f1: 0.8630, accuracy: 0.9122, batch_loss: 0.3671, loss: 0.2428 ||:  52%|#####2    | 5882/11253 [13:58<24:55,  3.59it/s]
2022-03-20 23:39:27,507 - INFO - tqdm - f1: 0.8628, accuracy: 0.9120, batch_loss: 0.2023, loss: 0.2432 ||:  53%|#####2    | 5925/11253 [14:08<19:15,  4.61it/s]
2022-03-20 23:39:37,643 - INFO - tqdm - f1: 0.8628, accuracy: 0.9121, batch_loss: 0.3556, loss: 0.2432 ||:  53%|#####3    | 5978/11253 [14:18<13:37,  6.45it/s]
2022-03-20 23:39:47,806 - INFO - tqdm - f1: 0.8625, accuracy: 0.9120, batch_loss: 0.1900, loss: 0.2433 ||:  54%|#####3    | 6052/11253 [14:28<13:52,  6.25it/s]
2022-03-20 23:39:57,844 - INFO - tqdm - f1: 0.8628, accuracy: 0.9121, batch_loss: 0.2558, loss: 0.2429 ||:  54%|#####4    | 6111/11253 [14:39<14:38,  5.85it/s]
2022-03-20 23:40:07,920 - INFO - tqdm - f1: 0.8628, accuracy: 0.9122, batch_loss: 0.1628, loss: 0.2426 ||:  55%|#####4    | 6174/11253 [14:49<11:19,  7.47it/s]
2022-03-20 23:40:18,079 - INFO - tqdm - f1: 0.8626, accuracy: 0.9121, batch_loss: 0.1109, loss: 0.2425 ||:  56%|#####5    | 6248/11253 [14:59<11:20,  7.36it/s]
2022-03-20 23:40:28,134 - INFO - tqdm - f1: 0.8625, accuracy: 0.9121, batch_loss: 0.2249, loss: 0.2425 ||:  56%|#####6    | 6315/11253 [15:09<12:22,  6.65it/s]
2022-03-20 23:40:38,162 - INFO - tqdm - f1: 0.8623, accuracy: 0.9121, batch_loss: 0.4210, loss: 0.2426 ||:  57%|#####6    | 6372/11253 [15:19<13:01,  6.24it/s]
2022-03-20 23:40:48,259 - INFO - tqdm - f1: 0.8623, accuracy: 0.9121, batch_loss: 0.2851, loss: 0.2427 ||:  57%|#####7    | 6436/11253 [15:29<12:13,  6.56it/s]
2022-03-20 23:40:58,295 - INFO - tqdm - f1: 0.8623, accuracy: 0.9120, batch_loss: 0.2996, loss: 0.2428 ||:  58%|#####7    | 6512/11253 [15:39<09:11,  8.60it/s]
2022-03-20 23:41:08,297 - INFO - tqdm - f1: 0.8622, accuracy: 0.9120, batch_loss: 0.2234, loss: 0.2430 ||:  59%|#####8    | 6610/11253 [15:49<07:43, 10.01it/s]
2022-03-20 23:41:18,484 - INFO - tqdm - f1: 0.8622, accuracy: 0.9120, batch_loss: 0.1143, loss: 0.2429 ||:  60%|#####9    | 6718/11253 [15:59<07:11, 10.50it/s]
2022-03-20 23:41:28,602 - INFO - tqdm - f1: 0.8625, accuracy: 0.9121, batch_loss: 0.0947, loss: 0.2433 ||:  61%|######    | 6821/11253 [16:09<07:12, 10.25it/s]
2022-03-20 23:41:38,607 - INFO - tqdm - f1: 0.8623, accuracy: 0.9119, batch_loss: 0.1594, loss: 0.2436 ||:  62%|######1   | 6924/11253 [16:19<07:02, 10.24it/s]
2022-03-20 23:41:48,779 - INFO - tqdm - f1: 0.8620, accuracy: 0.9117, batch_loss: 0.3927, loss: 0.2443 ||:  62%|######2   | 7028/11253 [16:29<06:45, 10.41it/s]
2022-03-20 23:41:58,797 - INFO - tqdm - f1: 0.8620, accuracy: 0.9117, batch_loss: 0.1403, loss: 0.2443 ||:  63%|######3   | 7130/11253 [16:39<06:53,  9.96it/s]
2022-03-20 23:42:08,842 - INFO - tqdm - f1: 0.8621, accuracy: 0.9117, batch_loss: 0.2170, loss: 0.2446 ||:  64%|######4   | 7231/11253 [16:50<06:15, 10.71it/s]
2022-03-20 23:42:18,914 - INFO - tqdm - f1: 0.8621, accuracy: 0.9116, batch_loss: 0.1238, loss: 0.2450 ||:  65%|######5   | 7336/11253 [17:00<06:06, 10.69it/s]
2022-03-20 23:42:29,029 - INFO - tqdm - f1: 0.8622, accuracy: 0.9116, batch_loss: 0.2076, loss: 0.2451 ||:  66%|######6   | 7440/11253 [17:10<05:46, 11.01it/s]
2022-03-20 23:42:39,158 - INFO - tqdm - f1: 0.8621, accuracy: 0.9115, batch_loss: 0.1719, loss: 0.2453 ||:  67%|######7   | 7542/11253 [17:20<06:57,  8.89it/s]
2022-03-20 23:42:49,179 - INFO - tqdm - f1: 0.8620, accuracy: 0.9115, batch_loss: 0.3287, loss: 0.2453 ||:  68%|######7   | 7645/11253 [17:30<05:47, 10.38it/s]
2022-03-20 23:42:59,254 - INFO - tqdm - f1: 0.8621, accuracy: 0.9116, batch_loss: 0.0219, loss: 0.2451 ||:  69%|######8   | 7748/11253 [17:40<05:39, 10.32it/s]
2022-03-20 23:43:09,400 - INFO - tqdm - f1: 0.8618, accuracy: 0.9114, batch_loss: 0.2635, loss: 0.2457 ||:  70%|######9   | 7856/11253 [17:50<05:21, 10.58it/s]
2022-03-20 23:43:19,497 - INFO - tqdm - f1: 0.8617, accuracy: 0.9113, batch_loss: 0.1449, loss: 0.2456 ||:  71%|#######   | 7958/11253 [18:00<05:48,  9.45it/s]
2022-03-20 23:43:29,677 - INFO - tqdm - f1: 0.8616, accuracy: 0.9112, batch_loss: 0.2872, loss: 0.2458 ||:  72%|#######1  | 8063/11253 [18:10<05:06, 10.42it/s]
2022-03-20 23:43:39,718 - INFO - tqdm - f1: 0.8616, accuracy: 0.9112, batch_loss: 0.3836, loss: 0.2459 ||:  73%|#######2  | 8166/11253 [18:20<04:51, 10.59it/s]
2022-03-20 23:43:49,878 - INFO - tqdm - f1: 0.8614, accuracy: 0.9111, batch_loss: 0.1875, loss: 0.2463 ||:  73%|#######3  | 8255/11253 [18:31<05:37,  8.89it/s]
2022-03-20 23:44:00,060 - INFO - tqdm - f1: 0.8613, accuracy: 0.9111, batch_loss: 0.2033, loss: 0.2464 ||:  74%|#######4  | 8356/11253 [18:41<04:40, 10.32it/s]
2022-03-20 23:44:10,201 - INFO - tqdm - f1: 0.8611, accuracy: 0.9109, batch_loss: 0.1211, loss: 0.2467 ||:  75%|#######5  | 8458/11253 [18:51<04:21, 10.70it/s]
2022-03-20 23:44:20,214 - INFO - tqdm - f1: 0.8611, accuracy: 0.9109, batch_loss: 0.5016, loss: 0.2468 ||:  76%|#######6  | 8560/11253 [19:01<04:14, 10.58it/s]
2022-03-20 23:44:31,225 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.2780, loss: 0.2467 ||:  77%|#######6  | 8659/11253 [19:12<16:31,  2.62it/s]
2022-03-20 23:44:41,220 - INFO - tqdm - f1: 0.8612, accuracy: 0.9108, batch_loss: 0.0809, loss: 0.2466 ||:  78%|#######7  | 8755/11253 [19:22<04:32,  9.15it/s]
2022-03-20 23:44:51,323 - INFO - tqdm - f1: 0.8611, accuracy: 0.9108, batch_loss: 0.1891, loss: 0.2466 ||:  79%|#######8  | 8851/11253 [19:32<04:11,  9.56it/s]
2022-03-20 23:45:01,447 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.2028, loss: 0.2466 ||:  80%|#######9  | 8954/11253 [19:42<03:27, 11.06it/s]
2022-03-20 23:45:11,474 - INFO - tqdm - f1: 0.8608, accuracy: 0.9107, batch_loss: 0.4774, loss: 0.2468 ||:  80%|########  | 9057/11253 [19:52<03:37, 10.11it/s]
2022-03-20 23:45:21,667 - INFO - tqdm - f1: 0.8607, accuracy: 0.9106, batch_loss: 0.5483, loss: 0.2468 ||:  81%|########1 | 9160/11253 [20:02<03:21, 10.38it/s]
2022-03-20 23:45:31,739 - INFO - tqdm - f1: 0.8605, accuracy: 0.9106, batch_loss: 0.0899, loss: 0.2469 ||:  82%|########2 | 9262/11253 [20:12<03:09, 10.48it/s]
2022-03-20 23:45:41,869 - INFO - tqdm - f1: 0.8605, accuracy: 0.9105, batch_loss: 0.2206, loss: 0.2471 ||:  83%|########3 | 9362/11253 [20:23<03:19,  9.49it/s]
2022-03-20 23:45:51,886 - INFO - tqdm - f1: 0.8604, accuracy: 0.9105, batch_loss: 0.0406, loss: 0.2474 ||:  84%|########4 | 9462/11253 [20:33<02:49, 10.54it/s]
2022-03-20 23:46:01,894 - INFO - tqdm - f1: 0.8604, accuracy: 0.9105, batch_loss: 0.3269, loss: 0.2472 ||:  85%|########4 | 9564/11253 [20:43<03:32,  7.95it/s]
2022-03-20 23:46:11,962 - INFO - tqdm - f1: 0.8606, accuracy: 0.9106, batch_loss: 0.0436, loss: 0.2470 ||:  86%|########5 | 9668/11253 [20:53<02:43,  9.68it/s]
2022-03-20 23:46:22,068 - INFO - tqdm - f1: 0.8606, accuracy: 0.9105, batch_loss: 0.1978, loss: 0.2471 ||:  87%|########6 | 9768/11253 [21:03<02:32,  9.75it/s]
2022-03-20 23:46:32,241 - INFO - tqdm - f1: 0.8609, accuracy: 0.9107, batch_loss: 0.1774, loss: 0.2467 ||:  88%|########7 | 9861/11253 [21:13<02:17, 10.13it/s]
2022-03-20 23:46:42,246 - INFO - tqdm - f1: 0.8608, accuracy: 0.9106, batch_loss: 0.6598, loss: 0.2469 ||:  89%|########8 | 9962/11253 [21:23<02:06, 10.23it/s]
2022-03-20 23:46:52,262 - INFO - tqdm - f1: 0.8607, accuracy: 0.9106, batch_loss: 0.1641, loss: 0.2469 ||:  89%|########9 | 10063/11253 [21:33<02:01,  9.78it/s]
2022-03-20 23:47:02,400 - INFO - tqdm - f1: 0.8609, accuracy: 0.9106, batch_loss: 0.3648, loss: 0.2470 ||:  90%|######### | 10156/11253 [21:43<01:44, 10.52it/s]
2022-03-20 23:47:12,564 - INFO - tqdm - f1: 0.8610, accuracy: 0.9106, batch_loss: 0.2188, loss: 0.2470 ||:  91%|#########1| 10260/11253 [21:53<01:40,  9.89it/s]
2022-03-20 23:47:22,607 - INFO - tqdm - f1: 0.8610, accuracy: 0.9106, batch_loss: 0.1360, loss: 0.2471 ||:  92%|#########2| 10360/11253 [22:03<01:35,  9.31it/s]
2022-03-20 23:47:32,818 - INFO - tqdm - f1: 0.8610, accuracy: 0.9106, batch_loss: 0.1136, loss: 0.2473 ||:  93%|#########2| 10465/11253 [22:14<01:17, 10.11it/s]
2022-03-20 23:47:42,991 - INFO - tqdm - f1: 0.8609, accuracy: 0.9106, batch_loss: 0.2636, loss: 0.2473 ||:  94%|#########3| 10568/11253 [22:24<01:06, 10.23it/s]
2022-03-20 23:47:53,189 - INFO - tqdm - f1: 0.8609, accuracy: 0.9106, batch_loss: 0.4340, loss: 0.2472 ||:  95%|#########4| 10670/11253 [22:34<01:00,  9.64it/s]
2022-03-20 23:48:03,329 - INFO - tqdm - f1: 0.8607, accuracy: 0.9105, batch_loss: 0.1959, loss: 0.2474 ||:  96%|#########5| 10770/11253 [22:44<00:47, 10.17it/s]
2022-03-20 23:48:13,334 - INFO - tqdm - f1: 0.8608, accuracy: 0.9105, batch_loss: 0.1694, loss: 0.2474 ||:  97%|#########6| 10869/11253 [22:54<00:39,  9.74it/s]
2022-03-20 23:48:23,363 - INFO - tqdm - f1: 0.8609, accuracy: 0.9106, batch_loss: 0.0514, loss: 0.2472 ||:  97%|#########7| 10969/11253 [23:04<00:29,  9.49it/s]
2022-03-20 23:48:33,488 - INFO - tqdm - f1: 0.8608, accuracy: 0.9105, batch_loss: 0.4330, loss: 0.2473 ||:  98%|#########8| 11060/11253 [23:14<00:18, 10.71it/s]
2022-03-20 23:48:43,607 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1893, loss: 0.2475 ||:  99%|#########9| 11162/11253 [23:24<00:09, 10.02it/s]
2022-03-20 23:48:47,270 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1014, loss: 0.2474 ||: 100%|#########9| 11198/11253 [23:28<00:05, 10.23it/s]
2022-03-20 23:48:47,466 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.2290, loss: 0.2475 ||: 100%|#########9| 11200/11253 [23:28<00:05, 10.23it/s]
2022-03-20 23:48:47,653 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.0916, loss: 0.2474 ||: 100%|#########9| 11202/11253 [23:28<00:04, 10.37it/s]
2022-03-20 23:48:47,873 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.3913, loss: 0.2474 ||: 100%|#########9| 11204/11253 [23:29<00:04,  9.93it/s]
2022-03-20 23:48:48,052 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.0368, loss: 0.2474 ||: 100%|#########9| 11206/11253 [23:29<00:04, 10.29it/s]
2022-03-20 23:48:48,253 - INFO - tqdm - f1: 0.8605, accuracy: 0.9104, batch_loss: 0.5940, loss: 0.2474 ||: 100%|#########9| 11208/11253 [23:29<00:04, 10.18it/s]
2022-03-20 23:48:48,444 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.3846, loss: 0.2475 ||: 100%|#########9| 11210/11253 [23:29<00:04, 10.27it/s]
2022-03-20 23:48:48,649 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.3138, loss: 0.2475 ||: 100%|#########9| 11212/11253 [23:29<00:04, 10.10it/s]
2022-03-20 23:48:48,849 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.4179, loss: 0.2476 ||: 100%|#########9| 11214/11253 [23:30<00:03, 10.08it/s]
2022-03-20 23:48:49,059 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1206, loss: 0.2475 ||: 100%|#########9| 11216/11253 [23:30<00:03,  9.90it/s]
2022-03-20 23:48:49,237 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1432, loss: 0.2475 ||: 100%|#########9| 11218/11253 [23:30<00:03, 10.27it/s]
2022-03-20 23:48:49,437 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.0496, loss: 0.2475 ||: 100%|#########9| 11220/11253 [23:30<00:03, 10.18it/s]
2022-03-20 23:48:49,631 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1657, loss: 0.2475 ||: 100%|#########9| 11222/11253 [23:30<00:03, 10.22it/s]
2022-03-20 23:48:49,837 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.3838, loss: 0.2475 ||: 100%|#########9| 11224/11253 [23:31<00:02, 10.06it/s]
2022-03-20 23:48:50,051 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1999, loss: 0.2475 ||: 100%|#########9| 11226/11253 [23:31<00:02,  9.84it/s]
2022-03-20 23:48:50,212 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1521, loss: 0.2475 ||: 100%|#########9| 11228/11253 [23:31<00:02, 10.49it/s]
2022-03-20 23:48:50,386 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1715, loss: 0.2475 ||: 100%|#########9| 11230/11253 [23:31<00:02, 10.77it/s]
2022-03-20 23:48:50,597 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1722, loss: 0.2475 ||: 100%|#########9| 11232/11253 [23:31<00:02, 10.36it/s]
2022-03-20 23:48:50,792 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.5157, loss: 0.2475 ||: 100%|#########9| 11234/11253 [23:31<00:01, 10.32it/s]
2022-03-20 23:48:50,965 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.2305, loss: 0.2475 ||: 100%|#########9| 11236/11253 [23:32<00:01, 10.66it/s]
2022-03-20 23:48:51,199 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1316, loss: 0.2475 ||: 100%|#########9| 11238/11253 [23:32<00:01,  9.94it/s]
2022-03-20 23:48:51,401 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.3700, loss: 0.2475 ||: 100%|#########9| 11240/11253 [23:32<00:01,  9.91it/s]
2022-03-20 23:48:51,618 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.6183, loss: 0.2475 ||: 100%|#########9| 11242/11253 [23:32<00:01,  9.70it/s]
2022-03-20 23:48:51,741 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.2982, loss: 0.2475 ||: 100%|#########9| 11243/11253 [23:32<00:01,  9.38it/s]
2022-03-20 23:48:51,849 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1403, loss: 0.2475 ||: 100%|#########9| 11244/11253 [23:33<00:00,  9.35it/s]
2022-03-20 23:48:52,046 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1706, loss: 0.2475 ||: 100%|#########9| 11246/11253 [23:33<00:00,  9.63it/s]
2022-03-20 23:48:52,147 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 1.1379, loss: 0.2476 ||: 100%|#########9| 11247/11253 [23:33<00:00,  9.69it/s]
2022-03-20 23:48:52,272 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.0271, loss: 0.2475 ||: 100%|#########9| 11248/11253 [23:33<00:00,  9.23it/s]
2022-03-20 23:48:52,374 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.5278, loss: 0.2476 ||: 100%|#########9| 11249/11253 [23:33<00:00,  9.38it/s]
2022-03-20 23:48:52,488 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.0849, loss: 0.2475 ||: 100%|#########9| 11250/11253 [23:33<00:00,  9.21it/s]
2022-03-20 23:48:52,592 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.4215, loss: 0.2476 ||: 100%|#########9| 11251/11253 [23:33<00:00,  9.31it/s]
2022-03-20 23:48:52,702 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.3521, loss: 0.2476 ||: 100%|#########9| 11252/11253 [23:33<00:00,  9.25it/s]
2022-03-20 23:48:52,817 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1553, loss: 0.2476 ||: 100%|##########| 11253/11253 [23:34<00:00,  9.08it/s]
2022-03-20 23:48:52,886 - INFO - tqdm - f1: 0.8606, accuracy: 0.9104, batch_loss: 0.1553, loss: 0.2476 ||: 100%|##########| 11253/11253 [23:34<00:00,  7.96it/s]
2022-03-20 23:48:52,892 - INFO - allennlp.training.trainer - Validating
2022-03-20 23:48:52,895 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-20 23:49:02,923 - INFO - tqdm - f1: 0.8162, accuracy: 0.8724, batch_loss: 0.2329, loss: 0.3775 ||:  12%|#1        | 219/1889 [00:10<01:10, 23.56it/s]
2022-03-20 23:49:12,997 - INFO - tqdm - f1: 0.8087, accuracy: 0.8657, batch_loss: 0.3257, loss: 0.3969 ||:  24%|##3       | 445/1889 [00:20<01:06, 21.70it/s]
2022-03-20 23:49:23,025 - INFO - tqdm - f1: 0.8106, accuracy: 0.8675, batch_loss: 0.2175, loss: 0.3931 ||:  35%|###5      | 668/1889 [00:30<00:54, 22.40it/s]
2022-03-20 23:49:33,096 - INFO - tqdm - f1: 0.8081, accuracy: 0.8658, batch_loss: 0.3742, loss: 0.3997 ||:  46%|####5     | 868/1889 [00:40<01:01, 16.72it/s]
2022-03-20 23:49:43,186 - INFO - tqdm - f1: 0.8109, accuracy: 0.8673, batch_loss: 0.1941, loss: 0.3969 ||:  57%|#####6    | 1072/1889 [00:50<00:34, 23.92it/s]
2022-03-20 23:49:53,195 - INFO - tqdm - f1: 0.8134, accuracy: 0.8680, batch_loss: 0.1244, loss: 0.3982 ||:  68%|######8   | 1285/1889 [01:00<00:41, 14.50it/s]
2022-03-20 23:50:03,235 - INFO - tqdm - f1: 0.8132, accuracy: 0.8681, batch_loss: 0.1111, loss: 0.3982 ||:  80%|#######9  | 1510/1889 [01:10<00:17, 21.31it/s]
2022-03-20 23:50:13,348 - INFO - tqdm - f1: 0.8140, accuracy: 0.8688, batch_loss: 0.5296, loss: 0.3956 ||:  91%|#########1| 1728/1889 [01:20<00:07, 21.81it/s]
2022-03-20 23:50:20,189 - INFO - tqdm - f1: 0.8150, accuracy: 0.8696, batch_loss: 0.7652, loss: 0.3945 ||: 100%|#########9| 1882/1889 [01:27<00:00, 23.17it/s]
2022-03-20 23:50:20,336 - INFO - tqdm - f1: 0.8149, accuracy: 0.8694, batch_loss: 0.1829, loss: 0.3947 ||: 100%|#########9| 1885/1889 [01:27<00:00, 22.26it/s]
2022-03-20 23:50:20,466 - INFO - tqdm - f1: 0.8150, accuracy: 0.8695, batch_loss: 0.3847, loss: 0.3945 ||: 100%|#########9| 1888/1889 [01:27<00:00, 22.49it/s]
2022-03-20 23:50:20,519 - INFO - tqdm - f1: 0.8150, accuracy: 0.8695, batch_loss: 0.3696, loss: 0.3945 ||: 100%|##########| 1889/1889 [01:27<00:00, 21.56it/s]
2022-03-20 23:50:20,536 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 23:50:20,542 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.910  |     0.869
2022-03-20 23:50:20,545 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.861  |     0.815
2022-03-20 23:50:20,548 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 23:50:20,551 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.248  |     0.395
2022-03-20 23:50:20,553 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8644.559  |       N/A
2022-03-20 23:50:20,556 - INFO - allennlp.training.trainer - Epoch duration: 0:25:01.760210
2022-03-20 23:50:20,559 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:53:03
2022-03-20 23:50:20,562 - INFO - allennlp.training.trainer - Epoch 5/9
2022-03-20 23:50:20,565 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-20 23:50:20,571 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 23:50:20,576 - INFO - allennlp.training.trainer - Training
2022-03-20 23:50:20,581 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-20 23:50:30,603 - INFO - tqdm - f1: 0.8596, accuracy: 0.9172, batch_loss: 0.1383, loss: 0.1997 ||:   0%|          | 37/11253 [00:10<18:45,  9.96it/s]
2022-03-20 23:50:40,820 - INFO - tqdm - f1: 0.8843, accuracy: 0.9254, batch_loss: 0.1997, loss: 0.2001 ||:   1%|1         | 139/11253 [00:20<18:52,  9.81it/s]
2022-03-20 23:50:50,829 - INFO - tqdm - f1: 0.8847, accuracy: 0.9255, batch_loss: 0.0864, loss: 0.2015 ||:   2%|2         | 240/11253 [00:30<18:27,  9.95it/s]
2022-03-20 23:51:00,832 - INFO - tqdm - f1: 0.8876, accuracy: 0.9287, batch_loss: 0.1807, loss: 0.1990 ||:   3%|3         | 342/11253 [00:40<17:27, 10.42it/s]
2022-03-20 23:51:10,878 - INFO - tqdm - f1: 0.8847, accuracy: 0.9268, batch_loss: 0.1240, loss: 0.2038 ||:   4%|3         | 443/11253 [00:50<18:42,  9.63it/s]
2022-03-20 23:51:20,984 - INFO - tqdm - f1: 0.8849, accuracy: 0.9271, batch_loss: 0.1511, loss: 0.2008 ||:   5%|4         | 547/11253 [01:00<17:36, 10.13it/s]
2022-03-20 23:51:31,022 - INFO - tqdm - f1: 0.8832, accuracy: 0.9260, batch_loss: 0.1910, loss: 0.2021 ||:   6%|5         | 649/11253 [01:10<17:55,  9.86it/s]
2022-03-20 23:51:41,102 - INFO - tqdm - f1: 0.8824, accuracy: 0.9243, batch_loss: 0.1887, loss: 0.2085 ||:   7%|6         | 752/11253 [01:20<19:54,  8.79it/s]
2022-03-20 23:51:51,168 - INFO - tqdm - f1: 0.8812, accuracy: 0.9235, batch_loss: 0.0957, loss: 0.2116 ||:   8%|7         | 855/11253 [01:30<17:06, 10.13it/s]
2022-03-20 23:52:01,230 - INFO - tqdm - f1: 0.8806, accuracy: 0.9230, batch_loss: 0.1118, loss: 0.2121 ||:   8%|8         | 955/11253 [01:40<16:28, 10.42it/s]
2022-03-20 23:52:11,412 - INFO - tqdm - f1: 0.8800, accuracy: 0.9228, batch_loss: 0.3057, loss: 0.2114 ||:   9%|9         | 1061/11253 [01:50<17:02,  9.97it/s]
2022-03-20 23:52:21,463 - INFO - tqdm - f1: 0.8802, accuracy: 0.9233, batch_loss: 0.0483, loss: 0.2099 ||:  10%|#         | 1162/11253 [02:00<16:05, 10.46it/s]
2022-03-20 23:52:31,590 - INFO - tqdm - f1: 0.8796, accuracy: 0.9229, batch_loss: 0.1408, loss: 0.2096 ||:  11%|#1        | 1267/11253 [02:11<16:09, 10.30it/s]
2022-03-20 23:52:41,601 - INFO - tqdm - f1: 0.8800, accuracy: 0.9231, batch_loss: 0.2027, loss: 0.2107 ||:  12%|#2        | 1371/11253 [02:21<14:39, 11.24it/s]
2022-03-20 23:52:51,699 - INFO - tqdm - f1: 0.8803, accuracy: 0.9235, batch_loss: 0.0888, loss: 0.2089 ||:  13%|#3        | 1474/11253 [02:31<14:43, 11.07it/s]
2022-03-20 23:53:01,776 - INFO - tqdm - f1: 0.8804, accuracy: 0.9241, batch_loss: 0.0124, loss: 0.2073 ||:  14%|#4        | 1577/11253 [02:41<15:40, 10.28it/s]
2022-03-20 23:53:11,888 - INFO - tqdm - f1: 0.8800, accuracy: 0.9240, batch_loss: 0.0276, loss: 0.2078 ||:  15%|#4        | 1682/11253 [02:51<15:44, 10.13it/s]
2022-03-20 23:53:21,955 - INFO - tqdm - f1: 0.8789, accuracy: 0.9239, batch_loss: 0.1160, loss: 0.2086 ||:  16%|#5        | 1782/11253 [03:01<15:32, 10.15it/s]
2022-03-20 23:53:32,113 - INFO - tqdm - f1: 0.8783, accuracy: 0.9234, batch_loss: 0.1690, loss: 0.2100 ||:  17%|#6        | 1886/11253 [03:11<15:40,  9.96it/s]
2022-03-20 23:53:42,186 - INFO - tqdm - f1: 0.8786, accuracy: 0.9230, batch_loss: 0.5811, loss: 0.2114 ||:  18%|#7        | 1988/11253 [03:21<14:57, 10.33it/s]
2022-03-20 23:53:52,231 - INFO - tqdm - f1: 0.8788, accuracy: 0.9229, batch_loss: 0.3627, loss: 0.2120 ||:  19%|#8        | 2092/11253 [03:31<14:38, 10.43it/s]
2022-03-20 23:54:02,325 - INFO - tqdm - f1: 0.8783, accuracy: 0.9227, batch_loss: 0.1001, loss: 0.2118 ||:  20%|#9        | 2195/11253 [03:41<18:20,  8.23it/s]
2022-03-20 23:54:12,467 - INFO - tqdm - f1: 0.8791, accuracy: 0.9231, batch_loss: 0.0959, loss: 0.2103 ||:  20%|##        | 2298/11253 [03:51<14:16, 10.46it/s]
2022-03-20 23:54:22,589 - INFO - tqdm - f1: 0.8789, accuracy: 0.9229, batch_loss: 0.1787, loss: 0.2109 ||:  21%|##1       | 2400/11253 [04:02<13:49, 10.68it/s]
2022-03-20 23:54:32,590 - INFO - tqdm - f1: 0.8784, accuracy: 0.9227, batch_loss: 0.2385, loss: 0.2115 ||:  22%|##2       | 2506/11253 [04:12<13:37, 10.70it/s]
2022-03-20 23:54:42,637 - INFO - tqdm - f1: 0.8783, accuracy: 0.9227, batch_loss: 0.1083, loss: 0.2118 ||:  23%|##3       | 2609/11253 [04:22<13:23, 10.75it/s]
2022-03-20 23:54:52,754 - INFO - tqdm - f1: 0.8775, accuracy: 0.9225, batch_loss: 0.0810, loss: 0.2117 ||:  24%|##4       | 2711/11253 [04:32<14:00, 10.16it/s]
2022-03-20 23:55:02,859 - INFO - tqdm - f1: 0.8779, accuracy: 0.9228, batch_loss: 0.1210, loss: 0.2120 ||:  25%|##4       | 2812/11253 [04:42<13:33, 10.37it/s]
2022-03-20 23:55:12,946 - INFO - tqdm - f1: 0.8779, accuracy: 0.9228, batch_loss: 0.3255, loss: 0.2113 ||:  26%|##5       | 2917/11253 [04:52<13:02, 10.66it/s]
2022-03-20 23:55:23,055 - INFO - tqdm - f1: 0.8777, accuracy: 0.9228, batch_loss: 0.1376, loss: 0.2119 ||:  27%|##6       | 3020/11253 [05:02<13:16, 10.34it/s]
2022-03-20 23:55:33,091 - INFO - tqdm - f1: 0.8773, accuracy: 0.9228, batch_loss: 0.0134, loss: 0.2114 ||:  28%|##7       | 3121/11253 [05:12<13:31, 10.03it/s]
2022-03-20 23:55:43,246 - INFO - tqdm - f1: 0.8766, accuracy: 0.9224, batch_loss: 0.0770, loss: 0.2115 ||:  29%|##8       | 3221/11253 [05:22<13:33,  9.87it/s]
2022-03-20 23:55:53,397 - INFO - tqdm - f1: 0.8767, accuracy: 0.9225, batch_loss: 0.3077, loss: 0.2115 ||:  30%|##9       | 3323/11253 [05:32<12:59, 10.17it/s]
2022-03-20 23:56:03,514 - INFO - tqdm - f1: 0.8766, accuracy: 0.9226, batch_loss: 0.0820, loss: 0.2111 ||:  30%|###       | 3426/11253 [05:42<12:32, 10.40it/s]
2022-03-20 23:56:13,566 - INFO - tqdm - f1: 0.8767, accuracy: 0.9227, batch_loss: 0.3380, loss: 0.2108 ||:  31%|###1      | 3527/11253 [05:52<12:41, 10.14it/s]
2022-03-20 23:56:23,634 - INFO - tqdm - f1: 0.8764, accuracy: 0.9225, batch_loss: 0.3976, loss: 0.2110 ||:  32%|###2      | 3628/11253 [06:03<11:59, 10.60it/s]
2022-03-20 23:56:33,695 - INFO - tqdm - f1: 0.8761, accuracy: 0.9224, batch_loss: 0.3565, loss: 0.2118 ||:  33%|###3      | 3728/11253 [06:13<12:15, 10.24it/s]
2022-03-20 23:56:43,838 - INFO - tqdm - f1: 0.8760, accuracy: 0.9223, batch_loss: 0.0236, loss: 0.2120 ||:  34%|###4      | 3831/11253 [06:23<11:37, 10.64it/s]
2022-03-20 23:56:53,902 - INFO - tqdm - f1: 0.8757, accuracy: 0.9221, batch_loss: 0.1707, loss: 0.2128 ||:  35%|###4      | 3935/11253 [06:33<11:37, 10.49it/s]
2022-03-20 23:57:04,092 - INFO - tqdm - f1: 0.8759, accuracy: 0.9222, batch_loss: 0.1777, loss: 0.2126 ||:  36%|###5      | 4039/11253 [06:43<11:35, 10.37it/s]
2022-03-20 23:57:14,098 - INFO - tqdm - f1: 0.8758, accuracy: 0.9219, batch_loss: 0.2051, loss: 0.2133 ||:  37%|###6      | 4142/11253 [06:53<11:25, 10.38it/s]
2022-03-20 23:57:24,225 - INFO - tqdm - f1: 0.8753, accuracy: 0.9216, batch_loss: 0.2312, loss: 0.2138 ||:  38%|###7      | 4241/11253 [07:03<15:43,  7.43it/s]
2022-03-20 23:57:34,247 - INFO - tqdm - f1: 0.8755, accuracy: 0.9218, batch_loss: 0.4823, loss: 0.2134 ||:  39%|###8      | 4342/11253 [07:13<11:25, 10.09it/s]
2022-03-20 23:57:44,296 - INFO - tqdm - f1: 0.8753, accuracy: 0.9217, batch_loss: 0.3862, loss: 0.2134 ||:  39%|###9      | 4443/11253 [07:23<10:43, 10.58it/s]
2022-03-20 23:57:54,388 - INFO - tqdm - f1: 0.8752, accuracy: 0.9216, batch_loss: 0.1814, loss: 0.2139 ||:  40%|####      | 4546/11253 [07:33<10:56, 10.21it/s]
2022-03-20 23:58:04,398 - INFO - tqdm - f1: 0.8747, accuracy: 0.9212, batch_loss: 0.2199, loss: 0.2146 ||:  41%|####1     | 4648/11253 [07:43<11:15,  9.78it/s]
2022-03-20 23:58:14,583 - INFO - tqdm - f1: 0.8745, accuracy: 0.9211, batch_loss: 0.1523, loss: 0.2147 ||:  42%|####2     | 4749/11253 [07:53<10:46, 10.06it/s]
2022-03-20 23:58:24,629 - INFO - tqdm - f1: 0.8745, accuracy: 0.9212, batch_loss: 0.3551, loss: 0.2147 ||:  43%|####3     | 4849/11253 [08:04<10:13, 10.44it/s]
2022-03-20 23:58:34,708 - INFO - tqdm - f1: 0.8746, accuracy: 0.9212, batch_loss: 0.0570, loss: 0.2146 ||:  44%|####3     | 4951/11253 [08:14<10:44,  9.78it/s]
2022-03-20 23:58:44,734 - INFO - tqdm - f1: 0.8748, accuracy: 0.9213, batch_loss: 0.3145, loss: 0.2147 ||:  45%|####4     | 5053/11253 [08:24<09:44, 10.61it/s]
2022-03-20 23:58:54,838 - INFO - tqdm - f1: 0.8743, accuracy: 0.9211, batch_loss: 0.0767, loss: 0.2151 ||:  46%|####5     | 5161/11253 [08:34<09:22, 10.84it/s]
2022-03-20 23:59:04,844 - INFO - tqdm - f1: 0.8745, accuracy: 0.9210, batch_loss: 0.5528, loss: 0.2155 ||:  47%|####6     | 5262/11253 [08:44<09:38, 10.36it/s]
2022-03-20 23:59:15,038 - INFO - tqdm - f1: 0.8742, accuracy: 0.9209, batch_loss: 0.1564, loss: 0.2155 ||:  48%|####7     | 5364/11253 [08:54<09:33, 10.28it/s]
2022-03-20 23:59:25,137 - INFO - tqdm - f1: 0.8742, accuracy: 0.9208, batch_loss: 0.1776, loss: 0.2159 ||:  49%|####8     | 5464/11253 [09:04<09:20, 10.33it/s]
2022-03-20 23:59:35,221 - INFO - tqdm - f1: 0.8743, accuracy: 0.9209, batch_loss: 0.2752, loss: 0.2157 ||:  49%|####9     | 5555/11253 [09:14<09:07, 10.41it/s]
2022-03-20 23:59:45,290 - INFO - tqdm - f1: 0.8743, accuracy: 0.9207, batch_loss: 0.2556, loss: 0.2163 ||:  50%|#####     | 5656/11253 [09:24<10:18,  9.05it/s]
2022-03-20 23:59:55,362 - INFO - tqdm - f1: 0.8740, accuracy: 0.9205, batch_loss: 0.0688, loss: 0.2167 ||:  51%|#####1    | 5760/11253 [09:34<08:30, 10.76it/s]
2022-03-21 00:00:05,498 - INFO - tqdm - f1: 0.8739, accuracy: 0.9205, batch_loss: 0.3916, loss: 0.2168 ||:  52%|#####2    | 5864/11253 [09:44<08:44, 10.28it/s]
2022-03-21 00:00:15,573 - INFO - tqdm - f1: 0.8743, accuracy: 0.9207, batch_loss: 0.1710, loss: 0.2165 ||:  53%|#####3    | 5965/11253 [09:54<09:19,  9.45it/s]
2022-03-21 00:00:25,676 - INFO - tqdm - f1: 0.8743, accuracy: 0.9207, batch_loss: 0.0887, loss: 0.2166 ||:  54%|#####3    | 6067/11253 [10:05<08:13, 10.50it/s]
2022-03-21 00:00:35,782 - INFO - tqdm - f1: 0.8742, accuracy: 0.9207, batch_loss: 0.2166, loss: 0.2164 ||:  55%|#####4    | 6169/11253 [10:15<08:22, 10.11it/s]
2022-03-21 00:00:45,785 - INFO - tqdm - f1: 0.8744, accuracy: 0.9208, batch_loss: 0.6311, loss: 0.2162 ||:  56%|#####5    | 6270/11253 [10:25<08:08, 10.20it/s]
2022-03-21 00:00:55,799 - INFO - tqdm - f1: 0.8742, accuracy: 0.9206, batch_loss: 0.2008, loss: 0.2168 ||:  57%|#####6    | 6370/11253 [10:35<07:48, 10.42it/s]
2022-03-21 00:01:05,812 - INFO - tqdm - f1: 0.8745, accuracy: 0.9207, batch_loss: 0.1227, loss: 0.2166 ||:  57%|#####7    | 6470/11253 [10:45<07:44, 10.30it/s]
2022-03-21 00:01:15,901 - INFO - tqdm - f1: 0.8744, accuracy: 0.9206, batch_loss: 0.1009, loss: 0.2171 ||:  58%|#####8    | 6571/11253 [10:55<08:21,  9.33it/s]
2022-03-21 00:01:25,994 - INFO - tqdm - f1: 0.8744, accuracy: 0.9207, batch_loss: 0.1803, loss: 0.2167 ||:  59%|#####9    | 6671/11253 [11:05<07:35, 10.06it/s]
2022-03-21 00:01:36,067 - INFO - tqdm - f1: 0.8745, accuracy: 0.9208, batch_loss: 0.0105, loss: 0.2167 ||:  60%|######    | 6772/11253 [11:15<07:13, 10.35it/s]
2022-03-21 00:01:46,206 - INFO - tqdm - f1: 0.8744, accuracy: 0.9206, batch_loss: 0.3331, loss: 0.2172 ||:  61%|######1   | 6876/11253 [11:25<06:32, 11.16it/s]
2022-03-21 00:01:56,365 - INFO - tqdm - f1: 0.8746, accuracy: 0.9207, batch_loss: 0.1804, loss: 0.2174 ||:  62%|######2   | 6979/11253 [11:35<06:32, 10.88it/s]
2022-03-21 00:02:06,549 - INFO - tqdm - f1: 0.8747, accuracy: 0.9208, batch_loss: 0.2033, loss: 0.2175 ||:  63%|######2   | 7082/11253 [11:45<07:12,  9.65it/s]
2022-03-21 00:02:16,642 - INFO - tqdm - f1: 0.8748, accuracy: 0.9207, batch_loss: 0.1073, loss: 0.2175 ||:  64%|######3   | 7186/11253 [11:56<06:59,  9.69it/s]
2022-03-21 00:02:26,816 - INFO - tqdm - f1: 0.8748, accuracy: 0.9207, batch_loss: 0.1354, loss: 0.2176 ||:  65%|######4   | 7292/11253 [12:06<06:19, 10.42it/s]
2022-03-21 00:02:36,965 - INFO - tqdm - f1: 0.8748, accuracy: 0.9207, batch_loss: 0.3851, loss: 0.2178 ||:  66%|######5   | 7394/11253 [12:16<07:04,  9.08it/s]
2022-03-21 00:02:47,023 - INFO - tqdm - f1: 0.8747, accuracy: 0.9207, batch_loss: 0.3308, loss: 0.2180 ||:  67%|######6   | 7498/11253 [12:26<05:22, 11.65it/s]
2022-03-21 00:02:57,046 - INFO - tqdm - f1: 0.8745, accuracy: 0.9204, batch_loss: 0.1569, loss: 0.2186 ||:  68%|######7   | 7601/11253 [12:36<05:39, 10.77it/s]
2022-03-21 00:03:07,164 - INFO - tqdm - f1: 0.8743, accuracy: 0.9204, batch_loss: 0.3688, loss: 0.2189 ||:  68%|######8   | 7705/11253 [12:46<05:41, 10.39it/s]
2022-03-21 00:03:17,312 - INFO - tqdm - f1: 0.8746, accuracy: 0.9205, batch_loss: 0.0651, loss: 0.2187 ||:  69%|######9   | 7809/11253 [12:56<05:08, 11.17it/s]
2022-03-21 00:03:27,333 - INFO - tqdm - f1: 0.8746, accuracy: 0.9205, batch_loss: 0.1227, loss: 0.2189 ||:  70%|#######   | 7910/11253 [13:06<05:24, 10.29it/s]
2022-03-21 00:03:37,373 - INFO - tqdm - f1: 0.8742, accuracy: 0.9203, batch_loss: 0.2125, loss: 0.2192 ||:  71%|#######1  | 8015/11253 [13:16<05:13, 10.33it/s]
2022-03-21 00:03:47,484 - INFO - tqdm - f1: 0.8743, accuracy: 0.9204, batch_loss: 0.1285, loss: 0.2194 ||:  72%|#######2  | 8117/11253 [13:26<05:10, 10.11it/s]
2022-03-21 00:03:57,565 - INFO - tqdm - f1: 0.8743, accuracy: 0.9204, batch_loss: 0.1616, loss: 0.2195 ||:  73%|#######3  | 8220/11253 [13:36<04:45, 10.62it/s]
2022-03-21 00:04:07,661 - INFO - tqdm - f1: 0.8743, accuracy: 0.9203, batch_loss: 0.0786, loss: 0.2195 ||:  74%|#######3  | 8326/11253 [13:47<04:41, 10.41it/s]
2022-03-21 00:04:17,805 - INFO - tqdm - f1: 0.8743, accuracy: 0.9203, batch_loss: 0.0431, loss: 0.2196 ||:  75%|#######4  | 8428/11253 [13:57<04:27, 10.55it/s]
2022-03-21 00:04:27,807 - INFO - tqdm - f1: 0.8740, accuracy: 0.9202, batch_loss: 0.3140, loss: 0.2201 ||:  76%|#######5  | 8524/11253 [14:07<04:35,  9.90it/s]
2022-03-21 00:04:37,844 - INFO - tqdm - f1: 0.8739, accuracy: 0.9201, batch_loss: 0.5792, loss: 0.2204 ||:  77%|#######6  | 8625/11253 [14:17<04:14, 10.31it/s]
2022-03-21 00:04:48,019 - INFO - tqdm - f1: 0.8739, accuracy: 0.9202, batch_loss: 0.4672, loss: 0.2203 ||:  77%|#######7  | 8721/11253 [14:27<04:11, 10.06it/s]
2022-03-21 00:04:58,107 - INFO - tqdm - f1: 0.8739, accuracy: 0.9201, batch_loss: 0.3845, loss: 0.2204 ||:  78%|#######8  | 8823/11253 [14:37<03:54, 10.38it/s]
2022-03-21 00:05:08,232 - INFO - tqdm - f1: 0.8737, accuracy: 0.9200, batch_loss: 0.4561, loss: 0.2203 ||:  79%|#######9  | 8925/11253 [14:47<03:46, 10.26it/s]
2022-03-21 00:05:18,258 - INFO - tqdm - f1: 0.8736, accuracy: 0.9200, batch_loss: 0.5123, loss: 0.2207 ||:  80%|########  | 9028/11253 [14:57<03:33, 10.42it/s]
2022-03-21 00:05:28,393 - INFO - tqdm - f1: 0.8734, accuracy: 0.9198, batch_loss: 0.0787, loss: 0.2208 ||:  81%|########1 | 9131/11253 [15:07<03:20, 10.58it/s]
2022-03-21 00:05:38,460 - INFO - tqdm - f1: 0.8734, accuracy: 0.9198, batch_loss: 0.1651, loss: 0.2210 ||:  82%|########2 | 9234/11253 [15:17<03:25,  9.83it/s]
2022-03-21 00:05:48,656 - INFO - tqdm - f1: 0.8734, accuracy: 0.9198, batch_loss: 0.0663, loss: 0.2212 ||:  83%|########2 | 9339/11253 [15:28<02:52, 11.09it/s]
2022-03-21 00:05:58,657 - INFO - tqdm - f1: 0.8733, accuracy: 0.9197, batch_loss: 0.8542, loss: 0.2212 ||:  84%|########3 | 9439/11253 [15:38<03:39,  8.28it/s]
2022-03-21 00:06:08,663 - INFO - tqdm - f1: 0.8733, accuracy: 0.9197, batch_loss: 0.3565, loss: 0.2214 ||:  85%|########4 | 9542/11253 [15:48<02:46, 10.29it/s]
2022-03-21 00:06:18,843 - INFO - tqdm - f1: 0.8734, accuracy: 0.9197, batch_loss: 0.0438, loss: 0.2213 ||:  86%|########5 | 9646/11253 [15:58<02:33, 10.45it/s]
2022-03-21 00:06:29,029 - INFO - tqdm - f1: 0.8731, accuracy: 0.9196, batch_loss: 0.0589, loss: 0.2216 ||:  87%|########6 | 9752/11253 [16:08<02:28, 10.08it/s]
2022-03-21 00:06:39,193 - INFO - tqdm - f1: 0.8729, accuracy: 0.9194, batch_loss: 0.3024, loss: 0.2217 ||:  88%|########7 | 9857/11253 [16:18<02:18, 10.10it/s]
2022-03-21 00:06:49,214 - INFO - tqdm - f1: 0.8729, accuracy: 0.9195, batch_loss: 0.0779, loss: 0.2219 ||:  89%|########8 | 9959/11253 [16:28<02:07, 10.14it/s]
2022-03-21 00:06:59,282 - INFO - tqdm - f1: 0.8730, accuracy: 0.9196, batch_loss: 0.2542, loss: 0.2219 ||:  89%|########9 | 10062/11253 [16:38<01:57, 10.12it/s]
2022-03-21 00:07:09,445 - INFO - tqdm - f1: 0.8730, accuracy: 0.9196, batch_loss: 0.1016, loss: 0.2221 ||:  90%|######### | 10164/11253 [16:48<01:43, 10.50it/s]
2022-03-21 00:07:19,473 - INFO - tqdm - f1: 0.8731, accuracy: 0.9196, batch_loss: 0.1089, loss: 0.2222 ||:  91%|#########1| 10266/11253 [16:58<01:41,  9.71it/s]
2022-03-21 00:07:29,591 - INFO - tqdm - f1: 0.8731, accuracy: 0.9195, batch_loss: 0.3513, loss: 0.2224 ||:  92%|#########2| 10367/11253 [17:09<01:24, 10.52it/s]
2022-03-21 00:07:39,641 - INFO - tqdm - f1: 0.8731, accuracy: 0.9195, batch_loss: 0.2529, loss: 0.2226 ||:  93%|#########3| 10469/11253 [17:19<01:12, 10.78it/s]
2022-03-21 00:07:49,731 - INFO - tqdm - f1: 0.8731, accuracy: 0.9195, batch_loss: 0.4577, loss: 0.2226 ||:  94%|#########3| 10573/11253 [17:29<01:03, 10.75it/s]
2022-03-21 00:07:59,864 - INFO - tqdm - f1: 0.8731, accuracy: 0.9195, batch_loss: 0.3543, loss: 0.2225 ||:  95%|#########4| 10680/11253 [17:39<00:53, 10.64it/s]
2022-03-21 00:08:09,876 - INFO - tqdm - f1: 0.8730, accuracy: 0.9194, batch_loss: 0.0529, loss: 0.2225 ||:  96%|#########5| 10781/11253 [17:49<00:49,  9.45it/s]
2022-03-21 00:08:20,039 - INFO - tqdm - f1: 0.8729, accuracy: 0.9193, batch_loss: 0.4909, loss: 0.2227 ||:  97%|#########6| 10884/11253 [17:59<00:34, 10.57it/s]
2022-03-21 00:08:30,191 - INFO - tqdm - f1: 0.8729, accuracy: 0.9192, batch_loss: 0.0693, loss: 0.2228 ||:  98%|#########7| 10988/11253 [18:09<00:25, 10.57it/s]
2022-03-21 00:08:40,203 - INFO - tqdm - f1: 0.8727, accuracy: 0.9191, batch_loss: 0.2443, loss: 0.2231 ||:  99%|#########8| 11091/11253 [18:19<00:15, 10.56it/s]
2022-03-21 00:08:50,267 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.0459, loss: 0.2230 ||:  99%|#########9| 11192/11253 [18:29<00:06,  9.01it/s]
2022-03-21 00:08:50,787 - INFO - tqdm - f1: 0.8729, accuracy: 0.9192, batch_loss: 0.1117, loss: 0.2230 ||: 100%|#########9| 11198/11253 [18:30<00:05, 10.46it/s]
2022-03-21 00:08:50,996 - INFO - tqdm - f1: 0.8729, accuracy: 0.9192, batch_loss: 0.1812, loss: 0.2230 ||: 100%|#########9| 11200/11253 [18:30<00:05, 10.16it/s]
2022-03-21 00:08:51,221 - INFO - tqdm - f1: 0.8729, accuracy: 0.9192, batch_loss: 0.0578, loss: 0.2230 ||: 100%|#########9| 11202/11253 [18:30<00:05,  9.72it/s]
2022-03-21 00:08:51,327 - INFO - tqdm - f1: 0.8729, accuracy: 0.9192, batch_loss: 0.2410, loss: 0.2230 ||: 100%|#########9| 11203/11253 [18:30<00:05,  9.67it/s]
2022-03-21 00:08:51,509 - INFO - tqdm - f1: 0.8729, accuracy: 0.9192, batch_loss: 0.7078, loss: 0.2230 ||: 100%|#########9| 11205/11253 [18:30<00:04, 10.09it/s]
2022-03-21 00:08:51,705 - INFO - tqdm - f1: 0.8729, accuracy: 0.9192, batch_loss: 0.0691, loss: 0.2230 ||: 100%|#########9| 11207/11253 [18:31<00:04, 10.13it/s]
2022-03-21 00:08:51,920 - INFO - tqdm - f1: 0.8729, accuracy: 0.9192, batch_loss: 0.0351, loss: 0.2230 ||: 100%|#########9| 11209/11253 [18:31<00:04,  9.84it/s]
2022-03-21 00:08:52,032 - INFO - tqdm - f1: 0.8729, accuracy: 0.9192, batch_loss: 0.1038, loss: 0.2229 ||: 100%|#########9| 11210/11253 [18:31<00:04,  9.65it/s]
2022-03-21 00:08:52,157 - INFO - tqdm - f1: 0.8729, accuracy: 0.9192, batch_loss: 0.0084, loss: 0.2229 ||: 100%|#########9| 11211/11253 [18:31<00:04,  9.27it/s]
2022-03-21 00:08:52,373 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.3731, loss: 0.2230 ||: 100%|#########9| 11213/11253 [18:31<00:04,  9.26it/s]
2022-03-21 00:08:52,577 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.2583, loss: 0.2230 ||: 100%|#########9| 11215/11253 [18:31<00:04,  9.44it/s]
2022-03-21 00:08:52,680 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.2805, loss: 0.2230 ||: 100%|#########9| 11216/11253 [18:32<00:03,  9.50it/s]
2022-03-21 00:08:52,800 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.5264, loss: 0.2231 ||: 100%|#########9| 11217/11253 [18:32<00:03,  9.22it/s]
2022-03-21 00:08:52,912 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.0570, loss: 0.2231 ||: 100%|#########9| 11218/11253 [18:32<00:03,  9.14it/s]
2022-03-21 00:08:53,018 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.3569, loss: 0.2231 ||: 100%|#########9| 11219/11253 [18:32<00:03,  9.21it/s]
2022-03-21 00:08:53,192 - INFO - tqdm - f1: 0.8729, accuracy: 0.9192, batch_loss: 0.0238, loss: 0.2230 ||: 100%|#########9| 11221/11253 [18:32<00:03, 10.06it/s]
2022-03-21 00:08:53,380 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.1301, loss: 0.2231 ||: 100%|#########9| 11223/11253 [18:32<00:02, 10.27it/s]
2022-03-21 00:08:53,548 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.2777, loss: 0.2231 ||: 100%|#########9| 11225/11253 [18:32<00:02, 10.79it/s]
2022-03-21 00:08:53,774 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.1692, loss: 0.2231 ||: 100%|#########9| 11227/11253 [18:33<00:02, 10.05it/s]
2022-03-21 00:08:53,998 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.3235, loss: 0.2231 ||: 100%|#########9| 11229/11253 [18:33<00:02,  9.66it/s]
2022-03-21 00:08:54,126 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.0102, loss: 0.2230 ||: 100%|#########9| 11230/11253 [18:33<00:02,  9.25it/s]
2022-03-21 00:08:54,302 - INFO - tqdm - f1: 0.8729, accuracy: 0.9192, batch_loss: 0.3283, loss: 0.2231 ||: 100%|#########9| 11232/11253 [18:33<00:02,  9.89it/s]
2022-03-21 00:08:54,409 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.3113, loss: 0.2231 ||: 100%|#########9| 11233/11253 [18:33<00:02,  9.77it/s]
2022-03-21 00:08:54,512 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.5074, loss: 0.2231 ||: 100%|#########9| 11234/11253 [18:33<00:01,  9.77it/s]
2022-03-21 00:08:54,708 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.0595, loss: 0.2231 ||: 100%|#########9| 11236/11253 [18:34<00:01,  9.93it/s]
2022-03-21 00:08:54,812 - INFO - tqdm - f1: 0.8728, accuracy: 0.9192, batch_loss: 0.1603, loss: 0.2231 ||: 100%|#########9| 11237/11253 [18:34<00:01,  9.86it/s]
2022-03-21 00:08:54,918 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.4318, loss: 0.2231 ||: 100%|#########9| 11238/11253 [18:34<00:01,  9.75it/s]
2022-03-21 00:08:55,024 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.1715, loss: 0.2231 ||: 100%|#########9| 11239/11253 [18:34<00:01,  9.66it/s]
2022-03-21 00:08:55,139 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.6384, loss: 0.2231 ||: 100%|#########9| 11240/11253 [18:34<00:01,  9.40it/s]
2022-03-21 00:08:55,257 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.2163, loss: 0.2231 ||: 100%|#########9| 11241/11253 [18:34<00:01,  9.12it/s]
2022-03-21 00:08:55,386 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.1675, loss: 0.2231 ||: 100%|#########9| 11242/11253 [18:34<00:01,  8.70it/s]
2022-03-21 00:08:55,498 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.3580, loss: 0.2231 ||: 100%|#########9| 11243/11253 [18:34<00:01,  8.75it/s]
2022-03-21 00:08:55,604 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.1696, loss: 0.2231 ||: 100%|#########9| 11244/11253 [18:35<00:00,  9.01it/s]
2022-03-21 00:08:55,713 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.4328, loss: 0.2232 ||: 100%|#########9| 11245/11253 [18:35<00:00,  8.99it/s]
2022-03-21 00:08:55,815 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.1669, loss: 0.2232 ||: 100%|#########9| 11246/11253 [18:35<00:00,  9.21it/s]
2022-03-21 00:08:56,015 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.0519, loss: 0.2232 ||: 100%|#########9| 11248/11253 [18:35<00:00,  9.57it/s]
2022-03-21 00:08:56,120 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.1247, loss: 0.2231 ||: 100%|#########9| 11249/11253 [18:35<00:00,  9.55it/s]
2022-03-21 00:08:56,228 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.2509, loss: 0.2231 ||: 100%|#########9| 11250/11253 [18:35<00:00,  9.47it/s]
2022-03-21 00:08:56,414 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.1627, loss: 0.2231 ||: 100%|#########9| 11252/11253 [18:35<00:00,  9.99it/s]
2022-03-21 00:08:56,578 - INFO - tqdm - f1: 0.8728, accuracy: 0.9191, batch_loss: 0.1449, loss: 0.2231 ||: 100%|##########| 11253/11253 [18:35<00:00, 10.08it/s]
2022-03-21 00:08:56,599 - INFO - allennlp.training.trainer - Validating
2022-03-21 00:08:56,602 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 00:09:06,662 - INFO - tqdm - f1: 0.8133, accuracy: 0.8623, batch_loss: 0.4508, loss: 0.4339 ||:  12%|#1        | 222/1889 [00:10<01:13, 22.79it/s]
2022-03-21 00:09:16,765 - INFO - tqdm - f1: 0.8178, accuracy: 0.8680, batch_loss: 1.2356, loss: 0.4221 ||:  24%|##3       | 444/1889 [00:20<01:01, 23.44it/s]
2022-03-21 00:09:26,888 - INFO - tqdm - f1: 0.8126, accuracy: 0.8667, batch_loss: 0.0819, loss: 0.4209 ||:  35%|###5      | 667/1889 [00:30<00:58, 21.02it/s]
2022-03-21 00:09:36,907 - INFO - tqdm - f1: 0.8120, accuracy: 0.8665, batch_loss: 0.0213, loss: 0.4242 ||:  47%|####7     | 890/1889 [00:40<00:45, 22.14it/s]
2022-03-21 00:09:46,927 - INFO - tqdm - f1: 0.8136, accuracy: 0.8672, batch_loss: 0.2442, loss: 0.4213 ||:  59%|#####8    | 1109/1889 [00:50<00:37, 21.07it/s]
2022-03-21 00:09:57,014 - INFO - tqdm - f1: 0.8163, accuracy: 0.8684, batch_loss: 0.1291, loss: 0.4224 ||:  71%|#######   | 1335/1889 [01:00<00:25, 21.44it/s]
2022-03-21 00:10:07,148 - INFO - tqdm - f1: 0.8149, accuracy: 0.8679, batch_loss: 0.0776, loss: 0.4223 ||:  83%|########2 | 1566/1889 [01:10<00:15, 20.98it/s]
2022-03-21 00:10:17,225 - INFO - tqdm - f1: 0.8136, accuracy: 0.8673, batch_loss: 0.5177, loss: 0.4241 ||:  95%|#########4| 1794/1889 [01:20<00:04, 23.00it/s]
2022-03-21 00:10:21,156 - INFO - tqdm - f1: 0.8145, accuracy: 0.8679, batch_loss: 0.2354, loss: 0.4219 ||: 100%|#########9| 1882/1889 [01:24<00:00, 22.77it/s]
2022-03-21 00:10:21,292 - INFO - tqdm - f1: 0.8146, accuracy: 0.8680, batch_loss: 0.0707, loss: 0.4217 ||: 100%|#########9| 1885/1889 [01:24<00:00, 22.57it/s]
2022-03-21 00:10:21,416 - INFO - tqdm - f1: 0.8146, accuracy: 0.8681, batch_loss: 0.5792, loss: 0.4218 ||: 100%|#########9| 1888/1889 [01:24<00:00, 22.99it/s]
2022-03-21 00:10:21,477 - INFO - tqdm - f1: 0.8146, accuracy: 0.8680, batch_loss: 0.9051, loss: 0.4221 ||: 100%|##########| 1889/1889 [01:24<00:00, 22.26it/s]
2022-03-21 00:10:21,495 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 00:10:21,497 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.919  |     0.868
2022-03-21 00:10:21,499 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.873  |     0.815
2022-03-21 00:10:21,502 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 00:10:21,504 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.223  |     0.422
2022-03-21 00:10:21,506 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8644.559  |       N/A
2022-03-21 00:10:21,509 - INFO - allennlp.training.trainer - Epoch duration: 0:20:00.946643
2022-03-21 00:10:21,511 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:28:43
2022-03-21 00:10:21,513 - INFO - allennlp.training.trainer - Epoch 6/9
2022-03-21 00:10:21,516 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 00:10:21,519 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 00:10:21,522 - INFO - allennlp.training.trainer - Training
2022-03-21 00:10:21,525 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 00:10:31,677 - INFO - tqdm - f1: 0.8908, accuracy: 0.9349, batch_loss: 0.1155, loss: 0.1680 ||:   1%|          | 95/11253 [00:10<16:59, 10.95it/s]
2022-03-21 00:10:41,765 - INFO - tqdm - f1: 0.8911, accuracy: 0.9322, batch_loss: 0.1853, loss: 0.1756 ||:   2%|1         | 199/11253 [00:20<17:54, 10.29it/s]
2022-03-21 00:10:51,806 - INFO - tqdm - f1: 0.8970, accuracy: 0.9356, batch_loss: 0.2179, loss: 0.1735 ||:   3%|2         | 300/11253 [00:30<17:14, 10.59it/s]
2022-03-21 00:11:01,995 - INFO - tqdm - f1: 0.8981, accuracy: 0.9378, batch_loss: 0.0359, loss: 0.1708 ||:   4%|3         | 406/11253 [00:40<18:11,  9.93it/s]
2022-03-21 00:11:12,060 - INFO - tqdm - f1: 0.9004, accuracy: 0.9390, batch_loss: 0.3950, loss: 0.1700 ||:   4%|4         | 506/11253 [00:50<17:41, 10.12it/s]
2022-03-21 00:11:22,094 - INFO - tqdm - f1: 0.9009, accuracy: 0.9390, batch_loss: 0.1525, loss: 0.1735 ||:   5%|5         | 611/11253 [01:00<16:59, 10.44it/s]
2022-03-21 00:11:32,196 - INFO - tqdm - f1: 0.8989, accuracy: 0.9375, batch_loss: 0.1635, loss: 0.1762 ||:   6%|6         | 714/11253 [01:10<17:46,  9.89it/s]
2022-03-21 00:11:42,346 - INFO - tqdm - f1: 0.8978, accuracy: 0.9363, batch_loss: 0.0732, loss: 0.1775 ||:   7%|7         | 817/11253 [01:20<17:26,  9.97it/s]
2022-03-21 00:11:52,474 - INFO - tqdm - f1: 0.8983, accuracy: 0.9365, batch_loss: 0.1452, loss: 0.1777 ||:   8%|8         | 922/11253 [01:30<16:48, 10.25it/s]
2022-03-21 00:12:02,564 - INFO - tqdm - f1: 0.8965, accuracy: 0.9349, batch_loss: 0.1222, loss: 0.1809 ||:   9%|9         | 1028/11253 [01:41<16:05, 10.59it/s]
2022-03-21 00:12:12,715 - INFO - tqdm - f1: 0.8963, accuracy: 0.9352, batch_loss: 0.0439, loss: 0.1794 ||:  10%|#         | 1131/11253 [01:51<16:23, 10.29it/s]
2022-03-21 00:12:22,759 - INFO - tqdm - f1: 0.8957, accuracy: 0.9346, batch_loss: 0.0860, loss: 0.1811 ||:  11%|#         | 1233/11253 [02:01<16:05, 10.38it/s]
2022-03-21 00:12:32,928 - INFO - tqdm - f1: 0.8960, accuracy: 0.9347, batch_loss: 0.1384, loss: 0.1814 ||:  12%|#1        | 1337/11253 [02:11<15:20, 10.77it/s]
2022-03-21 00:12:43,022 - INFO - tqdm - f1: 0.8957, accuracy: 0.9348, batch_loss: 0.1747, loss: 0.1806 ||:  13%|#2        | 1436/11253 [02:21<17:10,  9.53it/s]
2022-03-21 00:12:53,204 - INFO - tqdm - f1: 0.8959, accuracy: 0.9349, batch_loss: 0.1938, loss: 0.1807 ||:  14%|#3        | 1538/11253 [02:31<15:58, 10.14it/s]
2022-03-21 00:13:03,375 - INFO - tqdm - f1: 0.8957, accuracy: 0.9345, batch_loss: 0.0100, loss: 0.1817 ||:  15%|#4        | 1640/11253 [02:41<16:02,  9.99it/s]
2022-03-21 00:13:13,421 - INFO - tqdm - f1: 0.8959, accuracy: 0.9348, batch_loss: 0.0696, loss: 0.1817 ||:  15%|#5        | 1742/11253 [02:51<14:57, 10.59it/s]
2022-03-21 00:13:23,456 - INFO - tqdm - f1: 0.8961, accuracy: 0.9349, batch_loss: 0.0541, loss: 0.1818 ||:  16%|#6        | 1846/11253 [03:01<15:32, 10.09it/s]
2022-03-21 00:13:33,536 - INFO - tqdm - f1: 0.8960, accuracy: 0.9349, batch_loss: 0.1383, loss: 0.1813 ||:  17%|#7        | 1948/11253 [03:12<15:36,  9.94it/s]
2022-03-21 00:13:43,697 - INFO - tqdm - f1: 0.8954, accuracy: 0.9349, batch_loss: 0.1563, loss: 0.1811 ||:  18%|#8        | 2052/11253 [03:22<14:59, 10.22it/s]
2022-03-21 00:13:53,708 - INFO - tqdm - f1: 0.8951, accuracy: 0.9347, batch_loss: 0.1877, loss: 0.1814 ||:  19%|#9        | 2157/11253 [03:32<13:59, 10.83it/s]
2022-03-21 00:14:03,782 - INFO - tqdm - f1: 0.8950, accuracy: 0.9344, batch_loss: 0.1525, loss: 0.1829 ||:  20%|##        | 2260/11253 [03:42<14:41, 10.20it/s]
2022-03-21 00:14:13,812 - INFO - tqdm - f1: 0.8946, accuracy: 0.9340, batch_loss: 0.2246, loss: 0.1838 ||:  21%|##        | 2362/11253 [03:52<13:55, 10.64it/s]
2022-03-21 00:14:23,857 - INFO - tqdm - f1: 0.8940, accuracy: 0.9335, batch_loss: 0.2158, loss: 0.1845 ||:  22%|##1       | 2464/11253 [04:02<13:41, 10.70it/s]
2022-03-21 00:14:33,912 - INFO - tqdm - f1: 0.8937, accuracy: 0.9334, batch_loss: 0.0482, loss: 0.1845 ||:  23%|##2       | 2565/11253 [04:12<14:29,  9.99it/s]
2022-03-21 00:14:43,961 - INFO - tqdm - f1: 0.8940, accuracy: 0.9335, batch_loss: 0.1270, loss: 0.1848 ||:  24%|##3       | 2666/11253 [04:22<13:58, 10.24it/s]
2022-03-21 00:14:54,086 - INFO - tqdm - f1: 0.8932, accuracy: 0.9332, batch_loss: 0.0039, loss: 0.1845 ||:  25%|##4       | 2769/11253 [04:32<14:36,  9.68it/s]
2022-03-21 00:15:04,147 - INFO - tqdm - f1: 0.8929, accuracy: 0.9329, batch_loss: 0.1658, loss: 0.1856 ||:  25%|##5       | 2867/11253 [04:42<14:12,  9.83it/s]
2022-03-21 00:15:14,315 - INFO - tqdm - f1: 0.8931, accuracy: 0.9331, batch_loss: 0.0317, loss: 0.1855 ||:  26%|##6       | 2970/11253 [04:52<14:35,  9.46it/s]
2022-03-21 00:15:24,483 - INFO - tqdm - f1: 0.8931, accuracy: 0.9331, batch_loss: 0.1051, loss: 0.1857 ||:  27%|##7       | 3073/11253 [05:02<13:23, 10.18it/s]
2022-03-21 00:15:34,581 - INFO - tqdm - f1: 0.8922, accuracy: 0.9327, batch_loss: 0.1186, loss: 0.1862 ||:  28%|##8       | 3175/11253 [05:13<13:51,  9.72it/s]
2022-03-21 00:15:44,648 - INFO - tqdm - f1: 0.8920, accuracy: 0.9326, batch_loss: 0.0983, loss: 0.1870 ||:  29%|##9       | 3275/11253 [05:23<13:12, 10.07it/s]
2022-03-21 00:15:54,746 - INFO - tqdm - f1: 0.8915, accuracy: 0.9323, batch_loss: 0.0435, loss: 0.1878 ||:  30%|###       | 3376/11253 [05:33<12:56, 10.14it/s]
2022-03-21 00:16:04,797 - INFO - tqdm - f1: 0.8911, accuracy: 0.9320, batch_loss: 0.1685, loss: 0.1882 ||:  31%|###       | 3478/11253 [05:43<12:10, 10.64it/s]
2022-03-21 00:16:14,861 - INFO - tqdm - f1: 0.8905, accuracy: 0.9316, batch_loss: 0.4679, loss: 0.1889 ||:  32%|###1      | 3581/11253 [05:53<12:24, 10.30it/s]
2022-03-21 00:16:25,054 - INFO - tqdm - f1: 0.8907, accuracy: 0.9317, batch_loss: 0.0514, loss: 0.1887 ||:  33%|###2      | 3684/11253 [06:03<11:16, 11.18it/s]
2022-03-21 00:16:35,061 - INFO - tqdm - f1: 0.8904, accuracy: 0.9315, batch_loss: 0.0813, loss: 0.1894 ||:  34%|###3      | 3785/11253 [06:13<11:54, 10.45it/s]
2022-03-21 00:16:45,081 - INFO - tqdm - f1: 0.8899, accuracy: 0.9311, batch_loss: 0.2157, loss: 0.1902 ||:  35%|###4      | 3889/11253 [06:23<11:23, 10.77it/s]
2022-03-21 00:16:55,246 - INFO - tqdm - f1: 0.8899, accuracy: 0.9310, batch_loss: 0.0106, loss: 0.1908 ||:  35%|###5      | 3992/11253 [06:33<11:49, 10.23it/s]
2022-03-21 00:17:05,283 - INFO - tqdm - f1: 0.8902, accuracy: 0.9312, batch_loss: 0.1487, loss: 0.1904 ||:  36%|###6      | 4094/11253 [06:43<14:05,  8.47it/s]
2022-03-21 00:17:15,347 - INFO - tqdm - f1: 0.8897, accuracy: 0.9309, batch_loss: 0.1608, loss: 0.1909 ||:  37%|###7      | 4198/11253 [06:53<11:26, 10.27it/s]
2022-03-21 00:17:25,504 - INFO - tqdm - f1: 0.8895, accuracy: 0.9308, batch_loss: 0.6824, loss: 0.1914 ||:  38%|###8      | 4302/11253 [07:03<11:52,  9.76it/s]
2022-03-21 00:17:35,668 - INFO - tqdm - f1: 0.8893, accuracy: 0.9306, batch_loss: 0.1203, loss: 0.1918 ||:  39%|###9      | 4407/11253 [07:14<11:22, 10.04it/s]
2022-03-21 00:17:45,692 - INFO - tqdm - f1: 0.8893, accuracy: 0.9306, batch_loss: 0.4572, loss: 0.1922 ||:  40%|####      | 4507/11253 [07:24<11:21,  9.90it/s]
2022-03-21 00:17:55,802 - INFO - tqdm - f1: 0.8898, accuracy: 0.9309, batch_loss: 0.4646, loss: 0.1915 ||:  41%|####      | 4609/11253 [07:34<10:47, 10.27it/s]
2022-03-21 00:18:05,869 - INFO - tqdm - f1: 0.8896, accuracy: 0.9308, batch_loss: 0.0612, loss: 0.1920 ||:  42%|####1     | 4713/11253 [07:44<11:07,  9.80it/s]
2022-03-21 00:18:16,067 - INFO - tqdm - f1: 0.8893, accuracy: 0.9305, batch_loss: 0.7350, loss: 0.1925 ||:  43%|####2     | 4817/11253 [07:54<10:54,  9.83it/s]
2022-03-21 00:18:26,237 - INFO - tqdm - f1: 0.8894, accuracy: 0.9306, batch_loss: 0.0311, loss: 0.1927 ||:  44%|####3     | 4920/11253 [08:04<10:05, 10.47it/s]
2022-03-21 00:18:36,420 - INFO - tqdm - f1: 0.8893, accuracy: 0.9306, batch_loss: 0.4988, loss: 0.1924 ||:  45%|####4     | 5026/11253 [08:14<10:21, 10.02it/s]
2022-03-21 00:18:46,562 - INFO - tqdm - f1: 0.8891, accuracy: 0.9306, batch_loss: 0.0116, loss: 0.1926 ||:  46%|####5     | 5129/11253 [08:25<09:55, 10.28it/s]
2022-03-21 00:18:56,573 - INFO - tqdm - f1: 0.8891, accuracy: 0.9306, batch_loss: 0.0995, loss: 0.1928 ||:  46%|####6     | 5230/11253 [08:35<09:55, 10.11it/s]
2022-03-21 00:19:06,603 - INFO - tqdm - f1: 0.8890, accuracy: 0.9306, batch_loss: 0.3648, loss: 0.1929 ||:  47%|####7     | 5331/11253 [08:45<10:09,  9.71it/s]
2022-03-21 00:19:16,620 - INFO - tqdm - f1: 0.8891, accuracy: 0.9306, batch_loss: 0.4027, loss: 0.1930 ||:  48%|####8     | 5432/11253 [08:55<09:54,  9.79it/s]
2022-03-21 00:19:26,693 - INFO - tqdm - f1: 0.8888, accuracy: 0.9304, batch_loss: 0.0290, loss: 0.1935 ||:  49%|####9     | 5533/11253 [09:05<09:22, 10.18it/s]
2022-03-21 00:19:36,738 - INFO - tqdm - f1: 0.8888, accuracy: 0.9304, batch_loss: 0.1414, loss: 0.1935 ||:  50%|#####     | 5636/11253 [09:15<09:39,  9.69it/s]
2022-03-21 00:19:46,777 - INFO - tqdm - f1: 0.8888, accuracy: 0.9303, batch_loss: 0.2363, loss: 0.1943 ||:  51%|#####     | 5738/11253 [09:25<08:32, 10.77it/s]
2022-03-21 00:19:56,907 - INFO - tqdm - f1: 0.8891, accuracy: 0.9305, batch_loss: 0.1093, loss: 0.1940 ||:  52%|#####1    | 5838/11253 [09:35<08:07, 11.11it/s]
2022-03-21 00:20:07,026 - INFO - tqdm - f1: 0.8895, accuracy: 0.9307, batch_loss: 0.4936, loss: 0.1937 ||:  53%|#####2    | 5941/11253 [09:45<08:13, 10.76it/s]
2022-03-21 00:20:17,046 - INFO - tqdm - f1: 0.8897, accuracy: 0.9308, batch_loss: 0.0890, loss: 0.1936 ||:  54%|#####3    | 6043/11253 [09:55<08:10, 10.62it/s]
2022-03-21 00:20:27,269 - INFO - tqdm - f1: 0.8894, accuracy: 0.9307, batch_loss: 0.3290, loss: 0.1936 ||:  55%|#####4    | 6146/11253 [10:05<09:44,  8.74it/s]
2022-03-21 00:20:37,371 - INFO - tqdm - f1: 0.8889, accuracy: 0.9304, batch_loss: 0.1110, loss: 0.1939 ||:  56%|#####5    | 6250/11253 [10:15<07:50, 10.62it/s]
2022-03-21 00:20:47,501 - INFO - tqdm - f1: 0.8887, accuracy: 0.9302, batch_loss: 0.1138, loss: 0.1946 ||:  56%|#####6    | 6354/11253 [10:25<07:50, 10.42it/s]
2022-03-21 00:20:57,614 - INFO - tqdm - f1: 0.8888, accuracy: 0.9302, batch_loss: 0.2998, loss: 0.1945 ||:  57%|#####7    | 6457/11253 [10:36<07:39, 10.45it/s]
2022-03-21 00:21:07,745 - INFO - tqdm - f1: 0.8886, accuracy: 0.9301, batch_loss: 0.7266, loss: 0.1946 ||:  58%|#####8    | 6559/11253 [10:46<07:53,  9.91it/s]
2022-03-21 00:21:17,792 - INFO - tqdm - f1: 0.8885, accuracy: 0.9300, batch_loss: 0.4687, loss: 0.1955 ||:  59%|#####9    | 6660/11253 [10:56<07:35, 10.08it/s]
2022-03-21 00:21:27,888 - INFO - tqdm - f1: 0.8885, accuracy: 0.9300, batch_loss: 0.0849, loss: 0.1954 ||:  60%|######    | 6765/11253 [11:06<07:14, 10.32it/s]
2022-03-21 00:21:37,958 - INFO - tqdm - f1: 0.8887, accuracy: 0.9302, batch_loss: 0.0154, loss: 0.1949 ||:  61%|######1   | 6866/11253 [11:16<07:13, 10.12it/s]
2022-03-21 00:21:47,960 - INFO - tqdm - f1: 0.8886, accuracy: 0.9301, batch_loss: 0.0264, loss: 0.1951 ||:  62%|######1   | 6968/11253 [11:26<07:18,  9.77it/s]
2022-03-21 00:21:58,015 - INFO - tqdm - f1: 0.8885, accuracy: 0.9301, batch_loss: 0.1974, loss: 0.1950 ||:  63%|######2   | 7072/11253 [11:36<06:45, 10.32it/s]
2022-03-21 00:22:08,154 - INFO - tqdm - f1: 0.8886, accuracy: 0.9302, batch_loss: 0.4483, loss: 0.1950 ||:  64%|######3   | 7173/11253 [11:46<06:51,  9.92it/s]
2022-03-21 00:22:18,163 - INFO - tqdm - f1: 0.8883, accuracy: 0.9300, batch_loss: 0.3455, loss: 0.1953 ||:  65%|######4   | 7275/11253 [11:56<06:23, 10.36it/s]
2022-03-21 00:22:28,295 - INFO - tqdm - f1: 0.8883, accuracy: 0.9299, batch_loss: 0.1434, loss: 0.1955 ||:  66%|######5   | 7379/11253 [12:06<05:58, 10.81it/s]
2022-03-21 00:22:38,414 - INFO - tqdm - f1: 0.8882, accuracy: 0.9299, batch_loss: 0.0435, loss: 0.1956 ||:  66%|######6   | 7480/11253 [12:16<06:11, 10.17it/s]
2022-03-21 00:22:48,532 - INFO - tqdm - f1: 0.8882, accuracy: 0.9299, batch_loss: 0.0386, loss: 0.1958 ||:  67%|######7   | 7581/11253 [12:27<06:01, 10.14it/s]
2022-03-21 00:22:58,725 - INFO - tqdm - f1: 0.8881, accuracy: 0.9299, batch_loss: 0.1420, loss: 0.1959 ||:  68%|######8   | 7685/11253 [12:37<06:09,  9.66it/s]
2022-03-21 00:23:08,785 - INFO - tqdm - f1: 0.8880, accuracy: 0.9297, batch_loss: 0.0616, loss: 0.1962 ||:  69%|######9   | 7786/11253 [12:47<05:57,  9.71it/s]
2022-03-21 00:23:18,886 - INFO - tqdm - f1: 0.8879, accuracy: 0.9296, batch_loss: 0.1466, loss: 0.1963 ||:  70%|#######   | 7889/11253 [12:57<06:51,  8.17it/s]
2022-03-21 00:23:28,900 - INFO - tqdm - f1: 0.8880, accuracy: 0.9297, batch_loss: 0.2664, loss: 0.1962 ||:  71%|#######1  | 7992/11253 [13:07<05:16, 10.30it/s]
2022-03-21 00:23:39,037 - INFO - tqdm - f1: 0.8879, accuracy: 0.9296, batch_loss: 0.0734, loss: 0.1965 ||:  72%|#######1  | 8095/11253 [13:17<05:17,  9.94it/s]
2022-03-21 00:23:49,091 - INFO - tqdm - f1: 0.8879, accuracy: 0.9295, batch_loss: 0.3064, loss: 0.1967 ||:  73%|#######2  | 8198/11253 [13:27<04:27, 11.43it/s]
2022-03-21 00:23:59,251 - INFO - tqdm - f1: 0.8880, accuracy: 0.9296, batch_loss: 0.4206, loss: 0.1967 ||:  74%|#######3  | 8299/11253 [13:37<04:36, 10.70it/s]
2022-03-21 00:24:09,363 - INFO - tqdm - f1: 0.8881, accuracy: 0.9297, batch_loss: 0.0062, loss: 0.1965 ||:  75%|#######4  | 8400/11253 [13:47<04:50,  9.81it/s]
2022-03-21 00:24:19,406 - INFO - tqdm - f1: 0.8880, accuracy: 0.9296, batch_loss: 0.1018, loss: 0.1965 ||:  76%|#######5  | 8503/11253 [13:57<04:27, 10.28it/s]
2022-03-21 00:24:29,460 - INFO - tqdm - f1: 0.8880, accuracy: 0.9296, batch_loss: 0.0443, loss: 0.1964 ||:  76%|#######6  | 8604/11253 [14:07<04:01, 10.98it/s]
2022-03-21 00:24:39,595 - INFO - tqdm - f1: 0.8879, accuracy: 0.9296, batch_loss: 0.5001, loss: 0.1966 ||:  77%|#######7  | 8708/11253 [14:18<04:17,  9.88it/s]
2022-03-21 00:24:49,712 - INFO - tqdm - f1: 0.8879, accuracy: 0.9295, batch_loss: 0.0814, loss: 0.1967 ||:  78%|#######8  | 8811/11253 [14:28<03:58, 10.23it/s]
2022-03-21 00:24:59,781 - INFO - tqdm - f1: 0.8878, accuracy: 0.9295, batch_loss: 0.4426, loss: 0.1968 ||:  79%|#######9  | 8914/11253 [14:38<03:46, 10.31it/s]
2022-03-21 00:25:09,787 - INFO - tqdm - f1: 0.8879, accuracy: 0.9295, batch_loss: 0.0056, loss: 0.1966 ||:  80%|########  | 9018/11253 [14:48<03:40, 10.16it/s]
2022-03-21 00:25:19,878 - INFO - tqdm - f1: 0.8879, accuracy: 0.9295, batch_loss: 0.1240, loss: 0.1968 ||:  81%|########1 | 9123/11253 [14:58<03:27, 10.24it/s]
2022-03-21 00:25:29,958 - INFO - tqdm - f1: 0.8879, accuracy: 0.9294, batch_loss: 0.2130, loss: 0.1971 ||:  82%|########1 | 9225/11253 [15:08<03:21, 10.08it/s]
2022-03-21 00:25:40,049 - INFO - tqdm - f1: 0.8879, accuracy: 0.9294, batch_loss: 0.1043, loss: 0.1970 ||:  83%|########2 | 9328/11253 [15:18<02:55, 10.99it/s]
2022-03-21 00:25:50,221 - INFO - tqdm - f1: 0.8877, accuracy: 0.9292, batch_loss: 0.1102, loss: 0.1975 ||:  84%|########3 | 9431/11253 [15:28<03:01, 10.03it/s]
2022-03-21 00:26:00,273 - INFO - tqdm - f1: 0.8874, accuracy: 0.9290, batch_loss: 0.0800, loss: 0.1981 ||:  85%|########4 | 9534/11253 [15:38<02:46, 10.32it/s]
2022-03-21 00:26:10,280 - INFO - tqdm - f1: 0.8873, accuracy: 0.9289, batch_loss: 0.0429, loss: 0.1982 ||:  86%|########5 | 9635/11253 [15:48<03:19,  8.10it/s]
2022-03-21 00:26:20,458 - INFO - tqdm - f1: 0.8871, accuracy: 0.9287, batch_loss: 0.0525, loss: 0.1985 ||:  87%|########6 | 9741/11253 [15:58<02:36,  9.67it/s]
2022-03-21 00:26:30,524 - INFO - tqdm - f1: 0.8869, accuracy: 0.9286, batch_loss: 0.0285, loss: 0.1988 ||:  87%|########7 | 9842/11253 [16:08<02:19, 10.08it/s]
2022-03-21 00:26:40,568 - INFO - tqdm - f1: 0.8870, accuracy: 0.9287, batch_loss: 0.0577, loss: 0.1987 ||:  88%|########8 | 9945/11253 [16:19<02:06, 10.36it/s]
2022-03-21 00:26:50,758 - INFO - tqdm - f1: 0.8869, accuracy: 0.9286, batch_loss: 0.2117, loss: 0.1988 ||:  89%|########9 | 10048/11253 [16:29<01:56, 10.35it/s]
2022-03-21 00:27:00,946 - INFO - tqdm - f1: 0.8868, accuracy: 0.9286, batch_loss: 0.0221, loss: 0.1989 ||:  90%|######### | 10152/11253 [16:39<01:48, 10.17it/s]
2022-03-21 00:27:11,104 - INFO - tqdm - f1: 0.8867, accuracy: 0.9285, batch_loss: 0.0148, loss: 0.1991 ||:  91%|#########1| 10256/11253 [16:49<01:37, 10.19it/s]
2022-03-21 00:27:21,130 - INFO - tqdm - f1: 0.8867, accuracy: 0.9285, batch_loss: 0.0718, loss: 0.1992 ||:  92%|#########2| 10358/11253 [16:59<01:30,  9.94it/s]
2022-03-21 00:27:31,333 - INFO - tqdm - f1: 0.8867, accuracy: 0.9285, batch_loss: 0.0191, loss: 0.1991 ||:  93%|#########2| 10461/11253 [17:09<01:18, 10.08it/s]
2022-03-21 00:27:41,472 - INFO - tqdm - f1: 0.8866, accuracy: 0.9284, batch_loss: 0.3410, loss: 0.1995 ||:  94%|#########3| 10565/11253 [17:19<01:08, 10.07it/s]
2022-03-21 00:27:51,644 - INFO - tqdm - f1: 0.8865, accuracy: 0.9283, batch_loss: 0.3951, loss: 0.1996 ||:  95%|#########4| 10664/11253 [17:30<00:59,  9.93it/s]
2022-03-21 00:28:01,873 - INFO - tqdm - f1: 0.8866, accuracy: 0.9284, batch_loss: 0.2078, loss: 0.1997 ||:  96%|#########5| 10766/11253 [17:40<00:49,  9.85it/s]
2022-03-21 00:28:11,980 - INFO - tqdm - f1: 0.8866, accuracy: 0.9284, batch_loss: 0.1116, loss: 0.1998 ||:  97%|#########6| 10867/11253 [17:50<00:39,  9.84it/s]
2022-03-21 00:28:22,035 - INFO - tqdm - f1: 0.8864, accuracy: 0.9283, batch_loss: 0.4415, loss: 0.1998 ||:  97%|#########7| 10971/11253 [18:00<00:25, 10.99it/s]
2022-03-21 00:28:32,209 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.4004, loss: 0.1999 ||:  98%|#########8| 11076/11253 [18:10<00:17, 10.22it/s]
2022-03-21 00:28:42,275 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1095, loss: 0.1999 ||:  99%|#########9| 11179/11253 [18:20<00:07, 10.48it/s]
2022-03-21 00:28:44,007 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.4645, loss: 0.1999 ||: 100%|#########9| 11197/11253 [18:22<00:05, 10.37it/s]
2022-03-21 00:28:44,211 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.3350, loss: 0.2000 ||: 100%|#########9| 11199/11253 [18:22<00:05, 10.19it/s]
2022-03-21 00:28:44,402 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0741, loss: 0.1999 ||: 100%|#########9| 11201/11253 [18:22<00:05, 10.26it/s]
2022-03-21 00:28:44,623 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0491, loss: 0.1999 ||: 100%|#########9| 11203/11253 [18:23<00:05,  9.88it/s]
2022-03-21 00:28:44,731 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0674, loss: 0.1999 ||: 100%|#########9| 11204/11253 [18:23<00:05,  9.75it/s]
2022-03-21 00:28:44,855 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1830, loss: 0.1999 ||: 100%|#########9| 11205/11253 [18:23<00:05,  9.36it/s]
2022-03-21 00:28:45,042 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1830, loss: 0.1999 ||: 100%|#########9| 11207/11253 [18:23<00:04,  9.81it/s]
2022-03-21 00:28:45,230 - INFO - tqdm - f1: 0.8862, accuracy: 0.9282, batch_loss: 0.1079, loss: 0.1999 ||: 100%|#########9| 11209/11253 [18:23<00:04, 10.07it/s]
2022-03-21 00:28:45,353 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0137, loss: 0.1999 ||: 100%|#########9| 11210/11253 [18:23<00:04,  9.63it/s]
2022-03-21 00:28:45,458 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.2335, loss: 0.1999 ||: 100%|#########9| 11211/11253 [18:23<00:04,  9.60it/s]
2022-03-21 00:28:45,573 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0601, loss: 0.1999 ||: 100%|#########9| 11212/11253 [18:24<00:04,  9.37it/s]
2022-03-21 00:28:45,686 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.4370, loss: 0.1999 ||: 100%|#########9| 11213/11253 [18:24<00:04,  9.24it/s]
2022-03-21 00:28:45,811 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1110, loss: 0.1999 ||: 100%|#########9| 11214/11253 [18:24<00:04,  8.86it/s]
2022-03-21 00:28:45,988 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1874, loss: 0.1999 ||: 100%|#########9| 11216/11253 [18:24<00:03,  9.78it/s]
2022-03-21 00:28:46,108 - INFO - tqdm - f1: 0.8862, accuracy: 0.9282, batch_loss: 0.9628, loss: 0.2000 ||: 100%|#########9| 11217/11253 [18:24<00:03,  9.39it/s]
2022-03-21 00:28:46,217 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1329, loss: 0.2000 ||: 100%|#########9| 11218/11253 [18:24<00:03,  9.33it/s]
2022-03-21 00:28:46,384 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1166, loss: 0.2000 ||: 100%|#########9| 11219/11253 [18:24<00:04,  8.14it/s]
2022-03-21 00:28:46,490 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.4715, loss: 0.2000 ||: 100%|#########9| 11220/11253 [18:24<00:03,  8.45it/s]
2022-03-21 00:28:46,660 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1677, loss: 0.2000 ||: 100%|#########9| 11221/11253 [18:25<00:04,  7.53it/s]
2022-03-21 00:28:46,802 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0956, loss: 0.2000 ||: 100%|#########9| 11222/11253 [18:25<00:04,  7.39it/s]
2022-03-21 00:28:46,968 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0703, loss: 0.1999 ||: 100%|#########9| 11224/11253 [18:25<00:03,  8.94it/s]
2022-03-21 00:28:47,126 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.3492, loss: 0.2000 ||: 100%|#########9| 11226/11253 [18:25<00:02, 10.09it/s]
2022-03-21 00:28:47,311 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0443, loss: 0.2000 ||: 100%|#########9| 11228/11253 [18:25<00:02, 10.35it/s]
2022-03-21 00:28:47,524 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1479, loss: 0.2000 ||: 100%|#########9| 11230/11253 [18:25<00:02, 10.00it/s]
2022-03-21 00:28:47,643 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1236, loss: 0.2000 ||: 100%|#########9| 11231/11253 [18:26<00:02,  9.65it/s]
2022-03-21 00:28:47,752 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0492, loss: 0.2000 ||: 100%|#########9| 11232/11253 [18:26<00:02,  9.54it/s]
2022-03-21 00:28:47,857 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1044, loss: 0.2000 ||: 100%|#########9| 11233/11253 [18:26<00:02,  9.54it/s]
2022-03-21 00:28:47,970 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.6772, loss: 0.2000 ||: 100%|#########9| 11234/11253 [18:26<00:02,  9.34it/s]
2022-03-21 00:28:48,135 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.4124, loss: 0.2000 ||: 100%|#########9| 11236/11253 [18:26<00:01, 10.33it/s]
2022-03-21 00:28:48,354 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1457, loss: 0.2000 ||: 100%|#########9| 11238/11253 [18:26<00:01,  9.86it/s]
2022-03-21 00:28:48,463 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.4476, loss: 0.2000 ||: 100%|#########9| 11239/11253 [18:26<00:01,  9.69it/s]
2022-03-21 00:28:48,571 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1124, loss: 0.2000 ||: 100%|#########9| 11240/11253 [18:27<00:01,  9.59it/s]
2022-03-21 00:28:48,692 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0659, loss: 0.2000 ||: 100%|#########9| 11241/11253 [18:27<00:01,  9.24it/s]
2022-03-21 00:28:48,805 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.3957, loss: 0.2000 ||: 100%|#########9| 11242/11253 [18:27<00:01,  9.13it/s]
2022-03-21 00:28:48,927 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0217, loss: 0.2000 ||: 100%|#########9| 11243/11253 [18:27<00:01,  8.84it/s]
2022-03-21 00:28:49,126 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.8033, loss: 0.2000 ||: 100%|#########9| 11245/11253 [18:27<00:00,  9.33it/s]
2022-03-21 00:28:49,247 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.4219, loss: 0.2001 ||: 100%|#########9| 11246/11253 [18:27<00:00,  9.06it/s]
2022-03-21 00:28:49,366 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0081, loss: 0.2000 ||: 100%|#########9| 11247/11253 [18:27<00:00,  8.88it/s]
2022-03-21 00:28:49,469 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.3149, loss: 0.2001 ||: 100%|#########9| 11248/11253 [18:27<00:00,  9.09it/s]
2022-03-21 00:28:49,584 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1072, loss: 0.2000 ||: 100%|#########9| 11249/11253 [18:28<00:00,  8.98it/s]
2022-03-21 00:28:49,708 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.2665, loss: 0.2000 ||: 100%|#########9| 11250/11253 [18:28<00:00,  8.70it/s]
2022-03-21 00:28:49,833 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0710, loss: 0.2000 ||: 100%|#########9| 11251/11253 [18:28<00:00,  8.48it/s]
2022-03-21 00:28:49,956 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.0487, loss: 0.2000 ||: 100%|#########9| 11252/11253 [18:28<00:00,  8.39it/s]
2022-03-21 00:28:50,056 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1574, loss: 0.2000 ||: 100%|##########| 11253/11253 [18:28<00:00,  8.81it/s]
2022-03-21 00:28:50,144 - INFO - tqdm - f1: 0.8863, accuracy: 0.9282, batch_loss: 0.1574, loss: 0.2000 ||: 100%|##########| 11253/11253 [18:28<00:00, 10.15it/s]
2022-03-21 00:28:50,169 - INFO - allennlp.training.trainer - Validating
2022-03-21 00:28:50,174 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 00:29:00,295 - INFO - tqdm - f1: 0.8094, accuracy: 0.8692, batch_loss: 0.8880, loss: 0.4466 ||:  11%|#1        | 217/1889 [00:10<01:14, 22.29it/s]
2022-03-21 00:29:10,335 - INFO - tqdm - f1: 0.8076, accuracy: 0.8655, batch_loss: 0.2367, loss: 0.4531 ||:  23%|##3       | 435/1889 [00:20<01:05, 22.19it/s]
2022-03-21 00:29:20,466 - INFO - tqdm - f1: 0.8061, accuracy: 0.8664, batch_loss: 0.4281, loss: 0.4507 ||:  35%|###4      | 652/1889 [00:30<00:57, 21.64it/s]
2022-03-21 00:29:30,579 - INFO - tqdm - f1: 0.8089, accuracy: 0.8682, batch_loss: 0.3151, loss: 0.4475 ||:  46%|####6     | 874/1889 [00:40<00:46, 21.76it/s]
2022-03-21 00:29:40,655 - INFO - tqdm - f1: 0.8073, accuracy: 0.8675, batch_loss: 0.9987, loss: 0.4500 ||:  58%|#####7    | 1095/1889 [00:50<00:36, 21.94it/s]
2022-03-21 00:29:50,766 - INFO - tqdm - f1: 0.8059, accuracy: 0.8670, batch_loss: 0.2433, loss: 0.4491 ||:  70%|######9   | 1319/1889 [01:00<00:28, 20.07it/s]
2022-03-21 00:30:00,791 - INFO - tqdm - f1: 0.8066, accuracy: 0.8676, batch_loss: 0.2178, loss: 0.4442 ||:  81%|########1 | 1537/1889 [01:10<00:17, 20.47it/s]
2022-03-21 00:30:10,882 - INFO - tqdm - f1: 0.8060, accuracy: 0.8677, batch_loss: 0.3042, loss: 0.4423 ||:  93%|#########3| 1757/1889 [01:20<00:06, 20.97it/s]
2022-03-21 00:30:16,367 - INFO - tqdm - f1: 0.8063, accuracy: 0.8684, batch_loss: 0.6045, loss: 0.4410 ||: 100%|#########9| 1880/1889 [01:26<00:00, 19.82it/s]
2022-03-21 00:30:16,611 - INFO - tqdm - f1: 0.8063, accuracy: 0.8684, batch_loss: 0.6431, loss: 0.4412 ||: 100%|#########9| 1883/1889 [01:26<00:00, 16.75it/s]
2022-03-21 00:30:16,727 - INFO - tqdm - f1: 0.8063, accuracy: 0.8684, batch_loss: 0.1258, loss: 0.4410 ||: 100%|#########9| 1886/1889 [01:26<00:00, 18.74it/s]
2022-03-21 00:30:16,853 - INFO - tqdm - f1: 0.8064, accuracy: 0.8684, batch_loss: 1.1343, loss: 0.4410 ||: 100%|##########| 1889/1889 [01:26<00:00, 20.02it/s]
2022-03-21 00:30:16,867 - INFO - tqdm - f1: 0.8064, accuracy: 0.8684, batch_loss: 1.1343, loss: 0.4410 ||: 100%|##########| 1889/1889 [01:26<00:00, 21.79it/s]
2022-03-21 00:30:16,885 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-21 00:30:16,888 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-21 00:30:17,324 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-21 00:30:17,332 - INFO - allennlp.training.util - Iterating over dataset
2022-03-21 00:30:17,335 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-21 00:30:17,370 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 00:30:17,373 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 00:30:27,389 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.41 ||: : 212it [00:10, 20.60it/s]
2022-03-21 00:30:37,432 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.40 ||: : 432it [00:20, 22.58it/s]
2022-03-21 00:30:47,501 - INFO - tqdm - f1: 0.82, accuracy: 0.87, loss: 0.39 ||: : 654it [00:30, 23.49it/s]
2022-03-21 00:30:57,553 - INFO - tqdm - f1: 0.82, accuracy: 0.87, loss: 0.39 ||: : 874it [00:40, 22.78it/s]
2022-03-21 00:31:07,643 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.40 ||: : 1101it [00:50, 22.97it/s]
2022-03-21 00:31:17,684 - INFO - tqdm - f1: 0.82, accuracy: 0.87, loss: 0.41 ||: : 1320it [01:00, 23.11it/s]
2022-03-21 00:31:27,762 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.40 ||: : 1538it [01:10, 23.48it/s]
2022-03-21 00:31:37,845 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.40 ||: : 1757it [01:20, 21.35it/s]
2022-03-21 00:31:43,650 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 3,
  "peak_worker_0_memory_MB": 8644.55859375,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "2:13:04.921398",
  "training_start_epoch": 0,
  "training_epochs": 5,
  "epoch": 5,
  "training_f1": 0.8727614045143127,
  "training_accuracy": 0.9191068651410798,
  "training_loss": 0.22312493212930334,
  "training_worker_0_memory_MB": 8644.55859375,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.8145958781242371,
  "validation_accuracy": 0.8680325698397987,
  "validation_loss": 0.42207595550264354,
  "best_validation_f1": 0.8226816892623902,
  "best_validation_accuracy": 0.8773997087250099,
  "best_validation_loss": 0.37002096219504005,
  "test_f1": 0.8149429798126221,
  "test_accuracy": 0.8694209391073503,
  "test_loss": 0.40257847137999325
}
2022-03-21 00:31:43,856 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/rct-20k_base_hyper_small_seed_13/model.tar.gz
