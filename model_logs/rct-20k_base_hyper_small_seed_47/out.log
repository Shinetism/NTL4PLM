2022-03-21 00:32:32,100 - INFO - allennlp.common.params - random_seed = 47
2022-03-21 00:32:32,104 - INFO - allennlp.common.params - numpy_seed = 47
2022-03-21 00:32:32,106 - INFO - allennlp.common.params - pytorch_seed = 47
2022-03-21 00:32:32,114 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-21 00:32:32,117 - INFO - allennlp.common.params - type = default
2022-03-21 00:32:32,119 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-21 00:32:32,122 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 00:32:32,124 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 00:32:32,130 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 00:32:32,133 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 00:32:32,135 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 00:32:32,137 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 00:32:48,073 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 00:32:48,081 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 00:32:48,085 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 00:32:48,090 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-21 00:32:48,094 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-21 00:32:48,099 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 00:32:48,104 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-21 00:32:48,108 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-21 00:32:48,112 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-21 00:32:48,115 - INFO - allennlp.common.params - train_data_path = datasets/rct-20k/train.jsonl
2022-03-21 00:32:48,120 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f91bbb05210>
2022-03-21 00:32:48,123 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-21 00:32:48,126 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-21 00:32:48,130 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 00:32:48,133 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 00:32:48,136 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 00:32:48,139 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 00:32:48,142 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 00:32:48,145 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 00:32:48,149 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 00:32:48,153 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 00:32:48,157 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 00:32:48,162 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-21 00:32:48,167 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-21 00:32:48,171 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 00:32:48,176 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-21 00:32:48,184 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-21 00:32:48,188 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-21 00:32:48,191 - INFO - allennlp.common.params - validation_data_path = datasets/rct-20k/dev.jsonl
2022-03-21 00:32:48,193 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-21 00:32:48,194 - INFO - allennlp.common.params - test_data_path = datasets/rct-20k/test.jsonl
2022-03-21 00:32:48,196 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-21 00:32:48,198 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-21 00:32:48,199 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 00:32:48,202 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 00:32:48,204 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 00:32:48,207 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 00:32:48,209 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 00:32:48,211 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 00:32:48,213 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 00:32:48,215 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 00:32:48,217 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 00:32:48,218 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 00:32:48,221 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 00:32:48,223 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 00:32:48,224 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 00:32:48,226 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 00:32:48,229 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 00:32:58,285 - INFO - tqdm - loading instances: 36724it [00:10, 4331.92it/s]
2022-03-21 00:33:08,297 - INFO - tqdm - loading instances: 72971it [00:20, 4270.31it/s]
2022-03-21 00:33:18,332 - INFO - tqdm - loading instances: 106390it [00:30, 3891.05it/s]
2022-03-21 00:33:28,421 - INFO - tqdm - loading instances: 143181it [00:40, 4299.83it/s]
2022-03-21 00:33:38,479 - INFO - tqdm - loading instances: 178828it [00:50, 4397.71it/s]
2022-03-21 00:33:38,775 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 00:33:38,779 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 00:33:38,782 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 00:33:38,785 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 00:33:38,789 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 00:33:38,792 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 00:33:38,795 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 00:33:38,799 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 00:33:38,802 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 00:33:38,805 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 00:33:38,808 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 00:33:38,811 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 00:33:38,814 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 00:33:38,817 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 00:33:38,821 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 00:33:48,340 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 00:33:48,347 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 00:33:48,352 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 00:33:48,355 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 00:33:48,359 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 00:33:48,362 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 00:33:48,365 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 00:33:48,368 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 00:33:48,371 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 00:33:48,374 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 00:33:48,377 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 00:33:48,379 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 00:33:48,382 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 00:33:48,385 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 00:33:48,389 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 00:33:55,474 - INFO - allennlp.common.params - type = from_instances
2022-03-21 00:33:55,481 - INFO - allennlp.common.params - min_count = None
2022-03-21 00:33:55,483 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-21 00:33:55,485 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-21 00:33:55,488 - INFO - allennlp.common.params - pretrained_files = None
2022-03-21 00:33:55,490 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-21 00:33:55,492 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-21 00:33:55,495 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-21 00:33:55,497 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-21 00:33:55,503 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-21 00:33:55,505 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-21 00:33:55,508 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-21 00:33:56,863 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-21 00:33:56,866 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-21 00:33:56,868 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-21 00:33:56,871 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-21 00:33:56,873 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-21 00:33:56,875 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-21 00:33:56,877 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-21 00:33:56,879 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-21 00:33:56,882 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-21 00:33:56,884 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-21 00:33:56,887 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-21 00:33:56,890 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-21 00:33:56,892 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-21 00:34:03,295 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-21 00:34:03,298 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-21 00:34:03,308 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-21 00:34:03,311 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-21 00:34:03,314 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-21 00:34:03,317 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-21 00:34:03,320 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-21 00:34:03,323 - INFO - allennlp.common.params - type = tanh
2022-03-21 00:34:03,326 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-21 00:34:03,340 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-21 00:34:03,343 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-21 00:34:03,346 - INFO - allennlp.common.params - model.num_labels = None
2022-03-21 00:34:03,349 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-21 00:34:03,352 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f91bbb23290>
2022-03-21 00:34:03,354 - INFO - allennlp.common.params - model.regularizer = None
2022-03-21 00:34:03,357 - INFO - allennlp.common.params - model.track_weights = False
2022-03-21 00:34:03,360 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-21 00:34:03,364 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-21 00:34:03,369 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-21 00:34:03,372 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-21 00:34:03,375 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-21 00:34:03,378 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-21 00:34:03,381 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-21 00:34:03,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 00:34:03,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 00:34:03,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 00:34:03,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 00:34:03,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 00:34:03,406 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 00:34:03,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 00:34:03,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 00:34:03,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 00:34:03,424 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 00:34:03,427 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 00:34:03,431 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 00:34:03,437 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 00:34:03,440 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 00:34:03,443 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 00:34:03,446 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 00:34:03,449 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 00:34:03,452 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 00:34:03,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 00:34:03,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 00:34:03,461 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 00:34:03,464 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 00:34:03,467 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 00:34:03,470 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 00:34:03,473 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 00:34:03,476 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 00:34:03,479 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 00:34:03,483 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 00:34:03,486 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 00:34:03,488 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 00:34:03,491 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 00:34:03,494 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 00:34:03,497 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 00:34:03,501 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 00:34:03,505 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 00:34:03,510 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 00:34:03,515 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 00:34:03,522 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 00:34:03,527 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 00:34:03,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 00:34:03,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 00:34:03,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 00:34:03,537 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 00:34:03,539 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 00:34:03,540 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 00:34:03,542 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 00:34:03,544 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 00:34:03,546 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 00:34:03,547 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 00:34:03,549 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 00:34:03,551 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 00:34:03,552 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 00:34:03,554 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 00:34:03,556 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 00:34:03,558 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 00:34:03,560 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 00:34:03,562 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 00:34:03,563 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 00:34:03,565 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 00:34:03,567 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 00:34:03,569 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 00:34:03,571 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 00:34:03,573 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 00:34:03,575 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 00:34:03,576 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 00:34:03,578 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 00:34:03,580 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 00:34:03,581 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 00:34:03,583 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 00:34:03,585 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 00:34:03,586 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 00:34:03,588 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 00:34:03,590 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 00:34:03,592 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 00:34:03,594 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 00:34:03,596 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 00:34:03,598 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 00:34:03,600 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 00:34:03,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 00:34:03,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 00:34:03,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 00:34:03,608 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 00:34:03,610 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 00:34:03,612 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 00:34:03,614 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 00:34:03,617 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 00:34:03,620 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 00:34:03,623 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 00:34:03,628 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 00:34:03,631 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 00:34:03,633 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 00:34:03,635 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 00:34:03,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 00:34:03,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 00:34:03,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 00:34:03,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 00:34:03,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 00:34:03,648 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 00:34:03,650 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 00:34:03,653 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 00:34:03,655 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 00:34:03,658 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 00:34:03,661 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 00:34:03,663 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 00:34:03,665 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 00:34:03,668 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 00:34:03,670 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 00:34:03,672 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 00:34:03,674 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 00:34:03,677 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 00:34:03,679 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 00:34:03,683 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 00:34:03,686 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 00:34:03,688 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 00:34:03,691 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 00:34:03,693 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 00:34:03,695 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 00:34:03,698 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 00:34:03,700 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 00:34:03,703 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 00:34:03,705 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 00:34:03,708 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 00:34:03,710 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 00:34:03,713 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 00:34:03,716 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 00:34:03,719 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 00:34:03,721 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 00:34:03,724 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 00:34:03,727 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 00:34:03,730 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 00:34:03,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 00:34:03,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 00:34:03,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 00:34:03,740 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 00:34:03,742 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 00:34:03,745 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 00:34:03,750 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 00:34:03,752 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 00:34:03,755 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 00:34:03,757 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 00:34:03,760 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 00:34:03,763 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 00:34:03,765 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 00:34:03,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 00:34:03,771 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 00:34:03,774 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 00:34:03,777 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 00:34:03,780 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 00:34:03,782 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 00:34:03,785 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 00:34:03,788 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 00:34:03,791 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 00:34:03,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 00:34:03,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 00:34:03,799 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 00:34:03,802 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 00:34:03,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 00:34:03,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 00:34:03,811 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 00:34:03,814 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 00:34:03,820 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 00:34:03,823 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 00:34:03,826 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 00:34:03,829 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 00:34:03,833 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 00:34:03,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 00:34:03,842 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 00:34:03,846 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 00:34:03,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 00:34:03,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 00:34:03,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 00:34:03,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 00:34:03,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 00:34:03,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 00:34:03,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 00:34:03,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 00:34:03,876 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 00:34:03,879 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 00:34:03,882 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 00:34:03,885 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 00:34:03,888 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 00:34:03,891 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 00:34:03,893 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 00:34:03,896 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 00:34:03,899 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 00:34:03,905 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 00:34:03,908 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 00:34:03,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 00:34:03,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 00:34:03,918 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 00:34:03,921 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 00:34:03,924 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 00:34:03,928 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 00:34:03,933 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 00:34:03,937 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 00:34:03,941 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 00:34:03,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 00:34:03,952 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 00:34:03,955 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 00:34:12,794 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-21 00:34:12,802 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-21 00:34:12,806 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-21 00:34:12,808 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-21 00:34:12,809 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-21 00:34:12,811 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-21 00:34:12,813 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-21 00:34:12,815 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-21 00:34:12,821 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-21 00:34:12,824 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-21 00:34:12,825 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-21 00:34:12,827 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-21 00:34:12,830 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-21 00:34:12,831 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-21 00:34:12,833 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-21 00:34:12,835 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-21 00:34:12,837 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-21 00:34:17,539 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-21 00:34:17,546 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-21 00:34:17,548 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-21 00:34:17,553 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-21 00:34:17,555 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-21 00:34:17,558 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-21 00:34:17,563 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-21 00:34:17,565 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias'], {'weight_decay': 0}
2022-03-21 00:34:17,570 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight'], {}
2022-03-21 00:34:17,574 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-21 00:34:17,576 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125240069
2022-03-21 00:34:17,580 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-21 00:34:17,583 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-21 00:34:17,586 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 00:34:17,588 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 00:34:17,590 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 00:34:17,593 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 00:34:17,595 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 00:34:17,598 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 00:34:17,601 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 00:34:17,603 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 00:34:17,605 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 00:34:17,608 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 00:34:17,610 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 00:34:17,612 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 00:34:17,615 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 00:34:17,617 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 00:34:17,620 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 00:34:17,624 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 00:34:17,626 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 00:34:17,629 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 00:34:17,631 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 00:34:17,634 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 00:34:17,636 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 00:34:17,639 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 00:34:17,641 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 00:34:17,644 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 00:34:17,646 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 00:34:17,649 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 00:34:17,652 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 00:34:17,654 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 00:34:17,657 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 00:34:17,660 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 00:34:17,663 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 00:34:17,666 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 00:34:17,669 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 00:34:17,672 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 00:34:17,675 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 00:34:17,678 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 00:34:17,681 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 00:34:17,683 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 00:34:17,686 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 00:34:17,689 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 00:34:17,692 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 00:34:17,698 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 00:34:17,701 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 00:34:17,709 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 00:34:17,712 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 00:34:17,715 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 00:34:17,718 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 00:34:17,721 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 00:34:17,724 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 00:34:17,727 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 00:34:17,730 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 00:34:17,732 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 00:34:17,735 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 00:34:17,738 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 00:34:17,742 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 00:34:17,745 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 00:34:17,748 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 00:34:17,751 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 00:34:17,754 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 00:34:17,757 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 00:34:17,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 00:34:17,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 00:34:17,766 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 00:34:17,769 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 00:34:17,772 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 00:34:17,775 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 00:34:17,778 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 00:34:17,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 00:34:17,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 00:34:17,789 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 00:34:17,792 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 00:34:17,795 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 00:34:17,801 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 00:34:17,805 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 00:34:17,809 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 00:34:17,813 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 00:34:17,817 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 00:34:17,820 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 00:34:17,823 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 00:34:17,825 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 00:34:17,828 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 00:34:17,831 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 00:34:17,833 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 00:34:17,836 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 00:34:17,839 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 00:34:17,841 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 00:34:17,844 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 00:34:17,846 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 00:34:17,849 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 00:34:17,852 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 00:34:17,854 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 00:34:17,857 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 00:34:17,860 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 00:34:17,865 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 00:34:17,868 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 00:34:17,870 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 00:34:17,873 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 00:34:17,876 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 00:34:17,878 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 00:34:17,881 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 00:34:17,883 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 00:34:17,886 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 00:34:17,888 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 00:34:17,891 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 00:34:17,894 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 00:34:17,896 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 00:34:17,899 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 00:34:17,901 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 00:34:17,904 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 00:34:17,907 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 00:34:17,912 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 00:34:17,916 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 00:34:17,920 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 00:34:17,924 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 00:34:17,928 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 00:34:17,931 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 00:34:17,935 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 00:34:17,936 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 00:34:17,939 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 00:34:17,941 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 00:34:17,943 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 00:34:17,945 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 00:34:17,947 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 00:34:17,948 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 00:34:17,950 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 00:34:17,952 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 00:34:17,954 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 00:34:17,956 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 00:34:17,957 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 00:34:17,959 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 00:34:17,961 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 00:34:17,963 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 00:34:17,965 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 00:34:17,967 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 00:34:17,969 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 00:34:17,972 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 00:34:17,974 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 00:34:17,976 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 00:34:17,978 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 00:34:17,981 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 00:34:17,983 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 00:34:17,986 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 00:34:17,988 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 00:34:17,990 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 00:34:17,994 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 00:34:17,997 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 00:34:17,999 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 00:34:18,001 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 00:34:18,004 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 00:34:18,006 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 00:34:18,008 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 00:34:18,011 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 00:34:18,018 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 00:34:18,021 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 00:34:18,023 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 00:34:18,026 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 00:34:18,028 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 00:34:18,031 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 00:34:18,033 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 00:34:18,035 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 00:34:18,038 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 00:34:18,040 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 00:34:18,043 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 00:34:18,045 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 00:34:18,048 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 00:34:18,050 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 00:34:18,053 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 00:34:18,055 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 00:34:18,058 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 00:34:18,060 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 00:34:18,064 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 00:34:18,067 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 00:34:18,070 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 00:34:18,073 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 00:34:18,075 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 00:34:18,077 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 00:34:18,080 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 00:34:18,082 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 00:34:18,084 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 00:34:18,087 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 00:34:18,089 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 00:34:18,091 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 00:34:18,094 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 00:34:18,096 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 00:34:18,099 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 00:34:18,102 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 00:34:18,110 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 00:34:18,113 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 00:34:18,116 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 00:34:18,119 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 00:34:18,122 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 00:34:18,125 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 00:34:18,129 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 00:34:18,131 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 00:34:18,134 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 00:34:18,137 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 00:34:18,143 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 00:34:18,146 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 00:34:18,148 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 00:34:18,151 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-21 00:34:18,154 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-21 00:34:18,157 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-21 00:34:18,160 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-21 00:34:18,163 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-21 00:34:18,167 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-21 00:34:18,170 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-21 00:34:18,173 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-21 00:34:18,176 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-21 00:34:18,179 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-21 00:34:18,186 - INFO - allennlp.training.trainer - Beginning training.
2022-03-21 00:34:18,189 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-21 00:34:18,192 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.3G
2022-03-21 00:34:18,195 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 00:34:18,199 - INFO - allennlp.training.trainer - Training
2022-03-21 00:34:18,203 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 00:34:18,381 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 00:34:18,384 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 00:34:28,206 - INFO - tqdm - f1: 0.4690, accuracy: 0.5671, batch_loss: 0.8042, loss: 1.0442 ||:   1%|          | 82/11253 [00:10<18:14, 10.20it/s]
2022-03-21 00:34:38,379 - INFO - tqdm - f1: 0.6173, accuracy: 0.6943, batch_loss: 0.5499, loss: 0.7849 ||:   2%|1         | 185/11253 [00:20<18:11, 10.14it/s]
2022-03-21 00:34:48,514 - INFO - tqdm - f1: 0.6610, accuracy: 0.7334, batch_loss: 0.2538, loss: 0.7084 ||:   3%|2         | 287/11253 [00:30<17:35, 10.39it/s]
2022-03-21 00:34:58,667 - INFO - tqdm - f1: 0.6896, accuracy: 0.7562, batch_loss: 0.4893, loss: 0.6551 ||:   3%|3         | 392/11253 [00:40<16:49, 10.76it/s]
2022-03-21 00:35:08,768 - INFO - tqdm - f1: 0.6989, accuracy: 0.7650, batch_loss: 0.5736, loss: 0.6354 ||:   4%|4         | 500/11253 [00:50<16:12, 11.06it/s]
2022-03-21 00:35:18,901 - INFO - tqdm - f1: 0.7100, accuracy: 0.7742, batch_loss: 0.9650, loss: 0.6118 ||:   5%|5         | 606/11253 [01:00<16:57, 10.46it/s]
2022-03-21 00:35:29,058 - INFO - tqdm - f1: 0.7163, accuracy: 0.7821, batch_loss: 0.3512, loss: 0.5921 ||:   6%|6         | 709/11253 [01:10<16:45, 10.49it/s]
2022-03-21 00:35:39,226 - INFO - tqdm - f1: 0.7246, accuracy: 0.7886, batch_loss: 0.5456, loss: 0.5768 ||:   7%|7         | 815/11253 [01:21<16:21, 10.63it/s]
2022-03-21 00:35:49,333 - INFO - tqdm - f1: 0.7290, accuracy: 0.7939, batch_loss: 0.6277, loss: 0.5637 ||:   8%|8         | 919/11253 [01:31<18:05,  9.52it/s]
2022-03-21 00:35:59,403 - INFO - tqdm - f1: 0.7345, accuracy: 0.7985, batch_loss: 0.7407, loss: 0.5516 ||:   9%|9         | 1022/11253 [01:41<15:56, 10.69it/s]
2022-03-21 00:36:09,473 - INFO - tqdm - f1: 0.7378, accuracy: 0.8023, batch_loss: 0.4729, loss: 0.5403 ||:  10%|9         | 1124/11253 [01:51<16:12, 10.42it/s]
2022-03-21 00:36:19,634 - INFO - tqdm - f1: 0.7405, accuracy: 0.8051, batch_loss: 0.1493, loss: 0.5318 ||:  11%|#         | 1228/11253 [02:01<15:56, 10.48it/s]
2022-03-21 00:36:29,754 - INFO - tqdm - f1: 0.7425, accuracy: 0.8067, batch_loss: 0.4015, loss: 0.5273 ||:  12%|#1        | 1329/11253 [02:11<15:51, 10.43it/s]
2022-03-21 00:36:39,833 - INFO - tqdm - f1: 0.7456, accuracy: 0.8101, batch_loss: 0.1506, loss: 0.5185 ||:  13%|#2        | 1431/11253 [02:21<16:16, 10.06it/s]
2022-03-21 00:36:49,892 - INFO - tqdm - f1: 0.7458, accuracy: 0.8109, batch_loss: 0.6860, loss: 0.5154 ||:  14%|#3        | 1531/11253 [02:31<17:16,  9.38it/s]
2022-03-21 00:36:59,928 - INFO - tqdm - f1: 0.7487, accuracy: 0.8139, batch_loss: 0.4683, loss: 0.5090 ||:  15%|#4        | 1633/11253 [02:41<15:14, 10.52it/s]
2022-03-21 00:37:09,945 - INFO - tqdm - f1: 0.7506, accuracy: 0.8153, batch_loss: 0.2790, loss: 0.5059 ||:  15%|#5        | 1730/11253 [02:51<21:29,  7.39it/s]
2022-03-21 00:37:20,143 - INFO - tqdm - f1: 0.7526, accuracy: 0.8167, batch_loss: 0.6484, loss: 0.5025 ||:  16%|#6        | 1831/11253 [03:01<15:37, 10.05it/s]
2022-03-21 00:37:30,143 - INFO - tqdm - f1: 0.7535, accuracy: 0.8177, batch_loss: 0.3167, loss: 0.4984 ||:  17%|#7        | 1931/11253 [03:11<14:40, 10.58it/s]
2022-03-21 00:37:40,192 - INFO - tqdm - f1: 0.7549, accuracy: 0.8194, batch_loss: 0.5284, loss: 0.4946 ||:  18%|#8        | 2033/11253 [03:21<16:14,  9.46it/s]
2022-03-21 00:37:50,370 - INFO - tqdm - f1: 0.7565, accuracy: 0.8205, batch_loss: 0.4079, loss: 0.4917 ||:  19%|#8        | 2138/11253 [03:32<14:19, 10.61it/s]
2022-03-21 00:38:00,419 - INFO - tqdm - f1: 0.7586, accuracy: 0.8223, batch_loss: 0.5036, loss: 0.4874 ||:  20%|#9        | 2241/11253 [03:42<16:05,  9.33it/s]
2022-03-21 00:38:10,426 - INFO - tqdm - f1: 0.7605, accuracy: 0.8238, batch_loss: 0.1366, loss: 0.4849 ||:  21%|##        | 2346/11253 [03:52<15:04,  9.85it/s]
2022-03-21 00:38:20,595 - INFO - tqdm - f1: 0.7615, accuracy: 0.8247, batch_loss: 0.1788, loss: 0.4830 ||:  22%|##1       | 2447/11253 [04:02<13:51, 10.59it/s]
2022-03-21 00:38:30,714 - INFO - tqdm - f1: 0.7626, accuracy: 0.8256, batch_loss: 0.5266, loss: 0.4805 ||:  23%|##2       | 2553/11253 [04:12<12:37, 11.48it/s]
2022-03-21 00:38:40,830 - INFO - tqdm - f1: 0.7639, accuracy: 0.8267, batch_loss: 0.9982, loss: 0.4780 ||:  24%|##3       | 2659/11253 [04:22<13:22, 10.71it/s]
2022-03-21 00:38:50,863 - INFO - tqdm - f1: 0.7635, accuracy: 0.8269, batch_loss: 0.5847, loss: 0.4772 ||:  25%|##4       | 2761/11253 [04:32<13:28, 10.50it/s]
2022-03-21 00:39:00,986 - INFO - tqdm - f1: 0.7641, accuracy: 0.8274, batch_loss: 0.4050, loss: 0.4756 ||:  25%|##5       | 2868/11253 [04:42<13:13, 10.57it/s]
2022-03-21 00:39:11,141 - INFO - tqdm - f1: 0.7651, accuracy: 0.8285, batch_loss: 0.4471, loss: 0.4721 ||:  26%|##6       | 2972/11253 [04:52<13:08, 10.51it/s]
2022-03-21 00:39:21,340 - INFO - tqdm - f1: 0.7661, accuracy: 0.8292, batch_loss: 0.3184, loss: 0.4706 ||:  27%|##7       | 3079/11253 [05:03<12:45, 10.68it/s]
2022-03-21 00:39:31,369 - INFO - tqdm - f1: 0.7675, accuracy: 0.8302, batch_loss: 0.3612, loss: 0.4679 ||:  28%|##8       | 3180/11253 [05:13<13:08, 10.24it/s]
2022-03-21 00:39:41,454 - INFO - tqdm - f1: 0.7682, accuracy: 0.8310, batch_loss: 0.3786, loss: 0.4655 ||:  29%|##9       | 3283/11253 [05:23<13:42,  9.69it/s]
2022-03-21 00:39:51,521 - INFO - tqdm - f1: 0.7696, accuracy: 0.8318, batch_loss: 0.1241, loss: 0.4635 ||:  30%|###       | 3387/11253 [05:33<12:06, 10.83it/s]
2022-03-21 00:40:01,661 - INFO - tqdm - f1: 0.7701, accuracy: 0.8326, batch_loss: 0.2686, loss: 0.4611 ||:  31%|###       | 3488/11253 [05:43<12:53, 10.04it/s]
2022-03-21 00:40:11,752 - INFO - tqdm - f1: 0.7710, accuracy: 0.8335, batch_loss: 0.5781, loss: 0.4590 ||:  32%|###2      | 3605/11253 [05:53<08:20, 15.28it/s]
2022-03-21 00:40:21,882 - INFO - tqdm - f1: 0.7724, accuracy: 0.8349, batch_loss: 0.2204, loss: 0.4564 ||:  33%|###3      | 3755/11253 [06:03<08:23, 14.90it/s]
2022-03-21 00:40:31,885 - INFO - tqdm - f1: 0.7729, accuracy: 0.8353, batch_loss: 0.5810, loss: 0.4553 ||:  35%|###4      | 3907/11253 [06:13<07:57, 15.39it/s]
2022-03-21 00:40:41,996 - INFO - tqdm - f1: 0.7742, accuracy: 0.8365, batch_loss: 0.3360, loss: 0.4520 ||:  36%|###6      | 4059/11253 [06:23<07:53, 15.20it/s]
2022-03-21 00:40:52,147 - INFO - tqdm - f1: 0.7752, accuracy: 0.8374, batch_loss: 0.1411, loss: 0.4504 ||:  37%|###7      | 4211/11253 [06:33<07:56, 14.77it/s]
2022-03-21 00:41:02,187 - INFO - tqdm - f1: 0.7764, accuracy: 0.8384, batch_loss: 0.4148, loss: 0.4479 ||:  39%|###8      | 4359/11253 [06:43<07:41, 14.92it/s]
2022-03-21 00:41:12,327 - INFO - tqdm - f1: 0.7771, accuracy: 0.8391, batch_loss: 0.4897, loss: 0.4461 ||:  40%|####      | 4513/11253 [06:54<07:49, 14.35it/s]
2022-03-21 00:41:22,388 - INFO - tqdm - f1: 0.7776, accuracy: 0.8398, batch_loss: 0.5036, loss: 0.4442 ||:  41%|####1     | 4659/11253 [07:04<07:01, 15.66it/s]
2022-03-21 00:41:32,456 - INFO - tqdm - f1: 0.7777, accuracy: 0.8401, batch_loss: 0.5580, loss: 0.4424 ||:  43%|####2     | 4807/11253 [07:14<08:03, 13.32it/s]
2022-03-21 00:41:42,473 - INFO - tqdm - f1: 0.7782, accuracy: 0.8404, batch_loss: 0.2061, loss: 0.4416 ||:  44%|####3     | 4941/11253 [07:24<07:19, 14.37it/s]
2022-03-21 00:41:52,547 - INFO - tqdm - f1: 0.7787, accuracy: 0.8405, batch_loss: 0.5515, loss: 0.4407 ||:  45%|####5     | 5089/11253 [07:34<06:49, 15.06it/s]
2022-03-21 00:42:02,617 - INFO - tqdm - f1: 0.7789, accuracy: 0.8411, batch_loss: 0.2021, loss: 0.4391 ||:  47%|####6     | 5239/11253 [07:44<06:39, 15.07it/s]
2022-03-21 00:42:12,679 - INFO - tqdm - f1: 0.7787, accuracy: 0.8411, batch_loss: 0.5608, loss: 0.4385 ||:  48%|####7     | 5387/11253 [07:54<06:36, 14.79it/s]
2022-03-21 00:42:22,721 - INFO - tqdm - f1: 0.7791, accuracy: 0.8415, batch_loss: 0.7233, loss: 0.4376 ||:  49%|####9     | 5533/11253 [08:04<06:40, 14.30it/s]
2022-03-21 00:42:32,817 - INFO - tqdm - f1: 0.7793, accuracy: 0.8417, batch_loss: 0.4126, loss: 0.4367 ||:  50%|#####     | 5673/11253 [08:14<06:37, 14.03it/s]
2022-03-21 00:42:42,915 - INFO - tqdm - f1: 0.7798, accuracy: 0.8422, batch_loss: 0.5197, loss: 0.4356 ||:  52%|#####1    | 5821/11253 [08:24<06:12, 14.59it/s]
2022-03-21 00:42:53,030 - INFO - tqdm - f1: 0.7802, accuracy: 0.8426, batch_loss: 0.3004, loss: 0.4340 ||:  53%|#####3    | 5973/11253 [08:34<05:39, 15.55it/s]
2022-03-21 00:43:03,068 - INFO - tqdm - f1: 0.7807, accuracy: 0.8431, batch_loss: 0.1716, loss: 0.4324 ||:  54%|#####4    | 6121/11253 [08:44<05:25, 15.76it/s]
2022-03-21 00:43:13,176 - INFO - tqdm - f1: 0.7813, accuracy: 0.8435, batch_loss: 0.0808, loss: 0.4314 ||:  56%|#####5    | 6269/11253 [08:54<05:33, 14.96it/s]
2022-03-21 00:43:23,287 - INFO - tqdm - f1: 0.7819, accuracy: 0.8441, batch_loss: 0.7184, loss: 0.4299 ||:  57%|#####7    | 6417/11253 [09:05<05:24, 14.90it/s]
2022-03-21 00:43:33,341 - INFO - tqdm - f1: 0.7824, accuracy: 0.8445, batch_loss: 0.3029, loss: 0.4288 ||:  58%|#####8    | 6565/11253 [09:15<05:26, 14.34it/s]
2022-03-21 00:43:43,395 - INFO - tqdm - f1: 0.7827, accuracy: 0.8450, batch_loss: 0.0407, loss: 0.4281 ||:  60%|#####9    | 6713/11253 [09:25<05:21, 14.10it/s]
2022-03-21 00:43:53,433 - INFO - tqdm - f1: 0.7828, accuracy: 0.8452, batch_loss: 0.3429, loss: 0.4273 ||:  61%|######    | 6861/11253 [09:35<04:59, 14.68it/s]
2022-03-21 00:44:03,437 - INFO - tqdm - f1: 0.7834, accuracy: 0.8454, batch_loss: 0.4304, loss: 0.4269 ||:  62%|######2   | 7011/11253 [09:45<04:56, 14.30it/s]
2022-03-21 00:44:13,538 - INFO - tqdm - f1: 0.7837, accuracy: 0.8456, batch_loss: 0.6257, loss: 0.4265 ||:  64%|######3   | 7161/11253 [09:55<04:39, 14.65it/s]
2022-03-21 00:44:23,579 - INFO - tqdm - f1: 0.7838, accuracy: 0.8457, batch_loss: 0.6604, loss: 0.4261 ||:  65%|######4   | 7311/11253 [10:05<04:28, 14.70it/s]
2022-03-21 00:44:33,587 - INFO - tqdm - f1: 0.7841, accuracy: 0.8460, batch_loss: 0.3940, loss: 0.4251 ||:  66%|######6   | 7459/11253 [10:15<04:25, 14.31it/s]
2022-03-21 00:44:43,631 - INFO - tqdm - f1: 0.7843, accuracy: 0.8462, batch_loss: 0.2524, loss: 0.4245 ||:  68%|######7   | 7607/11253 [10:25<04:15, 14.28it/s]
2022-03-21 00:44:53,649 - INFO - tqdm - f1: 0.7844, accuracy: 0.8462, batch_loss: 0.7693, loss: 0.4242 ||:  69%|######8   | 7759/11253 [10:35<03:40, 15.86it/s]
2022-03-21 00:45:03,762 - INFO - tqdm - f1: 0.7846, accuracy: 0.8464, batch_loss: 0.3142, loss: 0.4235 ||:  70%|#######   | 7913/11253 [10:45<03:45, 14.83it/s]
2022-03-21 00:45:13,865 - INFO - tqdm - f1: 0.7844, accuracy: 0.8465, batch_loss: 0.2911, loss: 0.4228 ||:  72%|#######1  | 8065/11253 [10:55<03:29, 15.19it/s]
2022-03-21 00:45:23,993 - INFO - tqdm - f1: 0.7847, accuracy: 0.8468, batch_loss: 0.7366, loss: 0.4222 ||:  73%|#######2  | 8213/11253 [11:05<03:36, 14.04it/s]
2022-03-21 00:45:34,103 - INFO - tqdm - f1: 0.7851, accuracy: 0.8471, batch_loss: 0.3775, loss: 0.4217 ||:  74%|#######4  | 8361/11253 [11:15<03:04, 15.69it/s]
2022-03-21 00:45:44,174 - INFO - tqdm - f1: 0.7854, accuracy: 0.8474, batch_loss: 0.3041, loss: 0.4208 ||:  76%|#######5  | 8509/11253 [11:25<02:57, 15.43it/s]
2022-03-21 00:45:54,189 - INFO - tqdm - f1: 0.7862, accuracy: 0.8479, batch_loss: 0.3470, loss: 0.4201 ||:  77%|#######6  | 8659/11253 [11:35<02:48, 15.39it/s]
2022-03-21 00:46:04,221 - INFO - tqdm - f1: 0.7869, accuracy: 0.8484, batch_loss: 0.9757, loss: 0.4193 ||:  78%|#######8  | 8807/11253 [11:46<02:38, 15.43it/s]
2022-03-21 00:46:14,294 - INFO - tqdm - f1: 0.7872, accuracy: 0.8485, batch_loss: 0.1537, loss: 0.4190 ||:  80%|#######9  | 8957/11253 [11:56<02:34, 14.84it/s]
2022-03-21 00:46:24,391 - INFO - tqdm - f1: 0.7873, accuracy: 0.8486, batch_loss: 0.7160, loss: 0.4187 ||:  81%|########  | 9107/11253 [12:06<02:25, 14.76it/s]
2022-03-21 00:46:34,393 - INFO - tqdm - f1: 0.7877, accuracy: 0.8488, batch_loss: 0.5258, loss: 0.4183 ||:  82%|########2 | 9255/11253 [12:16<02:17, 14.57it/s]
2022-03-21 00:46:44,460 - INFO - tqdm - f1: 0.7884, accuracy: 0.8493, batch_loss: 0.2702, loss: 0.4174 ||:  84%|########3 | 9407/11253 [12:26<02:02, 15.09it/s]
2022-03-21 00:46:54,485 - INFO - tqdm - f1: 0.7885, accuracy: 0.8493, batch_loss: 0.3122, loss: 0.4173 ||:  85%|########4 | 9555/11253 [12:36<01:56, 14.56it/s]
2022-03-21 00:47:04,607 - INFO - tqdm - f1: 0.7887, accuracy: 0.8495, batch_loss: 0.2402, loss: 0.4167 ||:  86%|########6 | 9707/11253 [12:46<01:46, 14.58it/s]
2022-03-21 00:47:14,719 - INFO - tqdm - f1: 0.7888, accuracy: 0.8497, batch_loss: 0.1931, loss: 0.4158 ||:  88%|########7 | 9857/11253 [12:56<01:37, 14.29it/s]
2022-03-21 00:47:24,728 - INFO - tqdm - f1: 0.7890, accuracy: 0.8499, batch_loss: 0.4946, loss: 0.4155 ||:  89%|########8 | 10005/11253 [13:06<01:28, 14.02it/s]
2022-03-21 00:47:34,808 - INFO - tqdm - f1: 0.7890, accuracy: 0.8500, batch_loss: 0.2412, loss: 0.4150 ||:  90%|######### | 10157/11253 [13:16<01:09, 15.82it/s]
2022-03-21 00:47:44,836 - INFO - tqdm - f1: 0.7889, accuracy: 0.8500, batch_loss: 0.0334, loss: 0.4148 ||:  92%|#########1| 10307/11253 [13:26<01:02, 15.03it/s]
2022-03-21 00:47:54,892 - INFO - tqdm - f1: 0.7890, accuracy: 0.8502, batch_loss: 0.4958, loss: 0.4144 ||:  93%|#########2| 10457/11253 [13:36<00:52, 15.24it/s]
2022-03-21 00:48:04,994 - INFO - tqdm - f1: 0.7894, accuracy: 0.8505, batch_loss: 0.5548, loss: 0.4137 ||:  94%|#########4| 10609/11253 [13:46<00:43, 14.88it/s]
2022-03-21 00:48:15,006 - INFO - tqdm - f1: 0.7894, accuracy: 0.8505, batch_loss: 0.4047, loss: 0.4136 ||:  96%|#########5| 10759/11253 [13:56<00:33, 14.73it/s]
2022-03-21 00:48:25,094 - INFO - tqdm - f1: 0.7896, accuracy: 0.8506, batch_loss: 0.3475, loss: 0.4133 ||:  97%|#########6| 10907/11253 [14:06<00:23, 14.68it/s]
2022-03-21 00:48:35,212 - INFO - tqdm - f1: 0.7898, accuracy: 0.8509, batch_loss: 0.5428, loss: 0.4126 ||:  98%|#########8| 11057/11253 [14:17<00:13, 15.04it/s]
2022-03-21 00:48:44,743 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.1896, loss: 0.4125 ||: 100%|#########9| 11197/11253 [14:26<00:03, 14.15it/s]
2022-03-21 00:48:44,988 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.0085, loss: 0.4125 ||: 100%|#########9| 11199/11253 [14:26<00:04, 11.60it/s]
2022-03-21 00:48:45,115 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.3373, loss: 0.4125 ||: 100%|#########9| 11201/11253 [14:26<00:04, 12.58it/s]
2022-03-21 00:48:45,255 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.2171, loss: 0.4124 ||: 100%|#########9| 11203/11253 [14:27<00:03, 13.06it/s]
2022-03-21 00:48:45,383 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.3481, loss: 0.4124 ||: 100%|#########9| 11205/11253 [14:27<00:03, 13.71it/s]
2022-03-21 00:48:45,682 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.0074, loss: 0.4124 ||: 100%|#########9| 11207/11253 [14:27<00:04, 10.44it/s]
2022-03-21 00:48:45,819 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.4479, loss: 0.4124 ||: 100%|#########9| 11209/11253 [14:27<00:03, 11.41it/s]
2022-03-21 00:48:45,952 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.7013, loss: 0.4124 ||: 100%|#########9| 11211/11253 [14:27<00:03, 12.31it/s]
2022-03-21 00:48:46,084 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.2413, loss: 0.4124 ||: 100%|#########9| 11213/11253 [14:27<00:03, 13.03it/s]
2022-03-21 00:48:46,219 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.6084, loss: 0.4124 ||: 100%|#########9| 11215/11253 [14:28<00:02, 13.52it/s]
2022-03-21 00:48:46,361 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.1446, loss: 0.4124 ||: 100%|#########9| 11217/11253 [14:28<00:02, 13.69it/s]
2022-03-21 00:48:46,516 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.2110, loss: 0.4124 ||: 100%|#########9| 11219/11253 [14:28<00:02, 13.44it/s]
2022-03-21 00:48:46,666 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.2663, loss: 0.4124 ||: 100%|#########9| 11221/11253 [14:28<00:02, 13.43it/s]
2022-03-21 00:48:46,804 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.3454, loss: 0.4124 ||: 100%|#########9| 11223/11253 [14:28<00:02, 13.72it/s]
2022-03-21 00:48:46,943 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.4487, loss: 0.4125 ||: 100%|#########9| 11225/11253 [14:28<00:02, 13.90it/s]
2022-03-21 00:48:47,077 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.2696, loss: 0.4125 ||: 100%|#########9| 11227/11253 [14:28<00:01, 14.21it/s]
2022-03-21 00:48:47,207 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.8671, loss: 0.4125 ||: 100%|#########9| 11229/11253 [14:29<00:01, 14.54it/s]
2022-03-21 00:48:47,344 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.1638, loss: 0.4125 ||: 100%|#########9| 11231/11253 [14:29<00:01, 14.55it/s]
2022-03-21 00:48:47,495 - INFO - tqdm - f1: 0.7896, accuracy: 0.8509, batch_loss: 0.2658, loss: 0.4125 ||: 100%|#########9| 11233/11253 [14:29<00:01, 14.12it/s]
2022-03-21 00:48:47,638 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.0676, loss: 0.4124 ||: 100%|#########9| 11235/11253 [14:29<00:01, 14.08it/s]
2022-03-21 00:48:47,774 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.4228, loss: 0.4124 ||: 100%|#########9| 11237/11253 [14:29<00:01, 14.28it/s]
2022-03-21 00:48:47,914 - INFO - tqdm - f1: 0.7897, accuracy: 0.8509, batch_loss: 0.5447, loss: 0.4125 ||: 100%|#########9| 11239/11253 [14:29<00:00, 14.27it/s]
2022-03-21 00:48:48,039 - INFO - tqdm - f1: 0.7896, accuracy: 0.8509, batch_loss: 0.4045, loss: 0.4125 ||: 100%|#########9| 11241/11253 [14:29<00:00, 14.75it/s]
2022-03-21 00:48:48,171 - INFO - tqdm - f1: 0.7896, accuracy: 0.8508, batch_loss: 0.6804, loss: 0.4125 ||: 100%|#########9| 11243/11253 [14:29<00:00, 14.89it/s]
2022-03-21 00:48:48,306 - INFO - tqdm - f1: 0.7896, accuracy: 0.8508, batch_loss: 0.4736, loss: 0.4125 ||: 100%|#########9| 11245/11253 [14:30<00:00, 14.87it/s]
2022-03-21 00:48:48,454 - INFO - tqdm - f1: 0.7896, accuracy: 0.8508, batch_loss: 0.4028, loss: 0.4125 ||: 100%|#########9| 11247/11253 [14:30<00:00, 14.42it/s]
2022-03-21 00:48:48,605 - INFO - tqdm - f1: 0.7896, accuracy: 0.8508, batch_loss: 0.2514, loss: 0.4125 ||: 100%|#########9| 11249/11253 [14:30<00:00, 14.04it/s]
2022-03-21 00:48:48,754 - INFO - tqdm - f1: 0.7896, accuracy: 0.8508, batch_loss: 0.3914, loss: 0.4125 ||: 100%|#########9| 11251/11253 [14:30<00:00, 13.87it/s]
2022-03-21 00:48:48,885 - INFO - tqdm - f1: 0.7896, accuracy: 0.8508, batch_loss: 0.7203, loss: 0.4125 ||: 100%|##########| 11253/11253 [14:30<00:00, 14.25it/s]
2022-03-21 00:48:48,961 - INFO - tqdm - f1: 0.7896, accuracy: 0.8508, batch_loss: 0.7203, loss: 0.4125 ||: 100%|##########| 11253/11253 [14:30<00:00, 12.92it/s]
2022-03-21 00:48:48,969 - INFO - allennlp.training.trainer - Validating
2022-03-21 00:48:48,978 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 00:48:49,013 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 00:48:49,016 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 00:48:59,025 - INFO - tqdm - f1: 0.7998, accuracy: 0.8581, batch_loss: 0.5974, loss: 0.3849 ||:  24%|##3       | 449/1889 [00:10<00:29, 48.82it/s]
2022-03-21 00:49:09,078 - INFO - tqdm - f1: 0.8016, accuracy: 0.8591, batch_loss: 0.2315, loss: 0.3861 ||:  47%|####7     | 894/1889 [00:20<00:22, 43.26it/s]
2022-03-21 00:49:19,134 - INFO - tqdm - f1: 0.8077, accuracy: 0.8623, batch_loss: 0.2083, loss: 0.3855 ||:  71%|#######1  | 1344/1889 [00:30<00:10, 50.42it/s]
2022-03-21 00:49:29,210 - INFO - tqdm - f1: 0.8089, accuracy: 0.8633, batch_loss: 0.2193, loss: 0.3857 ||:  94%|#########4| 1784/1889 [00:40<00:02, 44.03it/s]
2022-03-21 00:49:31,336 - INFO - tqdm - f1: 0.8091, accuracy: 0.8631, batch_loss: 0.6241, loss: 0.3857 ||: 100%|#########9| 1884/1889 [00:42<00:00, 51.37it/s]
2022-03-21 00:49:31,508 - INFO - tqdm - f1: 0.8089, accuracy: 0.8630, batch_loss: 0.3124, loss: 0.3861 ||: 100%|##########| 1889/1889 [00:42<00:00, 44.42it/s]
2022-03-21 00:49:31,530 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct-20k_base_hyper_small_seed_47/best.th'.
2022-03-21 00:49:34,175 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 00:49:34,178 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.851  |     0.863
2022-03-21 00:49:34,180 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.790  |     0.809
2022-03-21 00:49:34,182 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 00:49:34,185 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.413  |     0.386
2022-03-21 00:49:34,187 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8466.617  |       N/A
2022-03-21 00:49:34,190 - INFO - allennlp.training.trainer - Epoch duration: 0:15:16.000910
2022-03-21 00:49:34,193 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:17:24
2022-03-21 00:49:34,199 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-21 00:49:34,201 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 00:49:34,204 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 00:49:34,208 - INFO - allennlp.training.trainer - Training
2022-03-21 00:49:34,217 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 00:49:44,331 - INFO - tqdm - f1: 0.8018, accuracy: 0.8689, batch_loss: 0.4054, loss: 0.3563 ||:   1%|1         | 133/11253 [00:10<13:00, 14.24it/s]
2022-03-21 00:49:54,364 - INFO - tqdm - f1: 0.8080, accuracy: 0.8704, batch_loss: 0.0666, loss: 0.3559 ||:   3%|2         | 283/11253 [00:20<11:37, 15.74it/s]
2022-03-21 00:50:04,436 - INFO - tqdm - f1: 0.8139, accuracy: 0.8730, batch_loss: 0.4147, loss: 0.3477 ||:   4%|3         | 433/11253 [00:30<11:30, 15.67it/s]
2022-03-21 00:50:14,449 - INFO - tqdm - f1: 0.8091, accuracy: 0.8737, batch_loss: 0.0616, loss: 0.3434 ||:   5%|5         | 583/11253 [00:40<11:34, 15.37it/s]
2022-03-21 00:50:24,544 - INFO - tqdm - f1: 0.8136, accuracy: 0.8748, batch_loss: 0.1490, loss: 0.3436 ||:   7%|6         | 733/11253 [00:50<11:13, 15.63it/s]
2022-03-21 00:50:34,625 - INFO - tqdm - f1: 0.8148, accuracy: 0.8741, batch_loss: 0.2782, loss: 0.3478 ||:   8%|7         | 885/11253 [01:00<11:25, 15.12it/s]
2022-03-21 00:50:44,690 - INFO - tqdm - f1: 0.8164, accuracy: 0.8746, batch_loss: 0.4163, loss: 0.3466 ||:   9%|9         | 1037/11253 [01:10<12:00, 14.18it/s]
2022-03-21 00:50:54,713 - INFO - tqdm - f1: 0.8155, accuracy: 0.8740, batch_loss: 0.2721, loss: 0.3484 ||:  11%|#         | 1187/11253 [01:20<11:59, 13.98it/s]
2022-03-21 00:51:04,740 - INFO - tqdm - f1: 0.8153, accuracy: 0.8738, batch_loss: 0.3450, loss: 0.3492 ||:  12%|#1        | 1337/11253 [01:30<11:21, 14.56it/s]
2022-03-21 00:51:14,785 - INFO - tqdm - f1: 0.8145, accuracy: 0.8735, batch_loss: 0.3608, loss: 0.3491 ||:  13%|#3        | 1487/11253 [01:40<11:05, 14.67it/s]
2022-03-21 00:51:24,832 - INFO - tqdm - f1: 0.8158, accuracy: 0.8744, batch_loss: 0.3581, loss: 0.3481 ||:  15%|#4        | 1637/11253 [01:50<11:13, 14.28it/s]
2022-03-21 00:51:34,881 - INFO - tqdm - f1: 0.8166, accuracy: 0.8751, batch_loss: 0.6880, loss: 0.3462 ||:  16%|#5        | 1785/11253 [02:00<11:08, 14.15it/s]
2022-03-21 00:51:44,961 - INFO - tqdm - f1: 0.8149, accuracy: 0.8746, batch_loss: 0.6501, loss: 0.3457 ||:  17%|#7        | 1935/11253 [02:10<10:47, 14.40it/s]
2022-03-21 00:51:54,984 - INFO - tqdm - f1: 0.8158, accuracy: 0.8751, batch_loss: 0.3298, loss: 0.3449 ||:  19%|#8        | 2085/11253 [02:20<10:24, 14.67it/s]
2022-03-21 00:52:05,050 - INFO - tqdm - f1: 0.8156, accuracy: 0.8750, batch_loss: 0.5528, loss: 0.3444 ||:  20%|#9        | 2233/11253 [02:30<09:37, 15.62it/s]
2022-03-21 00:52:15,175 - INFO - tqdm - f1: 0.8154, accuracy: 0.8750, batch_loss: 0.7571, loss: 0.3439 ||:  21%|##1       | 2385/11253 [02:40<09:26, 15.67it/s]
2022-03-21 00:52:25,239 - INFO - tqdm - f1: 0.8154, accuracy: 0.8750, batch_loss: 0.1543, loss: 0.3447 ||:  23%|##2       | 2535/11253 [02:51<09:34, 15.17it/s]
2022-03-21 00:52:35,285 - INFO - tqdm - f1: 0.8155, accuracy: 0.8747, batch_loss: 0.4463, loss: 0.3452 ||:  24%|##3       | 2685/11253 [03:01<09:26, 15.11it/s]
2022-03-21 00:52:45,362 - INFO - tqdm - f1: 0.8148, accuracy: 0.8743, batch_loss: 0.2985, loss: 0.3452 ||:  25%|##5       | 2835/11253 [03:11<09:24, 14.90it/s]
2022-03-21 00:52:55,439 - INFO - tqdm - f1: 0.8145, accuracy: 0.8742, batch_loss: 0.1879, loss: 0.3443 ||:  27%|##6       | 2985/11253 [03:21<09:11, 14.99it/s]
2022-03-21 00:53:05,440 - INFO - tqdm - f1: 0.8150, accuracy: 0.8745, batch_loss: 0.2447, loss: 0.3435 ||:  28%|##7       | 3133/11253 [03:31<08:40, 15.59it/s]
2022-03-21 00:53:15,490 - INFO - tqdm - f1: 0.8146, accuracy: 0.8744, batch_loss: 0.5064, loss: 0.3436 ||:  29%|##9       | 3277/11253 [03:41<08:40, 15.32it/s]
2022-03-21 00:53:25,515 - INFO - tqdm - f1: 0.8147, accuracy: 0.8741, batch_loss: 0.4240, loss: 0.3444 ||:  30%|###       | 3425/11253 [03:51<08:52, 14.71it/s]
2022-03-21 00:53:35,594 - INFO - tqdm - f1: 0.8138, accuracy: 0.8741, batch_loss: 0.6967, loss: 0.3442 ||:  32%|###1      | 3575/11253 [04:01<08:52, 14.41it/s]
2022-03-21 00:53:45,729 - INFO - tqdm - f1: 0.8143, accuracy: 0.8741, batch_loss: 0.3858, loss: 0.3440 ||:  33%|###3      | 3723/11253 [04:11<08:36, 14.58it/s]
2022-03-21 00:53:55,850 - INFO - tqdm - f1: 0.8149, accuracy: 0.8743, batch_loss: 0.4892, loss: 0.3443 ||:  34%|###4      | 3873/11253 [04:21<08:45, 14.05it/s]
2022-03-21 00:54:05,933 - INFO - tqdm - f1: 0.8155, accuracy: 0.8747, batch_loss: 0.3882, loss: 0.3439 ||:  36%|###5      | 4023/11253 [04:31<08:11, 14.70it/s]
2022-03-21 00:54:16,047 - INFO - tqdm - f1: 0.8161, accuracy: 0.8750, batch_loss: 0.1996, loss: 0.3430 ||:  37%|###7      | 4173/11253 [04:41<07:39, 15.42it/s]
2022-03-21 00:54:26,064 - INFO - tqdm - f1: 0.8160, accuracy: 0.8747, batch_loss: 0.6010, loss: 0.3438 ||:  38%|###8      | 4323/11253 [04:51<07:49, 14.78it/s]
2022-03-21 00:54:36,078 - INFO - tqdm - f1: 0.8169, accuracy: 0.8752, batch_loss: 0.5539, loss: 0.3437 ||:  40%|###9      | 4471/11253 [05:01<07:52, 14.34it/s]
2022-03-21 00:54:46,117 - INFO - tqdm - f1: 0.8171, accuracy: 0.8751, batch_loss: 0.2986, loss: 0.3438 ||:  41%|####1     | 4621/11253 [05:11<07:38, 14.47it/s]
2022-03-21 00:54:56,151 - INFO - tqdm - f1: 0.8175, accuracy: 0.8754, batch_loss: 0.2984, loss: 0.3433 ||:  42%|####2     | 4767/11253 [05:21<07:22, 14.64it/s]
2022-03-21 00:55:06,200 - INFO - tqdm - f1: 0.8172, accuracy: 0.8754, batch_loss: 0.4022, loss: 0.3432 ||:  44%|####3     | 4913/11253 [05:31<07:23, 14.30it/s]
2022-03-21 00:55:16,275 - INFO - tqdm - f1: 0.8166, accuracy: 0.8751, batch_loss: 0.3647, loss: 0.3439 ||:  45%|####4     | 5063/11253 [05:42<06:45, 15.27it/s]
2022-03-21 00:55:26,315 - INFO - tqdm - f1: 0.8164, accuracy: 0.8751, batch_loss: 0.3865, loss: 0.3439 ||:  46%|####6     | 5213/11253 [05:52<06:57, 14.45it/s]
2022-03-21 00:55:36,323 - INFO - tqdm - f1: 0.8167, accuracy: 0.8754, batch_loss: 0.4388, loss: 0.3433 ||:  48%|####7     | 5363/11253 [06:02<06:33, 14.98it/s]
2022-03-21 00:55:46,453 - INFO - tqdm - f1: 0.8167, accuracy: 0.8752, batch_loss: 0.1235, loss: 0.3440 ||:  49%|####8     | 5511/11253 [06:12<06:33, 14.60it/s]
2022-03-21 00:55:56,571 - INFO - tqdm - f1: 0.8167, accuracy: 0.8749, batch_loss: 0.2043, loss: 0.3445 ||:  50%|#####     | 5663/11253 [06:22<06:16, 14.86it/s]
2022-03-21 00:56:06,583 - INFO - tqdm - f1: 0.8167, accuracy: 0.8747, batch_loss: 0.2260, loss: 0.3452 ||:  52%|#####1    | 5811/11253 [06:32<05:56, 15.28it/s]
2022-03-21 00:56:16,669 - INFO - tqdm - f1: 0.8169, accuracy: 0.8749, batch_loss: 0.3257, loss: 0.3448 ||:  53%|#####2    | 5961/11253 [06:42<05:39, 15.58it/s]
2022-03-21 00:56:26,789 - INFO - tqdm - f1: 0.8169, accuracy: 0.8749, batch_loss: 0.6591, loss: 0.3447 ||:  54%|#####4    | 6111/11253 [06:52<05:49, 14.70it/s]
2022-03-21 00:56:36,845 - INFO - tqdm - f1: 0.8172, accuracy: 0.8752, batch_loss: 0.5943, loss: 0.3439 ||:  56%|#####5    | 6259/11253 [07:02<05:46, 14.41it/s]
2022-03-21 00:56:46,981 - INFO - tqdm - f1: 0.8171, accuracy: 0.8750, batch_loss: 0.3835, loss: 0.3442 ||:  57%|#####6    | 6407/11253 [07:12<06:05, 13.27it/s]
2022-03-21 00:56:57,089 - INFO - tqdm - f1: 0.8172, accuracy: 0.8749, batch_loss: 0.2585, loss: 0.3446 ||:  58%|#####8    | 6555/11253 [07:22<05:25, 14.44it/s]
2022-03-21 00:57:07,195 - INFO - tqdm - f1: 0.8171, accuracy: 0.8747, batch_loss: 0.2753, loss: 0.3451 ||:  60%|#####9    | 6707/11253 [07:32<05:04, 14.92it/s]
2022-03-21 00:57:17,230 - INFO - tqdm - f1: 0.8169, accuracy: 0.8746, batch_loss: 0.3228, loss: 0.3452 ||:  61%|######    | 6855/11253 [07:43<04:58, 14.74it/s]
2022-03-21 00:57:27,344 - INFO - tqdm - f1: 0.8170, accuracy: 0.8748, batch_loss: 0.1361, loss: 0.3449 ||:  62%|######2   | 7005/11253 [07:53<04:39, 15.22it/s]
2022-03-21 00:57:37,447 - INFO - tqdm - f1: 0.8171, accuracy: 0.8748, batch_loss: 0.1196, loss: 0.3448 ||:  64%|######3   | 7157/11253 [08:03<04:34, 14.90it/s]
2022-03-21 00:57:47,485 - INFO - tqdm - f1: 0.8169, accuracy: 0.8747, batch_loss: 0.1842, loss: 0.3454 ||:  65%|######4   | 7307/11253 [08:13<04:26, 14.80it/s]
2022-03-21 00:57:57,569 - INFO - tqdm - f1: 0.8166, accuracy: 0.8746, batch_loss: 0.4922, loss: 0.3456 ||:  66%|######6   | 7461/11253 [08:23<04:04, 15.49it/s]
2022-03-21 00:58:07,703 - INFO - tqdm - f1: 0.8166, accuracy: 0.8744, batch_loss: 0.0110, loss: 0.3460 ||:  68%|######7   | 7611/11253 [08:33<04:00, 15.17it/s]
2022-03-21 00:58:17,720 - INFO - tqdm - f1: 0.8167, accuracy: 0.8744, batch_loss: 0.9308, loss: 0.3462 ||:  69%|######8   | 7763/11253 [08:43<03:42, 15.66it/s]
2022-03-21 00:58:27,812 - INFO - tqdm - f1: 0.8167, accuracy: 0.8745, batch_loss: 0.3153, loss: 0.3456 ||:  70%|#######   | 7913/11253 [08:53<03:47, 14.66it/s]
2022-03-21 00:58:37,882 - INFO - tqdm - f1: 0.8163, accuracy: 0.8744, batch_loss: 0.9672, loss: 0.3459 ||:  72%|#######1  | 8065/11253 [09:03<03:33, 14.90it/s]
2022-03-21 00:58:47,930 - INFO - tqdm - f1: 0.8165, accuracy: 0.8744, batch_loss: 0.1188, loss: 0.3462 ||:  73%|#######2  | 8213/11253 [09:13<03:25, 14.80it/s]
2022-03-21 00:58:58,028 - INFO - tqdm - f1: 0.8167, accuracy: 0.8746, batch_loss: 0.3952, loss: 0.3457 ||:  74%|#######4  | 8363/11253 [09:23<03:22, 14.29it/s]
2022-03-21 00:59:08,104 - INFO - tqdm - f1: 0.8166, accuracy: 0.8745, batch_loss: 0.1960, loss: 0.3459 ||:  76%|#######5  | 8513/11253 [09:33<03:03, 14.90it/s]
2022-03-21 00:59:18,192 - INFO - tqdm - f1: 0.8165, accuracy: 0.8745, batch_loss: 0.1894, loss: 0.3460 ||:  77%|#######6  | 8663/11253 [09:43<03:02, 14.22it/s]
2022-03-21 00:59:28,285 - INFO - tqdm - f1: 0.8167, accuracy: 0.8746, batch_loss: 0.2820, loss: 0.3459 ||:  78%|#######8  | 8813/11253 [09:54<02:32, 15.99it/s]
2022-03-21 00:59:38,404 - INFO - tqdm - f1: 0.8167, accuracy: 0.8745, batch_loss: 0.2872, loss: 0.3462 ||:  80%|#######9  | 8961/11253 [10:04<02:39, 14.36it/s]
2022-03-21 00:59:48,522 - INFO - tqdm - f1: 0.8168, accuracy: 0.8745, batch_loss: 0.0260, loss: 0.3461 ||:  81%|########  | 9113/11253 [10:14<02:20, 15.21it/s]
2022-03-21 00:59:58,631 - INFO - tqdm - f1: 0.8171, accuracy: 0.8747, batch_loss: 0.2896, loss: 0.3460 ||:  82%|########2 | 9263/11253 [10:24<02:13, 14.88it/s]
2022-03-21 01:00:08,671 - INFO - tqdm - f1: 0.8172, accuracy: 0.8748, batch_loss: 0.1877, loss: 0.3459 ||:  84%|########3 | 9411/11253 [10:34<02:05, 14.73it/s]
2022-03-21 01:00:18,755 - INFO - tqdm - f1: 0.8171, accuracy: 0.8748, batch_loss: 0.3632, loss: 0.3457 ||:  85%|########4 | 9559/11253 [10:44<01:56, 14.60it/s]
2022-03-21 01:00:28,843 - INFO - tqdm - f1: 0.8171, accuracy: 0.8747, batch_loss: 0.2744, loss: 0.3460 ||:  86%|########6 | 9711/11253 [10:54<01:38, 15.68it/s]
2022-03-21 01:00:38,910 - INFO - tqdm - f1: 0.8170, accuracy: 0.8747, batch_loss: 0.2837, loss: 0.3462 ||:  88%|########7 | 9857/11253 [11:04<01:35, 14.69it/s]
2022-03-21 01:00:48,934 - INFO - tqdm - f1: 0.8170, accuracy: 0.8748, batch_loss: 0.1850, loss: 0.3459 ||:  89%|########8 | 10005/11253 [11:14<01:22, 15.08it/s]
2022-03-21 01:00:58,962 - INFO - tqdm - f1: 0.8170, accuracy: 0.8747, batch_loss: 0.5156, loss: 0.3460 ||:  90%|######### | 10155/11253 [11:24<01:12, 15.13it/s]
2022-03-21 01:01:08,977 - INFO - tqdm - f1: 0.8171, accuracy: 0.8749, batch_loss: 0.1744, loss: 0.3457 ||:  92%|#########1| 10303/11253 [11:34<01:05, 14.60it/s]
2022-03-21 01:01:19,107 - INFO - tqdm - f1: 0.8172, accuracy: 0.8750, batch_loss: 0.3309, loss: 0.3455 ||:  93%|#########2| 10455/11253 [11:44<00:53, 14.99it/s]
2022-03-21 01:01:29,108 - INFO - tqdm - f1: 0.8172, accuracy: 0.8750, batch_loss: 0.4190, loss: 0.3453 ||:  94%|#########4| 10601/11253 [11:54<00:46, 14.08it/s]
2022-03-21 01:01:39,124 - INFO - tqdm - f1: 0.8175, accuracy: 0.8752, batch_loss: 0.5019, loss: 0.3449 ||:  96%|#########5| 10751/11253 [12:04<00:33, 14.99it/s]
2022-03-21 01:01:49,153 - INFO - tqdm - f1: 0.8173, accuracy: 0.8752, batch_loss: 0.1417, loss: 0.3451 ||:  97%|#########6| 10899/11253 [12:14<00:23, 15.03it/s]
2022-03-21 01:01:59,234 - INFO - tqdm - f1: 0.8173, accuracy: 0.8751, batch_loss: 0.1439, loss: 0.3453 ||:  98%|#########8| 11049/11253 [12:25<00:14, 14.55it/s]
2022-03-21 01:02:09,338 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.2321, loss: 0.3455 ||:  99%|#########9| 11195/11253 [12:35<00:03, 14.97it/s]
2022-03-21 01:02:09,483 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.3759, loss: 0.3455 ||: 100%|#########9| 11197/11253 [12:35<00:03, 14.59it/s]
2022-03-21 01:02:09,609 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.3488, loss: 0.3455 ||: 100%|#########9| 11199/11253 [12:35<00:03, 14.96it/s]
2022-03-21 01:02:09,731 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.4335, loss: 0.3455 ||: 100%|#########9| 11201/11253 [12:35<00:03, 15.36it/s]
2022-03-21 01:02:09,884 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.1674, loss: 0.3455 ||: 100%|#########9| 11203/11253 [12:35<00:03, 14.60it/s]
2022-03-21 01:02:10,039 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.3226, loss: 0.3455 ||: 100%|#########9| 11205/11253 [12:35<00:03, 14.06it/s]
2022-03-21 01:02:10,189 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.2869, loss: 0.3455 ||: 100%|#########9| 11207/11253 [12:35<00:03, 13.81it/s]
2022-03-21 01:02:10,343 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.7523, loss: 0.3455 ||: 100%|#########9| 11209/11253 [12:36<00:03, 13.55it/s]
2022-03-21 01:02:10,482 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.1796, loss: 0.3455 ||: 100%|#########9| 11211/11253 [12:36<00:03, 13.81it/s]
2022-03-21 01:02:10,630 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.5663, loss: 0.3455 ||: 100%|#########9| 11213/11253 [12:36<00:02, 13.73it/s]
2022-03-21 01:02:10,757 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.2123, loss: 0.3455 ||: 100%|#########9| 11215/11253 [12:36<00:02, 14.27it/s]
2022-03-21 01:02:10,897 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.4250, loss: 0.3454 ||: 100%|#########9| 11217/11253 [12:36<00:02, 14.25it/s]
2022-03-21 01:02:11,058 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.3890, loss: 0.3454 ||: 100%|#########9| 11219/11253 [12:36<00:02, 13.66it/s]
2022-03-21 01:02:11,223 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.1956, loss: 0.3454 ||: 100%|#########9| 11221/11253 [12:37<00:02, 13.15it/s]
2022-03-21 01:02:11,363 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.2721, loss: 0.3454 ||: 100%|#########9| 11223/11253 [12:37<00:02, 13.49it/s]
2022-03-21 01:02:11,492 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.2455, loss: 0.3454 ||: 100%|#########9| 11225/11253 [12:37<00:01, 14.02it/s]
2022-03-21 01:02:11,646 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.4641, loss: 0.3454 ||: 100%|#########9| 11227/11253 [12:37<00:01, 13.69it/s]
2022-03-21 01:02:11,779 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.8451, loss: 0.3454 ||: 100%|#########9| 11229/11253 [12:37<00:01, 14.08it/s]
2022-03-21 01:02:11,912 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.7150, loss: 0.3455 ||: 100%|#########9| 11231/11253 [12:37<00:01, 14.36it/s]
2022-03-21 01:02:12,048 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.7681, loss: 0.3455 ||: 100%|#########9| 11233/11253 [12:37<00:01, 14.46it/s]
2022-03-21 01:02:12,189 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.4225, loss: 0.3455 ||: 100%|#########9| 11235/11253 [12:37<00:01, 14.37it/s]
2022-03-21 01:02:12,340 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.4504, loss: 0.3455 ||: 100%|#########9| 11237/11253 [12:38<00:01, 14.02it/s]
2022-03-21 01:02:12,488 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.1453, loss: 0.3455 ||: 100%|#########9| 11239/11253 [12:38<00:01, 13.87it/s]
2022-03-21 01:02:12,632 - INFO - tqdm - f1: 0.8175, accuracy: 0.8750, batch_loss: 0.3139, loss: 0.3456 ||: 100%|#########9| 11241/11253 [12:38<00:00, 13.88it/s]
2022-03-21 01:02:12,778 - INFO - tqdm - f1: 0.8175, accuracy: 0.8750, batch_loss: 0.4299, loss: 0.3456 ||: 100%|#########9| 11243/11253 [12:38<00:00, 13.83it/s]
2022-03-21 01:02:12,919 - INFO - tqdm - f1: 0.8175, accuracy: 0.8750, batch_loss: 0.4794, loss: 0.3457 ||: 100%|#########9| 11245/11253 [12:38<00:00, 13.93it/s]
2022-03-21 01:02:13,069 - INFO - tqdm - f1: 0.8175, accuracy: 0.8750, batch_loss: 0.1505, loss: 0.3457 ||: 100%|#########9| 11247/11253 [12:38<00:00, 13.73it/s]
2022-03-21 01:02:13,220 - INFO - tqdm - f1: 0.8175, accuracy: 0.8750, batch_loss: 0.2257, loss: 0.3457 ||: 100%|#########9| 11249/11253 [12:39<00:00, 13.57it/s]
2022-03-21 01:02:13,361 - INFO - tqdm - f1: 0.8175, accuracy: 0.8750, batch_loss: 0.3022, loss: 0.3457 ||: 100%|#########9| 11251/11253 [12:39<00:00, 13.77it/s]
2022-03-21 01:02:13,510 - INFO - tqdm - f1: 0.8175, accuracy: 0.8750, batch_loss: 0.2838, loss: 0.3457 ||: 100%|##########| 11253/11253 [12:39<00:00, 13.66it/s]
2022-03-21 01:02:13,586 - INFO - tqdm - f1: 0.8175, accuracy: 0.8750, batch_loss: 0.2838, loss: 0.3457 ||: 100%|##########| 11253/11253 [12:39<00:00, 14.82it/s]
2022-03-21 01:02:13,596 - INFO - allennlp.training.trainer - Validating
2022-03-21 01:02:13,602 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 01:02:23,644 - INFO - tqdm - f1: 0.8099, accuracy: 0.8723, batch_loss: 0.8904, loss: 0.3447 ||:  23%|##3       | 437/1889 [00:10<00:28, 50.78it/s]
2022-03-21 01:02:33,699 - INFO - tqdm - f1: 0.8075, accuracy: 0.8718, batch_loss: 0.3338, loss: 0.3459 ||:  47%|####6     | 881/1889 [00:20<00:20, 50.31it/s]
2022-03-21 01:02:43,781 - INFO - tqdm - f1: 0.8122, accuracy: 0.8754, batch_loss: 0.3907, loss: 0.3398 ||:  71%|#######   | 1332/1889 [00:30<00:12, 44.89it/s]
2022-03-21 01:02:53,858 - INFO - tqdm - f1: 0.8112, accuracy: 0.8739, batch_loss: 0.1977, loss: 0.3436 ||:  94%|#########4| 1780/1889 [00:40<00:02, 48.08it/s]
2022-03-21 01:02:56,253 - INFO - tqdm - f1: 0.8097, accuracy: 0.8731, batch_loss: 0.0118, loss: 0.3451 ||: 100%|#########9| 1884/1889 [00:42<00:00, 37.56it/s]
2022-03-21 01:02:56,359 - INFO - tqdm - f1: 0.8093, accuracy: 0.8729, batch_loss: 0.1033, loss: 0.3455 ||: 100%|##########| 1889/1889 [00:42<00:00, 44.19it/s]
2022-03-21 01:02:56,372 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct-20k_base_hyper_small_seed_47/best.th'.
2022-03-21 01:02:59,159 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 01:02:59,162 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.875  |     0.873
2022-03-21 01:02:59,165 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.817  |     0.809
2022-03-21 01:02:59,168 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 01:02:59,171 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.346  |     0.345
2022-03-21 01:02:59,173 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8642.770  |       N/A
2022-03-21 01:02:59,176 - INFO - allennlp.training.trainer - Epoch duration: 0:13:24.977755
2022-03-21 01:02:59,180 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:54:43
2022-03-21 01:02:59,184 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-21 01:02:59,190 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 01:02:59,194 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 01:02:59,198 - INFO - allennlp.training.trainer - Training
2022-03-21 01:02:59,204 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 01:03:09,228 - INFO - tqdm - f1: 0.8615, accuracy: 0.9016, batch_loss: 0.0301, loss: 0.3027 ||:   1%|          | 61/11253 [00:10<12:27, 14.97it/s]
2022-03-21 01:03:19,314 - INFO - tqdm - f1: 0.8407, accuracy: 0.8906, batch_loss: 0.1367, loss: 0.3060 ||:   2%|1         | 209/11253 [00:20<13:40, 13.45it/s]
2022-03-21 01:03:29,315 - INFO - tqdm - f1: 0.8378, accuracy: 0.8901, batch_loss: 0.2336, loss: 0.3040 ||:   3%|3         | 357/11253 [00:30<11:51, 15.31it/s]
2022-03-21 01:03:39,411 - INFO - tqdm - f1: 0.8371, accuracy: 0.8898, batch_loss: 0.3226, loss: 0.3004 ||:   4%|4         | 503/11253 [00:40<11:36, 15.43it/s]
2022-03-21 01:03:49,493 - INFO - tqdm - f1: 0.8365, accuracy: 0.8891, batch_loss: 0.3388, loss: 0.3060 ||:   6%|5         | 653/11253 [00:50<12:35, 14.03it/s]
2022-03-21 01:03:59,610 - INFO - tqdm - f1: 0.8346, accuracy: 0.8881, batch_loss: 0.4562, loss: 0.3055 ||:   7%|7         | 801/11253 [01:00<11:57, 14.57it/s]
2022-03-21 01:04:09,706 - INFO - tqdm - f1: 0.8336, accuracy: 0.8874, batch_loss: 0.2947, loss: 0.3089 ||:   8%|8         | 949/11253 [01:10<12:01, 14.28it/s]
2022-03-21 01:04:19,841 - INFO - tqdm - f1: 0.8310, accuracy: 0.8855, batch_loss: 1.0078, loss: 0.3109 ||:  10%|9         | 1099/11253 [01:20<11:23, 14.85it/s]
2022-03-21 01:04:29,880 - INFO - tqdm - f1: 0.8310, accuracy: 0.8853, batch_loss: 0.0975, loss: 0.3112 ||:  11%|#1        | 1247/11253 [01:30<10:49, 15.41it/s]
2022-03-21 01:04:39,985 - INFO - tqdm - f1: 0.8294, accuracy: 0.8848, batch_loss: 0.5676, loss: 0.3119 ||:  12%|#2        | 1399/11253 [01:40<10:49, 15.18it/s]
2022-03-21 01:04:49,998 - INFO - tqdm - f1: 0.8296, accuracy: 0.8856, batch_loss: 0.1039, loss: 0.3106 ||:  14%|#3        | 1547/11253 [01:50<10:33, 15.31it/s]
2022-03-21 01:05:00,074 - INFO - tqdm - f1: 0.8305, accuracy: 0.8865, batch_loss: 0.2766, loss: 0.3091 ||:  15%|#5        | 1697/11253 [02:00<10:38, 14.97it/s]
2022-03-21 01:05:10,140 - INFO - tqdm - f1: 0.8319, accuracy: 0.8871, batch_loss: 0.5562, loss: 0.3090 ||:  16%|#6        | 1845/11253 [02:10<10:34, 14.82it/s]
2022-03-21 01:05:20,191 - INFO - tqdm - f1: 0.8323, accuracy: 0.8868, batch_loss: 0.2653, loss: 0.3099 ||:  18%|#7        | 1993/11253 [02:20<10:29, 14.71it/s]
2022-03-21 01:05:30,273 - INFO - tqdm - f1: 0.8333, accuracy: 0.8875, batch_loss: 0.1999, loss: 0.3093 ||:  19%|#9        | 2143/11253 [02:31<10:10, 14.91it/s]
2022-03-21 01:05:40,307 - INFO - tqdm - f1: 0.8337, accuracy: 0.8877, batch_loss: 0.3184, loss: 0.3101 ||:  20%|##        | 2291/11253 [02:41<10:34, 14.13it/s]
2022-03-21 01:05:50,395 - INFO - tqdm - f1: 0.8337, accuracy: 0.8882, batch_loss: 0.3859, loss: 0.3084 ||:  22%|##1       | 2441/11253 [02:51<09:07, 16.10it/s]
2022-03-21 01:06:00,420 - INFO - tqdm - f1: 0.8344, accuracy: 0.8886, batch_loss: 0.0363, loss: 0.3091 ||:  23%|##3       | 2591/11253 [03:01<10:11, 14.15it/s]
2022-03-21 01:06:10,516 - INFO - tqdm - f1: 0.8351, accuracy: 0.8887, batch_loss: 0.4816, loss: 0.3089 ||:  24%|##4       | 2739/11253 [03:11<09:54, 14.32it/s]
2022-03-21 01:06:20,639 - INFO - tqdm - f1: 0.8352, accuracy: 0.8891, batch_loss: 0.1121, loss: 0.3076 ||:  26%|##5       | 2889/11253 [03:21<09:41, 14.38it/s]
2022-03-21 01:06:30,654 - INFO - tqdm - f1: 0.8345, accuracy: 0.8888, batch_loss: 0.1718, loss: 0.3079 ||:  27%|##7       | 3041/11253 [03:31<09:09, 14.94it/s]
2022-03-21 01:06:40,729 - INFO - tqdm - f1: 0.8341, accuracy: 0.8887, batch_loss: 0.3574, loss: 0.3074 ||:  28%|##8       | 3191/11253 [03:41<09:00, 14.91it/s]
2022-03-21 01:06:50,784 - INFO - tqdm - f1: 0.8333, accuracy: 0.8882, batch_loss: 0.5085, loss: 0.3090 ||:  30%|##9       | 3341/11253 [03:51<09:19, 14.15it/s]
2022-03-21 01:07:00,830 - INFO - tqdm - f1: 0.8329, accuracy: 0.8882, batch_loss: 0.2060, loss: 0.3081 ||:  31%|###1      | 3489/11253 [04:01<08:09, 15.86it/s]
2022-03-21 01:07:10,894 - INFO - tqdm - f1: 0.8331, accuracy: 0.8884, batch_loss: 0.3494, loss: 0.3082 ||:  32%|###2      | 3639/11253 [04:11<08:16, 15.35it/s]
2022-03-21 01:07:20,907 - INFO - tqdm - f1: 0.8330, accuracy: 0.8884, batch_loss: 0.4707, loss: 0.3082 ||:  34%|###3      | 3789/11253 [04:21<08:12, 15.15it/s]
2022-03-21 01:07:31,006 - INFO - tqdm - f1: 0.8332, accuracy: 0.8885, batch_loss: 0.6185, loss: 0.3081 ||:  35%|###5      | 3941/11253 [04:31<07:57, 15.31it/s]
2022-03-21 01:07:41,024 - INFO - tqdm - f1: 0.8335, accuracy: 0.8887, batch_loss: 0.4783, loss: 0.3079 ||:  36%|###6      | 4091/11253 [04:41<07:33, 15.79it/s]
2022-03-21 01:07:51,146 - INFO - tqdm - f1: 0.8337, accuracy: 0.8886, batch_loss: 0.5508, loss: 0.3086 ||:  38%|###7      | 4241/11253 [04:51<07:56, 14.72it/s]
2022-03-21 01:08:01,181 - INFO - tqdm - f1: 0.8342, accuracy: 0.8890, batch_loss: 0.3954, loss: 0.3077 ||:  39%|###9      | 4389/11253 [05:01<07:36, 15.04it/s]
2022-03-21 01:08:11,206 - INFO - tqdm - f1: 0.8334, accuracy: 0.8885, batch_loss: 0.1157, loss: 0.3083 ||:  40%|####      | 4537/11253 [05:11<07:23, 15.14it/s]
2022-03-21 01:08:21,345 - INFO - tqdm - f1: 0.8325, accuracy: 0.8881, batch_loss: 0.3360, loss: 0.3089 ||:  42%|####1     | 4687/11253 [05:22<07:29, 14.60it/s]
2022-03-21 01:08:31,443 - INFO - tqdm - f1: 0.8330, accuracy: 0.8884, batch_loss: 0.5913, loss: 0.3082 ||:  43%|####2     | 4837/11253 [05:32<06:59, 15.29it/s]
2022-03-21 01:08:41,566 - INFO - tqdm - f1: 0.8331, accuracy: 0.8884, batch_loss: 0.4882, loss: 0.3079 ||:  44%|####4     | 4987/11253 [05:42<07:05, 14.74it/s]
2022-03-21 01:08:51,689 - INFO - tqdm - f1: 0.8324, accuracy: 0.8878, batch_loss: 0.7103, loss: 0.3089 ||:  46%|####5     | 5139/11253 [05:52<06:58, 14.62it/s]
2022-03-21 01:09:01,803 - INFO - tqdm - f1: 0.8323, accuracy: 0.8878, batch_loss: 0.1494, loss: 0.3091 ||:  47%|####7     | 5291/11253 [06:02<06:59, 14.21it/s]
2022-03-21 01:09:11,832 - INFO - tqdm - f1: 0.8320, accuracy: 0.8877, batch_loss: 0.2326, loss: 0.3089 ||:  48%|####8     | 5439/11253 [06:12<06:35, 14.70it/s]
2022-03-21 01:09:21,886 - INFO - tqdm - f1: 0.8323, accuracy: 0.8880, batch_loss: 0.9486, loss: 0.3086 ||:  50%|####9     | 5589/11253 [06:22<05:58, 15.80it/s]
2022-03-21 01:09:31,887 - INFO - tqdm - f1: 0.8321, accuracy: 0.8880, batch_loss: 0.0228, loss: 0.3086 ||:  51%|#####     | 5739/11253 [06:32<06:17, 14.61it/s]
2022-03-21 01:09:41,971 - INFO - tqdm - f1: 0.8329, accuracy: 0.8884, batch_loss: 0.4028, loss: 0.3080 ||:  52%|#####2    | 5891/11253 [06:42<05:57, 15.00it/s]
2022-03-21 01:09:51,995 - INFO - tqdm - f1: 0.8329, accuracy: 0.8884, batch_loss: 0.2633, loss: 0.3081 ||:  54%|#####3    | 6041/11253 [06:52<05:53, 14.75it/s]
2022-03-21 01:10:02,120 - INFO - tqdm - f1: 0.8332, accuracy: 0.8887, batch_loss: 0.3380, loss: 0.3073 ||:  55%|#####5    | 6191/11253 [07:02<05:35, 15.08it/s]
2022-03-21 01:10:12,166 - INFO - tqdm - f1: 0.8332, accuracy: 0.8889, batch_loss: 0.2539, loss: 0.3068 ||:  56%|#####6    | 6343/11253 [07:12<05:27, 14.98it/s]
2022-03-21 01:10:22,266 - INFO - tqdm - f1: 0.8328, accuracy: 0.8885, batch_loss: 0.1391, loss: 0.3073 ||:  58%|#####7    | 6495/11253 [07:23<05:00, 15.86it/s]
2022-03-21 01:10:32,401 - INFO - tqdm - f1: 0.8326, accuracy: 0.8883, batch_loss: 0.5327, loss: 0.3076 ||:  59%|#####9    | 6643/11253 [07:33<06:29, 11.83it/s]
2022-03-21 01:10:42,511 - INFO - tqdm - f1: 0.8325, accuracy: 0.8882, batch_loss: 0.1690, loss: 0.3079 ||:  60%|#####9    | 6741/11253 [07:43<05:20, 14.09it/s]
2022-03-21 01:10:52,566 - INFO - tqdm - f1: 0.8326, accuracy: 0.8882, batch_loss: 0.5517, loss: 0.3081 ||:  61%|######    | 6841/11253 [07:53<05:24, 13.60it/s]
2022-03-21 01:11:02,663 - INFO - tqdm - f1: 0.8327, accuracy: 0.8882, batch_loss: 0.0432, loss: 0.3079 ||:  62%|######1   | 6939/11253 [08:03<06:16, 11.47it/s]
2022-03-21 01:11:12,717 - INFO - tqdm - f1: 0.8327, accuracy: 0.8881, batch_loss: 0.4983, loss: 0.3080 ||:  63%|######2   | 7039/11253 [08:13<06:29, 10.81it/s]
2022-03-21 01:11:22,817 - INFO - tqdm - f1: 0.8328, accuracy: 0.8881, batch_loss: 0.5276, loss: 0.3081 ||:  63%|######3   | 7141/11253 [08:23<07:10,  9.55it/s]
2022-03-21 01:11:32,931 - INFO - tqdm - f1: 0.8328, accuracy: 0.8881, batch_loss: 0.4896, loss: 0.3082 ||:  64%|######4   | 7243/11253 [08:33<08:17,  8.05it/s]
2022-03-21 01:11:43,038 - INFO - tqdm - f1: 0.8328, accuracy: 0.8882, batch_loss: 0.0383, loss: 0.3082 ||:  65%|######5   | 7343/11253 [08:43<08:13,  7.93it/s]
2022-03-21 01:11:53,045 - INFO - tqdm - f1: 0.8328, accuracy: 0.8883, batch_loss: 0.0914, loss: 0.3080 ||:  66%|######6   | 7441/11253 [08:53<09:20,  6.80it/s]
2022-03-21 01:12:03,122 - INFO - tqdm - f1: 0.8328, accuracy: 0.8882, batch_loss: 0.4696, loss: 0.3082 ||:  67%|######6   | 7539/11253 [09:03<13:59,  4.42it/s]
2022-03-21 01:12:13,257 - INFO - tqdm - f1: 0.8328, accuracy: 0.8882, batch_loss: 0.2143, loss: 0.3080 ||:  68%|######7   | 7641/11253 [09:14<10:31,  5.72it/s]
2022-03-21 01:12:23,357 - INFO - tqdm - f1: 0.8329, accuracy: 0.8883, batch_loss: 0.2856, loss: 0.3080 ||:  69%|######8   | 7737/11253 [09:24<10:28,  5.59it/s]
2022-03-21 01:12:33,561 - INFO - tqdm - f1: 0.8331, accuracy: 0.8883, batch_loss: 0.1455, loss: 0.3078 ||:  70%|######9   | 7837/11253 [09:34<12:54,  4.41it/s]
2022-03-21 01:12:43,977 - INFO - tqdm - f1: 0.8332, accuracy: 0.8885, batch_loss: 0.3226, loss: 0.3074 ||:  71%|#######   | 7939/11253 [09:44<12:25,  4.44it/s]
2022-03-21 01:12:54,080 - INFO - tqdm - f1: 0.8330, accuracy: 0.8883, batch_loss: 0.1528, loss: 0.3078 ||:  71%|#######1  | 8039/11253 [09:54<11:56,  4.49it/s]
2022-03-21 01:13:04,169 - INFO - tqdm - f1: 0.8326, accuracy: 0.8880, batch_loss: 0.3791, loss: 0.3083 ||:  72%|#######2  | 8141/11253 [10:04<08:47,  5.90it/s]
2022-03-21 01:13:14,328 - INFO - tqdm - f1: 0.8326, accuracy: 0.8879, batch_loss: 0.4807, loss: 0.3085 ||:  73%|#######3  | 8245/11253 [10:15<11:01,  4.54it/s]
2022-03-21 01:13:24,497 - INFO - tqdm - f1: 0.8326, accuracy: 0.8879, batch_loss: 0.0902, loss: 0.3086 ||:  74%|#######4  | 8347/11253 [10:25<10:43,  4.52it/s]
2022-03-21 01:13:34,532 - INFO - tqdm - f1: 0.8326, accuracy: 0.8879, batch_loss: 1.0404, loss: 0.3086 ||:  75%|#######5  | 8447/11253 [10:35<08:22,  5.58it/s]
2022-03-21 01:13:44,749 - INFO - tqdm - f1: 0.8324, accuracy: 0.8878, batch_loss: 0.0642, loss: 0.3088 ||:  76%|#######5  | 8551/11253 [10:45<09:52,  4.56it/s]
2022-03-21 01:13:54,773 - INFO - tqdm - f1: 0.8323, accuracy: 0.8879, batch_loss: 0.1475, loss: 0.3087 ||:  77%|#######6  | 8653/11253 [10:55<09:31,  4.55it/s]
2022-03-21 01:14:04,869 - INFO - tqdm - f1: 0.8323, accuracy: 0.8878, batch_loss: 0.2351, loss: 0.3088 ||:  78%|#######7  | 8753/11253 [11:05<07:24,  5.62it/s]
2022-03-21 01:14:15,922 - INFO - tqdm - f1: 0.8322, accuracy: 0.8878, batch_loss: 0.4208, loss: 0.3090 ||:  79%|#######8  | 8859/11253 [11:16<09:26,  4.22it/s]
2022-03-21 01:14:26,373 - INFO - tqdm - f1: 0.8322, accuracy: 0.8878, batch_loss: 0.6063, loss: 0.3090 ||:  80%|#######9  | 8965/11253 [11:27<08:22,  4.55it/s]
2022-03-21 01:14:37,501 - INFO - tqdm - f1: 0.8322, accuracy: 0.8877, batch_loss: 0.4369, loss: 0.3094 ||:  81%|########  | 9077/11253 [11:38<08:15,  4.39it/s]
2022-03-21 01:14:47,564 - INFO - tqdm - f1: 0.8321, accuracy: 0.8878, batch_loss: 0.8129, loss: 0.3091 ||:  82%|########1 | 9181/11253 [11:48<07:30,  4.60it/s]
2022-03-21 01:14:57,751 - INFO - tqdm - f1: 0.8320, accuracy: 0.8877, batch_loss: 0.4383, loss: 0.3092 ||:  83%|########2 | 9287/11253 [11:58<07:17,  4.50it/s]
2022-03-21 01:15:07,866 - INFO - tqdm - f1: 0.8322, accuracy: 0.8878, batch_loss: 0.3678, loss: 0.3091 ||:  83%|########3 | 9389/11253 [12:08<06:51,  4.53it/s]
2022-03-21 01:15:18,115 - INFO - tqdm - f1: 0.8323, accuracy: 0.8878, batch_loss: 0.3772, loss: 0.3093 ||:  84%|########4 | 9493/11253 [12:18<06:33,  4.47it/s]
2022-03-21 01:15:28,427 - INFO - tqdm - f1: 0.8326, accuracy: 0.8879, batch_loss: 0.1959, loss: 0.3091 ||:  85%|########5 | 9597/11253 [12:29<06:02,  4.57it/s]
2022-03-21 01:15:38,524 - INFO - tqdm - f1: 0.8324, accuracy: 0.8878, batch_loss: 0.3265, loss: 0.3092 ||:  86%|########6 | 9701/11253 [12:39<04:30,  5.74it/s]
2022-03-21 01:15:48,605 - INFO - tqdm - f1: 0.8327, accuracy: 0.8880, batch_loss: 0.2935, loss: 0.3090 ||:  87%|########7 | 9805/11253 [12:49<05:23,  4.48it/s]
2022-03-21 01:15:58,748 - INFO - tqdm - f1: 0.8328, accuracy: 0.8880, batch_loss: 0.4283, loss: 0.3091 ||:  88%|########8 | 9907/11253 [12:59<04:01,  5.58it/s]
2022-03-21 01:16:08,753 - INFO - tqdm - f1: 0.8327, accuracy: 0.8879, batch_loss: 0.3565, loss: 0.3093 ||:  89%|########8 | 10007/11253 [13:09<03:38,  5.71it/s]
2022-03-21 01:16:18,779 - INFO - tqdm - f1: 0.8327, accuracy: 0.8879, batch_loss: 0.0386, loss: 0.3093 ||:  90%|########9 | 10105/11253 [13:19<04:29,  4.27it/s]
2022-03-21 01:16:29,095 - INFO - tqdm - f1: 0.8325, accuracy: 0.8878, batch_loss: 0.1160, loss: 0.3097 ||:  91%|######### | 10209/11253 [13:29<03:49,  4.54it/s]
2022-03-21 01:16:39,297 - INFO - tqdm - f1: 0.8324, accuracy: 0.8878, batch_loss: 0.1554, loss: 0.3097 ||:  92%|#########1| 10311/11253 [13:40<03:29,  4.51it/s]
2022-03-21 01:16:49,358 - INFO - tqdm - f1: 0.8323, accuracy: 0.8877, batch_loss: 0.6296, loss: 0.3099 ||:  93%|#########2| 10413/11253 [13:50<02:26,  5.75it/s]
2022-03-21 01:16:59,480 - INFO - tqdm - f1: 0.8324, accuracy: 0.8877, batch_loss: 0.0758, loss: 0.3100 ||:  93%|#########3| 10515/11253 [14:00<02:41,  4.56it/s]
2022-03-21 01:17:09,534 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.2736, loss: 0.3099 ||:  94%|#########4| 10615/11253 [14:10<01:52,  5.67it/s]
2022-03-21 01:17:19,573 - INFO - tqdm - f1: 0.8323, accuracy: 0.8877, batch_loss: 0.1203, loss: 0.3098 ||:  95%|#########5| 10717/11253 [14:20<01:57,  4.55it/s]
2022-03-21 01:17:30,031 - INFO - tqdm - f1: 0.8322, accuracy: 0.8875, batch_loss: 0.6793, loss: 0.3102 ||:  96%|#########6| 10823/11253 [14:30<01:35,  4.48it/s]
2022-03-21 01:17:40,067 - INFO - tqdm - f1: 0.8322, accuracy: 0.8875, batch_loss: 0.1597, loss: 0.3101 ||:  97%|#########7| 10923/11253 [14:40<01:12,  4.53it/s]
2022-03-21 01:17:50,403 - INFO - tqdm - f1: 0.8323, accuracy: 0.8875, batch_loss: 0.0809, loss: 0.3104 ||:  98%|#########7| 11027/11253 [14:51<00:50,  4.43it/s]
2022-03-21 01:18:00,426 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.7488, loss: 0.3101 ||:  99%|#########8| 11127/11253 [15:01<00:18,  6.98it/s]
2022-03-21 01:18:07,413 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.2080, loss: 0.3100 ||: 100%|#########9| 11197/11253 [15:08<00:08,  6.61it/s]
2022-03-21 01:18:07,560 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.4540, loss: 0.3100 ||: 100%|#########9| 11199/11253 [15:08<00:06,  7.82it/s]
2022-03-21 01:18:07,699 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.1715, loss: 0.3100 ||: 100%|#########9| 11201/11253 [15:08<00:05,  9.07it/s]
2022-03-21 01:18:07,851 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.4217, loss: 0.3100 ||: 100%|#########9| 11203/11253 [15:08<00:05,  9.99it/s]
2022-03-21 01:18:07,993 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.1185, loss: 0.3100 ||: 100%|#########9| 11205/11253 [15:08<00:04, 10.95it/s]
2022-03-21 01:18:08,125 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.3700, loss: 0.3100 ||: 100%|#########9| 11207/11253 [15:08<00:03, 11.94it/s]
2022-03-21 01:18:08,296 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.4012, loss: 0.3100 ||: 100%|#########9| 11209/11253 [15:09<00:03, 11.87it/s]
2022-03-21 01:18:08,448 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.4383, loss: 0.3100 ||: 100%|#########9| 11211/11253 [15:09<00:03, 12.21it/s]
2022-03-21 01:18:08,593 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.1968, loss: 0.3100 ||: 100%|#########9| 11213/11253 [15:09<00:03, 12.67it/s]
2022-03-21 01:18:08,738 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.1452, loss: 0.3100 ||: 100%|#########9| 11215/11253 [15:09<00:02, 12.97it/s]
2022-03-21 01:18:08,885 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.3542, loss: 0.3100 ||: 100%|#########9| 11217/11253 [15:09<00:02, 13.17it/s]
2022-03-21 01:18:09,050 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.1336, loss: 0.3100 ||: 100%|#########9| 11219/11253 [15:09<00:02, 12.82it/s]
2022-03-21 01:18:09,197 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.4115, loss: 0.3100 ||: 100%|#########9| 11221/11253 [15:09<00:02, 13.05it/s]
2022-03-21 01:18:09,329 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.3999, loss: 0.3100 ||: 100%|#########9| 11223/11253 [15:10<00:02, 13.63it/s]
2022-03-21 01:18:10,475 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.2121, loss: 0.3100 ||: 100%|#########9| 11225/11253 [15:11<00:06,  4.48it/s]
2022-03-21 01:18:10,625 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.2473, loss: 0.3100 ||: 100%|#########9| 11227/11253 [15:11<00:04,  5.59it/s]
2022-03-21 01:18:10,788 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.1769, loss: 0.3100 ||: 100%|#########9| 11229/11253 [15:11<00:03,  6.68it/s]
2022-03-21 01:18:10,938 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.2478, loss: 0.3100 ||: 100%|#########9| 11231/11253 [15:11<00:02,  7.86it/s]
2022-03-21 01:18:11,079 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.3793, loss: 0.3100 ||: 100%|#########9| 11233/11253 [15:11<00:02,  9.08it/s]
2022-03-21 01:18:11,230 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.2245, loss: 0.3100 ||: 100%|#########9| 11235/11253 [15:12<00:01, 10.02it/s]
2022-03-21 01:18:11,382 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.1567, loss: 0.3099 ||: 100%|#########9| 11237/11253 [15:12<00:01, 10.80it/s]
2022-03-21 01:18:11,521 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.5380, loss: 0.3099 ||: 100%|#########9| 11239/11253 [15:12<00:01, 11.67it/s]
2022-03-21 01:18:11,662 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.1339, loss: 0.3099 ||: 100%|#########9| 11241/11253 [15:12<00:00, 12.32it/s]
2022-03-21 01:18:11,807 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.2459, loss: 0.3099 ||: 100%|#########9| 11243/11253 [15:12<00:00, 12.72it/s]
2022-03-21 01:18:11,947 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.2047, loss: 0.3099 ||: 100%|#########9| 11245/11253 [15:12<00:00, 13.17it/s]
2022-03-21 01:18:12,096 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.2347, loss: 0.3098 ||: 100%|#########9| 11247/11253 [15:12<00:00, 13.24it/s]
2022-03-21 01:18:12,250 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.3117, loss: 0.3098 ||: 100%|#########9| 11249/11253 [15:13<00:00, 13.15it/s]
2022-03-21 01:18:12,403 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.4981, loss: 0.3098 ||: 100%|#########9| 11251/11253 [15:13<00:00, 13.14it/s]
2022-03-21 01:18:12,554 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.8680, loss: 0.3099 ||: 100%|##########| 11253/11253 [15:13<00:00, 13.17it/s]
2022-03-21 01:18:12,625 - INFO - tqdm - f1: 0.8325, accuracy: 0.8877, batch_loss: 0.8680, loss: 0.3099 ||: 100%|##########| 11253/11253 [15:13<00:00, 12.32it/s]
2022-03-21 01:18:12,631 - INFO - allennlp.training.trainer - Validating
2022-03-21 01:18:12,637 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 01:18:22,720 - INFO - tqdm - f1: 0.8314, accuracy: 0.8834, batch_loss: 0.7361, loss: 0.3615 ||:  14%|#3        | 261/1889 [00:10<00:47, 34.49it/s]
2022-03-21 01:18:32,760 - INFO - tqdm - f1: 0.8253, accuracy: 0.8825, batch_loss: 0.3575, loss: 0.3566 ||:  29%|##8       | 540/1889 [00:20<00:38, 34.80it/s]
2022-03-21 01:18:42,843 - INFO - tqdm - f1: 0.8185, accuracy: 0.8783, batch_loss: 0.8979, loss: 0.3588 ||:  43%|####3     | 819/1889 [00:30<00:27, 39.61it/s]
2022-03-21 01:18:52,910 - INFO - tqdm - f1: 0.8179, accuracy: 0.8782, batch_loss: 0.1368, loss: 0.3588 ||:  58%|#####8    | 1097/1889 [00:40<00:20, 39.32it/s]
2022-03-21 01:19:02,949 - INFO - tqdm - f1: 0.8191, accuracy: 0.8780, batch_loss: 0.2158, loss: 0.3589 ||:  72%|#######2  | 1367/1889 [00:50<00:38, 13.52it/s]
2022-03-21 01:19:12,965 - INFO - tqdm - f1: 0.8195, accuracy: 0.8776, batch_loss: 0.4137, loss: 0.3599 ||:  87%|########6 | 1640/1889 [01:00<00:20, 12.26it/s]
2022-03-21 01:19:21,157 - INFO - tqdm - f1: 0.8199, accuracy: 0.8778, batch_loss: 0.0259, loss: 0.3600 ||: 100%|#########9| 1884/1889 [01:08<00:00, 37.17it/s]
2022-03-21 01:19:21,258 - INFO - tqdm - f1: 0.8200, accuracy: 0.8780, batch_loss: 0.1833, loss: 0.3596 ||: 100%|#########9| 1888/1889 [01:08<00:00, 37.86it/s]
2022-03-21 01:19:21,297 - INFO - tqdm - f1: 0.8201, accuracy: 0.8781, batch_loss: 0.0677, loss: 0.3594 ||: 100%|##########| 1889/1889 [01:08<00:00, 27.51it/s]
2022-03-21 01:19:21,311 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct-20k_base_hyper_small_seed_47/best.th'.
2022-03-21 01:19:26,771 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 01:19:26,773 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.888  |     0.878
2022-03-21 01:19:26,776 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.833  |     0.820
2022-03-21 01:19:26,778 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 01:19:26,780 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.310  |     0.359
2022-03-21 01:19:26,783 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8643.105  |       N/A
2022-03-21 01:19:26,785 - INFO - allennlp.training.trainer - Epoch duration: 0:16:27.601287
2022-03-21 01:19:26,788 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:45:20
2022-03-21 01:19:26,790 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-21 01:19:26,792 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 01:19:26,798 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 01:19:26,809 - INFO - allennlp.training.trainer - Training
2022-03-21 01:19:26,812 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 01:19:36,823 - INFO - tqdm - f1: 0.8375, accuracy: 0.9066, batch_loss: 0.2794, loss: 0.2578 ||:   1%|          | 85/11253 [00:10<41:47,  4.45it/s]
2022-03-21 01:19:47,177 - INFO - tqdm - f1: 0.8264, accuracy: 0.8930, batch_loss: 0.2515, loss: 0.2825 ||:   2%|1         | 191/11253 [00:20<40:40,  4.53it/s]
2022-03-21 01:19:57,441 - INFO - tqdm - f1: 0.8282, accuracy: 0.8929, batch_loss: 0.0422, loss: 0.2899 ||:   3%|2         | 293/11253 [00:30<42:04,  4.34it/s]
2022-03-21 01:20:07,844 - INFO - tqdm - f1: 0.8360, accuracy: 0.8963, batch_loss: 0.2262, loss: 0.2884 ||:   4%|3         | 399/11253 [00:41<39:31,  4.58it/s]
2022-03-21 01:20:18,119 - INFO - tqdm - f1: 0.8387, accuracy: 0.8965, batch_loss: 0.0998, loss: 0.2855 ||:   4%|4         | 505/11253 [00:51<38:41,  4.63it/s]
2022-03-21 01:20:28,500 - INFO - tqdm - f1: 0.8406, accuracy: 0.8991, batch_loss: 0.3923, loss: 0.2767 ||:   5%|5         | 609/11253 [01:01<39:41,  4.47it/s]
2022-03-21 01:20:39,375 - INFO - tqdm - f1: 0.8399, accuracy: 0.8982, batch_loss: 0.0563, loss: 0.2790 ||:   6%|6         | 717/11253 [01:12<39:59,  4.39it/s]
2022-03-21 01:20:49,668 - INFO - tqdm - f1: 0.8417, accuracy: 0.8992, batch_loss: 0.0531, loss: 0.2756 ||:   7%|7         | 821/11253 [01:22<39:59,  4.35it/s]
2022-03-21 01:20:59,827 - INFO - tqdm - f1: 0.8445, accuracy: 0.9005, batch_loss: 0.8403, loss: 0.2737 ||:   8%|8         | 925/11253 [01:33<38:56,  4.42it/s]
2022-03-21 01:21:10,131 - INFO - tqdm - f1: 0.8444, accuracy: 0.9006, batch_loss: 0.4805, loss: 0.2722 ||:   9%|9         | 1031/11253 [01:43<37:58,  4.49it/s]
2022-03-21 01:21:20,500 - INFO - tqdm - f1: 0.8452, accuracy: 0.9010, batch_loss: 0.1546, loss: 0.2705 ||:  10%|#         | 1135/11253 [01:53<38:12,  4.41it/s]
2022-03-21 01:21:30,887 - INFO - tqdm - f1: 0.8463, accuracy: 0.9016, batch_loss: 0.2821, loss: 0.2693 ||:  11%|#1        | 1243/11253 [02:04<36:55,  4.52it/s]
2022-03-21 01:21:41,318 - INFO - tqdm - f1: 0.8464, accuracy: 0.9018, batch_loss: 0.2585, loss: 0.2699 ||:  12%|#2        | 1351/11253 [02:14<37:28,  4.40it/s]
2022-03-21 01:21:51,461 - INFO - tqdm - f1: 0.8471, accuracy: 0.9023, batch_loss: 0.5161, loss: 0.2681 ||:  13%|#2        | 1453/11253 [02:24<32:17,  5.06it/s]
2022-03-21 01:22:01,913 - INFO - tqdm - f1: 0.8476, accuracy: 0.9023, batch_loss: 0.4040, loss: 0.2681 ||:  14%|#3        | 1559/11253 [02:35<36:35,  4.41it/s]
2022-03-21 01:22:12,358 - INFO - tqdm - f1: 0.8459, accuracy: 0.9011, batch_loss: 0.1176, loss: 0.2705 ||:  15%|#4        | 1667/11253 [02:45<36:47,  4.34it/s]
2022-03-21 01:22:22,676 - INFO - tqdm - f1: 0.8464, accuracy: 0.9010, batch_loss: 0.1196, loss: 0.2706 ||:  16%|#5        | 1775/11253 [02:55<34:29,  4.58it/s]
2022-03-21 01:22:32,944 - INFO - tqdm - f1: 0.8461, accuracy: 0.9010, batch_loss: 0.2795, loss: 0.2699 ||:  17%|#6        | 1881/11253 [03:06<34:23,  4.54it/s]
2022-03-21 01:22:43,384 - INFO - tqdm - f1: 0.8476, accuracy: 0.9017, batch_loss: 0.3018, loss: 0.2683 ||:  18%|#7        | 1987/11253 [03:16<35:18,  4.37it/s]
2022-03-21 01:22:53,656 - INFO - tqdm - f1: 0.8480, accuracy: 0.9018, batch_loss: 0.3423, loss: 0.2675 ||:  19%|#8        | 2091/11253 [03:26<34:18,  4.45it/s]
2022-03-21 01:23:03,964 - INFO - tqdm - f1: 0.8478, accuracy: 0.9015, batch_loss: 0.1244, loss: 0.2691 ||:  20%|#9        | 2197/11253 [03:37<33:40,  4.48it/s]
2022-03-21 01:23:14,390 - INFO - tqdm - f1: 0.8472, accuracy: 0.9009, batch_loss: 0.4219, loss: 0.2701 ||:  20%|##        | 2303/11253 [03:47<33:25,  4.46it/s]
2022-03-21 01:23:24,753 - INFO - tqdm - f1: 0.8469, accuracy: 0.9008, batch_loss: 0.0931, loss: 0.2706 ||:  21%|##1       | 2409/11253 [03:57<32:53,  4.48it/s]
2022-03-21 01:23:35,172 - INFO - tqdm - f1: 0.8466, accuracy: 0.9006, batch_loss: 0.4452, loss: 0.2711 ||:  22%|##2       | 2519/11253 [04:08<31:56,  4.56it/s]
2022-03-21 01:23:45,640 - INFO - tqdm - f1: 0.8472, accuracy: 0.9005, batch_loss: 0.3229, loss: 0.2716 ||:  23%|##3       | 2627/11253 [04:18<32:23,  4.44it/s]
2022-03-21 01:23:56,096 - INFO - tqdm - f1: 0.8470, accuracy: 0.9003, batch_loss: 0.5239, loss: 0.2715 ||:  24%|##4       | 2735/11253 [04:29<31:05,  4.57it/s]
2022-03-21 01:24:06,549 - INFO - tqdm - f1: 0.8470, accuracy: 0.9005, batch_loss: 0.2655, loss: 0.2711 ||:  25%|##5       | 2841/11253 [04:39<32:34,  4.30it/s]
2022-03-21 01:24:16,998 - INFO - tqdm - f1: 0.8465, accuracy: 0.9000, batch_loss: 0.1888, loss: 0.2730 ||:  26%|##6       | 2949/11253 [04:50<30:30,  4.54it/s]
2022-03-21 01:24:27,561 - INFO - tqdm - f1: 0.8464, accuracy: 0.8999, batch_loss: 0.6324, loss: 0.2736 ||:  27%|##7       | 3057/11253 [05:00<31:34,  4.33it/s]
2022-03-21 01:24:37,899 - INFO - tqdm - f1: 0.8462, accuracy: 0.8999, batch_loss: 0.4273, loss: 0.2739 ||:  28%|##8       | 3163/11253 [05:11<29:57,  4.50it/s]
2022-03-21 01:24:48,082 - INFO - tqdm - f1: 0.8461, accuracy: 0.9000, batch_loss: 0.1595, loss: 0.2735 ||:  29%|##9       | 3269/11253 [05:21<29:22,  4.53it/s]
2022-03-21 01:24:58,546 - INFO - tqdm - f1: 0.8462, accuracy: 0.9000, batch_loss: 0.1903, loss: 0.2742 ||:  30%|##9       | 3373/11253 [05:31<29:39,  4.43it/s]
2022-03-21 01:25:08,748 - INFO - tqdm - f1: 0.8456, accuracy: 0.8995, batch_loss: 0.2878, loss: 0.2751 ||:  31%|###       | 3475/11253 [05:41<29:09,  4.44it/s]
2022-03-21 01:25:18,829 - INFO - tqdm - f1: 0.8460, accuracy: 0.8998, batch_loss: 0.5468, loss: 0.2751 ||:  32%|###1      | 3577/11253 [05:52<23:08,  5.53it/s]
2022-03-21 01:25:28,835 - INFO - tqdm - f1: 0.8456, accuracy: 0.8997, batch_loss: 0.3415, loss: 0.2751 ||:  33%|###2      | 3677/11253 [06:02<28:21,  4.45it/s]
2022-03-21 01:25:39,114 - INFO - tqdm - f1: 0.8457, accuracy: 0.8999, batch_loss: 0.4495, loss: 0.2743 ||:  34%|###3      | 3779/11253 [06:12<28:30,  4.37it/s]
2022-03-21 01:25:49,172 - INFO - tqdm - f1: 0.8458, accuracy: 0.8999, batch_loss: 0.2449, loss: 0.2744 ||:  34%|###4      | 3879/11253 [06:22<27:39,  4.44it/s]
2022-03-21 01:25:59,304 - INFO - tqdm - f1: 0.8458, accuracy: 0.8998, batch_loss: 0.4619, loss: 0.2752 ||:  35%|###5      | 3981/11253 [06:32<27:24,  4.42it/s]
2022-03-21 01:26:09,686 - INFO - tqdm - f1: 0.8454, accuracy: 0.8996, batch_loss: 0.3088, loss: 0.2755 ||:  36%|###6      | 4085/11253 [06:42<26:41,  4.48it/s]
2022-03-21 01:26:20,045 - INFO - tqdm - f1: 0.8452, accuracy: 0.8993, batch_loss: 0.4769, loss: 0.2759 ||:  37%|###7      | 4189/11253 [06:53<26:44,  4.40it/s]
2022-03-21 01:26:30,500 - INFO - tqdm - f1: 0.8453, accuracy: 0.8995, batch_loss: 0.0978, loss: 0.2758 ||:  38%|###8      | 4297/11253 [07:03<25:57,  4.47it/s]
2022-03-21 01:26:40,748 - INFO - tqdm - f1: 0.8452, accuracy: 0.8995, batch_loss: 0.0492, loss: 0.2760 ||:  39%|###9      | 4401/11253 [07:13<25:35,  4.46it/s]
2022-03-21 01:26:51,163 - INFO - tqdm - f1: 0.8452, accuracy: 0.8995, batch_loss: 0.5607, loss: 0.2761 ||:  40%|####      | 4505/11253 [07:24<25:13,  4.46it/s]
2022-03-21 01:27:01,630 - INFO - tqdm - f1: 0.8452, accuracy: 0.8994, batch_loss: 0.3723, loss: 0.2765 ||:  41%|####      | 4611/11253 [07:34<24:55,  4.44it/s]
2022-03-21 01:27:12,097 - INFO - tqdm - f1: 0.8456, accuracy: 0.8995, batch_loss: 0.4863, loss: 0.2761 ||:  42%|####1     | 4719/11253 [07:45<23:50,  4.57it/s]
2022-03-21 01:27:22,552 - INFO - tqdm - f1: 0.8455, accuracy: 0.8994, batch_loss: 0.0651, loss: 0.2765 ||:  43%|####2     | 4827/11253 [07:55<24:05,  4.44it/s]
2022-03-21 01:27:32,850 - INFO - tqdm - f1: 0.8458, accuracy: 0.8997, batch_loss: 0.7127, loss: 0.2760 ||:  44%|####3     | 4933/11253 [08:06<23:25,  4.50it/s]
2022-03-21 01:27:43,388 - INFO - tqdm - f1: 0.8462, accuracy: 0.8997, batch_loss: 0.0722, loss: 0.2759 ||:  45%|####4     | 5043/11253 [08:16<23:01,  4.49it/s]
2022-03-21 01:27:53,642 - INFO - tqdm - f1: 0.8466, accuracy: 0.8998, batch_loss: 0.3797, loss: 0.2758 ||:  46%|####5     | 5147/11253 [08:26<22:50,  4.45it/s]
2022-03-21 01:28:03,873 - INFO - tqdm - f1: 0.8469, accuracy: 0.8999, batch_loss: 0.3638, loss: 0.2755 ||:  47%|####6     | 5251/11253 [08:37<21:46,  4.60it/s]
2022-03-21 01:28:14,305 - INFO - tqdm - f1: 0.8470, accuracy: 0.9000, batch_loss: 0.5821, loss: 0.2752 ||:  48%|####7     | 5359/11253 [08:47<22:07,  4.44it/s]
2022-03-21 01:28:24,754 - INFO - tqdm - f1: 0.8472, accuracy: 0.9000, batch_loss: 0.3615, loss: 0.2748 ||:  49%|####8     | 5469/11253 [08:57<21:02,  4.58it/s]
2022-03-21 01:28:35,081 - INFO - tqdm - f1: 0.8471, accuracy: 0.9001, batch_loss: 0.2271, loss: 0.2743 ||:  50%|####9     | 5577/11253 [09:08<21:13,  4.46it/s]
2022-03-21 01:28:45,427 - INFO - tqdm - f1: 0.8469, accuracy: 0.8999, batch_loss: 0.3982, loss: 0.2746 ||:  51%|#####     | 5683/11253 [09:18<21:32,  4.31it/s]
2022-03-21 01:28:55,546 - INFO - tqdm - f1: 0.8472, accuracy: 0.8999, batch_loss: 0.2591, loss: 0.2742 ||:  51%|#####1    | 5785/11253 [09:28<20:32,  4.44it/s]
2022-03-21 01:29:05,705 - INFO - tqdm - f1: 0.8471, accuracy: 0.8999, batch_loss: 0.0559, loss: 0.2745 ||:  52%|#####2    | 5889/11253 [09:38<19:51,  4.50it/s]
2022-03-21 01:29:15,854 - INFO - tqdm - f1: 0.8473, accuracy: 0.9000, batch_loss: 0.3719, loss: 0.2744 ||:  53%|#####3    | 5991/11253 [09:49<19:40,  4.46it/s]
2022-03-21 01:29:26,036 - INFO - tqdm - f1: 0.8471, accuracy: 0.9000, batch_loss: 0.9545, loss: 0.2748 ||:  54%|#####4    | 6097/11253 [09:59<19:08,  4.49it/s]
2022-03-21 01:29:36,513 - INFO - tqdm - f1: 0.8472, accuracy: 0.9001, batch_loss: 0.0581, loss: 0.2749 ||:  55%|#####5    | 6205/11253 [10:09<18:40,  4.51it/s]
2022-03-21 01:29:46,946 - INFO - tqdm - f1: 0.8473, accuracy: 0.9001, batch_loss: 0.5542, loss: 0.2749 ||:  56%|#####6    | 6311/11253 [10:20<17:36,  4.68it/s]
2022-03-21 01:29:57,436 - INFO - tqdm - f1: 0.8473, accuracy: 0.9000, batch_loss: 0.3593, loss: 0.2753 ||:  57%|#####7    | 6415/11253 [10:30<18:26,  4.37it/s]
2022-03-21 01:30:07,670 - INFO - tqdm - f1: 0.8473, accuracy: 0.9000, batch_loss: 0.3335, loss: 0.2752 ||:  58%|#####7    | 6519/11253 [10:40<18:01,  4.38it/s]
2022-03-21 01:30:18,280 - INFO - tqdm - f1: 0.8475, accuracy: 0.9002, batch_loss: 0.0957, loss: 0.2750 ||:  59%|#####8    | 6631/11253 [10:51<17:19,  4.45it/s]
2022-03-21 01:30:28,632 - INFO - tqdm - f1: 0.8476, accuracy: 0.9003, batch_loss: 0.1539, loss: 0.2746 ||:  60%|#####9    | 6739/11253 [11:01<16:53,  4.45it/s]
2022-03-21 01:30:38,737 - INFO - tqdm - f1: 0.8474, accuracy: 0.9002, batch_loss: 0.1562, loss: 0.2747 ||:  61%|######    | 6843/11253 [11:11<12:55,  5.69it/s]
2022-03-21 01:30:49,010 - INFO - tqdm - f1: 0.8474, accuracy: 0.9003, batch_loss: 0.2244, loss: 0.2745 ||:  62%|######1   | 6949/11253 [11:22<15:44,  4.56it/s]
2022-03-21 01:30:59,786 - INFO - tqdm - f1: 0.8474, accuracy: 0.9004, batch_loss: 0.1272, loss: 0.2743 ||:  63%|######2   | 7059/11253 [11:32<15:59,  4.37it/s]
2022-03-21 01:31:10,133 - INFO - tqdm - f1: 0.8473, accuracy: 0.9002, batch_loss: 0.2678, loss: 0.2746 ||:  64%|######3   | 7163/11253 [11:43<15:38,  4.36it/s]
2022-03-21 01:31:20,166 - INFO - tqdm - f1: 0.8471, accuracy: 0.9002, batch_loss: 0.2311, loss: 0.2749 ||:  65%|######4   | 7265/11253 [11:53<14:44,  4.51it/s]
2022-03-21 01:31:30,393 - INFO - tqdm - f1: 0.8471, accuracy: 0.9000, batch_loss: 0.4810, loss: 0.2754 ||:  66%|######5   | 7371/11253 [12:03<14:09,  4.57it/s]
2022-03-21 01:31:40,697 - INFO - tqdm - f1: 0.8472, accuracy: 0.9001, batch_loss: 0.2448, loss: 0.2755 ||:  66%|######6   | 7477/11253 [12:13<13:48,  4.56it/s]
2022-03-21 01:31:51,059 - INFO - tqdm - f1: 0.8473, accuracy: 0.9000, batch_loss: 0.3512, loss: 0.2757 ||:  67%|######7   | 7581/11253 [12:24<13:39,  4.48it/s]
2022-03-21 01:32:01,513 - INFO - tqdm - f1: 0.8472, accuracy: 0.9000, batch_loss: 0.2849, loss: 0.2758 ||:  68%|######8   | 7689/11253 [12:34<13:11,  4.50it/s]
2022-03-21 01:32:11,765 - INFO - tqdm - f1: 0.8469, accuracy: 0.8998, batch_loss: 0.1862, loss: 0.2761 ||:  69%|######9   | 7795/11253 [12:44<12:44,  4.52it/s]
2022-03-21 01:32:22,246 - INFO - tqdm - f1: 0.8467, accuracy: 0.8998, batch_loss: 0.2846, loss: 0.2763 ||:  70%|#######   | 7903/11253 [12:55<12:42,  4.39it/s]
2022-03-21 01:32:32,490 - INFO - tqdm - f1: 0.8467, accuracy: 0.8996, batch_loss: 0.0632, loss: 0.2766 ||:  71%|#######1  | 8007/11253 [13:05<12:11,  4.44it/s]
2022-03-21 01:32:42,675 - INFO - tqdm - f1: 0.8466, accuracy: 0.8996, batch_loss: 0.0532, loss: 0.2768 ||:  72%|#######2  | 8109/11253 [13:15<11:45,  4.46it/s]
2022-03-21 01:32:53,053 - INFO - tqdm - f1: 0.8464, accuracy: 0.8995, batch_loss: 0.4061, loss: 0.2771 ||:  73%|#######2  | 8213/11253 [13:26<11:35,  4.37it/s]
2022-03-21 01:33:03,478 - INFO - tqdm - f1: 0.8463, accuracy: 0.8996, batch_loss: 1.1434, loss: 0.2768 ||:  74%|#######3  | 8315/11253 [13:36<10:58,  4.46it/s]
2022-03-21 01:33:13,804 - INFO - tqdm - f1: 0.8464, accuracy: 0.8997, batch_loss: 0.2458, loss: 0.2764 ||:  75%|#######4  | 8419/11253 [13:46<10:25,  4.53it/s]
2022-03-21 01:33:24,142 - INFO - tqdm - f1: 0.8466, accuracy: 0.8998, batch_loss: 0.5506, loss: 0.2763 ||:  76%|#######5  | 8523/11253 [13:57<10:12,  4.46it/s]
2022-03-21 01:33:34,454 - INFO - tqdm - f1: 0.8465, accuracy: 0.8998, batch_loss: 0.1823, loss: 0.2763 ||:  77%|#######6  | 8625/11253 [14:07<10:08,  4.32it/s]
2022-03-21 01:33:44,904 - INFO - tqdm - f1: 0.8463, accuracy: 0.8997, batch_loss: 0.2724, loss: 0.2764 ||:  78%|#######7  | 8733/11253 [14:18<08:32,  4.92it/s]
2022-03-21 01:33:55,366 - INFO - tqdm - f1: 0.8464, accuracy: 0.8997, batch_loss: 0.5354, loss: 0.2762 ||:  79%|#######8  | 8839/11253 [14:28<08:12,  4.91it/s]
2022-03-21 01:34:05,720 - INFO - tqdm - f1: 0.8464, accuracy: 0.8997, batch_loss: 0.4067, loss: 0.2762 ||:  79%|#######9  | 8943/11253 [14:38<08:39,  4.44it/s]
2022-03-21 01:34:15,899 - INFO - tqdm - f1: 0.8463, accuracy: 0.8996, batch_loss: 0.1928, loss: 0.2765 ||:  80%|########  | 9047/11253 [14:49<08:03,  4.56it/s]
2022-03-21 01:34:26,307 - INFO - tqdm - f1: 0.8465, accuracy: 0.8997, batch_loss: 0.0844, loss: 0.2763 ||:  81%|########1 | 9155/11253 [14:59<07:49,  4.47it/s]
2022-03-21 01:34:36,591 - INFO - tqdm - f1: 0.8463, accuracy: 0.8996, batch_loss: 0.2762, loss: 0.2767 ||:  82%|########2 | 9259/11253 [15:09<07:26,  4.46it/s]
2022-03-21 01:34:46,751 - INFO - tqdm - f1: 0.8461, accuracy: 0.8994, batch_loss: 0.3323, loss: 0.2768 ||:  83%|########3 | 9363/11253 [15:19<07:00,  4.49it/s]
2022-03-21 01:34:57,093 - INFO - tqdm - f1: 0.8458, accuracy: 0.8992, batch_loss: 0.2946, loss: 0.2770 ||:  84%|########4 | 9471/11253 [15:30<06:35,  4.50it/s]
2022-03-21 01:35:07,249 - INFO - tqdm - f1: 0.8456, accuracy: 0.8991, batch_loss: 0.0893, loss: 0.2772 ||:  85%|########5 | 9575/11253 [15:40<06:13,  4.49it/s]
2022-03-21 01:35:17,303 - INFO - tqdm - f1: 0.8456, accuracy: 0.8991, batch_loss: 0.3868, loss: 0.2773 ||:  86%|########5 | 9677/11253 [15:50<05:41,  4.61it/s]
2022-03-21 01:35:27,351 - INFO - tqdm - f1: 0.8456, accuracy: 0.8991, batch_loss: 0.2127, loss: 0.2773 ||:  87%|########6 | 9783/11253 [16:00<05:24,  4.53it/s]
2022-03-21 01:35:37,630 - INFO - tqdm - f1: 0.8456, accuracy: 0.8991, batch_loss: 0.3075, loss: 0.2774 ||:  88%|########7 | 9891/11253 [16:10<05:03,  4.48it/s]
2022-03-21 01:35:47,904 - INFO - tqdm - f1: 0.8455, accuracy: 0.8989, batch_loss: 0.7135, loss: 0.2778 ||:  89%|########8 | 9999/11253 [16:21<04:37,  4.52it/s]
2022-03-21 01:35:58,314 - INFO - tqdm - f1: 0.8456, accuracy: 0.8989, batch_loss: 0.0987, loss: 0.2781 ||:  90%|########9 | 10109/11253 [16:31<04:08,  4.61it/s]
2022-03-21 01:36:08,529 - INFO - tqdm - f1: 0.8457, accuracy: 0.8989, batch_loss: 0.0551, loss: 0.2782 ||:  91%|######### | 10217/11253 [16:41<03:51,  4.48it/s]
2022-03-21 01:36:18,672 - INFO - tqdm - f1: 0.8458, accuracy: 0.8989, batch_loss: 0.0541, loss: 0.2784 ||:  92%|#########1| 10323/11253 [16:51<02:45,  5.61it/s]
2022-03-21 01:36:28,797 - INFO - tqdm - f1: 0.8458, accuracy: 0.8989, batch_loss: 0.3347, loss: 0.2784 ||:  93%|#########2| 10429/11253 [17:01<03:07,  4.39it/s]
2022-03-21 01:36:38,862 - INFO - tqdm - f1: 0.8458, accuracy: 0.8989, batch_loss: 0.1348, loss: 0.2784 ||:  94%|#########3| 10533/11253 [17:12<02:38,  4.53it/s]
2022-03-21 01:36:49,123 - INFO - tqdm - f1: 0.8459, accuracy: 0.8989, batch_loss: 0.1665, loss: 0.2784 ||:  94%|#########4| 10633/11253 [17:22<02:22,  4.36it/s]
2022-03-21 01:36:59,385 - INFO - tqdm - f1: 0.8456, accuracy: 0.8987, batch_loss: 0.3216, loss: 0.2788 ||:  95%|#########5| 10739/11253 [17:32<01:53,  4.51it/s]
2022-03-21 01:37:09,580 - INFO - tqdm - f1: 0.8456, accuracy: 0.8987, batch_loss: 0.8284, loss: 0.2787 ||:  96%|#########6| 10845/11253 [17:42<01:30,  4.52it/s]
2022-03-21 01:37:19,785 - INFO - tqdm - f1: 0.8454, accuracy: 0.8986, batch_loss: 0.2480, loss: 0.2789 ||:  97%|#########7| 10947/11253 [17:52<01:08,  4.44it/s]
2022-03-21 01:37:30,232 - INFO - tqdm - f1: 0.8455, accuracy: 0.8986, batch_loss: 0.2443, loss: 0.2788 ||:  98%|#########8| 11055/11253 [18:03<00:44,  4.45it/s]
2022-03-21 01:37:40,353 - INFO - tqdm - f1: 0.8456, accuracy: 0.8986, batch_loss: 0.0595, loss: 0.2789 ||:  99%|#########9| 11159/11253 [18:13<00:16,  5.80it/s]
2022-03-21 01:37:43,990 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.1628, loss: 0.2788 ||: 100%|#########9| 11197/11253 [18:17<00:06,  8.21it/s]
2022-03-21 01:37:44,154 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.1641, loss: 0.2788 ||: 100%|#########9| 11199/11253 [18:17<00:05,  9.11it/s]
2022-03-21 01:37:44,294 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.3276, loss: 0.2788 ||: 100%|#########9| 11201/11253 [18:17<00:05, 10.22it/s]
2022-03-21 01:37:44,434 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.1854, loss: 0.2788 ||: 100%|#########9| 11203/11253 [18:17<00:04, 11.17it/s]
2022-03-21 01:37:44,561 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.3953, loss: 0.2788 ||: 100%|#########9| 11205/11253 [18:17<00:03, 12.24it/s]
2022-03-21 01:37:44,688 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.0624, loss: 0.2788 ||: 100%|#########9| 11207/11253 [18:17<00:03, 13.11it/s]
2022-03-21 01:37:44,818 - INFO - tqdm - f1: 0.8458, accuracy: 0.8987, batch_loss: 0.1051, loss: 0.2788 ||: 100%|#########9| 11209/11253 [18:18<00:03, 13.72it/s]
2022-03-21 01:37:44,961 - INFO - tqdm - f1: 0.8458, accuracy: 0.8987, batch_loss: 0.2570, loss: 0.2788 ||: 100%|#########9| 11211/11253 [18:18<00:03, 13.79it/s]
2022-03-21 01:37:45,117 - INFO - tqdm - f1: 0.8458, accuracy: 0.8987, batch_loss: 0.0565, loss: 0.2788 ||: 100%|#########9| 11213/11253 [18:18<00:02, 13.50it/s]
2022-03-21 01:37:45,265 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.2580, loss: 0.2788 ||: 100%|#########9| 11215/11253 [18:18<00:02, 13.49it/s]
2022-03-21 01:37:45,406 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.0181, loss: 0.2788 ||: 100%|#########9| 11217/11253 [18:18<00:02, 13.71it/s]
2022-03-21 01:37:45,542 - INFO - tqdm - f1: 0.8458, accuracy: 0.8987, batch_loss: 0.2095, loss: 0.2787 ||: 100%|#########9| 11219/11253 [18:18<00:02, 13.98it/s]
2022-03-21 01:37:45,686 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.2129, loss: 0.2788 ||: 100%|#########9| 11221/11253 [18:18<00:02, 13.94it/s]
2022-03-21 01:37:45,823 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.2336, loss: 0.2788 ||: 100%|#########9| 11223/11253 [18:19<00:02, 14.14it/s]
2022-03-21 01:37:45,961 - INFO - tqdm - f1: 0.8458, accuracy: 0.8987, batch_loss: 0.3950, loss: 0.2788 ||: 100%|#########9| 11225/11253 [18:19<00:01, 14.24it/s]
2022-03-21 01:37:47,133 - INFO - tqdm - f1: 0.8458, accuracy: 0.8987, batch_loss: 0.3658, loss: 0.2788 ||: 100%|#########9| 11227/11253 [18:20<00:05,  4.45it/s]
2022-03-21 01:37:47,278 - INFO - tqdm - f1: 0.8458, accuracy: 0.8987, batch_loss: 0.1318, loss: 0.2788 ||: 100%|#########9| 11229/11253 [18:20<00:04,  5.58it/s]
2022-03-21 01:37:47,432 - INFO - tqdm - f1: 0.8458, accuracy: 0.8987, batch_loss: 0.0085, loss: 0.2788 ||: 100%|#########9| 11231/11253 [18:20<00:03,  6.74it/s]
2022-03-21 01:37:47,574 - INFO - tqdm - f1: 0.8458, accuracy: 0.8987, batch_loss: 0.4121, loss: 0.2788 ||: 100%|#########9| 11233/11253 [18:20<00:02,  7.98it/s]
2022-03-21 01:37:47,716 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.1775, loss: 0.2788 ||: 100%|#########9| 11235/11253 [18:20<00:01,  9.18it/s]
2022-03-21 01:37:47,846 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.1968, loss: 0.2788 ||: 100%|#########9| 11237/11253 [18:21<00:01, 10.44it/s]
2022-03-21 01:37:47,974 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.0691, loss: 0.2788 ||: 100%|#########9| 11239/11253 [18:21<00:01, 11.59it/s]
2022-03-21 01:37:48,097 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.2188, loss: 0.2788 ||: 100%|#########9| 11241/11253 [18:21<00:00, 12.67it/s]
2022-03-21 01:37:48,233 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.3639, loss: 0.2788 ||: 100%|#########9| 11243/11253 [18:21<00:00, 13.23it/s]
2022-03-21 01:37:48,386 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.4084, loss: 0.2788 ||: 100%|#########9| 11245/11253 [18:21<00:00, 13.18it/s]
2022-03-21 01:37:48,536 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.1575, loss: 0.2788 ||: 100%|#########9| 11247/11253 [18:21<00:00, 13.24it/s]
2022-03-21 01:37:48,678 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.1394, loss: 0.2788 ||: 100%|#########9| 11249/11253 [18:21<00:00, 13.46it/s]
2022-03-21 01:37:48,826 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.2474, loss: 0.2787 ||: 100%|#########9| 11251/11253 [18:22<00:00, 13.48it/s]
2022-03-21 01:37:48,965 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.2934, loss: 0.2788 ||: 100%|##########| 11253/11253 [18:22<00:00, 13.75it/s]
2022-03-21 01:37:49,029 - INFO - tqdm - f1: 0.8457, accuracy: 0.8987, batch_loss: 0.2934, loss: 0.2788 ||: 100%|##########| 11253/11253 [18:22<00:00, 10.21it/s]
2022-03-21 01:37:49,036 - INFO - allennlp.training.trainer - Validating
2022-03-21 01:37:49,038 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 01:37:59,132 - INFO - tqdm - f1: 0.8137, accuracy: 0.8759, batch_loss: 0.2162, loss: 0.3668 ||:  14%|#4        | 268/1889 [00:10<00:41, 39.31it/s]
2022-03-21 01:38:09,194 - INFO - tqdm - f1: 0.8184, accuracy: 0.8782, batch_loss: 0.2349, loss: 0.3520 ||:  28%|##8       | 534/1889 [00:20<00:34, 38.80it/s]
2022-03-21 01:38:19,287 - INFO - tqdm - f1: 0.8171, accuracy: 0.8778, batch_loss: 0.5052, loss: 0.3499 ||:  43%|####2     | 808/1889 [00:30<00:32, 32.87it/s]
2022-03-21 01:38:29,366 - INFO - tqdm - f1: 0.8170, accuracy: 0.8770, batch_loss: 0.0056, loss: 0.3526 ||:  58%|#####7    | 1088/1889 [00:40<00:39, 20.14it/s]
2022-03-21 01:38:39,814 - INFO - tqdm - f1: 0.8209, accuracy: 0.8785, batch_loss: 0.7901, loss: 0.3507 ||:  73%|#######3  | 1380/1889 [00:50<00:44, 11.49it/s]
2022-03-21 01:38:50,230 - INFO - tqdm - f1: 0.8178, accuracy: 0.8761, batch_loss: 0.1987, loss: 0.3565 ||:  88%|########8 | 1666/1889 [01:01<00:19, 11.54it/s]
2022-03-21 01:38:57,727 - INFO - tqdm - f1: 0.8185, accuracy: 0.8761, batch_loss: 0.5919, loss: 0.3567 ||: 100%|#########9| 1880/1889 [01:08<00:00, 24.42it/s]
2022-03-21 01:38:57,852 - INFO - tqdm - f1: 0.8185, accuracy: 0.8763, batch_loss: 0.0051, loss: 0.3564 ||: 100%|#########9| 1885/1889 [01:08<00:00, 27.91it/s]
2022-03-21 01:38:57,951 - INFO - tqdm - f1: 0.8183, accuracy: 0.8762, batch_loss: 0.0618, loss: 0.3564 ||: 100%|##########| 1889/1889 [01:08<00:00, 27.41it/s]
2022-03-21 01:38:57,967 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 01:38:57,969 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.899  |     0.876
2022-03-21 01:38:57,970 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.846  |     0.818
2022-03-21 01:38:57,972 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 01:38:57,973 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.279  |     0.356
2022-03-21 01:38:57,975 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8643.105  |       N/A
2022-03-21 01:38:57,977 - INFO - allennlp.training.trainer - Epoch duration: 0:19:31.186749
2022-03-21 01:38:57,978 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:36:59
2022-03-21 01:38:57,980 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-21 01:38:57,982 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 01:38:57,984 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 01:38:57,986 - INFO - allennlp.training.trainer - Training
2022-03-21 01:38:57,988 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 01:39:08,110 - INFO - tqdm - f1: 0.8726, accuracy: 0.9195, batch_loss: 0.3697, loss: 0.2203 ||:   1%|          | 87/11253 [00:10<28:38,  6.50it/s]
2022-03-21 01:39:18,259 - INFO - tqdm - f1: 0.8640, accuracy: 0.9120, batch_loss: 0.3361, loss: 0.2324 ||:   2%|1         | 189/11253 [00:20<41:53,  4.40it/s]
2022-03-21 01:39:28,689 - INFO - tqdm - f1: 0.8642, accuracy: 0.9118, batch_loss: 0.1781, loss: 0.2360 ||:   3%|2         | 297/11253 [00:30<40:05,  4.55it/s]
2022-03-21 01:39:39,190 - INFO - tqdm - f1: 0.8646, accuracy: 0.9121, batch_loss: 0.0979, loss: 0.2323 ||:   4%|3         | 403/11253 [00:41<41:07,  4.40it/s]
2022-03-21 01:39:49,738 - INFO - tqdm - f1: 0.8644, accuracy: 0.9135, batch_loss: 0.1448, loss: 0.2315 ||:   4%|4         | 505/11253 [00:51<40:18,  4.44it/s]
2022-03-21 01:40:00,104 - INFO - tqdm - f1: 0.8611, accuracy: 0.9115, batch_loss: 0.3674, loss: 0.2379 ||:   5%|5         | 611/11253 [01:02<39:19,  4.51it/s]
2022-03-21 01:40:10,336 - INFO - tqdm - f1: 0.8603, accuracy: 0.9116, batch_loss: 0.1562, loss: 0.2368 ||:   6%|6         | 715/11253 [01:12<39:33,  4.44it/s]
2022-03-21 01:40:20,840 - INFO - tqdm - f1: 0.8603, accuracy: 0.9118, batch_loss: 0.5354, loss: 0.2402 ||:   7%|7         | 823/11253 [01:22<39:56,  4.35it/s]
2022-03-21 01:40:30,988 - INFO - tqdm - f1: 0.8602, accuracy: 0.9119, batch_loss: 0.2661, loss: 0.2400 ||:   8%|8         | 927/11253 [01:32<37:54,  4.54it/s]
2022-03-21 01:40:41,287 - INFO - tqdm - f1: 0.8599, accuracy: 0.9119, batch_loss: 0.0882, loss: 0.2385 ||:   9%|9         | 1031/11253 [01:43<37:31,  4.54it/s]
2022-03-21 01:40:51,696 - INFO - tqdm - f1: 0.8599, accuracy: 0.9120, batch_loss: 0.2015, loss: 0.2393 ||:  10%|#         | 1137/11253 [01:53<37:51,  4.45it/s]
2022-03-21 01:41:02,070 - INFO - tqdm - f1: 0.8589, accuracy: 0.9114, batch_loss: 0.1312, loss: 0.2406 ||:  11%|#1        | 1243/11253 [02:04<37:29,  4.45it/s]
2022-03-21 01:41:12,377 - INFO - tqdm - f1: 0.8576, accuracy: 0.9099, batch_loss: 0.2742, loss: 0.2426 ||:  12%|#1        | 1349/11253 [02:14<36:36,  4.51it/s]
2022-03-21 01:41:22,637 - INFO - tqdm - f1: 0.8582, accuracy: 0.9103, batch_loss: 0.1616, loss: 0.2421 ||:  13%|#2        | 1451/11253 [02:24<37:54,  4.31it/s]
2022-03-21 01:41:33,039 - INFO - tqdm - f1: 0.8597, accuracy: 0.9112, batch_loss: 0.0703, loss: 0.2403 ||:  14%|#3        | 1559/11253 [02:35<36:40,  4.40it/s]
2022-03-21 01:41:43,061 - INFO - tqdm - f1: 0.8592, accuracy: 0.9111, batch_loss: 0.3926, loss: 0.2405 ||:  15%|#4        | 1663/11253 [02:45<35:17,  4.53it/s]
2022-03-21 01:41:53,466 - INFO - tqdm - f1: 0.8599, accuracy: 0.9116, batch_loss: 0.1511, loss: 0.2395 ||:  16%|#5        | 1769/11253 [02:55<35:59,  4.39it/s]
2022-03-21 01:42:03,767 - INFO - tqdm - f1: 0.8606, accuracy: 0.9119, batch_loss: 0.1368, loss: 0.2390 ||:  17%|#6        | 1875/11253 [03:05<35:26,  4.41it/s]
2022-03-21 01:42:13,939 - INFO - tqdm - f1: 0.8609, accuracy: 0.9120, batch_loss: 0.3053, loss: 0.2394 ||:  18%|#7        | 1979/11253 [03:15<34:57,  4.42it/s]
2022-03-21 01:42:24,025 - INFO - tqdm - f1: 0.8605, accuracy: 0.9120, batch_loss: 0.1393, loss: 0.2390 ||:  18%|#8        | 2081/11253 [03:26<35:04,  4.36it/s]
2022-03-21 01:42:34,445 - INFO - tqdm - f1: 0.8608, accuracy: 0.9121, batch_loss: 0.0172, loss: 0.2390 ||:  19%|#9        | 2189/11253 [03:36<34:41,  4.35it/s]
2022-03-21 01:42:44,891 - INFO - tqdm - f1: 0.8612, accuracy: 0.9120, batch_loss: 0.0966, loss: 0.2395 ||:  20%|##        | 2297/11253 [03:46<33:46,  4.42it/s]
2022-03-21 01:42:55,387 - INFO - tqdm - f1: 0.8620, accuracy: 0.9126, batch_loss: 0.0984, loss: 0.2387 ||:  21%|##1       | 2405/11253 [03:57<33:33,  4.40it/s]
2022-03-21 01:43:05,673 - INFO - tqdm - f1: 0.8615, accuracy: 0.9122, batch_loss: 0.2233, loss: 0.2390 ||:  22%|##2       | 2511/11253 [04:07<33:17,  4.38it/s]
2022-03-21 01:43:16,164 - INFO - tqdm - f1: 0.8619, accuracy: 0.9122, batch_loss: 0.1068, loss: 0.2389 ||:  23%|##3       | 2619/11253 [04:18<31:52,  4.51it/s]
2022-03-21 01:43:26,468 - INFO - tqdm - f1: 0.8617, accuracy: 0.9123, batch_loss: 0.2247, loss: 0.2391 ||:  24%|##4       | 2721/11253 [04:28<32:28,  4.38it/s]
2022-03-21 01:43:36,979 - INFO - tqdm - f1: 0.8619, accuracy: 0.9124, batch_loss: 0.0779, loss: 0.2395 ||:  25%|##5       | 2827/11253 [04:38<31:39,  4.44it/s]
2022-03-21 01:43:47,270 - INFO - tqdm - f1: 0.8617, accuracy: 0.9122, batch_loss: 0.1868, loss: 0.2398 ||:  26%|##6       | 2931/11253 [04:49<30:41,  4.52it/s]
2022-03-21 01:43:57,432 - INFO - tqdm - f1: 0.8613, accuracy: 0.9120, batch_loss: 0.1162, loss: 0.2396 ||:  27%|##6       | 3035/11253 [04:59<30:37,  4.47it/s]
2022-03-21 01:44:07,860 - INFO - tqdm - f1: 0.8611, accuracy: 0.9118, batch_loss: 0.1098, loss: 0.2400 ||:  28%|##7       | 3141/11253 [05:09<31:02,  4.36it/s]
2022-03-21 01:44:18,103 - INFO - tqdm - f1: 0.8612, accuracy: 0.9118, batch_loss: 0.5023, loss: 0.2405 ||:  29%|##8       | 3245/11253 [05:20<30:15,  4.41it/s]
2022-03-21 01:44:28,430 - INFO - tqdm - f1: 0.8615, accuracy: 0.9120, batch_loss: 0.2227, loss: 0.2404 ||:  30%|##9       | 3349/11253 [05:30<30:09,  4.37it/s]
2022-03-21 01:44:38,843 - INFO - tqdm - f1: 0.8613, accuracy: 0.9118, batch_loss: 0.0202, loss: 0.2402 ||:  31%|###       | 3455/11253 [05:40<29:17,  4.44it/s]
2022-03-21 01:44:49,154 - INFO - tqdm - f1: 0.8617, accuracy: 0.9120, batch_loss: 0.1106, loss: 0.2401 ||:  32%|###1      | 3557/11253 [05:51<29:33,  4.34it/s]
2022-03-21 01:44:59,396 - INFO - tqdm - f1: 0.8616, accuracy: 0.9120, batch_loss: 0.0702, loss: 0.2403 ||:  33%|###2      | 3661/11253 [06:01<28:06,  4.50it/s]
2022-03-21 01:45:09,572 - INFO - tqdm - f1: 0.8613, accuracy: 0.9120, batch_loss: 0.5528, loss: 0.2402 ||:  33%|###3      | 3765/11253 [06:11<28:10,  4.43it/s]
2022-03-21 01:45:19,625 - INFO - tqdm - f1: 0.8613, accuracy: 0.9120, batch_loss: 0.4652, loss: 0.2402 ||:  34%|###4      | 3867/11253 [06:21<21:53,  5.62it/s]
2022-03-21 01:45:29,710 - INFO - tqdm - f1: 0.8614, accuracy: 0.9121, batch_loss: 0.1525, loss: 0.2399 ||:  35%|###5      | 3967/11253 [06:31<27:07,  4.48it/s]
2022-03-21 01:45:40,081 - INFO - tqdm - f1: 0.8614, accuracy: 0.9117, batch_loss: 0.1165, loss: 0.2414 ||:  36%|###6      | 4073/11253 [06:42<26:34,  4.50it/s]
2022-03-21 01:45:50,423 - INFO - tqdm - f1: 0.8613, accuracy: 0.9117, batch_loss: 0.1976, loss: 0.2415 ||:  37%|###7      | 4177/11253 [06:52<27:17,  4.32it/s]
2022-03-21 01:46:00,793 - INFO - tqdm - f1: 0.8611, accuracy: 0.9116, batch_loss: 0.0500, loss: 0.2418 ||:  38%|###8      | 4281/11253 [07:02<26:22,  4.41it/s]
2022-03-21 01:46:11,015 - INFO - tqdm - f1: 0.8607, accuracy: 0.9115, batch_loss: 0.1500, loss: 0.2416 ||:  39%|###8      | 4383/11253 [07:13<26:39,  4.30it/s]
2022-03-21 01:46:21,945 - INFO - tqdm - f1: 0.8605, accuracy: 0.9114, batch_loss: 0.0773, loss: 0.2418 ||:  40%|###9      | 4493/11253 [07:23<25:18,  4.45it/s]
2022-03-21 01:46:32,349 - INFO - tqdm - f1: 0.8607, accuracy: 0.9116, batch_loss: 0.2233, loss: 0.2415 ||:  41%|####      | 4599/11253 [07:34<24:37,  4.50it/s]
2022-03-21 01:46:43,012 - INFO - tqdm - f1: 0.8608, accuracy: 0.9116, batch_loss: 0.0050, loss: 0.2418 ||:  42%|####1     | 4709/11253 [07:45<24:59,  4.36it/s]
2022-03-21 01:46:53,138 - INFO - tqdm - f1: 0.8611, accuracy: 0.9118, batch_loss: 0.0116, loss: 0.2415 ||:  43%|####2     | 4813/11253 [07:55<18:57,  5.66it/s]
2022-03-21 01:47:03,885 - INFO - tqdm - f1: 0.8613, accuracy: 0.9118, batch_loss: 0.3758, loss: 0.2416 ||:  44%|####3     | 4921/11253 [08:05<24:35,  4.29it/s]
2022-03-21 01:47:14,048 - INFO - tqdm - f1: 0.8611, accuracy: 0.9118, batch_loss: 0.0611, loss: 0.2413 ||:  45%|####4     | 5023/11253 [08:16<23:21,  4.45it/s]
2022-03-21 01:47:24,286 - INFO - tqdm - f1: 0.8610, accuracy: 0.9117, batch_loss: 0.0790, loss: 0.2415 ||:  46%|####5     | 5127/11253 [08:26<23:13,  4.40it/s]
2022-03-21 01:47:34,837 - INFO - tqdm - f1: 0.8615, accuracy: 0.9118, batch_loss: 0.1608, loss: 0.2413 ||:  47%|####6     | 5237/11253 [08:36<21:41,  4.62it/s]
2022-03-21 01:47:44,979 - INFO - tqdm - f1: 0.8616, accuracy: 0.9118, batch_loss: 0.2042, loss: 0.2412 ||:  47%|####7     | 5341/11253 [08:46<21:57,  4.49it/s]
2022-03-21 01:47:55,113 - INFO - tqdm - f1: 0.8616, accuracy: 0.9118, batch_loss: 0.1389, loss: 0.2411 ||:  48%|####8     | 5443/11253 [08:57<17:33,  5.52it/s]
2022-03-21 01:48:05,234 - INFO - tqdm - f1: 0.8613, accuracy: 0.9118, batch_loss: 0.0343, loss: 0.2412 ||:  49%|####9     | 5545/11253 [09:07<20:59,  4.53it/s]
2022-03-21 01:48:15,350 - INFO - tqdm - f1: 0.8613, accuracy: 0.9117, batch_loss: 0.5314, loss: 0.2412 ||:  50%|#####     | 5647/11253 [09:17<20:57,  4.46it/s]
2022-03-21 01:48:25,449 - INFO - tqdm - f1: 0.8612, accuracy: 0.9117, batch_loss: 0.0989, loss: 0.2411 ||:  51%|#####1    | 5747/11253 [09:27<16:28,  5.57it/s]
2022-03-21 01:48:35,600 - INFO - tqdm - f1: 0.8612, accuracy: 0.9116, batch_loss: 0.3054, loss: 0.2415 ||:  52%|#####1    | 5849/11253 [09:37<20:22,  4.42it/s]
2022-03-21 01:48:45,708 - INFO - tqdm - f1: 0.8612, accuracy: 0.9116, batch_loss: 0.1005, loss: 0.2416 ||:  53%|#####2    | 5951/11253 [09:47<19:51,  4.45it/s]
2022-03-21 01:48:56,146 - INFO - tqdm - f1: 0.8611, accuracy: 0.9115, batch_loss: 0.2735, loss: 0.2417 ||:  54%|#####3    | 6057/11253 [09:58<19:24,  4.46it/s]
2022-03-21 01:49:06,253 - INFO - tqdm - f1: 0.8609, accuracy: 0.9114, batch_loss: 0.2305, loss: 0.2420 ||:  55%|#####4    | 6161/11253 [10:08<18:54,  4.49it/s]
2022-03-21 01:49:16,379 - INFO - tqdm - f1: 0.8612, accuracy: 0.9115, batch_loss: 0.1967, loss: 0.2417 ||:  56%|#####5    | 6265/11253 [10:18<18:37,  4.46it/s]
2022-03-21 01:49:26,549 - INFO - tqdm - f1: 0.8612, accuracy: 0.9116, batch_loss: 0.1086, loss: 0.2417 ||:  57%|#####6    | 6373/11253 [10:28<17:32,  4.63it/s]
2022-03-21 01:49:36,750 - INFO - tqdm - f1: 0.8615, accuracy: 0.9118, batch_loss: 0.3923, loss: 0.2415 ||:  58%|#####7    | 6479/11253 [10:38<14:06,  5.64it/s]
2022-03-21 01:49:46,881 - INFO - tqdm - f1: 0.8615, accuracy: 0.9117, batch_loss: 0.4116, loss: 0.2415 ||:  58%|#####8    | 6583/11253 [10:48<17:24,  4.47it/s]
2022-03-21 01:49:57,354 - INFO - tqdm - f1: 0.8614, accuracy: 0.9116, batch_loss: 0.1807, loss: 0.2422 ||:  59%|#####9    | 6689/11253 [10:59<18:13,  4.17it/s]
2022-03-21 01:50:07,402 - INFO - tqdm - f1: 0.8613, accuracy: 0.9116, batch_loss: 0.0639, loss: 0.2424 ||:  60%|######    | 6789/11253 [11:09<13:31,  5.50it/s]
2022-03-21 01:50:17,542 - INFO - tqdm - f1: 0.8613, accuracy: 0.9116, batch_loss: 0.0093, loss: 0.2424 ||:  61%|######1   | 6893/11253 [11:19<12:39,  5.74it/s]
2022-03-21 01:50:27,632 - INFO - tqdm - f1: 0.8615, accuracy: 0.9117, batch_loss: 0.0909, loss: 0.2421 ||:  62%|######2   | 6997/11253 [11:29<12:26,  5.70it/s]
2022-03-21 01:50:37,722 - INFO - tqdm - f1: 0.8615, accuracy: 0.9116, batch_loss: 0.3444, loss: 0.2424 ||:  63%|######3   | 7101/11253 [11:39<12:15,  5.65it/s]
2022-03-21 01:50:47,866 - INFO - tqdm - f1: 0.8618, accuracy: 0.9117, batch_loss: 0.0476, loss: 0.2423 ||:  64%|######4   | 7207/11253 [11:49<11:49,  5.71it/s]
2022-03-21 01:50:57,922 - INFO - tqdm - f1: 0.8618, accuracy: 0.9116, batch_loss: 0.6157, loss: 0.2426 ||:  65%|######4   | 7309/11253 [11:59<09:36,  6.84it/s]
2022-03-21 01:51:08,009 - INFO - tqdm - f1: 0.8619, accuracy: 0.9117, batch_loss: 0.4025, loss: 0.2426 ||:  66%|######5   | 7409/11253 [12:10<07:58,  8.03it/s]
2022-03-21 01:51:18,263 - INFO - tqdm - f1: 0.8619, accuracy: 0.9117, batch_loss: 0.0262, loss: 0.2429 ||:  67%|######6   | 7509/11253 [12:20<13:45,  4.53it/s]
2022-03-21 01:51:28,862 - INFO - tqdm - f1: 0.8618, accuracy: 0.9115, batch_loss: 0.6085, loss: 0.2437 ||:  68%|######7   | 7619/11253 [12:30<13:28,  4.49it/s]
2022-03-21 01:51:39,883 - INFO - tqdm - f1: 0.8617, accuracy: 0.9113, batch_loss: 0.4521, loss: 0.2445 ||:  69%|######8   | 7731/11253 [12:41<13:05,  4.48it/s]
2022-03-21 01:51:50,235 - INFO - tqdm - f1: 0.8617, accuracy: 0.9112, batch_loss: 0.3105, loss: 0.2447 ||:  70%|######9   | 7833/11253 [12:52<12:54,  4.42it/s]
2022-03-21 01:52:00,850 - INFO - tqdm - f1: 0.8612, accuracy: 0.9109, batch_loss: 0.2264, loss: 0.2453 ||:  71%|#######   | 7941/11253 [13:02<12:16,  4.50it/s]
2022-03-21 01:52:11,269 - INFO - tqdm - f1: 0.8611, accuracy: 0.9109, batch_loss: 0.0880, loss: 0.2453 ||:  72%|#######1  | 8047/11253 [13:13<11:58,  4.46it/s]
2022-03-21 01:52:21,850 - INFO - tqdm - f1: 0.8609, accuracy: 0.9108, batch_loss: 0.0610, loss: 0.2456 ||:  72%|#######2  | 8155/11253 [13:23<11:43,  4.41it/s]
2022-03-21 01:52:32,590 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.0979, loss: 0.2453 ||:  73%|#######3  | 8263/11253 [13:34<11:03,  4.51it/s]
2022-03-21 01:52:42,859 - INFO - tqdm - f1: 0.8609, accuracy: 0.9107, batch_loss: 0.4312, loss: 0.2456 ||:  74%|#######4  | 8367/11253 [13:44<10:55,  4.40it/s]
2022-03-21 01:52:52,941 - INFO - tqdm - f1: 0.8609, accuracy: 0.9108, batch_loss: 0.7320, loss: 0.2457 ||:  75%|#######5  | 8469/11253 [13:54<10:22,  4.47it/s]
2022-03-21 01:53:03,053 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.2717, loss: 0.2459 ||:  76%|#######6  | 8571/11253 [14:05<10:09,  4.40it/s]
2022-03-21 01:53:13,106 - INFO - tqdm - f1: 0.8609, accuracy: 0.9107, batch_loss: 0.2372, loss: 0.2460 ||:  77%|#######7  | 8673/11253 [14:15<09:37,  4.47it/s]
2022-03-21 01:53:23,165 - INFO - tqdm - f1: 0.8605, accuracy: 0.9105, batch_loss: 0.3452, loss: 0.2464 ||:  78%|#######7  | 8775/11253 [14:25<07:17,  5.66it/s]
2022-03-21 01:53:33,184 - INFO - tqdm - f1: 0.8606, accuracy: 0.9106, batch_loss: 0.3127, loss: 0.2464 ||:  79%|#######8  | 8877/11253 [14:35<06:58,  5.68it/s]
2022-03-21 01:53:43,266 - INFO - tqdm - f1: 0.8605, accuracy: 0.9105, batch_loss: 0.4131, loss: 0.2467 ||:  80%|#######9  | 8977/11253 [14:45<06:54,  5.49it/s]
2022-03-21 01:53:53,380 - INFO - tqdm - f1: 0.8604, accuracy: 0.9105, batch_loss: 0.2360, loss: 0.2466 ||:  81%|########  | 9081/11253 [14:55<05:13,  6.93it/s]
2022-03-21 01:54:03,527 - INFO - tqdm - f1: 0.8603, accuracy: 0.9105, batch_loss: 0.0463, loss: 0.2467 ||:  82%|########1 | 9183/11253 [15:05<06:20,  5.44it/s]
2022-03-21 01:54:13,660 - INFO - tqdm - f1: 0.8602, accuracy: 0.9105, batch_loss: 0.1387, loss: 0.2466 ||:  82%|########2 | 9283/11253 [15:15<05:53,  5.57it/s]
2022-03-21 01:54:23,731 - INFO - tqdm - f1: 0.8602, accuracy: 0.9105, batch_loss: 0.0932, loss: 0.2467 ||:  83%|########3 | 9385/11253 [15:25<05:27,  5.70it/s]
2022-03-21 01:54:33,785 - INFO - tqdm - f1: 0.8603, accuracy: 0.9105, batch_loss: 0.7482, loss: 0.2465 ||:  84%|########4 | 9489/11253 [15:35<06:30,  4.52it/s]
2022-03-21 01:54:43,804 - INFO - tqdm - f1: 0.8601, accuracy: 0.9104, batch_loss: 0.4677, loss: 0.2468 ||:  85%|########5 | 9589/11253 [15:45<06:20,  4.37it/s]
2022-03-21 01:54:54,115 - INFO - tqdm - f1: 0.8599, accuracy: 0.9103, batch_loss: 0.2756, loss: 0.2471 ||:  86%|########6 | 9693/11253 [15:56<05:53,  4.41it/s]
2022-03-21 01:55:04,157 - INFO - tqdm - f1: 0.8599, accuracy: 0.9103, batch_loss: 0.4873, loss: 0.2470 ||:  87%|########7 | 9793/11253 [16:06<05:27,  4.46it/s]
2022-03-21 01:55:14,241 - INFO - tqdm - f1: 0.8600, accuracy: 0.9103, batch_loss: 0.1770, loss: 0.2470 ||:  88%|########7 | 9895/11253 [16:16<05:08,  4.41it/s]
2022-03-21 01:55:24,893 - INFO - tqdm - f1: 0.8600, accuracy: 0.9103, batch_loss: 0.2489, loss: 0.2469 ||:  89%|########8 | 10003/11253 [16:26<04:53,  4.25it/s]
2022-03-21 01:55:35,287 - INFO - tqdm - f1: 0.8599, accuracy: 0.9103, batch_loss: 0.1840, loss: 0.2470 ||:  90%|########9 | 10109/11253 [16:37<04:14,  4.50it/s]
2022-03-21 01:55:45,726 - INFO - tqdm - f1: 0.8600, accuracy: 0.9103, batch_loss: 0.4811, loss: 0.2468 ||:  91%|######### | 10215/11253 [16:47<03:59,  4.34it/s]
2022-03-21 01:55:56,052 - INFO - tqdm - f1: 0.8599, accuracy: 0.9102, batch_loss: 0.0181, loss: 0.2469 ||:  92%|#########1| 10321/11253 [16:58<03:33,  4.37it/s]
2022-03-21 01:56:06,526 - INFO - tqdm - f1: 0.8599, accuracy: 0.9103, batch_loss: 0.1131, loss: 0.2468 ||:  93%|#########2| 10427/11253 [17:08<03:08,  4.39it/s]
2022-03-21 01:56:17,086 - INFO - tqdm - f1: 0.8599, accuracy: 0.9102, batch_loss: 0.3103, loss: 0.2471 ||:  94%|#########3| 10535/11253 [17:19<02:41,  4.44it/s]
2022-03-21 01:56:27,400 - INFO - tqdm - f1: 0.8598, accuracy: 0.9102, batch_loss: 0.1646, loss: 0.2472 ||:  95%|#########4| 10641/11253 [17:29<02:17,  4.43it/s]
2022-03-21 01:56:37,446 - INFO - tqdm - f1: 0.8598, accuracy: 0.9102, batch_loss: 0.1605, loss: 0.2472 ||:  95%|#########5| 10743/11253 [17:39<01:53,  4.51it/s]
2022-03-21 01:56:47,491 - INFO - tqdm - f1: 0.8600, accuracy: 0.9103, batch_loss: 0.1203, loss: 0.2473 ||:  96%|#########6| 10845/11253 [17:49<01:30,  4.53it/s]
2022-03-21 01:56:57,586 - INFO - tqdm - f1: 0.8597, accuracy: 0.9101, batch_loss: 0.1043, loss: 0.2476 ||:  97%|#########7| 10947/11253 [17:59<00:53,  5.72it/s]
2022-03-21 01:57:07,754 - INFO - tqdm - f1: 0.8597, accuracy: 0.9101, batch_loss: 0.1532, loss: 0.2477 ||:  98%|#########8| 11049/11253 [18:09<00:45,  4.51it/s]
2022-03-21 01:57:17,847 - INFO - tqdm - f1: 0.8596, accuracy: 0.9099, batch_loss: 0.0821, loss: 0.2481 ||:  99%|#########9| 11149/11253 [18:19<00:23,  4.37it/s]
2022-03-21 01:57:22,193 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.2778, loss: 0.2482 ||: 100%|#########9| 11197/11253 [18:24<00:04, 12.64it/s]
2022-03-21 01:57:22,336 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.2636, loss: 0.2482 ||: 100%|#########9| 11199/11253 [18:24<00:04, 13.01it/s]
2022-03-21 01:57:22,478 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.2639, loss: 0.2482 ||: 100%|#########9| 11201/11253 [18:24<00:03, 13.32it/s]
2022-03-21 01:57:22,634 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.3993, loss: 0.2482 ||: 100%|#########9| 11203/11253 [18:24<00:03, 13.17it/s]
2022-03-21 01:57:22,787 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.2734, loss: 0.2482 ||: 100%|#########9| 11205/11253 [18:24<00:03, 13.12it/s]
2022-03-21 01:57:22,942 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.2444, loss: 0.2482 ||: 100%|#########9| 11207/11253 [18:24<00:03, 13.08it/s]
2022-03-21 01:57:23,079 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.0769, loss: 0.2482 ||: 100%|#########9| 11209/11253 [18:25<00:03, 13.49it/s]
2022-03-21 01:57:23,221 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.0570, loss: 0.2482 ||: 100%|#########9| 11211/11253 [18:25<00:03, 13.65it/s]
2022-03-21 01:57:23,354 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.0798, loss: 0.2482 ||: 100%|#########9| 11213/11253 [18:25<00:02, 14.06it/s]
2022-03-21 01:57:23,480 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.3427, loss: 0.2482 ||: 100%|#########9| 11215/11253 [18:25<00:02, 14.53it/s]
2022-03-21 01:57:24,677 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.0968, loss: 0.2482 ||: 100%|#########9| 11217/11253 [18:26<00:08,  4.39it/s]
2022-03-21 01:57:24,824 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.2149, loss: 0.2482 ||: 100%|#########9| 11219/11253 [18:26<00:06,  5.51it/s]
2022-03-21 01:57:24,977 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.7535, loss: 0.2483 ||: 100%|#########9| 11221/11253 [18:26<00:04,  6.67it/s]
2022-03-21 01:57:25,113 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.2224, loss: 0.2483 ||: 100%|#########9| 11223/11253 [18:27<00:03,  7.98it/s]
2022-03-21 01:57:25,250 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.0612, loss: 0.2483 ||: 100%|#########9| 11225/11253 [18:27<00:03,  9.23it/s]
2022-03-21 01:57:25,374 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.1069, loss: 0.2483 ||: 100%|#########9| 11227/11253 [18:27<00:02, 10.60it/s]
2022-03-21 01:57:25,512 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.1174, loss: 0.2482 ||: 100%|#########9| 11229/11253 [18:27<00:02, 11.51it/s]
2022-03-21 01:57:25,647 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.0950, loss: 0.2482 ||: 100%|#########9| 11231/11253 [18:27<00:01, 12.35it/s]
2022-03-21 01:57:25,774 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.0492, loss: 0.2482 ||: 100%|#########9| 11233/11253 [18:27<00:01, 13.19it/s]
2022-03-21 01:57:25,910 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.1002, loss: 0.2482 ||: 100%|#########9| 11235/11253 [18:27<00:01, 13.62it/s]
2022-03-21 01:57:26,069 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.2158, loss: 0.2482 ||: 100%|#########9| 11237/11253 [18:28<00:01, 13.30it/s]
2022-03-21 01:57:26,213 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.2618, loss: 0.2482 ||: 100%|#########9| 11239/11253 [18:28<00:01, 13.47it/s]
2022-03-21 01:57:26,356 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.2712, loss: 0.2482 ||: 100%|#########9| 11241/11253 [18:28<00:00, 13.63it/s]
2022-03-21 01:57:26,497 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.1385, loss: 0.2482 ||: 100%|#########9| 11243/11253 [18:28<00:00, 13.78it/s]
2022-03-21 01:57:26,622 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.0504, loss: 0.2481 ||: 100%|#########9| 11245/11253 [18:28<00:00, 14.37it/s]
2022-03-21 01:57:26,746 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.2637, loss: 0.2481 ||: 100%|#########9| 11247/11253 [18:28<00:00, 14.87it/s]
2022-03-21 01:57:27,925 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.6000, loss: 0.2481 ||: 100%|#########9| 11249/11253 [18:29<00:00,  4.46it/s]
2022-03-21 01:57:28,070 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.4496, loss: 0.2482 ||: 100%|#########9| 11251/11253 [18:30<00:00,  5.60it/s]
2022-03-21 01:57:28,217 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.0279, loss: 0.2482 ||: 100%|##########| 11253/11253 [18:30<00:00,  6.80it/s]
2022-03-21 01:57:28,285 - INFO - tqdm - f1: 0.8597, accuracy: 0.9100, batch_loss: 0.0279, loss: 0.2482 ||: 100%|##########| 11253/11253 [18:30<00:00, 10.14it/s]
2022-03-21 01:57:28,292 - INFO - allennlp.training.trainer - Validating
2022-03-21 01:57:28,294 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 01:57:38,368 - INFO - tqdm - f1: 0.8153, accuracy: 0.8773, batch_loss: 0.5042, loss: 0.4051 ||:  15%|#4        | 277/1889 [00:10<02:17, 11.77it/s]
2022-03-21 01:57:48,727 - INFO - tqdm - f1: 0.8165, accuracy: 0.8770, batch_loss: 0.6026, loss: 0.3941 ||:  30%|###       | 570/1889 [00:20<01:54, 11.54it/s]
2022-03-21 01:57:58,968 - INFO - tqdm - f1: 0.8161, accuracy: 0.8762, batch_loss: 0.9510, loss: 0.4004 ||:  45%|####5     | 856/1889 [00:30<01:20, 12.82it/s]
2022-03-21 01:58:09,250 - INFO - tqdm - f1: 0.8176, accuracy: 0.8774, batch_loss: 0.4977, loss: 0.3942 ||:  61%|######    | 1144/1889 [00:40<01:00, 12.23it/s]
2022-03-21 01:58:19,765 - INFO - tqdm - f1: 0.8175, accuracy: 0.8775, batch_loss: 0.6636, loss: 0.3951 ||:  76%|#######6  | 1440/1889 [00:51<00:39, 11.48it/s]
2022-03-21 01:58:29,941 - INFO - tqdm - f1: 0.8173, accuracy: 0.8765, batch_loss: 0.2160, loss: 0.4004 ||:  91%|#########1| 1722/1889 [01:01<00:13, 12.30it/s]
2022-03-21 01:58:34,917 - INFO - tqdm - f1: 0.8174, accuracy: 0.8764, batch_loss: 0.3836, loss: 0.4007 ||: 100%|#########9| 1880/1889 [01:06<00:00, 38.00it/s]
2022-03-21 01:58:35,018 - INFO - tqdm - f1: 0.8175, accuracy: 0.8765, batch_loss: 0.4140, loss: 0.4005 ||: 100%|#########9| 1884/1889 [01:06<00:00, 38.42it/s]
2022-03-21 01:58:35,138 - INFO - tqdm - f1: 0.8175, accuracy: 0.8764, batch_loss: 0.0629, loss: 0.4008 ||: 100%|##########| 1889/1889 [01:06<00:00, 39.41it/s]
2022-03-21 01:58:35,150 - INFO - tqdm - f1: 0.8175, accuracy: 0.8764, batch_loss: 0.0629, loss: 0.4008 ||: 100%|##########| 1889/1889 [01:06<00:00, 28.26it/s]
2022-03-21 01:58:35,166 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 01:58:35,168 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.910  |     0.876
2022-03-21 01:58:35,170 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.860  |     0.817
2022-03-21 01:58:35,172 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 01:58:35,174 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.248  |     0.401
2022-03-21 01:58:35,176 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8643.105  |       N/A
2022-03-21 01:58:35,177 - INFO - allennlp.training.trainer - Epoch duration: 0:19:37.197368
2022-03-21 01:58:35,179 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:24:16
2022-03-21 01:58:35,181 - INFO - allennlp.training.trainer - Epoch 5/9
2022-03-21 01:58:35,183 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 01:58:35,186 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 01:58:35,189 - INFO - allennlp.training.trainer - Training
2022-03-21 01:58:35,191 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 01:58:45,287 - INFO - tqdm - f1: 0.8512, accuracy: 0.9134, batch_loss: 0.1125, loss: 0.1995 ||:   1%|          | 57/11253 [00:10<13:50, 13.48it/s]
2022-03-21 01:58:55,328 - INFO - tqdm - f1: 0.8620, accuracy: 0.9147, batch_loss: 0.0964, loss: 0.2296 ||:   1%|1         | 159/11253 [00:20<13:21, 13.84it/s]
2022-03-21 01:59:05,446 - INFO - tqdm - f1: 0.8676, accuracy: 0.9187, batch_loss: 0.4026, loss: 0.2225 ||:   2%|2         | 259/11253 [00:30<15:36, 11.74it/s]
2022-03-21 01:59:15,505 - INFO - tqdm - f1: 0.8684, accuracy: 0.9171, batch_loss: 0.0862, loss: 0.2262 ||:   3%|3         | 362/11253 [00:40<21:38,  8.39it/s]
2022-03-21 01:59:25,560 - INFO - tqdm - f1: 0.8698, accuracy: 0.9173, batch_loss: 0.0073, loss: 0.2234 ||:   4%|4         | 462/11253 [00:50<32:12,  5.59it/s]
2022-03-21 01:59:35,867 - INFO - tqdm - f1: 0.8730, accuracy: 0.9188, batch_loss: 0.1521, loss: 0.2206 ||:   5%|5         | 566/11253 [01:00<39:53,  4.47it/s]
2022-03-21 01:59:46,288 - INFO - tqdm - f1: 0.8730, accuracy: 0.9188, batch_loss: 0.2885, loss: 0.2191 ||:   6%|5         | 672/11253 [01:11<39:24,  4.47it/s]
2022-03-21 01:59:56,549 - INFO - tqdm - f1: 0.8740, accuracy: 0.9200, batch_loss: 0.1417, loss: 0.2156 ||:   7%|6         | 776/11253 [01:21<40:15,  4.34it/s]
2022-03-21 02:00:06,818 - INFO - tqdm - f1: 0.8756, accuracy: 0.9207, batch_loss: 0.0870, loss: 0.2153 ||:   8%|7         | 880/11253 [01:31<39:05,  4.42it/s]
2022-03-21 02:00:16,899 - INFO - tqdm - f1: 0.8758, accuracy: 0.9207, batch_loss: 0.4102, loss: 0.2163 ||:   9%|8         | 982/11253 [01:41<38:13,  4.48it/s]
2022-03-21 02:00:26,966 - INFO - tqdm - f1: 0.8770, accuracy: 0.9216, batch_loss: 0.1318, loss: 0.2161 ||:  10%|9         | 1084/11253 [01:51<38:20,  4.42it/s]
2022-03-21 02:00:37,357 - INFO - tqdm - f1: 0.8764, accuracy: 0.9215, batch_loss: 0.1569, loss: 0.2169 ||:  11%|#         | 1192/11253 [02:02<37:30,  4.47it/s]
2022-03-21 02:00:47,396 - INFO - tqdm - f1: 0.8767, accuracy: 0.9220, batch_loss: 0.4222, loss: 0.2158 ||:  11%|#1        | 1294/11253 [02:12<36:42,  4.52it/s]
2022-03-21 02:00:57,588 - INFO - tqdm - f1: 0.8779, accuracy: 0.9223, batch_loss: 0.0127, loss: 0.2151 ||:  12%|#2        | 1396/11253 [02:22<36:28,  4.50it/s]
2022-03-21 02:01:07,657 - INFO - tqdm - f1: 0.8782, accuracy: 0.9220, batch_loss: 0.1248, loss: 0.2162 ||:  13%|#3        | 1500/11253 [02:32<35:40,  4.56it/s]
2022-03-21 02:01:17,879 - INFO - tqdm - f1: 0.8788, accuracy: 0.9225, batch_loss: 0.0430, loss: 0.2158 ||:  14%|#4        | 1606/11253 [02:42<35:08,  4.58it/s]
2022-03-21 02:01:28,097 - INFO - tqdm - f1: 0.8780, accuracy: 0.9223, batch_loss: 0.2601, loss: 0.2156 ||:  15%|#5        | 1712/11253 [02:52<35:38,  4.46it/s]
2022-03-21 02:01:38,441 - INFO - tqdm - f1: 0.8767, accuracy: 0.9217, batch_loss: 0.1455, loss: 0.2171 ||:  16%|#6        | 1816/11253 [03:03<36:01,  4.37it/s]
2022-03-21 02:01:48,878 - INFO - tqdm - f1: 0.8764, accuracy: 0.9216, batch_loss: 0.1398, loss: 0.2174 ||:  17%|#7        | 1924/11253 [03:13<35:10,  4.42it/s]
2022-03-21 02:01:59,155 - INFO - tqdm - f1: 0.8765, accuracy: 0.9218, batch_loss: 0.1943, loss: 0.2166 ||:  18%|#8        | 2028/11253 [03:23<35:06,  4.38it/s]
2022-03-21 02:02:09,534 - INFO - tqdm - f1: 0.8773, accuracy: 0.9223, batch_loss: 0.5037, loss: 0.2160 ||:  19%|#8        | 2136/11253 [03:34<33:52,  4.49it/s]
2022-03-21 02:02:19,679 - INFO - tqdm - f1: 0.8771, accuracy: 0.9222, batch_loss: 0.5675, loss: 0.2156 ||:  20%|#9        | 2242/11253 [03:44<33:12,  4.52it/s]
2022-03-21 02:02:29,772 - INFO - tqdm - f1: 0.8766, accuracy: 0.9220, batch_loss: 0.1070, loss: 0.2154 ||:  21%|##        | 2346/11253 [03:54<26:04,  5.69it/s]
2022-03-21 02:02:39,854 - INFO - tqdm - f1: 0.8765, accuracy: 0.9219, batch_loss: 0.0811, loss: 0.2155 ||:  22%|##1       | 2448/11253 [04:04<33:00,  4.45it/s]
2022-03-21 02:02:50,041 - INFO - tqdm - f1: 0.8768, accuracy: 0.9220, batch_loss: 0.3178, loss: 0.2162 ||:  23%|##2       | 2550/11253 [04:14<32:19,  4.49it/s]
2022-03-21 02:03:00,223 - INFO - tqdm - f1: 0.8758, accuracy: 0.9218, batch_loss: 0.0750, loss: 0.2156 ||:  24%|##3       | 2656/11253 [04:25<31:33,  4.54it/s]
2022-03-21 02:03:10,398 - INFO - tqdm - f1: 0.8753, accuracy: 0.9215, batch_loss: 0.2228, loss: 0.2162 ||:  25%|##4       | 2760/11253 [04:35<31:37,  4.48it/s]
2022-03-21 02:03:20,466 - INFO - tqdm - f1: 0.8761, accuracy: 0.9220, batch_loss: 0.1391, loss: 0.2157 ||:  25%|##5       | 2862/11253 [04:45<31:26,  4.45it/s]
2022-03-21 02:03:30,632 - INFO - tqdm - f1: 0.8757, accuracy: 0.9217, batch_loss: 0.3228, loss: 0.2163 ||:  26%|##6       | 2968/11253 [04:55<31:00,  4.45it/s]
2022-03-21 02:03:40,991 - INFO - tqdm - f1: 0.8759, accuracy: 0.9218, batch_loss: 0.0807, loss: 0.2159 ||:  27%|##7       | 3072/11253 [05:05<30:52,  4.42it/s]
2022-03-21 02:03:51,305 - INFO - tqdm - f1: 0.8761, accuracy: 0.9219, batch_loss: 0.2054, loss: 0.2155 ||:  28%|##8       | 3174/11253 [05:16<30:06,  4.47it/s]
2022-03-21 02:04:01,459 - INFO - tqdm - f1: 0.8762, accuracy: 0.9219, batch_loss: 0.1404, loss: 0.2154 ||:  29%|##9       | 3276/11253 [05:26<29:38,  4.48it/s]
2022-03-21 02:04:11,870 - INFO - tqdm - f1: 0.8759, accuracy: 0.9217, batch_loss: 0.3655, loss: 0.2160 ||:  30%|###       | 3380/11253 [05:36<29:25,  4.46it/s]
2022-03-21 02:04:22,130 - INFO - tqdm - f1: 0.8762, accuracy: 0.9218, batch_loss: 0.3247, loss: 0.2161 ||:  31%|###       | 3486/11253 [05:46<28:34,  4.53it/s]
2022-03-21 02:04:32,392 - INFO - tqdm - f1: 0.8757, accuracy: 0.9215, batch_loss: 0.0955, loss: 0.2165 ||:  32%|###1      | 3592/11253 [05:57<28:21,  4.50it/s]
2022-03-21 02:04:42,582 - INFO - tqdm - f1: 0.8754, accuracy: 0.9214, batch_loss: 0.4274, loss: 0.2171 ||:  33%|###2      | 3698/11253 [06:07<28:08,  4.48it/s]
2022-03-21 02:04:52,765 - INFO - tqdm - f1: 0.8752, accuracy: 0.9212, batch_loss: 0.4031, loss: 0.2171 ||:  34%|###3      | 3806/11253 [06:17<27:40,  4.49it/s]
2022-03-21 02:05:03,000 - INFO - tqdm - f1: 0.8751, accuracy: 0.9211, batch_loss: 0.0888, loss: 0.2169 ||:  35%|###4      | 3914/11253 [06:27<27:42,  4.41it/s]
2022-03-21 02:05:13,498 - INFO - tqdm - f1: 0.8749, accuracy: 0.9211, batch_loss: 0.5773, loss: 0.2169 ||:  36%|###5      | 4026/11253 [06:38<27:00,  4.46it/s]
2022-03-21 02:05:23,539 - INFO - tqdm - f1: 0.8751, accuracy: 0.9212, batch_loss: 0.0589, loss: 0.2166 ||:  37%|###6      | 4128/11253 [06:48<26:21,  4.50it/s]
2022-03-21 02:05:33,976 - INFO - tqdm - f1: 0.8746, accuracy: 0.9210, batch_loss: 0.0773, loss: 0.2167 ||:  38%|###7      | 4236/11253 [06:58<26:07,  4.48it/s]
2022-03-21 02:05:44,269 - INFO - tqdm - f1: 0.8743, accuracy: 0.9210, batch_loss: 0.1903, loss: 0.2168 ||:  39%|###8      | 4342/11253 [07:09<25:39,  4.49it/s]
2022-03-21 02:05:54,329 - INFO - tqdm - f1: 0.8745, accuracy: 0.9210, batch_loss: 0.0237, loss: 0.2168 ||:  39%|###9      | 4444/11253 [07:19<25:38,  4.42it/s]
2022-03-21 02:06:04,761 - INFO - tqdm - f1: 0.8746, accuracy: 0.9210, batch_loss: 0.3133, loss: 0.2166 ||:  40%|####      | 4552/11253 [07:29<25:01,  4.46it/s]
2022-03-21 02:06:15,214 - INFO - tqdm - f1: 0.8745, accuracy: 0.9210, batch_loss: 0.0593, loss: 0.2167 ||:  41%|####1     | 4660/11253 [07:40<24:56,  4.41it/s]
2022-03-21 02:06:25,473 - INFO - tqdm - f1: 0.8744, accuracy: 0.9209, batch_loss: 0.1161, loss: 0.2169 ||:  42%|####2     | 4766/11253 [07:50<23:50,  4.53it/s]
2022-03-21 02:06:35,592 - INFO - tqdm - f1: 0.8746, accuracy: 0.9211, batch_loss: 0.0701, loss: 0.2165 ||:  43%|####3     | 4870/11253 [08:00<15:28,  6.87it/s]
2022-03-21 02:06:45,680 - INFO - tqdm - f1: 0.8746, accuracy: 0.9210, batch_loss: 0.1669, loss: 0.2169 ||:  44%|####4     | 4972/11253 [08:10<22:58,  4.56it/s]
2022-03-21 02:06:55,835 - INFO - tqdm - f1: 0.8743, accuracy: 0.9208, batch_loss: 0.0398, loss: 0.2166 ||:  45%|####5     | 5076/11253 [08:20<22:51,  4.50it/s]
2022-03-21 02:07:06,254 - INFO - tqdm - f1: 0.8742, accuracy: 0.9206, batch_loss: 0.1078, loss: 0.2169 ||:  46%|####6     | 5182/11253 [08:31<20:46,  4.87it/s]
2022-03-21 02:07:16,426 - INFO - tqdm - f1: 0.8743, accuracy: 0.9206, batch_loss: 0.4573, loss: 0.2170 ||:  47%|####6     | 5284/11253 [08:41<23:02,  4.32it/s]
2022-03-21 02:07:26,795 - INFO - tqdm - f1: 0.8742, accuracy: 0.9205, batch_loss: 0.2355, loss: 0.2172 ||:  48%|####7     | 5390/11253 [08:51<22:10,  4.41it/s]
2022-03-21 02:07:37,180 - INFO - tqdm - f1: 0.8741, accuracy: 0.9205, batch_loss: 0.1750, loss: 0.2174 ||:  49%|####8     | 5494/11253 [09:01<21:53,  4.38it/s]
2022-03-21 02:07:47,398 - INFO - tqdm - f1: 0.8737, accuracy: 0.9202, batch_loss: 0.0530, loss: 0.2178 ||:  50%|####9     | 5596/11253 [09:12<21:36,  4.36it/s]
2022-03-21 02:07:57,578 - INFO - tqdm - f1: 0.8733, accuracy: 0.9200, batch_loss: 0.1792, loss: 0.2184 ||:  51%|#####     | 5698/11253 [09:22<20:54,  4.43it/s]
2022-03-21 02:08:07,873 - INFO - tqdm - f1: 0.8737, accuracy: 0.9202, batch_loss: 0.1433, loss: 0.2180 ||:  52%|#####1    | 5802/11253 [09:32<20:54,  4.35it/s]
2022-03-21 02:08:17,892 - INFO - tqdm - f1: 0.8736, accuracy: 0.9201, batch_loss: 0.5857, loss: 0.2181 ||:  52%|#####2    | 5902/11253 [09:42<19:44,  4.52it/s]
2022-03-21 02:08:28,185 - INFO - tqdm - f1: 0.8733, accuracy: 0.9199, batch_loss: 0.2378, loss: 0.2184 ||:  53%|#####3    | 6004/11253 [09:52<20:12,  4.33it/s]
2022-03-21 02:08:38,568 - INFO - tqdm - f1: 0.8734, accuracy: 0.9200, batch_loss: 0.0810, loss: 0.2184 ||:  54%|#####4    | 6110/11253 [10:03<19:24,  4.42it/s]
2022-03-21 02:08:49,025 - INFO - tqdm - f1: 0.8735, accuracy: 0.9200, batch_loss: 0.0900, loss: 0.2186 ||:  55%|#####5    | 6216/11253 [10:13<19:04,  4.40it/s]
2022-03-21 02:08:59,321 - INFO - tqdm - f1: 0.8733, accuracy: 0.9199, batch_loss: 0.5359, loss: 0.2190 ||:  56%|#####6    | 6320/11253 [10:24<18:53,  4.35it/s]
2022-03-21 02:09:09,414 - INFO - tqdm - f1: 0.8734, accuracy: 0.9200, batch_loss: 0.2702, loss: 0.2188 ||:  57%|#####7    | 6422/11253 [10:34<17:40,  4.56it/s]
2022-03-21 02:09:19,579 - INFO - tqdm - f1: 0.8730, accuracy: 0.9198, batch_loss: 0.0519, loss: 0.2192 ||:  58%|#####7    | 6524/11253 [10:44<18:14,  4.32it/s]
2022-03-21 02:09:29,809 - INFO - tqdm - f1: 0.8730, accuracy: 0.9199, batch_loss: 0.0883, loss: 0.2192 ||:  59%|#####8    | 6628/11253 [10:54<15:23,  5.01it/s]
2022-03-21 02:09:40,172 - INFO - tqdm - f1: 0.8729, accuracy: 0.9199, batch_loss: 0.1714, loss: 0.2189 ||:  60%|#####9    | 6734/11253 [11:04<17:03,  4.42it/s]
2022-03-21 02:09:50,440 - INFO - tqdm - f1: 0.8728, accuracy: 0.9198, batch_loss: 0.0509, loss: 0.2190 ||:  61%|######    | 6838/11253 [11:15<16:21,  4.50it/s]
2022-03-21 02:10:00,792 - INFO - tqdm - f1: 0.8730, accuracy: 0.9199, batch_loss: 0.0569, loss: 0.2189 ||:  62%|######1   | 6946/11253 [11:25<16:03,  4.47it/s]
2022-03-21 02:10:10,849 - INFO - tqdm - f1: 0.8729, accuracy: 0.9198, batch_loss: 0.0422, loss: 0.2190 ||:  63%|######2   | 7050/11253 [11:35<15:19,  4.57it/s]
2022-03-21 02:10:21,161 - INFO - tqdm - f1: 0.8729, accuracy: 0.9198, batch_loss: 0.1407, loss: 0.2191 ||:  64%|######3   | 7156/11253 [11:45<15:05,  4.52it/s]
2022-03-21 02:10:31,219 - INFO - tqdm - f1: 0.8726, accuracy: 0.9196, batch_loss: 0.4968, loss: 0.2194 ||:  65%|######4   | 7260/11253 [11:56<14:34,  4.56it/s]
2022-03-21 02:10:41,739 - INFO - tqdm - f1: 0.8726, accuracy: 0.9196, batch_loss: 0.0227, loss: 0.2195 ||:  65%|######5   | 7368/11253 [12:06<14:35,  4.44it/s]
2022-03-21 02:10:52,085 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.0377, loss: 0.2191 ||:  66%|######6   | 7474/11253 [12:16<13:54,  4.53it/s]
2022-03-21 02:11:02,093 - INFO - tqdm - f1: 0.8726, accuracy: 0.9197, batch_loss: 0.1288, loss: 0.2191 ||:  67%|######7   | 7578/11253 [12:26<13:40,  4.48it/s]
2022-03-21 02:11:12,304 - INFO - tqdm - f1: 0.8722, accuracy: 0.9194, batch_loss: 0.3828, loss: 0.2199 ||:  68%|######8   | 7686/11253 [12:37<13:15,  4.48it/s]
2022-03-21 02:11:22,555 - INFO - tqdm - f1: 0.8720, accuracy: 0.9194, batch_loss: 0.1736, loss: 0.2199 ||:  69%|######9   | 7794/11253 [12:47<12:45,  4.52it/s]
2022-03-21 02:11:32,700 - INFO - tqdm - f1: 0.8721, accuracy: 0.9195, batch_loss: 0.2716, loss: 0.2199 ||:  70%|#######   | 7900/11253 [12:57<12:33,  4.45it/s]
2022-03-21 02:11:42,936 - INFO - tqdm - f1: 0.8720, accuracy: 0.9194, batch_loss: 0.2403, loss: 0.2204 ||:  71%|#######1  | 8006/11253 [13:07<12:24,  4.36it/s]
2022-03-21 02:11:53,346 - INFO - tqdm - f1: 0.8720, accuracy: 0.9194, batch_loss: 0.0691, loss: 0.2206 ||:  72%|#######2  | 8114/11253 [13:18<11:45,  4.45it/s]
2022-03-21 02:12:03,585 - INFO - tqdm - f1: 0.8719, accuracy: 0.9193, batch_loss: 0.1612, loss: 0.2206 ||:  73%|#######3  | 8220/11253 [13:28<11:31,  4.39it/s]
2022-03-21 02:12:13,932 - INFO - tqdm - f1: 0.8716, accuracy: 0.9192, batch_loss: 0.1613, loss: 0.2208 ||:  74%|#######4  | 8328/11253 [13:38<10:48,  4.51it/s]
2022-03-21 02:12:24,139 - INFO - tqdm - f1: 0.8716, accuracy: 0.9190, batch_loss: 0.5916, loss: 0.2213 ||:  75%|#######4  | 8432/11253 [13:48<10:22,  4.53it/s]
2022-03-21 02:12:34,664 - INFO - tqdm - f1: 0.8717, accuracy: 0.9192, batch_loss: 0.4791, loss: 0.2211 ||:  76%|#######5  | 8538/11253 [13:59<10:25,  4.34it/s]
2022-03-21 02:12:45,014 - INFO - tqdm - f1: 0.8717, accuracy: 0.9191, batch_loss: 0.2612, loss: 0.2214 ||:  77%|#######6  | 8644/11253 [14:09<10:04,  4.32it/s]
2022-03-21 02:12:55,337 - INFO - tqdm - f1: 0.8717, accuracy: 0.9191, batch_loss: 0.3116, loss: 0.2215 ||:  78%|#######7  | 8752/11253 [14:20<09:25,  4.42it/s]
2022-03-21 02:13:05,546 - INFO - tqdm - f1: 0.8716, accuracy: 0.9191, batch_loss: 0.1763, loss: 0.2216 ||:  79%|#######8  | 8858/11253 [14:30<08:45,  4.56it/s]
2022-03-21 02:13:15,818 - INFO - tqdm - f1: 0.8717, accuracy: 0.9192, batch_loss: 0.1352, loss: 0.2212 ||:  80%|#######9  | 8966/11253 [14:40<07:46,  4.91it/s]
2022-03-21 02:13:25,953 - INFO - tqdm - f1: 0.8715, accuracy: 0.9191, batch_loss: 0.4515, loss: 0.2214 ||:  81%|########  | 9070/11253 [14:50<08:03,  4.52it/s]
2022-03-21 02:13:36,265 - INFO - tqdm - f1: 0.8715, accuracy: 0.9190, batch_loss: 0.0312, loss: 0.2215 ||:  82%|########1 | 9178/11253 [15:01<07:45,  4.45it/s]
2022-03-21 02:13:46,601 - INFO - tqdm - f1: 0.8713, accuracy: 0.9188, batch_loss: 0.4221, loss: 0.2219 ||:  83%|########2 | 9286/11253 [15:11<07:22,  4.45it/s]
2022-03-21 02:13:57,073 - INFO - tqdm - f1: 0.8712, accuracy: 0.9188, batch_loss: 0.1088, loss: 0.2223 ||:  83%|########3 | 9396/11253 [15:21<06:58,  4.43it/s]
2022-03-21 02:14:07,173 - INFO - tqdm - f1: 0.8712, accuracy: 0.9187, batch_loss: 0.3289, loss: 0.2226 ||:  84%|########4 | 9502/11253 [15:31<06:32,  4.46it/s]
2022-03-21 02:14:17,875 - INFO - tqdm - f1: 0.8710, accuracy: 0.9186, batch_loss: 0.3020, loss: 0.2231 ||:  85%|########5 | 9614/11253 [15:42<06:04,  4.50it/s]
2022-03-21 02:14:28,234 - INFO - tqdm - f1: 0.8710, accuracy: 0.9186, batch_loss: 0.0147, loss: 0.2233 ||:  86%|########6 | 9718/11253 [15:53<05:44,  4.45it/s]
2022-03-21 02:14:38,420 - INFO - tqdm - f1: 0.8709, accuracy: 0.9185, batch_loss: 0.4959, loss: 0.2234 ||:  87%|########7 | 9820/11253 [16:03<05:24,  4.41it/s]
2022-03-21 02:14:48,694 - INFO - tqdm - f1: 0.8710, accuracy: 0.9186, batch_loss: 0.2348, loss: 0.2233 ||:  88%|########8 | 9924/11253 [16:13<05:03,  4.38it/s]
2022-03-21 02:14:59,241 - INFO - tqdm - f1: 0.8708, accuracy: 0.9185, batch_loss: 0.3612, loss: 0.2233 ||:  89%|########9 | 10030/11253 [16:24<04:37,  4.41it/s]
2022-03-21 02:15:09,873 - INFO - tqdm - f1: 0.8708, accuracy: 0.9185, batch_loss: 0.5468, loss: 0.2233 ||:  90%|######### | 10138/11253 [16:34<04:14,  4.38it/s]
2022-03-21 02:15:20,234 - INFO - tqdm - f1: 0.8708, accuracy: 0.9185, batch_loss: 0.4925, loss: 0.2233 ||:  91%|#########1| 10244/11253 [16:45<03:43,  4.52it/s]
2022-03-21 02:15:30,665 - INFO - tqdm - f1: 0.8709, accuracy: 0.9184, batch_loss: 0.3056, loss: 0.2232 ||:  92%|#########2| 10354/11253 [16:55<03:20,  4.49it/s]
2022-03-21 02:15:40,839 - INFO - tqdm - f1: 0.8710, accuracy: 0.9184, batch_loss: 0.4852, loss: 0.2232 ||:  93%|#########2| 10458/11253 [17:05<02:58,  4.45it/s]
2022-03-21 02:15:50,987 - INFO - tqdm - f1: 0.8710, accuracy: 0.9184, batch_loss: 0.2330, loss: 0.2231 ||:  94%|#########3| 10560/11253 [17:15<02:38,  4.38it/s]
2022-03-21 02:16:01,245 - INFO - tqdm - f1: 0.8711, accuracy: 0.9185, batch_loss: 0.3004, loss: 0.2230 ||:  95%|#########4| 10664/11253 [17:26<02:15,  4.34it/s]
2022-03-21 02:16:11,376 - INFO - tqdm - f1: 0.8710, accuracy: 0.9184, batch_loss: 0.2556, loss: 0.2231 ||:  96%|#########5| 10766/11253 [17:36<01:51,  4.37it/s]
2022-03-21 02:16:21,664 - INFO - tqdm - f1: 0.8709, accuracy: 0.9183, batch_loss: 0.5990, loss: 0.2233 ||:  97%|#########6| 10870/11253 [17:46<01:23,  4.58it/s]
2022-03-21 02:16:31,842 - INFO - tqdm - f1: 0.8709, accuracy: 0.9182, batch_loss: 0.3644, loss: 0.2237 ||:  98%|#########7| 10974/11253 [17:56<01:03,  4.39it/s]
2022-03-21 02:16:41,934 - INFO - tqdm - f1: 0.8706, accuracy: 0.9181, batch_loss: 0.1238, loss: 0.2237 ||:  98%|#########8| 11076/11253 [18:06<00:38,  4.56it/s]
2022-03-21 02:16:52,025 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.2798, loss: 0.2239 ||:  99%|#########9| 11178/11253 [18:16<00:17,  4.38it/s]
2022-03-21 02:16:53,387 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.4441, loss: 0.2240 ||: 100%|#########9| 11198/11253 [18:18<00:03, 14.02it/s]
2022-03-21 02:16:53,546 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.1082, loss: 0.2239 ||: 100%|#########9| 11200/11253 [18:18<00:03, 13.55it/s]
2022-03-21 02:16:53,699 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.0863, loss: 0.2239 ||: 100%|#########9| 11202/11253 [18:18<00:03, 13.38it/s]
2022-03-21 02:16:53,825 - INFO - tqdm - f1: 0.8706, accuracy: 0.9181, batch_loss: 0.1500, loss: 0.2239 ||: 100%|#########9| 11204/11253 [18:18<00:03, 14.04it/s]
2022-03-21 02:16:53,963 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.2531, loss: 0.2239 ||: 100%|#########9| 11206/11253 [18:18<00:03, 14.20it/s]
2022-03-21 02:16:54,099 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.2028, loss: 0.2239 ||: 100%|#########9| 11208/11253 [18:18<00:03, 14.33it/s]
2022-03-21 02:16:54,227 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.3337, loss: 0.2239 ||: 100%|#########9| 11210/11253 [18:19<00:02, 14.69it/s]
2022-03-21 02:16:55,398 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.1295, loss: 0.2239 ||: 100%|#########9| 11212/11253 [18:20<00:09,  4.48it/s]
2022-03-21 02:16:55,545 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.1536, loss: 0.2239 ||: 100%|#########9| 11214/11253 [18:20<00:06,  5.61it/s]
2022-03-21 02:16:55,690 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.1063, loss: 0.2239 ||: 100%|#########9| 11216/11253 [18:20<00:05,  6.82it/s]
2022-03-21 02:16:55,836 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.4965, loss: 0.2239 ||: 100%|#########9| 11218/11253 [18:20<00:04,  8.04it/s]
2022-03-21 02:16:55,967 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.0927, loss: 0.2239 ||: 100%|#########9| 11220/11253 [18:20<00:03,  9.36it/s]
2022-03-21 02:16:56,101 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.0053, loss: 0.2238 ||: 100%|#########9| 11222/11253 [18:20<00:02, 10.55it/s]
2022-03-21 02:16:56,232 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.3253, loss: 0.2238 ||: 100%|#########9| 11224/11253 [18:21<00:02, 11.62it/s]
2022-03-21 02:16:56,369 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.0680, loss: 0.2238 ||: 100%|#########9| 11226/11253 [18:21<00:02, 12.37it/s]
2022-03-21 02:16:56,508 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.1621, loss: 0.2239 ||: 100%|#########9| 11228/11253 [18:21<00:01, 12.93it/s]
2022-03-21 02:16:56,646 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.1618, loss: 0.2238 ||: 100%|#########9| 11230/11253 [18:21<00:01, 13.35it/s]
2022-03-21 02:16:56,793 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.2129, loss: 0.2239 ||: 100%|#########9| 11232/11253 [18:21<00:01, 13.41it/s]
2022-03-21 02:16:56,953 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.2561, loss: 0.2239 ||: 100%|#########9| 11234/11253 [18:21<00:01, 13.14it/s]
2022-03-21 02:16:57,113 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.1237, loss: 0.2239 ||: 100%|#########9| 11236/11253 [18:21<00:01, 12.93it/s]
2022-03-21 02:16:57,245 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.0720, loss: 0.2238 ||: 100%|#########9| 11238/11253 [18:22<00:01, 13.54it/s]
2022-03-21 02:16:57,389 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.0520, loss: 0.2238 ||: 100%|#########9| 11240/11253 [18:22<00:00, 13.63it/s]
2022-03-21 02:16:57,516 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.1934, loss: 0.2238 ||: 100%|#########9| 11242/11253 [18:22<00:00, 14.22it/s]
2022-03-21 02:16:58,438 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.2670, loss: 0.2239 ||: 100%|#########9| 11244/11253 [18:23<00:01,  5.33it/s]
2022-03-21 02:16:58,808 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.5332, loss: 0.2239 ||: 100%|#########9| 11246/11253 [18:23<00:01,  5.35it/s]
2022-03-21 02:16:58,956 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.6569, loss: 0.2239 ||: 100%|#########9| 11248/11253 [18:23<00:00,  6.54it/s]
2022-03-21 02:16:59,111 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.1091, loss: 0.2239 ||: 100%|#########9| 11250/11253 [18:23<00:00,  7.67it/s]
2022-03-21 02:16:59,263 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.0094, loss: 0.2239 ||: 100%|#########9| 11252/11253 [18:24<00:00,  8.78it/s]
2022-03-21 02:16:59,396 - INFO - tqdm - f1: 0.8705, accuracy: 0.9181, batch_loss: 0.2114, loss: 0.2239 ||: 100%|##########| 11253/11253 [18:24<00:00, 10.19it/s]
2022-03-21 02:16:59,404 - INFO - allennlp.training.trainer - Validating
2022-03-21 02:16:59,406 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 02:17:09,493 - INFO - tqdm - f1: 0.7996, accuracy: 0.8619, batch_loss: 1.1312, loss: 0.4395 ||:  15%|#4        | 276/1889 [00:10<01:24, 18.99it/s]
2022-03-21 02:17:19,576 - INFO - tqdm - f1: 0.8075, accuracy: 0.8690, batch_loss: 0.4680, loss: 0.4300 ||:  30%|##9       | 559/1889 [00:20<01:53, 11.70it/s]
2022-03-21 02:17:29,976 - INFO - tqdm - f1: 0.8133, accuracy: 0.8719, batch_loss: 0.1437, loss: 0.4243 ||:  45%|####4     | 848/1889 [00:30<01:27, 11.93it/s]
2022-03-21 02:17:40,404 - INFO - tqdm - f1: 0.8133, accuracy: 0.8723, batch_loss: 0.2191, loss: 0.4226 ||:  61%|######    | 1144/1889 [00:40<01:02, 11.92it/s]
2022-03-21 02:17:50,675 - INFO - tqdm - f1: 0.8133, accuracy: 0.8724, batch_loss: 0.1068, loss: 0.4244 ||:  76%|#######5  | 1435/1889 [00:51<00:38, 11.66it/s]
2022-03-21 02:18:01,112 - INFO - tqdm - f1: 0.8136, accuracy: 0.8721, batch_loss: 0.0562, loss: 0.4245 ||:  91%|#########1| 1728/1889 [01:01<00:13, 11.57it/s]
2022-03-21 02:18:05,950 - INFO - tqdm - f1: 0.8144, accuracy: 0.8725, batch_loss: 0.6288, loss: 0.4238 ||: 100%|#########9| 1881/1889 [01:06<00:00, 38.91it/s]
2022-03-21 02:18:06,076 - INFO - tqdm - f1: 0.8145, accuracy: 0.8727, batch_loss: 0.0713, loss: 0.4234 ||: 100%|#########9| 1886/1889 [01:06<00:00, 39.16it/s]
2022-03-21 02:18:06,167 - INFO - tqdm - f1: 0.8145, accuracy: 0.8726, batch_loss: 0.9473, loss: 0.4237 ||: 100%|##########| 1889/1889 [01:06<00:00, 28.30it/s]
2022-03-21 02:18:06,171 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-21 02:18:06,173 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-21 02:18:07,692 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-21 02:18:07,696 - INFO - allennlp.training.util - Iterating over dataset
2022-03-21 02:18:07,697 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-21 02:18:07,733 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 02:18:07,735 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 02:18:18,412 - INFO - tqdm - f1: 0.80, accuracy: 0.87, loss: 0.40 ||: : 292it [00:10, 11.75it/s]
2022-03-21 02:18:28,879 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.39 ||: : 585it [00:21, 11.21it/s]
2022-03-21 02:18:39,439 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.39 ||: : 879it [00:31, 11.26it/s]
2022-03-21 02:18:49,639 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.40 ||: : 1158it [00:41, 11.51it/s]
2022-03-21 02:18:59,894 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.39 ||: : 1446it [00:52, 12.24it/s]
2022-03-21 02:19:10,507 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.39 ||: : 1740it [01:02, 12.01it/s]
2022-03-21 02:19:15,261 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 2,
  "peak_worker_0_memory_MB": 8643.10546875,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "1:24:16.966233",
  "training_start_epoch": 0,
  "training_epochs": 4,
  "epoch": 4,
  "training_f1": 0.8597000360488891,
  "training_accuracy": 0.9100255498778049,
  "training_loss": 0.24815557120405293,
  "training_worker_0_memory_MB": 8643.10546875,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.817468786239624,
  "validation_accuracy": 0.876439825235006,
  "validation_loss": 0.400814842763803,
  "best_validation_f1": 0.8200812578201294,
  "best_validation_accuracy": 0.8780616973388058,
  "best_validation_loss": 0.3594020447225885,
  "test_f1": 0.8101668119430542,
  "test_accuracy": 0.8684586029533765,
  "test_loss": 0.3912964483662241
}
2022-03-21 02:19:15,443 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/rct-20k_base_hyper_small_seed_47/model.tar.gz
