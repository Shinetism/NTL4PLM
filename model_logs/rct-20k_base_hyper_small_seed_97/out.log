2022-03-21 02:20:05,869 - INFO - allennlp.common.params - random_seed = 97
2022-03-21 02:20:05,872 - INFO - allennlp.common.params - numpy_seed = 97
2022-03-21 02:20:05,874 - INFO - allennlp.common.params - pytorch_seed = 97
2022-03-21 02:20:05,881 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-21 02:20:05,884 - INFO - allennlp.common.params - type = default
2022-03-21 02:20:05,886 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-21 02:20:05,893 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 02:20:05,895 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 02:20:05,897 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 02:20:05,899 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 02:20:05,900 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 02:20:05,902 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 02:20:18,359 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 02:20:18,366 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 02:20:18,368 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 02:20:18,369 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-21 02:20:18,371 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-21 02:20:18,373 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 02:20:18,375 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-21 02:20:18,377 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-21 02:20:18,379 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-21 02:20:18,381 - INFO - allennlp.common.params - train_data_path = datasets/rct-20k/train.jsonl
2022-03-21 02:20:18,384 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f0a4c9561d0>
2022-03-21 02:20:18,385 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-21 02:20:18,387 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-21 02:20:18,389 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 02:20:18,391 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 02:20:18,393 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 02:20:18,395 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 02:20:18,396 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 02:20:18,398 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 02:20:18,401 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 02:20:18,402 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 02:20:18,404 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 02:20:18,406 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-21 02:20:18,407 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-21 02:20:18,409 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 02:20:18,412 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-21 02:20:18,415 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-21 02:20:18,416 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-21 02:20:18,418 - INFO - allennlp.common.params - validation_data_path = datasets/rct-20k/dev.jsonl
2022-03-21 02:20:18,420 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-21 02:20:18,422 - INFO - allennlp.common.params - test_data_path = datasets/rct-20k/test.jsonl
2022-03-21 02:20:18,423 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-21 02:20:18,425 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-21 02:20:18,426 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 02:20:18,428 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 02:20:18,430 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 02:20:18,432 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 02:20:18,434 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 02:20:18,435 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 02:20:18,437 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 02:20:18,439 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 02:20:18,440 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 02:20:18,442 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 02:20:18,443 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 02:20:18,445 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 02:20:18,446 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 02:20:18,448 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 02:20:18,450 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 02:20:28,515 - INFO - tqdm - loading instances: 36978it [00:10, 4338.15it/s]
2022-03-21 02:20:38,611 - INFO - tqdm - loading instances: 73641it [00:20, 4266.65it/s]
2022-03-21 02:20:48,693 - INFO - tqdm - loading instances: 109189it [00:30, 4213.42it/s]
2022-03-21 02:20:58,738 - INFO - tqdm - loading instances: 146969it [00:40, 4338.55it/s]
2022-03-21 02:21:08,010 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 02:21:08,017 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 02:21:08,019 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 02:21:08,021 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 02:21:08,023 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 02:21:08,026 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 02:21:08,028 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 02:21:08,029 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 02:21:08,031 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 02:21:08,033 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 02:21:08,034 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 02:21:08,036 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 02:21:08,037 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 02:21:08,039 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 02:21:08,041 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 02:21:17,437 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 02:21:17,444 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 02:21:17,446 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 02:21:17,448 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 02:21:17,450 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 02:21:17,452 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 02:21:17,454 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 02:21:17,455 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 02:21:17,457 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 02:21:17,459 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 02:21:17,460 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 02:21:17,465 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 02:21:17,467 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 02:21:17,469 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 02:21:17,470 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 02:21:24,513 - INFO - allennlp.common.params - type = from_instances
2022-03-21 02:21:24,520 - INFO - allennlp.common.params - min_count = None
2022-03-21 02:21:24,522 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-21 02:21:24,524 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-21 02:21:24,526 - INFO - allennlp.common.params - pretrained_files = None
2022-03-21 02:21:24,527 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-21 02:21:24,529 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-21 02:21:24,531 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-21 02:21:24,532 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-21 02:21:24,534 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-21 02:21:24,536 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-21 02:21:24,538 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-21 02:21:25,731 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-21 02:21:25,738 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-21 02:21:25,741 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-21 02:21:25,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-21 02:21:25,744 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-21 02:21:25,746 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-21 02:21:25,748 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-21 02:21:25,750 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-21 02:21:25,752 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-21 02:21:25,753 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-21 02:21:25,755 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-21 02:21:25,757 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-21 02:21:25,758 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-21 02:21:30,561 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-21 02:21:30,567 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-21 02:21:30,569 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-21 02:21:30,571 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-21 02:21:30,573 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-21 02:21:30,574 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-21 02:21:30,576 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-21 02:21:30,577 - INFO - allennlp.common.params - type = tanh
2022-03-21 02:21:30,579 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-21 02:21:30,588 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-21 02:21:30,589 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-21 02:21:30,590 - INFO - allennlp.common.params - model.num_labels = None
2022-03-21 02:21:30,592 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-21 02:21:30,593 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f0bbe433a90>
2022-03-21 02:21:30,595 - INFO - allennlp.common.params - model.regularizer = None
2022-03-21 02:21:30,596 - INFO - allennlp.common.params - model.track_weights = False
2022-03-21 02:21:30,597 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-21 02:21:30,599 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-21 02:21:30,603 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-21 02:21:30,604 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-21 02:21:30,606 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-21 02:21:30,607 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-21 02:21:30,609 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-21 02:21:30,610 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 02:21:30,611 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 02:21:30,613 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 02:21:30,614 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 02:21:30,616 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 02:21:30,617 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 02:21:30,618 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 02:21:30,620 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 02:21:30,621 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 02:21:30,623 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 02:21:30,624 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 02:21:30,626 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 02:21:30,627 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 02:21:30,629 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 02:21:30,631 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 02:21:30,632 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 02:21:30,633 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 02:21:30,635 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 02:21:30,636 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 02:21:30,637 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 02:21:30,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 02:21:30,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 02:21:30,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 02:21:30,647 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 02:21:30,648 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 02:21:30,650 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 02:21:30,651 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 02:21:30,652 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 02:21:30,654 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 02:21:30,656 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 02:21:30,657 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 02:21:30,659 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 02:21:30,660 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 02:21:30,662 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 02:21:30,664 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 02:21:30,666 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 02:21:30,667 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 02:21:30,669 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 02:21:30,671 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 02:21:30,672 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 02:21:30,674 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 02:21:30,675 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 02:21:30,676 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 02:21:30,678 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 02:21:30,679 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 02:21:30,681 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 02:21:30,682 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 02:21:30,684 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 02:21:30,685 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 02:21:30,687 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 02:21:30,688 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 02:21:30,689 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 02:21:30,691 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 02:21:30,692 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 02:21:30,694 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 02:21:30,695 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 02:21:30,697 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 02:21:30,698 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 02:21:30,700 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 02:21:30,701 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 02:21:30,703 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 02:21:30,704 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 02:21:30,706 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 02:21:30,708 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 02:21:30,711 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 02:21:30,713 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 02:21:30,714 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 02:21:30,715 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 02:21:30,717 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 02:21:30,718 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 02:21:30,720 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 02:21:30,721 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 02:21:30,722 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 02:21:30,724 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 02:21:30,726 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 02:21:30,727 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 02:21:30,729 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 02:21:30,730 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 02:21:30,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 02:21:30,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 02:21:30,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 02:21:30,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 02:21:30,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 02:21:30,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 02:21:30,741 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 02:21:30,742 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 02:21:30,744 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 02:21:30,746 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 02:21:30,748 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 02:21:30,749 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 02:21:30,750 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 02:21:30,752 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 02:21:30,753 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 02:21:30,754 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 02:21:30,756 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 02:21:30,757 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 02:21:30,759 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 02:21:30,760 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 02:21:30,765 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 02:21:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 02:21:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 02:21:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 02:21:30,771 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 02:21:30,772 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 02:21:30,774 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 02:21:30,775 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 02:21:30,777 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 02:21:30,778 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 02:21:30,780 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 02:21:30,781 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 02:21:30,783 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 02:21:30,785 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 02:21:30,789 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 02:21:30,790 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 02:21:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 02:21:30,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 02:21:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 02:21:30,799 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 02:21:30,800 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 02:21:30,802 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 02:21:30,803 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 02:21:30,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 02:21:30,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 02:21:30,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 02:21:30,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 02:21:30,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 02:21:30,812 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 02:21:30,814 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 02:21:30,815 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 02:21:30,817 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 02:21:30,818 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 02:21:30,820 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 02:21:30,821 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 02:21:30,823 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 02:21:30,824 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 02:21:30,826 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 02:21:30,828 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 02:21:30,829 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 02:21:30,831 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 02:21:30,832 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 02:21:30,834 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 02:21:30,835 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 02:21:30,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 02:21:30,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 02:21:30,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 02:21:30,841 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 02:21:30,842 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 02:21:30,844 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 02:21:30,845 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 02:21:30,847 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 02:21:30,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 02:21:30,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 02:21:30,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 02:21:30,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 02:21:30,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 02:21:30,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 02:21:30,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 02:21:30,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 02:21:30,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 02:21:30,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 02:21:30,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 02:21:30,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 02:21:30,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 02:21:30,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 02:21:30,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 02:21:30,875 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 02:21:30,876 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 02:21:30,877 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 02:21:30,881 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 02:21:30,886 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 02:21:30,887 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 02:21:30,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 02:21:30,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 02:21:30,891 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 02:21:30,893 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 02:21:30,895 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 02:21:30,896 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 02:21:30,897 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 02:21:30,902 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 02:21:30,904 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 02:21:30,905 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 02:21:30,907 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 02:21:30,908 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 02:21:30,909 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 02:21:30,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 02:21:30,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 02:21:30,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 02:21:30,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 02:21:30,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 02:21:30,918 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 02:21:30,919 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 02:21:30,920 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 02:21:30,922 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 02:21:30,923 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 02:21:30,924 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 02:21:30,925 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 02:21:30,927 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 02:21:30,928 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 02:21:30,929 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 02:21:39,519 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-21 02:21:39,526 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-21 02:21:39,528 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-21 02:21:39,529 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-21 02:21:39,531 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-21 02:21:39,532 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-21 02:21:39,534 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-21 02:21:39,536 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-21 02:21:39,537 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-21 02:21:39,539 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-21 02:21:39,540 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-21 02:21:39,542 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-21 02:21:39,544 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-21 02:21:39,545 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-21 02:21:39,547 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-21 02:21:39,549 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-21 02:21:39,550 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-21 02:21:46,611 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-21 02:21:46,618 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-21 02:21:46,620 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-21 02:21:46,622 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-21 02:21:46,624 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-21 02:21:46,626 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-21 02:21:46,630 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-21 02:21:46,632 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias'], {'weight_decay': 0}
2022-03-21 02:21:46,635 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_feedforward_layer._linear_layers.0.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight'], {}
2022-03-21 02:21:46,638 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-21 02:21:46,640 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125240069
2022-03-21 02:21:46,642 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-21 02:21:46,644 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-21 02:21:46,646 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 02:21:46,647 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 02:21:46,649 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 02:21:46,650 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 02:21:46,651 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 02:21:46,656 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 02:21:46,658 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 02:21:46,659 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 02:21:46,661 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 02:21:46,662 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 02:21:46,664 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 02:21:46,665 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 02:21:46,667 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 02:21:46,668 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 02:21:46,670 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 02:21:46,671 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 02:21:46,673 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 02:21:46,675 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 02:21:46,676 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 02:21:46,678 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 02:21:46,680 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 02:21:46,681 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 02:21:46,683 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 02:21:46,684 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 02:21:46,686 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 02:21:46,687 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 02:21:46,689 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 02:21:46,691 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 02:21:46,692 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 02:21:46,694 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 02:21:46,695 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 02:21:46,697 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 02:21:46,698 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 02:21:46,700 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 02:21:46,702 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 02:21:46,705 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 02:21:46,707 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 02:21:46,709 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 02:21:46,710 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 02:21:46,712 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 02:21:46,713 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 02:21:46,715 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 02:21:46,717 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 02:21:46,718 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 02:21:46,720 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 02:21:46,721 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 02:21:46,723 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 02:21:46,724 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 02:21:46,726 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 02:21:46,728 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 02:21:46,729 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 02:21:46,730 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 02:21:46,732 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 02:21:46,733 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 02:21:46,735 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 02:21:46,736 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 02:21:46,739 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 02:21:46,741 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 02:21:46,742 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 02:21:46,744 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 02:21:46,745 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 02:21:46,746 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 02:21:46,748 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 02:21:46,749 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 02:21:46,751 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 02:21:46,752 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 02:21:46,754 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 02:21:46,755 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 02:21:46,757 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 02:21:46,759 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 02:21:46,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 02:21:46,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 02:21:46,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 02:21:46,764 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 02:21:46,766 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 02:21:46,767 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 02:21:46,769 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 02:21:46,770 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 02:21:46,772 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 02:21:46,773 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 02:21:46,775 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 02:21:46,776 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 02:21:46,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 02:21:46,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 02:21:46,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 02:21:46,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 02:21:46,788 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 02:21:46,789 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 02:21:46,791 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 02:21:46,792 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 02:21:46,794 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 02:21:46,796 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 02:21:46,797 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 02:21:46,801 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 02:21:46,802 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 02:21:46,804 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 02:21:46,805 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 02:21:46,807 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 02:21:46,808 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 02:21:46,810 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 02:21:46,811 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 02:21:46,812 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 02:21:46,814 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 02:21:46,815 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 02:21:46,817 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 02:21:46,818 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 02:21:46,820 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 02:21:46,821 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 02:21:46,823 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 02:21:46,824 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 02:21:46,826 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 02:21:46,827 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 02:21:46,829 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 02:21:46,830 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 02:21:46,831 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 02:21:46,833 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 02:21:46,834 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 02:21:46,836 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 02:21:46,837 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 02:21:46,839 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 02:21:46,841 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 02:21:46,842 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 02:21:46,844 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 02:21:46,845 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 02:21:46,847 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 02:21:46,848 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 02:21:46,850 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 02:21:46,851 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 02:21:46,853 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 02:21:46,854 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 02:21:46,856 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 02:21:46,858 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 02:21:46,859 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 02:21:46,861 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 02:21:46,862 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 02:21:46,865 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 02:21:46,867 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 02:21:46,868 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 02:21:46,870 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 02:21:46,871 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 02:21:46,873 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 02:21:46,874 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 02:21:46,876 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 02:21:46,877 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 02:21:46,879 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 02:21:46,881 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 02:21:46,882 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 02:21:46,884 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 02:21:46,885 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 02:21:46,887 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 02:21:46,888 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 02:21:46,889 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 02:21:46,891 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 02:21:46,892 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 02:21:46,894 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 02:21:46,898 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 02:21:46,900 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 02:21:46,902 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 02:21:46,903 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 02:21:46,905 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 02:21:46,906 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 02:21:46,908 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 02:21:46,909 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 02:21:46,911 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 02:21:46,917 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 02:21:46,918 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 02:21:46,920 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 02:21:46,921 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 02:21:46,923 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 02:21:46,924 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 02:21:46,925 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 02:21:46,928 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 02:21:46,929 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 02:21:46,930 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 02:21:46,932 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 02:21:46,933 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 02:21:46,934 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 02:21:46,936 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 02:21:46,937 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 02:21:46,938 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 02:21:46,940 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 02:21:46,941 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 02:21:46,942 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 02:21:46,944 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 02:21:46,945 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 02:21:46,946 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 02:21:46,948 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 02:21:46,949 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 02:21:46,951 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 02:21:46,952 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 02:21:46,953 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 02:21:46,955 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 02:21:46,956 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 02:21:46,958 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 02:21:46,959 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 02:21:46,960 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 02:21:46,962 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 02:21:46,964 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 02:21:46,965 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 02:21:46,966 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-21 02:21:46,968 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-21 02:21:46,969 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-21 02:21:46,970 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-21 02:21:46,972 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-21 02:21:46,974 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-21 02:21:46,975 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-21 02:21:46,976 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-21 02:21:46,978 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-21 02:21:46,980 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-21 02:21:46,985 - INFO - allennlp.training.trainer - Beginning training.
2022-03-21 02:21:46,986 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-21 02:21:46,988 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.3G
2022-03-21 02:21:46,990 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 02:21:46,992 - INFO - allennlp.training.trainer - Training
2022-03-21 02:21:46,993 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 02:21:47,164 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 02:21:47,166 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 02:21:57,095 - INFO - tqdm - f1: 0.3702, accuracy: 0.5507, batch_loss: 0.3375, loss: 1.0587 ||:   1%|          | 69/11253 [00:10<34:02,  5.48it/s]
2022-03-21 02:22:07,223 - INFO - tqdm - f1: 0.5835, accuracy: 0.6817, batch_loss: 0.9144, loss: 0.7892 ||:   2%|1         | 173/11253 [00:20<32:55,  5.61it/s]
2022-03-21 02:22:17,347 - INFO - tqdm - f1: 0.6514, accuracy: 0.7301, batch_loss: 0.6255, loss: 0.6927 ||:   2%|2         | 279/11253 [00:30<26:29,  6.91it/s]
2022-03-21 02:22:27,414 - INFO - tqdm - f1: 0.6785, accuracy: 0.7531, batch_loss: 0.6245, loss: 0.6460 ||:   3%|3         | 381/11253 [00:40<26:15,  6.90it/s]
2022-03-21 02:22:37,436 - INFO - tqdm - f1: 0.6975, accuracy: 0.7724, batch_loss: 0.2486, loss: 0.6021 ||:   4%|4         | 483/11253 [00:50<31:13,  5.75it/s]
2022-03-21 02:22:47,543 - INFO - tqdm - f1: 0.7113, accuracy: 0.7821, batch_loss: 0.1039, loss: 0.5760 ||:   5%|5         | 585/11253 [01:00<40:45,  4.36it/s]
2022-03-21 02:22:57,565 - INFO - tqdm - f1: 0.7166, accuracy: 0.7868, batch_loss: 0.5839, loss: 0.5649 ||:   6%|6         | 685/11253 [01:10<40:39,  4.33it/s]
2022-03-21 02:23:07,878 - INFO - tqdm - f1: 0.7285, accuracy: 0.7939, batch_loss: 0.6687, loss: 0.5528 ||:   7%|7         | 791/11253 [01:20<39:23,  4.43it/s]
2022-03-21 02:23:18,144 - INFO - tqdm - f1: 0.7345, accuracy: 0.7984, batch_loss: 0.5274, loss: 0.5409 ||:   8%|7         | 897/11253 [01:31<38:56,  4.43it/s]
2022-03-21 02:23:28,515 - INFO - tqdm - f1: 0.7385, accuracy: 0.8025, batch_loss: 1.2552, loss: 0.5320 ||:   9%|8         | 1005/11253 [01:41<38:05,  4.48it/s]
2022-03-21 02:23:38,886 - INFO - tqdm - f1: 0.7419, accuracy: 0.8062, batch_loss: 0.4788, loss: 0.5257 ||:  10%|9         | 1113/11253 [01:51<37:40,  4.49it/s]
2022-03-21 02:23:48,919 - INFO - tqdm - f1: 0.7457, accuracy: 0.8094, batch_loss: 0.4384, loss: 0.5188 ||:  11%|#         | 1215/11253 [02:01<37:45,  4.43it/s]
2022-03-21 02:23:59,005 - INFO - tqdm - f1: 0.7467, accuracy: 0.8110, batch_loss: 0.6436, loss: 0.5144 ||:  12%|#1        | 1317/11253 [02:12<37:20,  4.43it/s]
2022-03-21 02:24:09,876 - INFO - tqdm - f1: 0.7490, accuracy: 0.8142, batch_loss: 0.9147, loss: 0.5066 ||:  13%|#2        | 1425/11253 [02:22<37:54,  4.32it/s]
2022-03-21 02:24:20,450 - INFO - tqdm - f1: 0.7503, accuracy: 0.8154, batch_loss: 0.5475, loss: 0.5042 ||:  14%|#3        | 1535/11253 [02:33<36:14,  4.47it/s]
2022-03-21 02:24:31,579 - INFO - tqdm - f1: 0.7537, accuracy: 0.8177, batch_loss: 0.5053, loss: 0.4984 ||:  15%|#4        | 1647/11253 [02:44<35:53,  4.46it/s]
2022-03-21 02:24:41,614 - INFO - tqdm - f1: 0.7553, accuracy: 0.8194, batch_loss: 0.0822, loss: 0.4941 ||:  16%|#5        | 1749/11253 [02:54<35:20,  4.48it/s]
2022-03-21 02:24:51,717 - INFO - tqdm - f1: 0.7566, accuracy: 0.8210, batch_loss: 0.4227, loss: 0.4902 ||:  16%|#6        | 1847/11253 [03:04<27:55,  5.61it/s]
2022-03-21 02:25:01,780 - INFO - tqdm - f1: 0.7597, accuracy: 0.8236, batch_loss: 0.2305, loss: 0.4853 ||:  17%|#7        | 1949/11253 [03:14<22:59,  6.75it/s]
2022-03-21 02:25:11,819 - INFO - tqdm - f1: 0.7624, accuracy: 0.8249, batch_loss: 0.3316, loss: 0.4817 ||:  18%|#8        | 2049/11253 [03:24<22:35,  6.79it/s]
2022-03-21 02:25:21,858 - INFO - tqdm - f1: 0.7637, accuracy: 0.8259, batch_loss: 0.7423, loss: 0.4784 ||:  19%|#9        | 2151/11253 [03:34<26:47,  5.66it/s]
2022-03-21 02:25:31,966 - INFO - tqdm - f1: 0.7649, accuracy: 0.8268, batch_loss: 0.3816, loss: 0.4762 ||:  20%|##        | 2255/11253 [03:44<26:48,  5.59it/s]
2022-03-21 02:25:41,981 - INFO - tqdm - f1: 0.7648, accuracy: 0.8269, batch_loss: 0.4105, loss: 0.4753 ||:  21%|##        | 2359/11253 [03:54<26:14,  5.65it/s]
2022-03-21 02:25:51,984 - INFO - tqdm - f1: 0.7651, accuracy: 0.8272, batch_loss: 0.3663, loss: 0.4743 ||:  22%|##1       | 2459/11253 [04:04<25:29,  5.75it/s]
2022-03-21 02:26:02,146 - INFO - tqdm - f1: 0.7654, accuracy: 0.8276, batch_loss: 0.5214, loss: 0.4731 ||:  23%|##2       | 2563/11253 [04:15<32:14,  4.49it/s]
2022-03-21 02:26:12,211 - INFO - tqdm - f1: 0.7670, accuracy: 0.8287, batch_loss: 0.3300, loss: 0.4709 ||:  24%|##3       | 2667/11253 [04:25<31:20,  4.57it/s]
2022-03-21 02:26:22,299 - INFO - tqdm - f1: 0.7682, accuracy: 0.8293, batch_loss: 0.2876, loss: 0.4700 ||:  25%|##4       | 2771/11253 [04:35<31:03,  4.55it/s]
2022-03-21 02:26:32,426 - INFO - tqdm - f1: 0.7682, accuracy: 0.8298, batch_loss: 0.2244, loss: 0.4683 ||:  26%|##5       | 2875/11253 [04:45<22:45,  6.14it/s]
2022-03-21 02:26:42,457 - INFO - tqdm - f1: 0.7688, accuracy: 0.8303, batch_loss: 0.3927, loss: 0.4665 ||:  26%|##6       | 2977/11253 [04:55<24:35,  5.61it/s]
2022-03-21 02:26:52,479 - INFO - tqdm - f1: 0.7691, accuracy: 0.8312, batch_loss: 0.0305, loss: 0.4639 ||:  27%|##7       | 3077/11253 [05:05<30:31,  4.46it/s]
2022-03-21 02:27:02,484 - INFO - tqdm - f1: 0.7700, accuracy: 0.8319, batch_loss: 0.1768, loss: 0.4617 ||:  28%|##8       | 3177/11253 [05:15<30:05,  4.47it/s]
2022-03-21 02:27:12,584 - INFO - tqdm - f1: 0.7704, accuracy: 0.8320, batch_loss: 0.5654, loss: 0.4612 ||:  29%|##9       | 3279/11253 [05:25<23:51,  5.57it/s]
2022-03-21 02:27:22,975 - INFO - tqdm - f1: 0.7712, accuracy: 0.8327, batch_loss: 0.3609, loss: 0.4601 ||:  30%|###       | 3385/11253 [05:35<29:34,  4.43it/s]
2022-03-21 02:27:33,081 - INFO - tqdm - f1: 0.7714, accuracy: 0.8332, batch_loss: 0.0240, loss: 0.4586 ||:  31%|###       | 3485/11253 [05:46<28:47,  4.50it/s]
2022-03-21 02:27:43,228 - INFO - tqdm - f1: 0.7720, accuracy: 0.8340, batch_loss: 0.4917, loss: 0.4560 ||:  32%|###1      | 3589/11253 [05:56<29:08,  4.38it/s]
2022-03-21 02:27:53,422 - INFO - tqdm - f1: 0.7729, accuracy: 0.8347, batch_loss: 0.6816, loss: 0.4542 ||:  33%|###2      | 3697/11253 [06:06<27:22,  4.60it/s]
2022-03-21 02:28:03,768 - INFO - tqdm - f1: 0.7737, accuracy: 0.8351, batch_loss: 0.4062, loss: 0.4530 ||:  34%|###3      | 3807/11253 [06:16<27:14,  4.55it/s]
2022-03-21 02:28:13,835 - INFO - tqdm - f1: 0.7741, accuracy: 0.8357, batch_loss: 0.4394, loss: 0.4512 ||:  35%|###4      | 3911/11253 [06:26<26:44,  4.58it/s]
2022-03-21 02:28:24,191 - INFO - tqdm - f1: 0.7748, accuracy: 0.8362, batch_loss: 0.1800, loss: 0.4502 ||:  36%|###5      | 4021/11253 [06:37<26:58,  4.47it/s]
2022-03-21 02:28:34,584 - INFO - tqdm - f1: 0.7750, accuracy: 0.8365, batch_loss: 0.8000, loss: 0.4499 ||:  37%|###6      | 4131/11253 [06:47<27:24,  4.33it/s]
2022-03-21 02:28:44,703 - INFO - tqdm - f1: 0.7752, accuracy: 0.8368, batch_loss: 0.3838, loss: 0.4490 ||:  38%|###7      | 4237/11253 [06:57<26:15,  4.45it/s]
2022-03-21 02:28:54,736 - INFO - tqdm - f1: 0.7756, accuracy: 0.8372, batch_loss: 0.5445, loss: 0.4480 ||:  39%|###8      | 4341/11253 [07:07<25:14,  4.56it/s]
2022-03-21 02:29:04,831 - INFO - tqdm - f1: 0.7759, accuracy: 0.8375, batch_loss: 0.1257, loss: 0.4472 ||:  39%|###9      | 4443/11253 [07:17<25:51,  4.39it/s]
2022-03-21 02:29:14,993 - INFO - tqdm - f1: 0.7764, accuracy: 0.8380, batch_loss: 0.1851, loss: 0.4461 ||:  40%|####      | 4547/11253 [07:27<25:26,  4.39it/s]
2022-03-21 02:29:25,304 - INFO - tqdm - f1: 0.7771, accuracy: 0.8386, batch_loss: 0.0533, loss: 0.4447 ||:  41%|####1     | 4651/11253 [07:38<24:57,  4.41it/s]
2022-03-21 02:29:35,707 - INFO - tqdm - f1: 0.7768, accuracy: 0.8385, batch_loss: 0.6544, loss: 0.4446 ||:  42%|####2     | 4757/11253 [07:48<24:45,  4.37it/s]
2022-03-21 02:29:46,040 - INFO - tqdm - f1: 0.7769, accuracy: 0.8387, batch_loss: 0.2713, loss: 0.4435 ||:  43%|####3     | 4863/11253 [07:59<23:38,  4.51it/s]
2022-03-21 02:29:56,244 - INFO - tqdm - f1: 0.7775, accuracy: 0.8393, batch_loss: 0.4523, loss: 0.4422 ||:  44%|####4     | 4967/11253 [08:09<23:26,  4.47it/s]
2022-03-21 02:30:06,471 - INFO - tqdm - f1: 0.7776, accuracy: 0.8394, batch_loss: 0.3964, loss: 0.4418 ||:  45%|####5     | 5069/11253 [08:19<23:09,  4.45it/s]
2022-03-21 02:30:16,532 - INFO - tqdm - f1: 0.7778, accuracy: 0.8396, batch_loss: 0.1598, loss: 0.4414 ||:  46%|####5     | 5171/11253 [08:29<17:58,  5.64it/s]
2022-03-21 02:30:26,809 - INFO - tqdm - f1: 0.7781, accuracy: 0.8399, batch_loss: 0.5801, loss: 0.4404 ||:  47%|####6     | 5275/11253 [08:39<22:11,  4.49it/s]
2022-03-21 02:30:37,162 - INFO - tqdm - f1: 0.7784, accuracy: 0.8405, batch_loss: 0.1595, loss: 0.4390 ||:  48%|####7     | 5381/11253 [08:50<21:56,  4.46it/s]
2022-03-21 02:30:47,219 - INFO - tqdm - f1: 0.7787, accuracy: 0.8407, batch_loss: 0.4548, loss: 0.4384 ||:  49%|####8     | 5483/11253 [09:00<21:57,  4.38it/s]
2022-03-21 02:30:57,246 - INFO - tqdm - f1: 0.7791, accuracy: 0.8411, batch_loss: 0.4552, loss: 0.4374 ||:  50%|####9     | 5585/11253 [09:10<20:57,  4.51it/s]
2022-03-21 02:31:07,361 - INFO - tqdm - f1: 0.7787, accuracy: 0.8409, batch_loss: 0.3438, loss: 0.4374 ||:  51%|#####     | 5689/11253 [09:20<20:40,  4.49it/s]
2022-03-21 02:31:17,416 - INFO - tqdm - f1: 0.7793, accuracy: 0.8416, batch_loss: 0.4500, loss: 0.4364 ||:  51%|#####1    | 5793/11253 [09:30<20:02,  4.54it/s]
2022-03-21 02:31:27,453 - INFO - tqdm - f1: 0.7793, accuracy: 0.8417, batch_loss: 0.4955, loss: 0.4357 ||:  52%|#####2    | 5895/11253 [09:40<20:17,  4.40it/s]
2022-03-21 02:31:37,642 - INFO - tqdm - f1: 0.7792, accuracy: 0.8418, batch_loss: 0.2157, loss: 0.4353 ||:  53%|#####3    | 5997/11253 [09:50<19:56,  4.39it/s]
2022-03-21 02:31:47,786 - INFO - tqdm - f1: 0.7798, accuracy: 0.8423, batch_loss: 0.7616, loss: 0.4339 ||:  54%|#####4    | 6101/11253 [10:00<19:31,  4.40it/s]
2022-03-21 02:31:58,053 - INFO - tqdm - f1: 0.7804, accuracy: 0.8425, batch_loss: 0.5255, loss: 0.4333 ||:  55%|#####5    | 6207/11253 [10:11<18:30,  4.54it/s]
2022-03-21 02:32:08,127 - INFO - tqdm - f1: 0.7804, accuracy: 0.8426, batch_loss: 0.6226, loss: 0.4332 ||:  56%|#####6    | 6311/11253 [10:21<18:09,  4.54it/s]
2022-03-21 02:32:18,235 - INFO - tqdm - f1: 0.7808, accuracy: 0.8428, batch_loss: 0.3961, loss: 0.4329 ||:  57%|#####6    | 6413/11253 [10:31<14:03,  5.74it/s]
2022-03-21 02:32:28,338 - INFO - tqdm - f1: 0.7813, accuracy: 0.8433, batch_loss: 0.2818, loss: 0.4317 ||:  58%|#####7    | 6515/11253 [10:41<17:34,  4.49it/s]
2022-03-21 02:32:38,389 - INFO - tqdm - f1: 0.7816, accuracy: 0.8437, batch_loss: 0.1461, loss: 0.4311 ||:  59%|#####8    | 6621/11253 [10:51<17:28,  4.42it/s]
2022-03-21 02:32:48,670 - INFO - tqdm - f1: 0.7820, accuracy: 0.8440, batch_loss: 0.5905, loss: 0.4303 ||:  60%|#####9    | 6729/11253 [11:01<16:31,  4.56it/s]
2022-03-21 02:32:58,980 - INFO - tqdm - f1: 0.7821, accuracy: 0.8440, batch_loss: 0.3280, loss: 0.4301 ||:  61%|######    | 6839/11253 [11:11<16:23,  4.49it/s]
2022-03-21 02:33:09,127 - INFO - tqdm - f1: 0.7824, accuracy: 0.8442, batch_loss: 0.1452, loss: 0.4299 ||:  62%|######1   | 6943/11253 [11:22<16:27,  4.37it/s]
2022-03-21 02:33:19,155 - INFO - tqdm - f1: 0.7823, accuracy: 0.8443, batch_loss: 0.5822, loss: 0.4297 ||:  63%|######2   | 7049/11253 [11:32<12:01,  5.83it/s]
2022-03-21 02:33:29,249 - INFO - tqdm - f1: 0.7823, accuracy: 0.8443, batch_loss: 0.4645, loss: 0.4297 ||:  64%|######3   | 7157/11253 [11:42<10:27,  6.53it/s]
2022-03-21 02:33:39,378 - INFO - tqdm - f1: 0.7823, accuracy: 0.8443, batch_loss: 0.4528, loss: 0.4293 ||:  65%|######4   | 7265/11253 [11:52<09:19,  7.13it/s]
2022-03-21 02:33:49,502 - INFO - tqdm - f1: 0.7825, accuracy: 0.8447, batch_loss: 0.2496, loss: 0.4282 ||:  66%|######5   | 7371/11253 [12:02<09:16,  6.98it/s]
2022-03-21 02:33:59,569 - INFO - tqdm - f1: 0.7828, accuracy: 0.8450, batch_loss: 1.2035, loss: 0.4272 ||:  66%|######6   | 7475/11253 [12:12<09:18,  6.76it/s]
2022-03-21 02:34:09,670 - INFO - tqdm - f1: 0.7829, accuracy: 0.8451, batch_loss: 0.1620, loss: 0.4266 ||:  67%|######7   | 7579/11253 [12:22<08:53,  6.89it/s]
2022-03-21 02:34:19,738 - INFO - tqdm - f1: 0.7829, accuracy: 0.8451, batch_loss: 0.2881, loss: 0.4265 ||:  68%|######8   | 7685/11253 [12:32<13:14,  4.49it/s]
2022-03-21 02:34:29,757 - INFO - tqdm - f1: 0.7833, accuracy: 0.8454, batch_loss: 0.1843, loss: 0.4260 ||:  69%|######9   | 7791/11253 [12:42<09:52,  5.84it/s]
2022-03-21 02:34:39,857 - INFO - tqdm - f1: 0.7837, accuracy: 0.8456, batch_loss: 0.2210, loss: 0.4251 ||:  70%|#######   | 7897/11253 [12:52<09:48,  5.70it/s]
2022-03-21 02:34:49,949 - INFO - tqdm - f1: 0.7839, accuracy: 0.8458, batch_loss: 0.3291, loss: 0.4248 ||:  71%|#######1  | 8001/11253 [13:02<09:26,  5.74it/s]
2022-03-21 02:35:00,079 - INFO - tqdm - f1: 0.7841, accuracy: 0.8459, batch_loss: 0.3023, loss: 0.4244 ||:  72%|#######2  | 8105/11253 [13:13<07:36,  6.90it/s]
2022-03-21 02:35:10,115 - INFO - tqdm - f1: 0.7841, accuracy: 0.8461, batch_loss: 0.4428, loss: 0.4238 ||:  73%|#######2  | 8207/11253 [13:23<07:22,  6.88it/s]
2022-03-21 02:35:20,183 - INFO - tqdm - f1: 0.7843, accuracy: 0.8462, batch_loss: 0.2339, loss: 0.4233 ||:  74%|#######3  | 8307/11253 [13:33<08:49,  5.57it/s]
2022-03-21 02:35:30,325 - INFO - tqdm - f1: 0.7847, accuracy: 0.8465, batch_loss: 0.4608, loss: 0.4225 ||:  75%|#######4  | 8411/11253 [13:43<10:47,  4.39it/s]
2022-03-21 02:35:40,373 - INFO - tqdm - f1: 0.7849, accuracy: 0.8467, batch_loss: 0.3103, loss: 0.4221 ||:  76%|#######5  | 8515/11253 [13:53<10:05,  4.52it/s]
2022-03-21 02:35:50,622 - INFO - tqdm - f1: 0.7854, accuracy: 0.8470, batch_loss: 0.3864, loss: 0.4213 ||:  77%|#######6  | 8623/11253 [14:03<09:55,  4.42it/s]
2022-03-21 02:36:00,762 - INFO - tqdm - f1: 0.7855, accuracy: 0.8472, batch_loss: 0.8569, loss: 0.4209 ||:  78%|#######7  | 8725/11253 [14:13<10:06,  4.17it/s]
2022-03-21 02:36:10,922 - INFO - tqdm - f1: 0.7856, accuracy: 0.8473, batch_loss: 0.5324, loss: 0.4203 ||:  78%|#######8  | 8831/11253 [14:23<08:51,  4.56it/s]
2022-03-21 02:36:21,222 - INFO - tqdm - f1: 0.7856, accuracy: 0.8474, batch_loss: 0.5808, loss: 0.4201 ||:  79%|#######9  | 8937/11253 [14:34<08:52,  4.35it/s]
2022-03-21 02:36:31,530 - INFO - tqdm - f1: 0.7859, accuracy: 0.8477, batch_loss: 0.1846, loss: 0.4191 ||:  80%|########  | 9043/11253 [14:44<08:08,  4.53it/s]
2022-03-21 02:36:42,051 - INFO - tqdm - f1: 0.7862, accuracy: 0.8479, batch_loss: 0.1399, loss: 0.4189 ||:  81%|########1 | 9155/11253 [14:55<06:58,  5.02it/s]
2022-03-21 02:36:52,525 - INFO - tqdm - f1: 0.7866, accuracy: 0.8480, batch_loss: 0.5481, loss: 0.4186 ||:  82%|########2 | 9267/11253 [15:05<07:28,  4.43it/s]
2022-03-21 02:37:02,720 - INFO - tqdm - f1: 0.7867, accuracy: 0.8482, batch_loss: 0.0735, loss: 0.4181 ||:  83%|########3 | 9375/11253 [15:15<06:48,  4.60it/s]
2022-03-21 02:37:12,735 - INFO - tqdm - f1: 0.7866, accuracy: 0.8481, batch_loss: 0.2811, loss: 0.4182 ||:  84%|########4 | 9481/11253 [15:25<05:06,  5.78it/s]
2022-03-21 02:37:22,782 - INFO - tqdm - f1: 0.7868, accuracy: 0.8484, batch_loss: 0.4936, loss: 0.4175 ||:  85%|########5 | 9587/11253 [15:35<04:45,  5.84it/s]
2022-03-21 02:37:32,818 - INFO - tqdm - f1: 0.7871, accuracy: 0.8486, batch_loss: 0.2555, loss: 0.4169 ||:  86%|########6 | 9691/11253 [15:45<05:49,  4.46it/s]
2022-03-21 02:37:42,948 - INFO - tqdm - f1: 0.7875, accuracy: 0.8490, batch_loss: 0.3953, loss: 0.4163 ||:  87%|########7 | 9795/11253 [15:55<05:29,  4.42it/s]
2022-03-21 02:37:53,045 - INFO - tqdm - f1: 0.7877, accuracy: 0.8491, batch_loss: 0.5190, loss: 0.4160 ||:  88%|########7 | 9901/11253 [16:06<05:04,  4.44it/s]
2022-03-21 02:38:03,280 - INFO - tqdm - f1: 0.7878, accuracy: 0.8492, batch_loss: 0.2947, loss: 0.4155 ||:  89%|########8 | 10009/11253 [16:16<04:40,  4.44it/s]
2022-03-21 02:38:13,378 - INFO - tqdm - f1: 0.7880, accuracy: 0.8493, batch_loss: 0.2027, loss: 0.4153 ||:  90%|########9 | 10117/11253 [16:26<04:15,  4.45it/s]
2022-03-21 02:38:23,507 - INFO - tqdm - f1: 0.7884, accuracy: 0.8496, batch_loss: 0.0275, loss: 0.4149 ||:  91%|######### | 10225/11253 [16:36<02:58,  5.74it/s]
2022-03-21 02:38:33,787 - INFO - tqdm - f1: 0.7886, accuracy: 0.8498, batch_loss: 0.3102, loss: 0.4143 ||:  92%|#########1| 10335/11253 [16:46<03:26,  4.44it/s]
2022-03-21 02:38:43,820 - INFO - tqdm - f1: 0.7886, accuracy: 0.8499, batch_loss: 0.5338, loss: 0.4140 ||:  93%|#########2| 10441/11253 [16:56<02:58,  4.55it/s]
2022-03-21 02:38:54,303 - INFO - tqdm - f1: 0.7886, accuracy: 0.8499, batch_loss: 0.8371, loss: 0.4135 ||:  94%|#########3| 10551/11253 [17:07<02:38,  4.42it/s]
2022-03-21 02:39:04,649 - INFO - tqdm - f1: 0.7888, accuracy: 0.8502, batch_loss: 0.5509, loss: 0.4129 ||:  95%|#########4| 10661/11253 [17:17<02:12,  4.47it/s]
2022-03-21 02:39:14,787 - INFO - tqdm - f1: 0.7891, accuracy: 0.8505, batch_loss: 0.0890, loss: 0.4121 ||:  96%|#########5| 10767/11253 [17:27<01:47,  4.54it/s]
2022-03-21 02:39:25,151 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.4167, loss: 0.4115 ||:  97%|#########6| 10875/11253 [17:38<01:26,  4.39it/s]
2022-03-21 02:39:35,591 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.4796, loss: 0.4114 ||:  98%|#########7| 10985/11253 [17:48<00:59,  4.48it/s]
2022-03-21 02:39:45,633 - INFO - tqdm - f1: 0.7893, accuracy: 0.8508, batch_loss: 0.6689, loss: 0.4115 ||:  99%|#########8| 11089/11253 [17:58<00:36,  4.48it/s]
2022-03-21 02:39:55,782 - INFO - tqdm - f1: 0.7894, accuracy: 0.8509, batch_loss: 0.2976, loss: 0.4111 ||:  99%|#########9| 11193/11253 [18:08<00:13,  4.38it/s]
2022-03-21 02:39:56,063 - INFO - tqdm - f1: 0.7894, accuracy: 0.8509, batch_loss: 0.0883, loss: 0.4110 ||: 100%|#########9| 11197/11253 [18:09<00:08,  6.78it/s]
2022-03-21 02:39:56,203 - INFO - tqdm - f1: 0.7895, accuracy: 0.8510, batch_loss: 0.3141, loss: 0.4110 ||: 100%|#########9| 11199/11253 [18:09<00:06,  8.06it/s]
2022-03-21 02:39:56,347 - INFO - tqdm - f1: 0.7895, accuracy: 0.8510, batch_loss: 0.5047, loss: 0.4110 ||: 100%|#########9| 11201/11253 [18:09<00:05,  9.22it/s]
2022-03-21 02:39:56,488 - INFO - tqdm - f1: 0.7895, accuracy: 0.8510, batch_loss: 0.0070, loss: 0.4110 ||: 100%|#########9| 11203/11253 [18:09<00:04, 10.29it/s]
2022-03-21 02:39:56,625 - INFO - tqdm - f1: 0.7895, accuracy: 0.8510, batch_loss: 0.7097, loss: 0.4110 ||: 100%|#########9| 11205/11253 [18:09<00:04, 11.29it/s]
2022-03-21 02:39:56,766 - INFO - tqdm - f1: 0.7895, accuracy: 0.8510, batch_loss: 0.4656, loss: 0.4110 ||: 100%|#########9| 11207/11253 [18:09<00:03, 12.04it/s]
2022-03-21 02:39:56,891 - INFO - tqdm - f1: 0.7895, accuracy: 0.8510, batch_loss: 0.5349, loss: 0.4110 ||: 100%|#########9| 11209/11253 [18:09<00:03, 12.99it/s]
2022-03-21 02:39:57,028 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.1503, loss: 0.4109 ||: 100%|#########9| 11211/11253 [18:10<00:03, 13.44it/s]
2022-03-21 02:39:57,187 - INFO - tqdm - f1: 0.7895, accuracy: 0.8510, batch_loss: 0.7093, loss: 0.4109 ||: 100%|#########9| 11213/11253 [18:10<00:03, 13.17it/s]
2022-03-21 02:39:57,328 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.2522, loss: 0.4109 ||: 100%|#########9| 11215/11253 [18:10<00:02, 13.47it/s]
2022-03-21 02:39:57,472 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.4366, loss: 0.4109 ||: 100%|#########9| 11217/11253 [18:10<00:02, 13.57it/s]
2022-03-21 02:39:57,618 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.6623, loss: 0.4109 ||: 100%|#########9| 11219/11253 [18:10<00:02, 13.63it/s]
2022-03-21 02:39:57,751 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.1085, loss: 0.4109 ||: 100%|#########9| 11221/11253 [18:10<00:02, 14.01it/s]
2022-03-21 02:39:57,873 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.0143, loss: 0.4109 ||: 100%|#########9| 11223/11253 [18:10<00:02, 14.65it/s]
2022-03-21 02:39:57,997 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.2029, loss: 0.4109 ||: 100%|#########9| 11225/11253 [18:11<00:01, 15.06it/s]
2022-03-21 02:39:59,167 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.4510, loss: 0.4110 ||: 100%|#########9| 11227/11253 [18:12<00:05,  4.51it/s]
2022-03-21 02:39:59,305 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.2319, loss: 0.4109 ||: 100%|#########9| 11229/11253 [18:12<00:04,  5.68it/s]
2022-03-21 02:39:59,449 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.5623, loss: 0.4109 ||: 100%|#########9| 11231/11253 [18:12<00:03,  6.90it/s]
2022-03-21 02:39:59,591 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.1156, loss: 0.4109 ||: 100%|#########9| 11233/11253 [18:12<00:02,  8.15it/s]
2022-03-21 02:39:59,723 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.3177, loss: 0.4109 ||: 100%|#########9| 11235/11253 [18:12<00:01,  9.46it/s]
2022-03-21 02:39:59,861 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.1956, loss: 0.4109 ||: 100%|#########9| 11237/11253 [18:12<00:01, 10.56it/s]
2022-03-21 02:39:59,992 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.2743, loss: 0.4109 ||: 100%|#########9| 11239/11253 [18:12<00:01, 11.65it/s]
2022-03-21 02:40:00,126 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.3015, loss: 0.4109 ||: 100%|#########9| 11241/11253 [18:13<00:00, 12.47it/s]
2022-03-21 02:40:00,260 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.6586, loss: 0.4109 ||: 100%|#########9| 11243/11253 [18:13<00:00, 13.11it/s]
2022-03-21 02:40:00,390 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.4156, loss: 0.4109 ||: 100%|#########9| 11245/11253 [18:13<00:00, 13.71it/s]
2022-03-21 02:40:00,533 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.2131, loss: 0.4109 ||: 100%|#########9| 11247/11253 [18:13<00:00, 13.80it/s]
2022-03-21 02:40:00,687 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.9873, loss: 0.4109 ||: 100%|#########9| 11249/11253 [18:13<00:00, 13.54it/s]
2022-03-21 02:40:00,841 - INFO - tqdm - f1: 0.7896, accuracy: 0.8510, batch_loss: 0.7616, loss: 0.4109 ||: 100%|#########9| 11251/11253 [18:13<00:00, 13.38it/s]
2022-03-21 02:40:00,979 - INFO - tqdm - f1: 0.7897, accuracy: 0.8510, batch_loss: 0.1306, loss: 0.4109 ||: 100%|##########| 11253/11253 [18:13<00:00, 13.69it/s]
2022-03-21 02:40:01,041 - INFO - tqdm - f1: 0.7897, accuracy: 0.8510, batch_loss: 0.1306, loss: 0.4109 ||: 100%|##########| 11253/11253 [18:14<00:00, 10.29it/s]
2022-03-21 02:40:01,048 - INFO - allennlp.training.trainer - Validating
2022-03-21 02:40:01,052 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 02:40:01,085 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 02:40:01,087 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 02:40:11,129 - INFO - tqdm - f1: 0.8293, accuracy: 0.8795, batch_loss: 0.1027, loss: 0.3442 ||:  15%|#4        | 275/1889 [00:10<00:42, 38.08it/s]
2022-03-21 02:40:21,140 - INFO - tqdm - f1: 0.8204, accuracy: 0.8763, batch_loss: 0.8958, loss: 0.3516 ||:  30%|##9       | 563/1889 [00:20<00:33, 40.11it/s]
2022-03-21 02:40:31,221 - INFO - tqdm - f1: 0.8181, accuracy: 0.8742, batch_loss: 0.7513, loss: 0.3536 ||:  45%|####4     | 847/1889 [00:30<00:28, 36.23it/s]
2022-03-21 02:40:41,322 - INFO - tqdm - f1: 0.8155, accuracy: 0.8726, batch_loss: 0.4030, loss: 0.3579 ||:  60%|######    | 1136/1889 [00:40<00:18, 40.08it/s]
2022-03-21 02:40:51,323 - INFO - tqdm - f1: 0.8194, accuracy: 0.8756, batch_loss: 0.1426, loss: 0.3492 ||:  75%|#######4  | 1416/1889 [00:50<00:11, 41.64it/s]
2022-03-21 02:41:01,346 - INFO - tqdm - f1: 0.8179, accuracy: 0.8746, batch_loss: 0.2991, loss: 0.3521 ||:  89%|########9 | 1690/1889 [01:00<00:07, 26.97it/s]
2022-03-21 02:41:08,090 - INFO - tqdm - f1: 0.8179, accuracy: 0.8748, batch_loss: 0.4059, loss: 0.3500 ||: 100%|#########9| 1881/1889 [01:07<00:00, 26.26it/s]
2022-03-21 02:41:08,209 - INFO - tqdm - f1: 0.8178, accuracy: 0.8747, batch_loss: 0.2427, loss: 0.3500 ||: 100%|#########9| 1886/1889 [01:07<00:00, 29.88it/s]
2022-03-21 02:41:08,279 - INFO - tqdm - f1: 0.8177, accuracy: 0.8748, batch_loss: 0.1517, loss: 0.3497 ||: 100%|##########| 1889/1889 [01:07<00:00, 28.10it/s]
2022-03-21 02:41:08,295 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct-20k_base_hyper_small_seed_97/best.th'.
2022-03-21 02:41:10,476 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 02:41:10,479 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.851  |     0.875
2022-03-21 02:41:10,480 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.790  |     0.818
2022-03-21 02:41:10,482 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 02:41:10,483 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.411  |     0.350
2022-03-21 02:41:10,485 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8462.121  |       N/A
2022-03-21 02:41:10,486 - INFO - allennlp.training.trainer - Epoch duration: 0:19:23.499989
2022-03-21 02:41:10,489 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:54:31
2022-03-21 02:41:10,490 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-21 02:41:10,492 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 02:41:10,494 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 02:41:10,497 - INFO - allennlp.training.trainer - Training
2022-03-21 02:41:10,499 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 02:41:21,224 - INFO - tqdm - f1: 0.8047, accuracy: 0.8688, batch_loss: 0.1833, loss: 0.3537 ||:   1%|          | 101/11253 [00:10<41:52,  4.44it/s]
2022-03-21 02:41:31,404 - INFO - tqdm - f1: 0.8002, accuracy: 0.8621, batch_loss: 0.2759, loss: 0.3669 ||:   2%|1         | 209/11253 [00:20<40:58,  4.49it/s]
2022-03-21 02:41:41,727 - INFO - tqdm - f1: 0.8004, accuracy: 0.8659, batch_loss: 0.2605, loss: 0.3568 ||:   3%|2         | 315/11253 [00:31<41:49,  4.36it/s]
2022-03-21 02:41:52,151 - INFO - tqdm - f1: 0.8015, accuracy: 0.8664, batch_loss: 0.6920, loss: 0.3540 ||:   4%|3         | 423/11253 [00:41<41:45,  4.32it/s]
2022-03-21 02:42:02,311 - INFO - tqdm - f1: 0.8075, accuracy: 0.8705, batch_loss: 0.7110, loss: 0.3455 ||:   5%|4         | 527/11253 [00:51<40:02,  4.47it/s]
2022-03-21 02:42:12,586 - INFO - tqdm - f1: 0.8094, accuracy: 0.8728, batch_loss: 0.1462, loss: 0.3424 ||:   6%|5         | 633/11253 [01:02<39:59,  4.43it/s]
2022-03-21 02:42:22,780 - INFO - tqdm - f1: 0.8102, accuracy: 0.8733, batch_loss: 0.2413, loss: 0.3453 ||:   7%|6         | 737/11253 [01:12<39:57,  4.39it/s]
2022-03-21 02:42:32,868 - INFO - tqdm - f1: 0.8116, accuracy: 0.8736, batch_loss: 0.3630, loss: 0.3432 ||:   7%|7         | 839/11253 [01:22<38:33,  4.50it/s]
2022-03-21 02:42:43,049 - INFO - tqdm - f1: 0.8105, accuracy: 0.8732, batch_loss: 0.2432, loss: 0.3419 ||:   8%|8         | 943/11253 [01:32<38:15,  4.49it/s]
2022-03-21 02:42:53,482 - INFO - tqdm - f1: 0.8130, accuracy: 0.8739, batch_loss: 0.2132, loss: 0.3416 ||:   9%|9         | 1051/11253 [01:42<37:52,  4.49it/s]
2022-03-21 02:43:03,859 - INFO - tqdm - f1: 0.8148, accuracy: 0.8738, batch_loss: 0.1642, loss: 0.3441 ||:  10%|#         | 1159/11253 [01:53<37:39,  4.47it/s]
2022-03-21 02:43:13,919 - INFO - tqdm - f1: 0.8135, accuracy: 0.8731, batch_loss: 0.2196, loss: 0.3458 ||:  11%|#1        | 1263/11253 [02:03<37:15,  4.47it/s]
2022-03-21 02:43:24,213 - INFO - tqdm - f1: 0.8153, accuracy: 0.8740, batch_loss: 0.1743, loss: 0.3459 ||:  12%|#2        | 1369/11253 [02:13<36:16,  4.54it/s]
2022-03-21 02:43:34,254 - INFO - tqdm - f1: 0.8153, accuracy: 0.8741, batch_loss: 0.4611, loss: 0.3442 ||:  13%|#3        | 1471/11253 [02:23<28:35,  5.70it/s]
2022-03-21 02:43:44,376 - INFO - tqdm - f1: 0.8149, accuracy: 0.8738, batch_loss: 0.3031, loss: 0.3453 ||:  14%|#4        | 1577/11253 [02:33<35:22,  4.56it/s]
2022-03-21 02:43:54,758 - INFO - tqdm - f1: 0.8156, accuracy: 0.8744, batch_loss: 0.0426, loss: 0.3445 ||:  15%|#4        | 1685/11253 [02:44<36:19,  4.39it/s]
2022-03-21 02:44:05,107 - INFO - tqdm - f1: 0.8161, accuracy: 0.8743, batch_loss: 0.5580, loss: 0.3449 ||:  16%|#5        | 1793/11253 [02:54<35:30,  4.44it/s]
2022-03-21 02:44:15,419 - INFO - tqdm - f1: 0.8157, accuracy: 0.8738, batch_loss: 0.3499, loss: 0.3463 ||:  17%|#6        | 1901/11253 [03:04<35:24,  4.40it/s]
2022-03-21 02:44:25,643 - INFO - tqdm - f1: 0.8156, accuracy: 0.8738, batch_loss: 0.4332, loss: 0.3458 ||:  18%|#7        | 2005/11253 [03:15<34:48,  4.43it/s]
2022-03-21 02:44:35,694 - INFO - tqdm - f1: 0.8160, accuracy: 0.8742, batch_loss: 0.2319, loss: 0.3460 ||:  19%|#8        | 2107/11253 [03:25<33:54,  4.49it/s]
2022-03-21 02:44:45,714 - INFO - tqdm - f1: 0.8160, accuracy: 0.8745, batch_loss: 0.2553, loss: 0.3454 ||:  20%|#9        | 2209/11253 [03:35<34:23,  4.38it/s]
2022-03-21 02:44:55,986 - INFO - tqdm - f1: 0.8165, accuracy: 0.8745, batch_loss: 0.3457, loss: 0.3456 ||:  21%|##        | 2315/11253 [03:45<33:44,  4.42it/s]
2022-03-21 02:45:06,303 - INFO - tqdm - f1: 0.8165, accuracy: 0.8745, batch_loss: 0.2811, loss: 0.3454 ||:  22%|##1       | 2421/11253 [03:55<32:43,  4.50it/s]
2022-03-21 02:45:16,491 - INFO - tqdm - f1: 0.8166, accuracy: 0.8747, batch_loss: 0.3092, loss: 0.3449 ||:  22%|##2       | 2523/11253 [04:05<32:16,  4.51it/s]
2022-03-21 02:45:26,795 - INFO - tqdm - f1: 0.8171, accuracy: 0.8746, batch_loss: 0.3565, loss: 0.3448 ||:  23%|##3       | 2627/11253 [04:16<32:06,  4.48it/s]
2022-03-21 02:45:36,926 - INFO - tqdm - f1: 0.8174, accuracy: 0.8748, batch_loss: 0.0288, loss: 0.3448 ||:  24%|##4       | 2729/11253 [04:26<31:55,  4.45it/s]
2022-03-21 02:45:47,340 - INFO - tqdm - f1: 0.8184, accuracy: 0.8755, batch_loss: 0.2313, loss: 0.3437 ||:  25%|##5       | 2837/11253 [04:36<31:18,  4.48it/s]
2022-03-21 02:45:57,737 - INFO - tqdm - f1: 0.8185, accuracy: 0.8755, batch_loss: 0.3887, loss: 0.3443 ||:  26%|##6       | 2943/11253 [04:47<31:22,  4.42it/s]
2022-03-21 02:46:07,785 - INFO - tqdm - f1: 0.8185, accuracy: 0.8756, batch_loss: 0.1174, loss: 0.3438 ||:  27%|##7       | 3045/11253 [04:57<30:43,  4.45it/s]
2022-03-21 02:46:18,007 - INFO - tqdm - f1: 0.8187, accuracy: 0.8757, batch_loss: 0.3241, loss: 0.3436 ||:  28%|##7       | 3149/11253 [05:07<30:26,  4.44it/s]
2022-03-21 02:46:28,279 - INFO - tqdm - f1: 0.8188, accuracy: 0.8755, batch_loss: 0.5199, loss: 0.3444 ||:  29%|##8       | 3253/11253 [05:17<29:34,  4.51it/s]
2022-03-21 02:46:38,443 - INFO - tqdm - f1: 0.8185, accuracy: 0.8753, batch_loss: 0.3268, loss: 0.3445 ||:  30%|##9       | 3355/11253 [05:27<30:10,  4.36it/s]
2022-03-21 02:46:48,589 - INFO - tqdm - f1: 0.8188, accuracy: 0.8755, batch_loss: 0.1194, loss: 0.3440 ||:  31%|###       | 3457/11253 [05:38<29:11,  4.45it/s]
2022-03-21 02:46:58,687 - INFO - tqdm - f1: 0.8182, accuracy: 0.8752, batch_loss: 0.4941, loss: 0.3446 ||:  32%|###1      | 3559/11253 [05:48<28:42,  4.47it/s]
2022-03-21 02:47:08,809 - INFO - tqdm - f1: 0.8186, accuracy: 0.8753, batch_loss: 0.8298, loss: 0.3447 ||:  33%|###2      | 3661/11253 [05:58<28:23,  4.46it/s]
2022-03-21 02:47:18,982 - INFO - tqdm - f1: 0.8191, accuracy: 0.8755, batch_loss: 0.1577, loss: 0.3446 ||:  33%|###3      | 3765/11253 [06:08<27:39,  4.51it/s]
2022-03-21 02:47:29,214 - INFO - tqdm - f1: 0.8191, accuracy: 0.8755, batch_loss: 0.0460, loss: 0.3447 ||:  34%|###4      | 3869/11253 [06:18<27:19,  4.50it/s]
2022-03-21 02:47:39,548 - INFO - tqdm - f1: 0.8194, accuracy: 0.8757, batch_loss: 0.1569, loss: 0.3443 ||:  35%|###5      | 3975/11253 [06:29<27:05,  4.48it/s]
2022-03-21 02:47:49,861 - INFO - tqdm - f1: 0.8196, accuracy: 0.8756, batch_loss: 0.4186, loss: 0.3448 ||:  36%|###6      | 4081/11253 [06:39<26:59,  4.43it/s]
2022-03-21 02:48:00,118 - INFO - tqdm - f1: 0.8188, accuracy: 0.8752, batch_loss: 0.1263, loss: 0.3457 ||:  37%|###7      | 4187/11253 [06:49<26:49,  4.39it/s]
2022-03-21 02:48:10,465 - INFO - tqdm - f1: 0.8189, accuracy: 0.8751, batch_loss: 0.2657, loss: 0.3459 ||:  38%|###8      | 4295/11253 [06:59<26:23,  4.39it/s]
2022-03-21 02:48:20,679 - INFO - tqdm - f1: 0.8187, accuracy: 0.8750, batch_loss: 0.6404, loss: 0.3457 ||:  39%|###9      | 4399/11253 [07:10<25:15,  4.52it/s]
2022-03-21 02:48:30,831 - INFO - tqdm - f1: 0.8187, accuracy: 0.8749, batch_loss: 0.2837, loss: 0.3459 ||:  40%|###9      | 4501/11253 [07:20<25:49,  4.36it/s]
2022-03-21 02:48:40,889 - INFO - tqdm - f1: 0.8185, accuracy: 0.8748, batch_loss: 0.7362, loss: 0.3460 ||:  41%|####      | 4603/11253 [07:30<25:01,  4.43it/s]
2022-03-21 02:48:51,278 - INFO - tqdm - f1: 0.8184, accuracy: 0.8748, batch_loss: 0.0855, loss: 0.3459 ||:  42%|####1     | 4707/11253 [07:40<24:59,  4.37it/s]
2022-03-21 02:49:01,578 - INFO - tqdm - f1: 0.8180, accuracy: 0.8746, batch_loss: 0.1732, loss: 0.3462 ||:  43%|####2     | 4813/11253 [07:51<24:01,  4.47it/s]
2022-03-21 02:49:11,758 - INFO - tqdm - f1: 0.8180, accuracy: 0.8747, batch_loss: 0.1089, loss: 0.3461 ||:  44%|####3     | 4917/11253 [08:01<23:23,  4.51it/s]
2022-03-21 02:49:22,189 - INFO - tqdm - f1: 0.8183, accuracy: 0.8750, batch_loss: 0.0359, loss: 0.3457 ||:  45%|####4     | 5027/11253 [08:11<23:30,  4.42it/s]
2022-03-21 02:49:32,263 - INFO - tqdm - f1: 0.8182, accuracy: 0.8749, batch_loss: 0.2620, loss: 0.3457 ||:  46%|####5     | 5129/11253 [08:21<23:09,  4.41it/s]
2022-03-21 02:49:42,444 - INFO - tqdm - f1: 0.8178, accuracy: 0.8747, batch_loss: 0.2044, loss: 0.3460 ||:  47%|####6     | 5233/11253 [08:31<22:43,  4.41it/s]
2022-03-21 02:49:52,543 - INFO - tqdm - f1: 0.8182, accuracy: 0.8748, batch_loss: 0.2872, loss: 0.3461 ||:  47%|####7     | 5337/11253 [08:42<22:26,  4.39it/s]
2022-03-21 02:50:02,906 - INFO - tqdm - f1: 0.8185, accuracy: 0.8749, batch_loss: 0.1909, loss: 0.3464 ||:  48%|####8     | 5443/11253 [08:52<21:47,  4.44it/s]
2022-03-21 02:50:12,943 - INFO - tqdm - f1: 0.8183, accuracy: 0.8749, batch_loss: 0.1258, loss: 0.3467 ||:  49%|####9     | 5545/11253 [09:02<21:41,  4.38it/s]
2022-03-21 02:50:23,046 - INFO - tqdm - f1: 0.8185, accuracy: 0.8751, batch_loss: 0.1002, loss: 0.3465 ||:  50%|#####     | 5645/11253 [09:12<20:50,  4.48it/s]
2022-03-21 02:50:33,430 - INFO - tqdm - f1: 0.8183, accuracy: 0.8751, batch_loss: 0.4266, loss: 0.3466 ||:  51%|#####1    | 5751/11253 [09:22<20:51,  4.40it/s]
2022-03-21 02:50:43,475 - INFO - tqdm - f1: 0.8180, accuracy: 0.8748, batch_loss: 0.4478, loss: 0.3467 ||:  52%|#####1    | 5851/11253 [09:32<20:07,  4.47it/s]
2022-03-21 02:50:53,915 - INFO - tqdm - f1: 0.8180, accuracy: 0.8748, batch_loss: 0.2375, loss: 0.3469 ||:  53%|#####2    | 5957/11253 [09:43<17:52,  4.94it/s]
2022-03-21 02:51:04,005 - INFO - tqdm - f1: 0.8180, accuracy: 0.8748, batch_loss: 0.1289, loss: 0.3469 ||:  54%|#####3    | 6059/11253 [09:53<19:15,  4.50it/s]
2022-03-21 02:51:14,243 - INFO - tqdm - f1: 0.8179, accuracy: 0.8748, batch_loss: 0.6761, loss: 0.3471 ||:  55%|#####4    | 6163/11253 [10:03<19:06,  4.44it/s]
2022-03-21 02:51:24,265 - INFO - tqdm - f1: 0.8180, accuracy: 0.8750, batch_loss: 0.2317, loss: 0.3465 ||:  56%|#####5    | 6263/11253 [10:13<14:56,  5.57it/s]
2022-03-21 02:51:34,638 - INFO - tqdm - f1: 0.8177, accuracy: 0.8748, batch_loss: 0.5271, loss: 0.3466 ||:  57%|#####6    | 6367/11253 [10:24<18:19,  4.44it/s]
2022-03-21 02:51:44,946 - INFO - tqdm - f1: 0.8180, accuracy: 0.8749, batch_loss: 0.3273, loss: 0.3466 ||:  58%|#####7    | 6471/11253 [10:34<18:02,  4.42it/s]
2022-03-21 02:51:55,195 - INFO - tqdm - f1: 0.8180, accuracy: 0.8749, batch_loss: 0.2330, loss: 0.3467 ||:  58%|#####8    | 6575/11253 [10:44<17:41,  4.41it/s]
2022-03-21 02:52:05,514 - INFO - tqdm - f1: 0.8180, accuracy: 0.8749, batch_loss: 0.2718, loss: 0.3467 ||:  59%|#####9    | 6681/11253 [10:55<17:07,  4.45it/s]
2022-03-21 02:52:15,984 - INFO - tqdm - f1: 0.8176, accuracy: 0.8748, batch_loss: 0.0837, loss: 0.3466 ||:  60%|######    | 6789/11253 [11:05<16:36,  4.48it/s]
2022-03-21 02:52:26,090 - INFO - tqdm - f1: 0.8176, accuracy: 0.8750, batch_loss: 0.1101, loss: 0.3462 ||:  61%|######1   | 6893/11253 [11:15<16:31,  4.40it/s]
2022-03-21 02:52:36,148 - INFO - tqdm - f1: 0.8179, accuracy: 0.8752, batch_loss: 0.2691, loss: 0.3457 ||:  62%|######2   | 6997/11253 [11:25<15:57,  4.45it/s]
2022-03-21 02:52:46,474 - INFO - tqdm - f1: 0.8176, accuracy: 0.8751, batch_loss: 0.2950, loss: 0.3454 ||:  63%|######3   | 7105/11253 [11:35<15:15,  4.53it/s]
2022-03-21 02:52:56,633 - INFO - tqdm - f1: 0.8174, accuracy: 0.8750, batch_loss: 0.2314, loss: 0.3456 ||:  64%|######4   | 7209/11253 [11:46<15:24,  4.37it/s]
2022-03-21 02:53:06,800 - INFO - tqdm - f1: 0.8175, accuracy: 0.8751, batch_loss: 0.0521, loss: 0.3454 ||:  65%|######4   | 7311/11253 [11:56<15:08,  4.34it/s]
2022-03-21 02:53:16,973 - INFO - tqdm - f1: 0.8173, accuracy: 0.8749, batch_loss: 0.2271, loss: 0.3458 ||:  66%|######5   | 7415/11253 [12:06<14:18,  4.47it/s]
2022-03-21 02:53:27,222 - INFO - tqdm - f1: 0.8171, accuracy: 0.8748, batch_loss: 0.2258, loss: 0.3460 ||:  67%|######6   | 7521/11253 [12:16<13:55,  4.47it/s]
2022-03-21 02:53:37,264 - INFO - tqdm - f1: 0.8171, accuracy: 0.8747, batch_loss: 0.3152, loss: 0.3459 ||:  68%|######7   | 7625/11253 [12:26<13:16,  4.55it/s]
2022-03-21 02:53:47,671 - INFO - tqdm - f1: 0.8168, accuracy: 0.8745, batch_loss: 0.5805, loss: 0.3461 ||:  69%|######8   | 7733/11253 [12:37<13:17,  4.41it/s]
2022-03-21 02:53:57,807 - INFO - tqdm - f1: 0.8168, accuracy: 0.8745, batch_loss: 0.3972, loss: 0.3462 ||:  70%|######9   | 7837/11253 [12:47<10:05,  5.64it/s]
2022-03-21 02:54:08,127 - INFO - tqdm - f1: 0.8168, accuracy: 0.8746, batch_loss: 0.3160, loss: 0.3461 ||:  71%|#######   | 7943/11253 [12:57<12:09,  4.54it/s]
2022-03-21 02:54:18,399 - INFO - tqdm - f1: 0.8165, accuracy: 0.8744, batch_loss: 0.1949, loss: 0.3461 ||:  72%|#######1  | 8051/11253 [13:07<11:55,  4.48it/s]
2022-03-21 02:54:28,825 - INFO - tqdm - f1: 0.8166, accuracy: 0.8745, batch_loss: 0.3578, loss: 0.3460 ||:  73%|#######2  | 8159/11253 [13:18<11:41,  4.41it/s]
2022-03-21 02:54:39,146 - INFO - tqdm - f1: 0.8166, accuracy: 0.8746, batch_loss: 0.0959, loss: 0.3457 ||:  73%|#######3  | 8267/11253 [13:28<11:11,  4.45it/s]
2022-03-21 02:54:49,323 - INFO - tqdm - f1: 0.8165, accuracy: 0.8745, batch_loss: 0.4470, loss: 0.3460 ||:  74%|#######4  | 8371/11253 [13:38<10:31,  4.57it/s]
2022-03-21 02:54:59,389 - INFO - tqdm - f1: 0.8166, accuracy: 0.8746, batch_loss: 0.2395, loss: 0.3459 ||:  75%|#######5  | 8477/11253 [13:48<10:13,  4.52it/s]
2022-03-21 02:55:09,478 - INFO - tqdm - f1: 0.8165, accuracy: 0.8746, batch_loss: 0.5445, loss: 0.3459 ||:  76%|#######6  | 8581/11253 [13:58<09:57,  4.47it/s]
2022-03-21 02:55:19,839 - INFO - tqdm - f1: 0.8165, accuracy: 0.8746, batch_loss: 0.3042, loss: 0.3459 ||:  77%|#######7  | 8689/11253 [14:09<09:31,  4.49it/s]
2022-03-21 02:55:30,399 - INFO - tqdm - f1: 0.8165, accuracy: 0.8747, batch_loss: 0.4019, loss: 0.3457 ||:  78%|#######8  | 8797/11253 [14:19<09:28,  4.32it/s]
2022-03-21 02:55:40,642 - INFO - tqdm - f1: 0.8166, accuracy: 0.8748, batch_loss: 0.5669, loss: 0.3455 ||:  79%|#######9  | 8901/11253 [14:30<09:02,  4.33it/s]
2022-03-21 02:55:51,189 - INFO - tqdm - f1: 0.8169, accuracy: 0.8749, batch_loss: 0.0567, loss: 0.3452 ||:  80%|########  | 9009/11253 [14:40<08:31,  4.39it/s]
2022-03-21 02:56:01,195 - INFO - tqdm - f1: 0.8167, accuracy: 0.8749, batch_loss: 0.4216, loss: 0.3453 ||:  81%|########  | 9113/11253 [14:50<07:18,  4.88it/s]
2022-03-21 02:56:11,259 - INFO - tqdm - f1: 0.8168, accuracy: 0.8749, batch_loss: 0.5535, loss: 0.3454 ||:  82%|########2 | 9228/11253 [15:00<02:09, 15.59it/s]
2022-03-21 02:56:21,404 - INFO - tqdm - f1: 0.8169, accuracy: 0.8749, batch_loss: 0.2691, loss: 0.3453 ||:  83%|########2 | 9314/11253 [15:10<03:54,  8.28it/s]
2022-03-21 02:56:31,577 - INFO - tqdm - f1: 0.8169, accuracy: 0.8749, batch_loss: 0.0861, loss: 0.3454 ||:  83%|########3 | 9361/11253 [15:21<17:57,  1.76it/s]
2022-03-21 02:56:41,638 - INFO - tqdm - f1: 0.8167, accuracy: 0.8749, batch_loss: 0.1458, loss: 0.3453 ||:  84%|########4 | 9462/11253 [15:31<02:02, 14.64it/s]
2022-03-21 02:56:51,685 - INFO - tqdm - f1: 0.8167, accuracy: 0.8748, batch_loss: 0.6198, loss: 0.3459 ||:  85%|########4 | 9556/11253 [15:41<02:21, 12.02it/s]
2022-03-21 02:57:01,754 - INFO - tqdm - f1: 0.8170, accuracy: 0.8750, batch_loss: 0.5798, loss: 0.3456 ||:  86%|########5 | 9654/11253 [15:51<04:46,  5.59it/s]
2022-03-21 02:57:11,794 - INFO - tqdm - f1: 0.8170, accuracy: 0.8751, batch_loss: 0.2260, loss: 0.3455 ||:  87%|########6 | 9756/11253 [16:01<05:28,  4.56it/s]
2022-03-21 02:57:22,060 - INFO - tqdm - f1: 0.8171, accuracy: 0.8752, batch_loss: 0.2913, loss: 0.3455 ||:  88%|########7 | 9860/11253 [16:11<05:12,  4.45it/s]
2022-03-21 02:57:32,300 - INFO - tqdm - f1: 0.8170, accuracy: 0.8752, batch_loss: 0.0104, loss: 0.3453 ||:  89%|########8 | 9970/11253 [16:21<02:14,  9.56it/s]
2022-03-21 02:57:42,534 - INFO - tqdm - f1: 0.8171, accuracy: 0.8752, batch_loss: 0.1365, loss: 0.3452 ||:  89%|########9 | 10043/11253 [16:32<05:43,  3.52it/s]
2022-03-21 02:57:52,673 - INFO - tqdm - f1: 0.8172, accuracy: 0.8752, batch_loss: 0.3135, loss: 0.3450 ||:  90%|######### | 10137/11253 [16:42<02:38,  7.04it/s]
2022-03-21 02:58:02,791 - INFO - tqdm - f1: 0.8172, accuracy: 0.8753, batch_loss: 0.5358, loss: 0.3449 ||:  91%|######### | 10202/11253 [16:52<02:17,  7.63it/s]
2022-03-21 02:58:12,899 - INFO - tqdm - f1: 0.8172, accuracy: 0.8753, batch_loss: 0.4341, loss: 0.3449 ||:  92%|#########1| 10298/11253 [17:02<01:47,  8.92it/s]
2022-03-21 02:58:22,925 - INFO - tqdm - f1: 0.8172, accuracy: 0.8752, batch_loss: 0.1813, loss: 0.3450 ||:  92%|#########2| 10387/11253 [17:12<01:41,  8.50it/s]
2022-03-21 02:58:33,035 - INFO - tqdm - f1: 0.8171, accuracy: 0.8751, batch_loss: 0.3140, loss: 0.3452 ||:  93%|#########3| 10475/11253 [17:22<01:26,  8.99it/s]
2022-03-21 02:58:43,131 - INFO - tqdm - f1: 0.8170, accuracy: 0.8752, batch_loss: 0.1016, loss: 0.3450 ||:  94%|#########3| 10563/11253 [17:32<01:18,  8.74it/s]
2022-03-21 02:58:53,172 - INFO - tqdm - f1: 0.8170, accuracy: 0.8752, batch_loss: 0.3418, loss: 0.3449 ||:  95%|#########4| 10650/11253 [17:42<01:09,  8.74it/s]
2022-03-21 02:59:03,186 - INFO - tqdm - f1: 0.8169, accuracy: 0.8751, batch_loss: 0.4442, loss: 0.3450 ||:  95%|#########5| 10741/11253 [17:52<00:59,  8.67it/s]
2022-03-21 02:59:13,215 - INFO - tqdm - f1: 0.8169, accuracy: 0.8751, batch_loss: 0.4496, loss: 0.3450 ||:  96%|#########6| 10830/11253 [18:02<00:50,  8.35it/s]
2022-03-21 02:59:23,245 - INFO - tqdm - f1: 0.8170, accuracy: 0.8752, batch_loss: 0.1247, loss: 0.3447 ||:  97%|#########6| 10914/11253 [18:12<00:38,  8.82it/s]
2022-03-21 02:59:33,350 - INFO - tqdm - f1: 0.8171, accuracy: 0.8753, batch_loss: 0.5350, loss: 0.3446 ||:  98%|#########7| 11005/11253 [18:22<00:27,  9.13it/s]
2022-03-21 02:59:43,444 - INFO - tqdm - f1: 0.8169, accuracy: 0.8752, batch_loss: 0.3387, loss: 0.3446 ||:  99%|#########8| 11092/11253 [18:32<00:17,  9.14it/s]
2022-03-21 02:59:53,526 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.1668, loss: 0.3450 ||:  99%|#########9| 11183/11253 [18:43<00:07,  9.44it/s]
2022-03-21 02:59:55,139 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.3587, loss: 0.3449 ||: 100%|#########9| 11197/11253 [18:44<00:06,  8.29it/s]
2022-03-21 02:59:55,301 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.1977, loss: 0.3449 ||: 100%|#########9| 11198/11253 [18:44<00:07,  7.64it/s]
2022-03-21 02:59:55,420 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.0523, loss: 0.3449 ||: 100%|#########9| 11199/11253 [18:44<00:06,  7.82it/s]
2022-03-21 02:59:55,539 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.2021, loss: 0.3449 ||: 100%|#########9| 11200/11253 [18:45<00:06,  7.97it/s]
2022-03-21 02:59:55,644 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.5007, loss: 0.3449 ||: 100%|#########9| 11201/11253 [18:45<00:06,  8.35it/s]
2022-03-21 02:59:55,763 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.6160, loss: 0.3449 ||: 100%|#########9| 11202/11253 [18:45<00:06,  8.37it/s]
2022-03-21 02:59:55,885 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.2652, loss: 0.3449 ||: 100%|#########9| 11203/11253 [18:45<00:06,  8.32it/s]
2022-03-21 02:59:56,036 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.2636, loss: 0.3449 ||: 100%|#########9| 11204/11253 [18:45<00:06,  7.74it/s]
2022-03-21 02:59:56,147 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.1387, loss: 0.3449 ||: 100%|#########9| 11205/11253 [18:45<00:05,  8.08it/s]
2022-03-21 02:59:56,264 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.1614, loss: 0.3448 ||: 100%|#########9| 11206/11253 [18:45<00:05,  8.21it/s]
2022-03-21 02:59:56,463 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.1722, loss: 0.3449 ||: 100%|#########9| 11208/11253 [18:45<00:05,  8.96it/s]
2022-03-21 02:59:56,682 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.2236, loss: 0.3448 ||: 100%|#########9| 11210/11253 [18:46<00:04,  9.03it/s]
2022-03-21 02:59:56,888 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.8204, loss: 0.3449 ||: 100%|#########9| 11212/11253 [18:46<00:04,  9.26it/s]
2022-03-21 02:59:57,002 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.7767, loss: 0.3449 ||: 100%|#########9| 11213/11253 [18:46<00:04,  9.16it/s]
2022-03-21 02:59:57,161 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.3240, loss: 0.3449 ||: 100%|#########9| 11214/11253 [18:46<00:04,  8.29it/s]
2022-03-21 02:59:57,277 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.4155, loss: 0.3449 ||: 100%|#########9| 11215/11253 [18:46<00:04,  8.38it/s]
2022-03-21 02:59:57,395 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.4903, loss: 0.3449 ||: 100%|#########9| 11216/11253 [18:46<00:04,  8.39it/s]
2022-03-21 02:59:57,507 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.2009, loss: 0.3449 ||: 100%|#########9| 11217/11253 [18:47<00:04,  8.54it/s]
2022-03-21 02:59:57,625 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.4866, loss: 0.3449 ||: 100%|#########9| 11218/11253 [18:47<00:04,  8.52it/s]
2022-03-21 02:59:57,734 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.1806, loss: 0.3449 ||: 100%|#########9| 11219/11253 [18:47<00:03,  8.70it/s]
2022-03-21 02:59:57,847 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 1.0478, loss: 0.3450 ||: 100%|#########9| 11220/11253 [18:47<00:03,  8.75it/s]
2022-03-21 02:59:57,954 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.3796, loss: 0.3450 ||: 100%|#########9| 11221/11253 [18:47<00:03,  8.91it/s]
2022-03-21 02:59:58,061 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.3362, loss: 0.3450 ||: 100%|#########9| 11222/11253 [18:47<00:03,  9.03it/s]
2022-03-21 02:59:58,172 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.1992, loss: 0.3450 ||: 100%|#########9| 11223/11253 [18:47<00:03,  9.02it/s]
2022-03-21 02:59:58,316 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.2702, loss: 0.3450 ||: 100%|#########9| 11224/11253 [18:47<00:03,  8.29it/s]
2022-03-21 02:59:58,429 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.8414, loss: 0.3450 ||: 100%|#########9| 11225/11253 [18:47<00:03,  8.44it/s]
2022-03-21 02:59:58,540 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.7963, loss: 0.3451 ||: 100%|#########9| 11226/11253 [18:48<00:03,  8.61it/s]
2022-03-21 02:59:58,658 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.6471, loss: 0.3451 ||: 100%|#########9| 11227/11253 [18:48<00:03,  8.57it/s]
2022-03-21 02:59:58,870 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.2767, loss: 0.3451 ||: 100%|#########9| 11229/11253 [18:48<00:02,  8.95it/s]
2022-03-21 02:59:58,978 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.3146, loss: 0.3451 ||: 100%|#########9| 11230/11253 [18:48<00:02,  9.01it/s]
2022-03-21 02:59:59,165 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.5973, loss: 0.3451 ||: 100%|#########9| 11231/11253 [18:48<00:02,  7.65it/s]
2022-03-21 02:59:59,412 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.2613, loss: 0.3451 ||: 100%|#########9| 11232/11253 [18:48<00:03,  6.16it/s]
2022-03-21 02:59:59,573 - INFO - tqdm - f1: 0.8168, accuracy: 0.8751, batch_loss: 0.1572, loss: 0.3451 ||: 100%|#########9| 11233/11253 [18:49<00:03,  6.17it/s]
2022-03-21 02:59:59,802 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.3165, loss: 0.3451 ||: 100%|#########9| 11234/11253 [18:49<00:03,  5.52it/s]
2022-03-21 02:59:59,998 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.2745, loss: 0.3450 ||: 100%|#########9| 11235/11253 [18:49<00:03,  5.39it/s]
2022-03-21 03:00:00,252 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.4801, loss: 0.3451 ||: 100%|#########9| 11236/11253 [18:49<00:03,  4.86it/s]
2022-03-21 03:00:00,398 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.1385, loss: 0.3450 ||: 100%|#########9| 11237/11253 [18:49<00:03,  5.32it/s]
2022-03-21 03:00:00,540 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.3432, loss: 0.3450 ||: 100%|#########9| 11239/11253 [18:50<00:01,  7.47it/s]
2022-03-21 03:00:00,683 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.2942, loss: 0.3451 ||: 100%|#########9| 11241/11253 [18:50<00:01,  9.11it/s]
2022-03-21 03:00:00,892 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.2374, loss: 0.3450 ||: 100%|#########9| 11243/11253 [18:50<00:01,  9.27it/s]
2022-03-21 03:00:00,994 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.3744, loss: 0.3450 ||: 100%|#########9| 11244/11253 [18:50<00:00,  9.39it/s]
2022-03-21 03:00:01,125 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.4775, loss: 0.3451 ||: 100%|#########9| 11245/11253 [18:50<00:00,  8.91it/s]
2022-03-21 03:00:01,275 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.5074, loss: 0.3451 ||: 100%|#########9| 11246/11253 [18:50<00:00,  8.23it/s]
2022-03-21 03:00:01,392 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.1382, loss: 0.3451 ||: 100%|#########9| 11247/11253 [18:50<00:00,  8.31it/s]
2022-03-21 03:00:01,503 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.4838, loss: 0.3451 ||: 100%|#########9| 11248/11253 [18:51<00:00,  8.50it/s]
2022-03-21 03:00:01,608 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.3338, loss: 0.3451 ||: 100%|#########9| 11249/11253 [18:51<00:00,  8.76it/s]
2022-03-21 03:00:01,719 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.4511, loss: 0.3451 ||: 100%|#########9| 11250/11253 [18:51<00:00,  8.83it/s]
2022-03-21 03:00:01,848 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.2729, loss: 0.3451 ||: 100%|#########9| 11251/11253 [18:51<00:00,  8.49it/s]
2022-03-21 03:00:01,973 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.4007, loss: 0.3451 ||: 100%|#########9| 11252/11253 [18:51<00:00,  8.35it/s]
2022-03-21 03:00:02,088 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.4547, loss: 0.3451 ||: 100%|##########| 11253/11253 [18:51<00:00,  8.44it/s]
2022-03-21 03:00:02,156 - INFO - tqdm - f1: 0.8167, accuracy: 0.8751, batch_loss: 0.4547, loss: 0.3451 ||: 100%|##########| 11253/11253 [18:51<00:00,  9.94it/s]
2022-03-21 03:00:02,173 - INFO - allennlp.training.trainer - Validating
2022-03-21 03:00:02,176 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 03:00:12,287 - INFO - tqdm - f1: 0.8127, accuracy: 0.8733, batch_loss: 0.5858, loss: 0.3527 ||:  10%|9         | 186/1889 [00:10<01:27, 19.54it/s]
2022-03-21 03:00:22,410 - INFO - tqdm - f1: 0.8143, accuracy: 0.8726, batch_loss: 0.0584, loss: 0.3525 ||:  19%|#9        | 368/1889 [00:20<01:22, 18.44it/s]
2022-03-21 03:00:32,528 - INFO - tqdm - f1: 0.8156, accuracy: 0.8740, batch_loss: 0.3461, loss: 0.3493 ||:  29%|##9       | 551/1889 [00:30<01:09, 19.19it/s]
2022-03-21 03:00:42,594 - INFO - tqdm - f1: 0.8182, accuracy: 0.8760, batch_loss: 0.5488, loss: 0.3481 ||:  39%|###8      | 728/1889 [00:40<01:15, 15.46it/s]
2022-03-21 03:00:52,612 - INFO - tqdm - f1: 0.8176, accuracy: 0.8746, batch_loss: 0.0904, loss: 0.3526 ||:  48%|####8     | 913/1889 [00:50<00:55, 17.68it/s]
2022-03-21 03:01:02,670 - INFO - tqdm - f1: 0.8174, accuracy: 0.8741, batch_loss: 0.4820, loss: 0.3561 ||:  58%|#####7    | 1095/1889 [01:00<00:58, 13.59it/s]
2022-03-21 03:01:12,718 - INFO - tqdm - f1: 0.8182, accuracy: 0.8753, batch_loss: 0.1935, loss: 0.3533 ||:  68%|######7   | 1280/1889 [01:10<00:32, 18.48it/s]
2022-03-21 03:01:22,790 - INFO - tqdm - f1: 0.8184, accuracy: 0.8755, batch_loss: 0.7006, loss: 0.3518 ||:  77%|#######7  | 1459/1889 [01:20<00:21, 19.97it/s]
2022-03-21 03:01:32,925 - INFO - tqdm - f1: 0.8185, accuracy: 0.8755, batch_loss: 0.4026, loss: 0.3531 ||:  86%|########6 | 1632/1889 [01:30<00:20, 12.34it/s]
2022-03-21 03:01:43,012 - INFO - tqdm - f1: 0.8191, accuracy: 0.8751, batch_loss: 0.3482, loss: 0.3542 ||:  95%|#########4| 1789/1889 [01:40<00:05, 17.56it/s]
2022-03-21 03:01:48,469 - INFO - tqdm - f1: 0.8198, accuracy: 0.8756, batch_loss: 0.1006, loss: 0.3528 ||: 100%|#########9| 1881/1889 [01:46<00:00, 17.46it/s]
2022-03-21 03:01:48,591 - INFO - tqdm - f1: 0.8197, accuracy: 0.8756, batch_loss: 0.2407, loss: 0.3527 ||: 100%|#########9| 1883/1889 [01:46<00:00, 17.12it/s]
2022-03-21 03:01:48,692 - INFO - tqdm - f1: 0.8197, accuracy: 0.8755, batch_loss: 0.3581, loss: 0.3526 ||: 100%|#########9| 1885/1889 [01:46<00:00, 17.87it/s]
2022-03-21 03:01:48,812 - INFO - tqdm - f1: 0.8199, accuracy: 0.8756, batch_loss: 0.0941, loss: 0.3524 ||: 100%|#########9| 1887/1889 [01:46<00:00, 17.48it/s]
2022-03-21 03:01:48,957 - INFO - tqdm - f1: 0.8199, accuracy: 0.8757, batch_loss: 0.0301, loss: 0.3522 ||: 100%|##########| 1889/1889 [01:46<00:00, 16.21it/s]
2022-03-21 03:01:48,968 - INFO - tqdm - f1: 0.8199, accuracy: 0.8757, batch_loss: 0.0301, loss: 0.3522 ||: 100%|##########| 1889/1889 [01:46<00:00, 17.69it/s]
2022-03-21 03:01:49,008 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct-20k_base_hyper_small_seed_97/best.th'.
2022-03-21 03:01:51,381 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 03:01:51,383 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.875  |     0.876
2022-03-21 03:01:51,385 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.817  |     0.820
2022-03-21 03:01:51,387 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 03:01:51,388 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.345  |     0.352
2022-03-21 03:01:51,390 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8638.316  |       N/A
2022-03-21 03:01:51,392 - INFO - allennlp.training.trainer - Epoch duration: 0:20:40.901444
2022-03-21 03:01:51,393 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:40:17
2022-03-21 03:01:51,395 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-21 03:01:51,397 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 03:01:51,399 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 03:01:51,402 - INFO - allennlp.training.trainer - Training
2022-03-21 03:01:51,404 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 03:02:01,575 - INFO - tqdm - f1: 0.8271, accuracy: 0.8818, batch_loss: 0.3907, loss: 0.2989 ||:   0%|          | 46/11253 [00:10<21:17,  8.77it/s]
2022-03-21 03:02:11,697 - INFO - tqdm - f1: 0.8358, accuracy: 0.8887, batch_loss: 0.0202, loss: 0.2935 ||:   1%|1         | 132/11253 [00:20<22:53,  8.10it/s]
2022-03-21 03:02:21,785 - INFO - tqdm - f1: 0.8385, accuracy: 0.8881, batch_loss: 0.2939, loss: 0.2921 ||:   2%|1         | 224/11253 [00:30<19:54,  9.23it/s]
2022-03-21 03:02:31,812 - INFO - tqdm - f1: 0.8405, accuracy: 0.8885, batch_loss: 0.4660, loss: 0.2967 ||:   3%|2         | 310/11253 [00:40<21:26,  8.51it/s]
2022-03-21 03:02:41,913 - INFO - tqdm - f1: 0.8379, accuracy: 0.8885, batch_loss: 0.4671, loss: 0.2953 ||:   4%|3         | 403/11253 [00:50<18:57,  9.54it/s]
2022-03-21 03:02:52,009 - INFO - tqdm - f1: 0.8357, accuracy: 0.8866, batch_loss: 0.4844, loss: 0.3052 ||:   4%|4         | 492/11253 [01:00<19:41,  9.11it/s]
2022-03-21 03:03:02,017 - INFO - tqdm - f1: 0.8376, accuracy: 0.8887, batch_loss: 0.0841, loss: 0.3013 ||:   5%|5         | 582/11253 [01:10<19:37,  9.06it/s]
2022-03-21 03:03:12,032 - INFO - tqdm - f1: 0.8364, accuracy: 0.8887, batch_loss: 0.3152, loss: 0.3017 ||:   6%|5         | 671/11253 [01:20<24:47,  7.11it/s]
2022-03-21 03:03:22,056 - INFO - tqdm - f1: 0.8369, accuracy: 0.8892, batch_loss: 0.1546, loss: 0.3013 ||:   7%|6         | 755/11253 [01:30<21:17,  8.22it/s]
2022-03-21 03:03:32,076 - INFO - tqdm - f1: 0.8352, accuracy: 0.8888, batch_loss: 0.2839, loss: 0.3045 ||:   8%|7         | 845/11253 [01:40<19:16,  9.00it/s]
2022-03-21 03:03:42,092 - INFO - tqdm - f1: 0.8343, accuracy: 0.8884, batch_loss: 0.0739, loss: 0.3039 ||:   8%|8         | 931/11253 [01:50<18:40,  9.21it/s]
2022-03-21 03:03:52,174 - INFO - tqdm - f1: 0.8345, accuracy: 0.8885, batch_loss: 0.0169, loss: 0.3052 ||:   9%|9         | 1022/11253 [02:00<20:44,  8.22it/s]
2022-03-21 03:04:02,246 - INFO - tqdm - f1: 0.8354, accuracy: 0.8890, batch_loss: 0.1027, loss: 0.3054 ||:  10%|9         | 1108/11253 [02:10<20:32,  8.23it/s]
2022-03-21 03:04:12,336 - INFO - tqdm - f1: 0.8360, accuracy: 0.8891, batch_loss: 0.2752, loss: 0.3050 ||:  11%|#         | 1201/11253 [02:20<18:20,  9.13it/s]
2022-03-21 03:04:22,404 - INFO - tqdm - f1: 0.8364, accuracy: 0.8897, batch_loss: 0.1702, loss: 0.3038 ||:  11%|#1        | 1291/11253 [02:30<17:24,  9.54it/s]
2022-03-21 03:04:32,503 - INFO - tqdm - f1: 0.8355, accuracy: 0.8893, batch_loss: 0.4127, loss: 0.3035 ||:  12%|#2        | 1382/11253 [02:41<17:15,  9.53it/s]
2022-03-21 03:04:42,578 - INFO - tqdm - f1: 0.8346, accuracy: 0.8891, batch_loss: 0.0465, loss: 0.3036 ||:  13%|#3        | 1467/11253 [02:51<30:41,  5.32it/s]
2022-03-21 03:04:52,661 - INFO - tqdm - f1: 0.8349, accuracy: 0.8894, batch_loss: 0.1455, loss: 0.3039 ||:  14%|#3        | 1561/11253 [03:01<18:58,  8.51it/s]
2022-03-21 03:05:02,704 - INFO - tqdm - f1: 0.8346, accuracy: 0.8892, batch_loss: 0.2282, loss: 0.3046 ||:  15%|#4        | 1650/11253 [03:11<17:18,  9.25it/s]
2022-03-21 03:05:12,764 - INFO - tqdm - f1: 0.8340, accuracy: 0.8889, batch_loss: 0.3374, loss: 0.3066 ||:  15%|#5        | 1736/11253 [03:21<15:57,  9.94it/s]
2022-03-21 03:05:22,819 - INFO - tqdm - f1: 0.8338, accuracy: 0.8889, batch_loss: 0.2000, loss: 0.3074 ||:  16%|#6        | 1826/11253 [03:31<18:18,  8.58it/s]
2022-03-21 03:05:32,868 - INFO - tqdm - f1: 0.8340, accuracy: 0.8887, batch_loss: 0.5116, loss: 0.3075 ||:  17%|#7        | 1914/11253 [03:41<15:58,  9.74it/s]
2022-03-21 03:05:42,950 - INFO - tqdm - f1: 0.8343, accuracy: 0.8886, batch_loss: 0.9646, loss: 0.3078 ||:  18%|#7        | 2004/11253 [03:51<17:15,  8.94it/s]
2022-03-21 03:05:53,049 - INFO - tqdm - f1: 0.8335, accuracy: 0.8880, batch_loss: 0.3098, loss: 0.3085 ||:  19%|#8        | 2092/11253 [04:01<16:09,  9.45it/s]
2022-03-21 03:06:03,140 - INFO - tqdm - f1: 0.8337, accuracy: 0.8885, batch_loss: 0.2471, loss: 0.3067 ||:  19%|#9        | 2183/11253 [04:11<16:35,  9.11it/s]
2022-03-21 03:06:13,262 - INFO - tqdm - f1: 0.8331, accuracy: 0.8884, batch_loss: 0.1677, loss: 0.3067 ||:  20%|##        | 2269/11253 [04:21<17:39,  8.48it/s]
2022-03-21 03:06:23,273 - INFO - tqdm - f1: 0.8336, accuracy: 0.8887, batch_loss: 0.0969, loss: 0.3058 ||:  21%|##        | 2358/11253 [04:31<17:40,  8.39it/s]
2022-03-21 03:06:33,368 - INFO - tqdm - f1: 0.8333, accuracy: 0.8884, batch_loss: 0.3685, loss: 0.3053 ||:  22%|##1       | 2446/11253 [04:41<23:14,  6.31it/s]
2022-03-21 03:06:43,447 - INFO - tqdm - f1: 0.8340, accuracy: 0.8890, batch_loss: 1.0202, loss: 0.3045 ||:  23%|##2       | 2535/11253 [04:52<15:59,  9.08it/s]
2022-03-21 03:06:53,491 - INFO - tqdm - f1: 0.8341, accuracy: 0.8891, batch_loss: 0.2292, loss: 0.3040 ||:  23%|##3       | 2626/11253 [05:02<14:27,  9.94it/s]
2022-03-21 03:07:03,585 - INFO - tqdm - f1: 0.8339, accuracy: 0.8890, batch_loss: 0.3435, loss: 0.3042 ||:  24%|##4       | 2712/11253 [05:12<15:14,  9.34it/s]
2022-03-21 03:07:13,613 - INFO - tqdm - f1: 0.8341, accuracy: 0.8891, batch_loss: 0.0888, loss: 0.3045 ||:  25%|##4       | 2801/11253 [05:22<17:00,  8.28it/s]
2022-03-21 03:07:23,722 - INFO - tqdm - f1: 0.8343, accuracy: 0.8894, batch_loss: 0.1953, loss: 0.3042 ||:  26%|##5       | 2885/11253 [05:32<16:06,  8.66it/s]
2022-03-21 03:07:33,834 - INFO - tqdm - f1: 0.8340, accuracy: 0.8891, batch_loss: 0.2246, loss: 0.3045 ||:  26%|##6       | 2977/11253 [05:42<15:31,  8.89it/s]
2022-03-21 03:07:43,919 - INFO - tqdm - f1: 0.8344, accuracy: 0.8894, batch_loss: 0.4973, loss: 0.3037 ||:  27%|##7       | 3064/11253 [05:52<14:38,  9.32it/s]
2022-03-21 03:07:53,929 - INFO - tqdm - f1: 0.8345, accuracy: 0.8898, batch_loss: 0.2359, loss: 0.3031 ||:  28%|##8       | 3151/11253 [06:02<14:56,  9.04it/s]
2022-03-21 03:08:03,953 - INFO - tqdm - f1: 0.8347, accuracy: 0.8897, batch_loss: 0.3105, loss: 0.3030 ||:  29%|##8       | 3239/11253 [06:12<15:08,  8.82it/s]
2022-03-21 03:08:14,052 - INFO - tqdm - f1: 0.8347, accuracy: 0.8897, batch_loss: 0.1905, loss: 0.3030 ||:  30%|##9       | 3330/11253 [06:22<15:29,  8.53it/s]
2022-03-21 03:08:24,149 - INFO - tqdm - f1: 0.8347, accuracy: 0.8896, batch_loss: 0.5809, loss: 0.3032 ||:  30%|###       | 3421/11253 [06:32<13:57,  9.36it/s]
2022-03-21 03:08:34,263 - INFO - tqdm - f1: 0.8353, accuracy: 0.8899, batch_loss: 0.0430, loss: 0.3028 ||:  31%|###1      | 3509/11253 [06:42<14:48,  8.72it/s]
2022-03-21 03:08:44,329 - INFO - tqdm - f1: 0.8354, accuracy: 0.8900, batch_loss: 0.1699, loss: 0.3026 ||:  32%|###2      | 3601/11253 [06:52<14:11,  8.99it/s]
2022-03-21 03:08:54,402 - INFO - tqdm - f1: 0.8353, accuracy: 0.8903, batch_loss: 0.2561, loss: 0.3026 ||:  33%|###2      | 3688/11253 [07:02<14:23,  8.76it/s]
2022-03-21 03:09:04,475 - INFO - tqdm - f1: 0.8350, accuracy: 0.8901, batch_loss: 0.2109, loss: 0.3026 ||:  34%|###3      | 3778/11253 [07:13<16:19,  7.63it/s]
2022-03-21 03:09:14,531 - INFO - tqdm - f1: 0.8348, accuracy: 0.8899, batch_loss: 0.3366, loss: 0.3029 ||:  34%|###4      | 3864/11253 [07:23<14:43,  8.36it/s]
2022-03-21 03:09:24,631 - INFO - tqdm - f1: 0.8347, accuracy: 0.8896, batch_loss: 0.2823, loss: 0.3039 ||:  35%|###5      | 3957/11253 [07:33<12:34,  9.67it/s]
2022-03-21 03:09:34,743 - INFO - tqdm - f1: 0.8348, accuracy: 0.8897, batch_loss: 0.0561, loss: 0.3038 ||:  36%|###5      | 4044/11253 [07:43<14:28,  8.30it/s]
2022-03-21 03:09:44,799 - INFO - tqdm - f1: 0.8344, accuracy: 0.8892, batch_loss: 0.5358, loss: 0.3051 ||:  37%|###6      | 4136/11253 [07:53<12:37,  9.39it/s]
2022-03-21 03:09:54,807 - INFO - tqdm - f1: 0.8341, accuracy: 0.8891, batch_loss: 0.4344, loss: 0.3057 ||:  38%|###7      | 4221/11253 [08:03<20:17,  5.78it/s]
2022-03-21 03:10:04,856 - INFO - tqdm - f1: 0.8347, accuracy: 0.8896, batch_loss: 0.2736, loss: 0.3047 ||:  38%|###8      | 4311/11253 [08:13<12:03,  9.60it/s]
2022-03-21 03:10:14,884 - INFO - tqdm - f1: 0.8351, accuracy: 0.8899, batch_loss: 0.0090, loss: 0.3042 ||:  39%|###9      | 4403/11253 [08:23<13:30,  8.46it/s]
2022-03-21 03:10:24,889 - INFO - tqdm - f1: 0.8352, accuracy: 0.8898, batch_loss: 0.1089, loss: 0.3043 ||:  40%|###9      | 4489/11253 [08:33<12:42,  8.87it/s]
2022-03-21 03:10:34,963 - INFO - tqdm - f1: 0.8348, accuracy: 0.8895, batch_loss: 0.1252, loss: 0.3050 ||:  41%|####      | 4580/11253 [08:43<11:37,  9.56it/s]
2022-03-21 03:10:45,035 - INFO - tqdm - f1: 0.8345, accuracy: 0.8895, batch_loss: 0.5087, loss: 0.3049 ||:  41%|####1     | 4668/11253 [08:53<12:17,  8.93it/s]
2022-03-21 03:10:55,070 - INFO - tqdm - f1: 0.8342, accuracy: 0.8894, batch_loss: 0.0812, loss: 0.3054 ||:  42%|####2     | 4759/11253 [09:03<12:42,  8.52it/s]
2022-03-21 03:11:05,070 - INFO - tqdm - f1: 0.8345, accuracy: 0.8897, batch_loss: 1.1964, loss: 0.3051 ||:  43%|####3     | 4845/11253 [09:13<12:01,  8.88it/s]
2022-03-21 03:11:15,117 - INFO - tqdm - f1: 0.8342, accuracy: 0.8896, batch_loss: 0.0979, loss: 0.3048 ||:  44%|####3     | 4936/11253 [09:23<12:24,  8.48it/s]
2022-03-21 03:11:25,229 - INFO - tqdm - f1: 0.8340, accuracy: 0.8894, batch_loss: 0.3679, loss: 0.3053 ||:  45%|####4     | 5022/11253 [09:33<11:08,  9.31it/s]
2022-03-21 03:11:35,342 - INFO - tqdm - f1: 0.8336, accuracy: 0.8893, batch_loss: 0.1006, loss: 0.3050 ||:  45%|####5     | 5111/11253 [09:43<13:05,  7.82it/s]
2022-03-21 03:11:45,402 - INFO - tqdm - f1: 0.8333, accuracy: 0.8890, batch_loss: 0.2960, loss: 0.3053 ||:  46%|####6     | 5203/11253 [09:53<10:54,  9.24it/s]
2022-03-21 03:11:55,579 - INFO - tqdm - f1: 0.8330, accuracy: 0.8887, batch_loss: 0.2346, loss: 0.3057 ||:  47%|####7     | 5292/11253 [10:04<10:35,  9.38it/s]
2022-03-21 03:12:05,648 - INFO - tqdm - f1: 0.8331, accuracy: 0.8889, batch_loss: 0.1057, loss: 0.3052 ||:  48%|####7     | 5383/11253 [10:14<11:22,  8.60it/s]
2022-03-21 03:12:15,769 - INFO - tqdm - f1: 0.8331, accuracy: 0.8889, batch_loss: 0.4821, loss: 0.3050 ||:  49%|####8     | 5468/11253 [10:24<10:10,  9.48it/s]
2022-03-21 03:12:25,851 - INFO - tqdm - f1: 0.8334, accuracy: 0.8891, batch_loss: 0.1820, loss: 0.3049 ||:  49%|####9     | 5558/11253 [10:34<09:50,  9.65it/s]
2022-03-21 03:12:35,925 - INFO - tqdm - f1: 0.8334, accuracy: 0.8890, batch_loss: 0.2741, loss: 0.3050 ||:  50%|#####     | 5646/11253 [10:44<09:46,  9.56it/s]
2022-03-21 03:12:45,964 - INFO - tqdm - f1: 0.8327, accuracy: 0.8887, batch_loss: 0.1945, loss: 0.3056 ||:  51%|#####     | 5736/11253 [10:54<09:36,  9.56it/s]
2022-03-21 03:12:56,060 - INFO - tqdm - f1: 0.8328, accuracy: 0.8888, batch_loss: 0.2433, loss: 0.3057 ||:  52%|#####1    | 5822/11253 [11:04<10:36,  8.53it/s]
2022-03-21 03:13:06,076 - INFO - tqdm - f1: 0.8328, accuracy: 0.8888, batch_loss: 0.2957, loss: 0.3057 ||:  53%|#####2    | 5912/11253 [11:14<10:08,  8.78it/s]
2022-03-21 03:13:16,232 - INFO - tqdm - f1: 0.8324, accuracy: 0.8886, batch_loss: 0.3787, loss: 0.3059 ||:  53%|#####3    | 5997/11253 [11:24<15:47,  5.55it/s]
2022-03-21 03:13:26,234 - INFO - tqdm - f1: 0.8325, accuracy: 0.8886, batch_loss: 0.1420, loss: 0.3060 ||:  54%|#####4    | 6086/11253 [11:34<09:56,  8.67it/s]
2022-03-21 03:13:36,300 - INFO - tqdm - f1: 0.8324, accuracy: 0.8887, batch_loss: 0.3407, loss: 0.3061 ||:  55%|#####4    | 6174/11253 [11:44<09:07,  9.28it/s]
2022-03-21 03:13:46,319 - INFO - tqdm - f1: 0.8322, accuracy: 0.8886, batch_loss: 0.1649, loss: 0.3061 ||:  56%|#####5    | 6258/11253 [11:54<10:04,  8.26it/s]
2022-03-21 03:13:56,407 - INFO - tqdm - f1: 0.8324, accuracy: 0.8888, batch_loss: 0.4697, loss: 0.3058 ||:  56%|#####6    | 6349/11253 [12:05<09:40,  8.45it/s]
2022-03-21 03:14:06,646 - INFO - tqdm - f1: 0.8326, accuracy: 0.8888, batch_loss: 0.0919, loss: 0.3055 ||:  57%|#####7    | 6437/11253 [12:15<09:34,  8.38it/s]
2022-03-21 03:14:16,699 - INFO - tqdm - f1: 0.8326, accuracy: 0.8887, batch_loss: 0.2622, loss: 0.3058 ||:  58%|#####8    | 6529/11253 [12:25<08:22,  9.41it/s]
2022-03-21 03:14:26,789 - INFO - tqdm - f1: 0.8324, accuracy: 0.8885, batch_loss: 0.1279, loss: 0.3062 ||:  59%|#####8    | 6617/11253 [12:35<09:01,  8.56it/s]
2022-03-21 03:14:36,899 - INFO - tqdm - f1: 0.8320, accuracy: 0.8883, batch_loss: 0.0695, loss: 0.3064 ||:  60%|#####9    | 6709/11253 [12:45<08:11,  9.24it/s]
2022-03-21 03:14:47,064 - INFO - tqdm - f1: 0.8321, accuracy: 0.8883, batch_loss: 0.2599, loss: 0.3064 ||:  60%|######    | 6799/11253 [12:55<08:06,  9.15it/s]
2022-03-21 03:14:57,181 - INFO - tqdm - f1: 0.8321, accuracy: 0.8883, batch_loss: 0.2466, loss: 0.3065 ||:  61%|######1   | 6888/11253 [13:05<07:52,  9.23it/s]
2022-03-21 03:15:07,213 - INFO - tqdm - f1: 0.8320, accuracy: 0.8881, batch_loss: 0.2560, loss: 0.3067 ||:  62%|######2   | 6979/11253 [13:15<07:41,  9.26it/s]
2022-03-21 03:15:17,346 - INFO - tqdm - f1: 0.8320, accuracy: 0.8881, batch_loss: 0.4417, loss: 0.3070 ||:  63%|######2   | 7065/11253 [13:25<07:25,  9.40it/s]
2022-03-21 03:15:27,354 - INFO - tqdm - f1: 0.8318, accuracy: 0.8880, batch_loss: 0.1391, loss: 0.3072 ||:  64%|######3   | 7153/11253 [13:35<07:43,  8.86it/s]
2022-03-21 03:15:37,402 - INFO - tqdm - f1: 0.8318, accuracy: 0.8880, batch_loss: 0.4093, loss: 0.3073 ||:  64%|######4   | 7241/11253 [13:45<06:54,  9.68it/s]
2022-03-21 03:15:47,557 - INFO - tqdm - f1: 0.8318, accuracy: 0.8880, batch_loss: 0.5949, loss: 0.3073 ||:  65%|######5   | 7334/11253 [13:56<06:57,  9.38it/s]
2022-03-21 03:15:57,677 - INFO - tqdm - f1: 0.8319, accuracy: 0.8882, batch_loss: 0.1738, loss: 0.3069 ||:  66%|######5   | 7419/11253 [14:06<07:42,  8.29it/s]
2022-03-21 03:16:07,791 - INFO - tqdm - f1: 0.8317, accuracy: 0.8880, batch_loss: 0.5196, loss: 0.3075 ||:  67%|######6   | 7510/11253 [14:16<07:35,  8.22it/s]
2022-03-21 03:16:17,797 - INFO - tqdm - f1: 0.8317, accuracy: 0.8880, batch_loss: 0.2489, loss: 0.3073 ||:  68%|######7   | 7596/11253 [14:26<07:09,  8.51it/s]
2022-03-21 03:16:27,848 - INFO - tqdm - f1: 0.8318, accuracy: 0.8880, batch_loss: 0.3152, loss: 0.3076 ||:  68%|######8   | 7687/11253 [14:36<06:39,  8.94it/s]
2022-03-21 03:16:38,062 - INFO - tqdm - f1: 0.8319, accuracy: 0.8880, batch_loss: 0.2583, loss: 0.3076 ||:  69%|######9   | 7776/11253 [14:46<09:39,  6.01it/s]
2022-03-21 03:16:48,161 - INFO - tqdm - f1: 0.8321, accuracy: 0.8881, batch_loss: 0.2915, loss: 0.3074 ||:  70%|######9   | 7865/11253 [14:56<06:21,  8.88it/s]
2022-03-21 03:16:58,193 - INFO - tqdm - f1: 0.8321, accuracy: 0.8881, batch_loss: 0.3153, loss: 0.3075 ||:  71%|#######   | 7956/11253 [15:06<05:46,  9.52it/s]
2022-03-21 03:17:08,207 - INFO - tqdm - f1: 0.8319, accuracy: 0.8880, batch_loss: 0.2702, loss: 0.3077 ||:  71%|#######1  | 8043/11253 [15:16<06:12,  8.61it/s]
2022-03-21 03:17:18,406 - INFO - tqdm - f1: 0.8320, accuracy: 0.8881, batch_loss: 0.0817, loss: 0.3076 ||:  72%|#######2  | 8136/11253 [15:26<05:29,  9.46it/s]
2022-03-21 03:17:28,418 - INFO - tqdm - f1: 0.8322, accuracy: 0.8882, batch_loss: 0.2876, loss: 0.3074 ||:  73%|#######3  | 8221/11253 [15:37<05:56,  8.50it/s]
2022-03-21 03:17:38,423 - INFO - tqdm - f1: 0.8322, accuracy: 0.8883, batch_loss: 0.2387, loss: 0.3072 ||:  74%|#######3  | 8311/11253 [15:47<05:23,  9.09it/s]
2022-03-21 03:17:48,522 - INFO - tqdm - f1: 0.8324, accuracy: 0.8883, batch_loss: 0.2840, loss: 0.3073 ||:  75%|#######4  | 8400/11253 [15:57<05:15,  9.05it/s]
2022-03-21 03:17:58,602 - INFO - tqdm - f1: 0.8322, accuracy: 0.8882, batch_loss: 0.3038, loss: 0.3077 ||:  75%|#######5  | 8491/11253 [16:07<05:05,  9.04it/s]
2022-03-21 03:18:08,647 - INFO - tqdm - f1: 0.8322, accuracy: 0.8881, batch_loss: 0.0797, loss: 0.3080 ||:  76%|#######6  | 8575/11253 [16:17<05:59,  7.44it/s]
2022-03-21 03:18:18,706 - INFO - tqdm - f1: 0.8322, accuracy: 0.8881, batch_loss: 0.2454, loss: 0.3081 ||:  77%|#######6  | 8664/11253 [16:27<04:45,  9.06it/s]
2022-03-21 03:18:28,709 - INFO - tqdm - f1: 0.8322, accuracy: 0.8881, batch_loss: 0.1094, loss: 0.3079 ||:  78%|#######7  | 8754/11253 [16:37<04:26,  9.38it/s]
2022-03-21 03:18:38,754 - INFO - tqdm - f1: 0.8320, accuracy: 0.8879, batch_loss: 0.1337, loss: 0.3083 ||:  79%|#######8  | 8841/11253 [16:47<04:32,  8.85it/s]
2022-03-21 03:18:48,802 - INFO - tqdm - f1: 0.8322, accuracy: 0.8879, batch_loss: 0.6967, loss: 0.3084 ||:  79%|#######9  | 8930/11253 [16:57<04:29,  8.61it/s]
2022-03-21 03:18:58,881 - INFO - tqdm - f1: 0.8321, accuracy: 0.8879, batch_loss: 0.3032, loss: 0.3083 ||:  80%|########  | 9017/11253 [17:07<04:35,  8.11it/s]
2022-03-21 03:19:09,062 - INFO - tqdm - f1: 0.8321, accuracy: 0.8881, batch_loss: 0.0701, loss: 0.3081 ||:  81%|########  | 9108/11253 [17:17<03:58,  9.00it/s]
2022-03-21 03:19:19,109 - INFO - tqdm - f1: 0.8323, accuracy: 0.8881, batch_loss: 0.2725, loss: 0.3079 ||:  82%|########1 | 9196/11253 [17:27<03:57,  8.67it/s]
2022-03-21 03:19:29,227 - INFO - tqdm - f1: 0.8322, accuracy: 0.8880, batch_loss: 0.1725, loss: 0.3085 ||:  83%|########2 | 9286/11253 [17:37<03:55,  8.36it/s]
2022-03-21 03:19:39,292 - INFO - tqdm - f1: 0.8323, accuracy: 0.8880, batch_loss: 0.1661, loss: 0.3085 ||:  83%|########3 | 9373/11253 [17:47<03:47,  8.28it/s]
2022-03-21 03:19:49,460 - INFO - tqdm - f1: 0.8323, accuracy: 0.8881, batch_loss: 0.1394, loss: 0.3083 ||:  84%|########4 | 9465/11253 [17:58<03:11,  9.33it/s]
2022-03-21 03:19:59,561 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.5822, loss: 0.3081 ||:  85%|########4 | 9550/11253 [18:08<05:04,  5.59it/s]
2022-03-21 03:20:09,652 - INFO - tqdm - f1: 0.8323, accuracy: 0.8881, batch_loss: 0.5340, loss: 0.3082 ||:  86%|########5 | 9639/11253 [18:18<02:52,  9.36it/s]
2022-03-21 03:20:19,779 - INFO - tqdm - f1: 0.8322, accuracy: 0.8880, batch_loss: 0.2281, loss: 0.3084 ||:  86%|########6 | 9728/11253 [18:28<02:50,  8.97it/s]
2022-03-21 03:20:29,822 - INFO - tqdm - f1: 0.8322, accuracy: 0.8880, batch_loss: 0.3730, loss: 0.3085 ||:  87%|########7 | 9813/11253 [18:38<02:41,  8.94it/s]
2022-03-21 03:20:39,925 - INFO - tqdm - f1: 0.8323, accuracy: 0.8881, batch_loss: 0.6508, loss: 0.3084 ||:  88%|########8 | 9904/11253 [18:48<02:26,  9.21it/s]
2022-03-21 03:20:50,039 - INFO - tqdm - f1: 0.8324, accuracy: 0.8881, batch_loss: 0.3172, loss: 0.3082 ||:  89%|########8 | 9991/11253 [18:58<02:31,  8.35it/s]
2022-03-21 03:21:00,088 - INFO - tqdm - f1: 0.8326, accuracy: 0.8882, batch_loss: 0.6763, loss: 0.3081 ||:  90%|########9 | 10081/11253 [19:08<02:15,  8.63it/s]
2022-03-21 03:21:10,163 - INFO - tqdm - f1: 0.8326, accuracy: 0.8882, batch_loss: 0.0226, loss: 0.3082 ||:  90%|######### | 10169/11253 [19:18<02:07,  8.51it/s]
2022-03-21 03:21:20,264 - INFO - tqdm - f1: 0.8326, accuracy: 0.8882, batch_loss: 0.4376, loss: 0.3082 ||:  91%|#########1| 10261/11253 [19:28<01:48,  9.10it/s]
2022-03-21 03:21:30,440 - INFO - tqdm - f1: 0.8326, accuracy: 0.8883, batch_loss: 0.3440, loss: 0.3080 ||:  92%|#########1| 10349/11253 [19:39<01:36,  9.35it/s]
2022-03-21 03:21:40,453 - INFO - tqdm - f1: 0.8326, accuracy: 0.8882, batch_loss: 0.2768, loss: 0.3081 ||:  93%|#########2| 10438/11253 [19:49<01:38,  8.28it/s]
2022-03-21 03:21:50,507 - INFO - tqdm - f1: 0.8327, accuracy: 0.8883, batch_loss: 0.1957, loss: 0.3078 ||:  94%|#########3| 10525/11253 [19:59<01:37,  7.47it/s]
2022-03-21 03:22:00,512 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.4521, loss: 0.3081 ||:  94%|#########4| 10610/11253 [20:09<01:08,  9.43it/s]
2022-03-21 03:22:10,554 - INFO - tqdm - f1: 0.8326, accuracy: 0.8883, batch_loss: 0.0153, loss: 0.3079 ||:  95%|#########5| 10703/11253 [20:19<01:00,  9.05it/s]
2022-03-21 03:22:20,577 - INFO - tqdm - f1: 0.8326, accuracy: 0.8883, batch_loss: 0.1398, loss: 0.3080 ||:  96%|#########5| 10787/11253 [20:29<00:53,  8.69it/s]
2022-03-21 03:22:30,715 - INFO - tqdm - f1: 0.8327, accuracy: 0.8884, batch_loss: 0.3941, loss: 0.3079 ||:  97%|#########6| 10878/11253 [20:39<00:40,  9.23it/s]
2022-03-21 03:22:40,875 - INFO - tqdm - f1: 0.8327, accuracy: 0.8884, batch_loss: 0.4868, loss: 0.3080 ||:  97%|#########7| 10963/11253 [20:49<00:33,  8.64it/s]
2022-03-21 03:22:50,953 - INFO - tqdm - f1: 0.8327, accuracy: 0.8883, batch_loss: 0.2381, loss: 0.3082 ||:  98%|#########8| 11054/11253 [20:59<00:23,  8.60it/s]
2022-03-21 03:23:01,050 - INFO - tqdm - f1: 0.8325, accuracy: 0.8882, batch_loss: 0.1818, loss: 0.3085 ||:  99%|#########8| 11139/11253 [21:09<00:13,  8.33it/s]
2022-03-21 03:23:07,417 - INFO - tqdm - f1: 0.8323, accuracy: 0.8881, batch_loss: 0.3831, loss: 0.3087 ||: 100%|#########9| 11197/11253 [21:16<00:05,  9.49it/s]
2022-03-21 03:23:07,518 - INFO - tqdm - f1: 0.8323, accuracy: 0.8881, batch_loss: 0.2377, loss: 0.3087 ||: 100%|#########9| 11198/11253 [21:16<00:05,  9.57it/s]
2022-03-21 03:23:07,629 - INFO - tqdm - f1: 0.8323, accuracy: 0.8881, batch_loss: 0.2936, loss: 0.3087 ||: 100%|#########9| 11199/11253 [21:16<00:05,  9.43it/s]
2022-03-21 03:23:07,747 - INFO - tqdm - f1: 0.8323, accuracy: 0.8881, batch_loss: 0.2556, loss: 0.3087 ||: 100%|#########9| 11200/11253 [21:16<00:05,  9.15it/s]
2022-03-21 03:23:07,871 - INFO - tqdm - f1: 0.8323, accuracy: 0.8881, batch_loss: 0.0626, loss: 0.3087 ||: 100%|#########9| 11201/11253 [21:16<00:05,  8.80it/s]
2022-03-21 03:23:07,972 - INFO - tqdm - f1: 0.8323, accuracy: 0.8881, batch_loss: 0.2046, loss: 0.3087 ||: 100%|#########9| 11202/11253 [21:16<00:05,  9.10it/s]
2022-03-21 03:23:08,114 - INFO - tqdm - f1: 0.8324, accuracy: 0.8881, batch_loss: 0.0291, loss: 0.3087 ||: 100%|#########9| 11203/11253 [21:16<00:05,  8.39it/s]
2022-03-21 03:23:08,236 - INFO - tqdm - f1: 0.8323, accuracy: 0.8881, batch_loss: 0.2581, loss: 0.3086 ||: 100%|#########9| 11204/11253 [21:16<00:05,  8.33it/s]
2022-03-21 03:23:08,350 - INFO - tqdm - f1: 0.8324, accuracy: 0.8881, batch_loss: 0.0556, loss: 0.3086 ||: 100%|#########9| 11205/11253 [21:16<00:05,  8.46it/s]
2022-03-21 03:23:08,481 - INFO - tqdm - f1: 0.8324, accuracy: 0.8881, batch_loss: 0.0505, loss: 0.3086 ||: 100%|#########9| 11206/11253 [21:17<00:05,  8.19it/s]
2022-03-21 03:23:08,589 - INFO - tqdm - f1: 0.8324, accuracy: 0.8881, batch_loss: 0.4381, loss: 0.3086 ||: 100%|#########9| 11207/11253 [21:17<00:05,  8.48it/s]
2022-03-21 03:23:08,693 - INFO - tqdm - f1: 0.8324, accuracy: 0.8881, batch_loss: 0.3855, loss: 0.3086 ||: 100%|#########9| 11208/11253 [21:17<00:05,  8.79it/s]
2022-03-21 03:23:08,804 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.0280, loss: 0.3086 ||: 100%|#########9| 11209/11253 [21:17<00:04,  8.85it/s]
2022-03-21 03:23:08,952 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.2926, loss: 0.3086 ||: 100%|#########9| 11210/11253 [21:17<00:05,  8.10it/s]
2022-03-21 03:23:09,074 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.0949, loss: 0.3086 ||: 100%|#########9| 11211/11253 [21:17<00:05,  8.14it/s]
2022-03-21 03:23:09,198 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.2152, loss: 0.3086 ||: 100%|#########9| 11212/11253 [21:17<00:05,  8.12it/s]
2022-03-21 03:23:09,399 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.3812, loss: 0.3086 ||: 100%|#########9| 11214/11253 [21:17<00:04,  8.87it/s]
2022-03-21 03:23:09,505 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.6226, loss: 0.3086 ||: 100%|#########9| 11215/11253 [21:18<00:04,  9.01it/s]
2022-03-21 03:23:09,644 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.1772, loss: 0.3086 ||: 100%|#########9| 11216/11253 [21:18<00:04,  8.45it/s]
2022-03-21 03:23:09,749 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.5217, loss: 0.3086 ||: 100%|#########9| 11217/11253 [21:18<00:04,  8.72it/s]
2022-03-21 03:23:09,863 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.3084, loss: 0.3086 ||: 100%|#########9| 11218/11253 [21:18<00:04,  8.72it/s]
2022-03-21 03:23:09,970 - INFO - tqdm - f1: 0.8324, accuracy: 0.8881, batch_loss: 0.3147, loss: 0.3086 ||: 100%|#########9| 11219/11253 [21:18<00:03,  8.89it/s]
2022-03-21 03:23:10,109 - INFO - tqdm - f1: 0.8324, accuracy: 0.8881, batch_loss: 0.4378, loss: 0.3086 ||: 100%|#########9| 11220/11253 [21:18<00:03,  8.32it/s]
2022-03-21 03:23:10,222 - INFO - tqdm - f1: 0.8324, accuracy: 0.8881, batch_loss: 0.5892, loss: 0.3087 ||: 100%|#########9| 11221/11253 [21:18<00:03,  8.47it/s]
2022-03-21 03:23:10,342 - INFO - tqdm - f1: 0.8324, accuracy: 0.8881, batch_loss: 0.0751, loss: 0.3086 ||: 100%|#########9| 11222/11253 [21:18<00:03,  8.43it/s]
2022-03-21 03:23:10,454 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.0599, loss: 0.3086 ||: 100%|#########9| 11223/11253 [21:19<00:03,  8.58it/s]
2022-03-21 03:23:10,560 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.0784, loss: 0.3086 ||: 100%|#########9| 11224/11253 [21:19<00:03,  8.82it/s]
2022-03-21 03:23:10,700 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.0859, loss: 0.3086 ||: 100%|#########9| 11225/11253 [21:19<00:03,  8.23it/s]
2022-03-21 03:23:10,817 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.4729, loss: 0.3086 ||: 100%|#########9| 11226/11253 [21:19<00:03,  8.33it/s]
2022-03-21 03:23:10,930 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.3461, loss: 0.3086 ||: 100%|#########9| 11227/11253 [21:19<00:03,  8.48it/s]
2022-03-21 03:23:11,037 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.4034, loss: 0.3086 ||: 100%|#########9| 11228/11253 [21:19<00:02,  8.72it/s]
2022-03-21 03:23:11,147 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.1621, loss: 0.3086 ||: 100%|#########9| 11229/11253 [21:19<00:02,  8.84it/s]
2022-03-21 03:23:11,250 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.1962, loss: 0.3086 ||: 100%|#########9| 11230/11253 [21:19<00:02,  9.07it/s]
2022-03-21 03:23:11,359 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.1431, loss: 0.3086 ||: 100%|#########9| 11231/11253 [21:19<00:02,  9.11it/s]
2022-03-21 03:23:11,567 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.4716, loss: 0.3086 ||: 100%|#########9| 11233/11253 [21:20<00:02,  9.34it/s]
2022-03-21 03:23:11,677 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.0814, loss: 0.3086 ||: 100%|#########9| 11234/11253 [21:20<00:02,  9.27it/s]
2022-03-21 03:23:11,788 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.3624, loss: 0.3086 ||: 100%|#########9| 11235/11253 [21:20<00:01,  9.22it/s]
2022-03-21 03:23:11,903 - INFO - tqdm - f1: 0.8324, accuracy: 0.8881, batch_loss: 0.4779, loss: 0.3086 ||: 100%|#########9| 11236/11253 [21:20<00:01,  9.06it/s]
2022-03-21 03:23:12,006 - INFO - tqdm - f1: 0.8324, accuracy: 0.8881, batch_loss: 0.2144, loss: 0.3086 ||: 100%|#########9| 11237/11253 [21:20<00:01,  9.22it/s]
2022-03-21 03:23:12,114 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.1865, loss: 0.3086 ||: 100%|#########9| 11238/11253 [21:20<00:01,  9.25it/s]
2022-03-21 03:23:12,226 - INFO - tqdm - f1: 0.8323, accuracy: 0.8881, batch_loss: 0.4704, loss: 0.3086 ||: 100%|#########9| 11239/11253 [21:20<00:01,  9.15it/s]
2022-03-21 03:23:12,330 - INFO - tqdm - f1: 0.8323, accuracy: 0.8881, batch_loss: 0.3279, loss: 0.3086 ||: 100%|#########9| 11240/11253 [21:20<00:01,  9.28it/s]
2022-03-21 03:23:12,460 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.1122, loss: 0.3086 ||: 100%|#########9| 11241/11253 [21:21<00:01,  8.74it/s]
2022-03-21 03:23:12,578 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.1098, loss: 0.3085 ||: 100%|#########9| 11242/11253 [21:21<00:01,  8.66it/s]
2022-03-21 03:23:12,680 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.1220, loss: 0.3085 ||: 100%|#########9| 11243/11253 [21:21<00:01,  8.98it/s]
2022-03-21 03:23:12,824 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.1410, loss: 0.3085 ||: 100%|#########9| 11244/11253 [21:21<00:01,  8.24it/s]
2022-03-21 03:23:12,937 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.0926, loss: 0.3085 ||: 100%|#########9| 11245/11253 [21:21<00:00,  8.43it/s]
2022-03-21 03:23:13,037 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.3092, loss: 0.3085 ||: 100%|#########9| 11246/11253 [21:21<00:00,  8.84it/s]
2022-03-21 03:23:13,142 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.1225, loss: 0.3085 ||: 100%|#########9| 11247/11253 [21:21<00:00,  9.05it/s]
2022-03-21 03:23:13,247 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.1688, loss: 0.3085 ||: 100%|#########9| 11248/11253 [21:21<00:00,  9.18it/s]
2022-03-21 03:23:13,347 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.0736, loss: 0.3084 ||: 100%|#########9| 11249/11253 [21:21<00:00,  9.41it/s]
2022-03-21 03:23:13,455 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.2020, loss: 0.3084 ||: 100%|#########9| 11250/11253 [21:22<00:00,  9.35it/s]
2022-03-21 03:23:13,557 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.3524, loss: 0.3084 ||: 100%|#########9| 11251/11253 [21:22<00:00,  9.49it/s]
2022-03-21 03:23:13,691 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.2692, loss: 0.3084 ||: 100%|#########9| 11252/11253 [21:22<00:00,  8.78it/s]
2022-03-21 03:23:13,815 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.2345, loss: 0.3084 ||: 100%|##########| 11253/11253 [21:22<00:00,  8.55it/s]
2022-03-21 03:23:13,880 - INFO - tqdm - f1: 0.8324, accuracy: 0.8882, batch_loss: 0.2345, loss: 0.3084 ||: 100%|##########| 11253/11253 [21:22<00:00,  8.77it/s]
2022-03-21 03:23:13,895 - INFO - allennlp.training.trainer - Validating
2022-03-21 03:23:13,897 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 03:23:24,001 - INFO - tqdm - f1: 0.8019, accuracy: 0.8644, batch_loss: 0.7030, loss: 0.3832 ||:   9%|9         | 177/1889 [00:10<01:45, 16.25it/s]
2022-03-21 03:23:34,052 - INFO - tqdm - f1: 0.7999, accuracy: 0.8653, batch_loss: 0.0763, loss: 0.3841 ||:  19%|#9        | 362/1889 [00:20<01:22, 18.45it/s]
2022-03-21 03:23:44,057 - INFO - tqdm - f1: 0.8008, accuracy: 0.8678, batch_loss: 0.1515, loss: 0.3809 ||:  28%|##8       | 535/1889 [00:30<01:13, 18.42it/s]
2022-03-21 03:23:54,156 - INFO - tqdm - f1: 0.8038, accuracy: 0.8688, batch_loss: 0.4764, loss: 0.3841 ||:  38%|###8      | 721/1889 [00:40<01:08, 17.09it/s]
2022-03-21 03:24:04,244 - INFO - tqdm - f1: 0.8019, accuracy: 0.8680, batch_loss: 0.1550, loss: 0.3866 ||:  48%|####7     | 898/1889 [00:50<00:55, 17.96it/s]
2022-03-21 03:24:14,332 - INFO - tqdm - f1: 0.8046, accuracy: 0.8682, batch_loss: 0.1483, loss: 0.3868 ||:  57%|#####7    | 1078/1889 [01:00<00:48, 16.78it/s]
2022-03-21 03:24:24,464 - INFO - tqdm - f1: 0.8037, accuracy: 0.8663, batch_loss: 0.6602, loss: 0.3921 ||:  66%|######6   | 1255/1889 [01:10<00:36, 17.57it/s]
2022-03-21 03:24:34,515 - INFO - tqdm - f1: 0.8048, accuracy: 0.8664, batch_loss: 0.5220, loss: 0.3910 ||:  76%|#######5  | 1434/1889 [01:20<00:21, 20.79it/s]
2022-03-21 03:24:44,573 - INFO - tqdm - f1: 0.8049, accuracy: 0.8664, batch_loss: 0.5749, loss: 0.3916 ||:  85%|########5 | 1611/1889 [01:30<00:15, 18.41it/s]
2022-03-21 03:24:54,580 - INFO - tqdm - f1: 0.8059, accuracy: 0.8665, batch_loss: 0.3588, loss: 0.3902 ||:  95%|#########4| 1790/1889 [01:40<00:05, 18.47it/s]
2022-03-21 03:24:59,640 - INFO - tqdm - f1: 0.8059, accuracy: 0.8667, batch_loss: 0.0385, loss: 0.3894 ||: 100%|#########9| 1882/1889 [01:45<00:00, 19.25it/s]
2022-03-21 03:24:59,748 - INFO - tqdm - f1: 0.8059, accuracy: 0.8667, batch_loss: 0.3461, loss: 0.3893 ||: 100%|#########9| 1884/1889 [01:45<00:00, 19.05it/s]
2022-03-21 03:24:59,883 - INFO - tqdm - f1: 0.8061, accuracy: 0.8668, batch_loss: 0.6755, loss: 0.3893 ||: 100%|#########9| 1886/1889 [01:45<00:00, 17.72it/s]
2022-03-21 03:25:00,040 - INFO - tqdm - f1: 0.8060, accuracy: 0.8667, batch_loss: 0.5513, loss: 0.3894 ||: 100%|#########9| 1888/1889 [01:46<00:00, 16.01it/s]
2022-03-21 03:25:00,135 - INFO - tqdm - f1: 0.8059, accuracy: 0.8667, batch_loss: 0.1816, loss: 0.3893 ||: 100%|##########| 1889/1889 [01:46<00:00, 17.78it/s]
2022-03-21 03:25:00,174 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 03:25:00,176 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.888  |     0.867
2022-03-21 03:25:00,178 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.832  |     0.806
2022-03-21 03:25:00,179 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 03:25:00,181 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.308  |     0.389
2022-03-21 03:25:00,183 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8639.090  |       N/A
2022-03-21 03:25:00,184 - INFO - allennlp.training.trainer - Epoch duration: 0:23:08.789058
2022-03-21 03:25:00,186 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:27:30
2022-03-21 03:25:00,188 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-21 03:25:00,190 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 03:25:00,191 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 03:25:00,194 - INFO - allennlp.training.trainer - Training
2022-03-21 03:25:00,196 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 03:25:10,304 - INFO - tqdm - f1: 0.8350, accuracy: 0.9062, batch_loss: 0.1818, loss: 0.2353 ||:   1%|          | 78/11253 [00:10<21:50,  8.53it/s]
2022-03-21 03:25:20,381 - INFO - tqdm - f1: 0.8531, accuracy: 0.9087, batch_loss: 0.0307, loss: 0.2434 ||:   2%|1         | 169/11253 [00:20<21:40,  8.52it/s]
2022-03-21 03:25:30,483 - INFO - tqdm - f1: 0.8476, accuracy: 0.9077, batch_loss: 0.1006, loss: 0.2443 ||:   2%|2         | 254/11253 [00:30<19:57,  9.19it/s]
2022-03-21 03:25:40,565 - INFO - tqdm - f1: 0.8452, accuracy: 0.9032, batch_loss: 0.2486, loss: 0.2583 ||:   3%|3         | 346/11253 [00:40<20:18,  8.95it/s]
2022-03-21 03:25:50,671 - INFO - tqdm - f1: 0.8423, accuracy: 0.8993, batch_loss: 0.1954, loss: 0.2700 ||:   4%|3         | 434/11253 [00:50<20:22,  8.85it/s]
2022-03-21 03:26:00,770 - INFO - tqdm - f1: 0.8445, accuracy: 0.9012, batch_loss: 0.1129, loss: 0.2640 ||:   5%|4         | 525/11253 [01:00<18:49,  9.50it/s]
2022-03-21 03:26:10,799 - INFO - tqdm - f1: 0.8465, accuracy: 0.9022, batch_loss: 0.1366, loss: 0.2618 ||:   5%|5         | 615/11253 [01:10<26:41,  6.64it/s]
2022-03-21 03:26:20,921 - INFO - tqdm - f1: 0.8466, accuracy: 0.9025, batch_loss: 0.2511, loss: 0.2606 ||:   6%|6         | 701/11253 [01:20<19:18,  9.11it/s]
2022-03-21 03:26:30,990 - INFO - tqdm - f1: 0.8465, accuracy: 0.9016, batch_loss: 0.6345, loss: 0.2615 ||:   7%|7         | 790/11253 [01:30<20:42,  8.42it/s]
2022-03-21 03:26:41,040 - INFO - tqdm - f1: 0.8461, accuracy: 0.9023, batch_loss: 0.2254, loss: 0.2590 ||:   8%|7         | 876/11253 [01:40<18:43,  9.24it/s]
2022-03-21 03:26:51,127 - INFO - tqdm - f1: 0.8467, accuracy: 0.9024, batch_loss: 0.2826, loss: 0.2574 ||:   9%|8         | 966/11253 [01:50<18:42,  9.16it/s]
2022-03-21 03:27:01,243 - INFO - tqdm - f1: 0.8458, accuracy: 0.9016, batch_loss: 0.0804, loss: 0.2598 ||:   9%|9         | 1052/11253 [02:01<20:08,  8.44it/s]
2022-03-21 03:27:11,288 - INFO - tqdm - f1: 0.8465, accuracy: 0.9017, batch_loss: 0.7542, loss: 0.2592 ||:  10%|#         | 1142/11253 [02:11<17:58,  9.37it/s]
2022-03-21 03:27:21,336 - INFO - tqdm - f1: 0.8473, accuracy: 0.9023, batch_loss: 0.2123, loss: 0.2585 ||:  11%|#         | 1229/11253 [02:21<16:58,  9.84it/s]
2022-03-21 03:27:31,349 - INFO - tqdm - f1: 0.8472, accuracy: 0.9021, batch_loss: 0.2918, loss: 0.2599 ||:  12%|#1        | 1319/11253 [02:31<16:59,  9.75it/s]
2022-03-21 03:27:41,376 - INFO - tqdm - f1: 0.8487, accuracy: 0.9032, batch_loss: 0.4890, loss: 0.2580 ||:  12%|#2        | 1405/11253 [02:41<18:09,  9.04it/s]
2022-03-21 03:27:51,380 - INFO - tqdm - f1: 0.8488, accuracy: 0.9028, batch_loss: 0.1148, loss: 0.2587 ||:  13%|#3        | 1494/11253 [02:51<20:09,  8.07it/s]
2022-03-21 03:28:01,437 - INFO - tqdm - f1: 0.8478, accuracy: 0.9021, batch_loss: 0.0593, loss: 0.2608 ||:  14%|#4        | 1582/11253 [03:01<20:16,  7.95it/s]
2022-03-21 03:28:11,531 - INFO - tqdm - f1: 0.8476, accuracy: 0.9020, batch_loss: 0.0879, loss: 0.2606 ||:  15%|#4        | 1668/11253 [03:11<16:55,  9.44it/s]
2022-03-21 03:28:21,655 - INFO - tqdm - f1: 0.8472, accuracy: 0.9021, batch_loss: 0.2070, loss: 0.2617 ||:  16%|#5        | 1760/11253 [03:21<16:18,  9.70it/s]
2022-03-21 03:28:31,736 - INFO - tqdm - f1: 0.8472, accuracy: 0.9025, batch_loss: 0.2242, loss: 0.2606 ||:  16%|#6        | 1848/11253 [03:31<16:30,  9.49it/s]
2022-03-21 03:28:41,752 - INFO - tqdm - f1: 0.8471, accuracy: 0.9026, batch_loss: 0.6472, loss: 0.2598 ||:  17%|#7        | 1937/11253 [03:41<15:55,  9.75it/s]
2022-03-21 03:28:51,854 - INFO - tqdm - f1: 0.8476, accuracy: 0.9030, batch_loss: 0.0650, loss: 0.2590 ||:  18%|#7        | 2021/11253 [03:51<17:20,  8.88it/s]
2022-03-21 03:29:02,011 - INFO - tqdm - f1: 0.8473, accuracy: 0.9027, batch_loss: 0.1940, loss: 0.2599 ||:  19%|#8        | 2110/11253 [04:01<16:29,  9.24it/s]
2022-03-21 03:29:12,182 - INFO - tqdm - f1: 0.8475, accuracy: 0.9030, batch_loss: 0.4141, loss: 0.2591 ||:  20%|#9        | 2199/11253 [04:11<15:44,  9.58it/s]
2022-03-21 03:29:22,196 - INFO - tqdm - f1: 0.8479, accuracy: 0.9033, batch_loss: 0.1292, loss: 0.2590 ||:  20%|##        | 2288/11253 [04:21<19:32,  7.65it/s]
2022-03-21 03:29:32,257 - INFO - tqdm - f1: 0.8472, accuracy: 0.9027, batch_loss: 0.3473, loss: 0.2601 ||:  21%|##1       | 2378/11253 [04:32<23:22,  6.33it/s]
2022-03-21 03:29:42,343 - INFO - tqdm - f1: 0.8469, accuracy: 0.9028, batch_loss: 0.3074, loss: 0.2594 ||:  22%|##1       | 2466/11253 [04:42<17:00,  8.61it/s]
2022-03-21 03:29:52,428 - INFO - tqdm - f1: 0.8472, accuracy: 0.9032, batch_loss: 0.0627, loss: 0.2587 ||:  23%|##2       | 2558/11253 [04:52<15:08,  9.57it/s]
2022-03-21 03:30:02,631 - INFO - tqdm - f1: 0.8469, accuracy: 0.9028, batch_loss: 0.2500, loss: 0.2592 ||:  24%|##3       | 2650/11253 [05:02<15:23,  9.31it/s]
2022-03-21 03:30:12,686 - INFO - tqdm - f1: 0.8474, accuracy: 0.9028, batch_loss: 0.1385, loss: 0.2598 ||:  24%|##4       | 2739/11253 [05:12<17:02,  8.32it/s]
2022-03-21 03:30:22,687 - INFO - tqdm - f1: 0.8469, accuracy: 0.9023, batch_loss: 0.1280, loss: 0.2610 ||:  25%|##5       | 2826/11253 [05:22<14:28,  9.70it/s]
2022-03-21 03:30:32,828 - INFO - tqdm - f1: 0.8465, accuracy: 0.9022, batch_loss: 0.3299, loss: 0.2614 ||:  26%|##5       | 2916/11253 [05:32<14:11,  9.79it/s]
2022-03-21 03:30:42,914 - INFO - tqdm - f1: 0.8464, accuracy: 0.9023, batch_loss: 0.3458, loss: 0.2617 ||:  27%|##6       | 3002/11253 [05:42<15:02,  9.14it/s]
2022-03-21 03:30:53,022 - INFO - tqdm - f1: 0.8461, accuracy: 0.9021, batch_loss: 0.0087, loss: 0.2624 ||:  28%|##7       | 3095/11253 [05:52<16:35,  8.20it/s]
2022-03-21 03:31:03,049 - INFO - tqdm - f1: 0.8463, accuracy: 0.9023, batch_loss: 0.5783, loss: 0.2624 ||:  28%|##8       | 3184/11253 [06:02<23:18,  5.77it/s]
2022-03-21 03:31:13,212 - INFO - tqdm - f1: 0.8462, accuracy: 0.9019, batch_loss: 0.2430, loss: 0.2633 ||:  29%|##9       | 3275/11253 [06:13<14:08,  9.40it/s]
2022-03-21 03:31:23,300 - INFO - tqdm - f1: 0.8460, accuracy: 0.9018, batch_loss: 0.2247, loss: 0.2638 ||:  30%|##9       | 3361/11253 [06:23<16:32,  7.95it/s]
2022-03-21 03:31:33,308 - INFO - tqdm - f1: 0.8463, accuracy: 0.9018, batch_loss: 0.6781, loss: 0.2640 ||:  31%|###       | 3446/11253 [06:33<14:27,  9.00it/s]
2022-03-21 03:31:43,482 - INFO - tqdm - f1: 0.8461, accuracy: 0.9016, batch_loss: 0.3281, loss: 0.2646 ||:  31%|###1      | 3538/11253 [06:43<13:42,  9.38it/s]
2022-03-21 03:31:53,528 - INFO - tqdm - f1: 0.8459, accuracy: 0.9015, batch_loss: 0.0482, loss: 0.2644 ||:  32%|###2      | 3625/11253 [06:53<16:41,  7.62it/s]
2022-03-21 03:32:03,622 - INFO - tqdm - f1: 0.8465, accuracy: 0.9016, batch_loss: 0.2568, loss: 0.2647 ||:  33%|###3      | 3717/11253 [07:03<13:50,  9.08it/s]
2022-03-21 03:32:13,707 - INFO - tqdm - f1: 0.8464, accuracy: 0.9014, batch_loss: 0.3093, loss: 0.2656 ||:  34%|###3      | 3804/11253 [07:13<13:45,  9.03it/s]
2022-03-21 03:32:23,798 - INFO - tqdm - f1: 0.8465, accuracy: 0.9013, batch_loss: 0.5407, loss: 0.2660 ||:  35%|###4      | 3894/11253 [07:23<14:03,  8.72it/s]
2022-03-21 03:32:33,830 - INFO - tqdm - f1: 0.8463, accuracy: 0.9012, batch_loss: 0.2420, loss: 0.2665 ||:  35%|###5      | 3979/11253 [07:33<14:28,  8.38it/s]
2022-03-21 03:32:43,850 - INFO - tqdm - f1: 0.8466, accuracy: 0.9013, batch_loss: 0.1474, loss: 0.2664 ||:  36%|###6      | 4067/11253 [07:43<14:23,  8.32it/s]
2022-03-21 03:32:53,859 - INFO - tqdm - f1: 0.8467, accuracy: 0.9013, batch_loss: 0.4346, loss: 0.2668 ||:  37%|###6      | 4154/11253 [07:53<12:46,  9.26it/s]
2022-03-21 03:33:03,925 - INFO - tqdm - f1: 0.8469, accuracy: 0.9011, batch_loss: 0.0602, loss: 0.2674 ||:  38%|###7      | 4242/11253 [08:03<14:02,  8.33it/s]
2022-03-21 03:33:13,953 - INFO - tqdm - f1: 0.8468, accuracy: 0.9009, batch_loss: 0.2580, loss: 0.2679 ||:  39%|###8      | 4333/11253 [08:13<12:41,  9.08it/s]
2022-03-21 03:33:23,977 - INFO - tqdm - f1: 0.8464, accuracy: 0.9008, batch_loss: 0.0182, loss: 0.2678 ||:  39%|###9      | 4420/11253 [08:23<12:09,  9.37it/s]
2022-03-21 03:33:34,151 - INFO - tqdm - f1: 0.8465, accuracy: 0.9008, batch_loss: 0.1315, loss: 0.2679 ||:  40%|####      | 4513/11253 [08:33<12:01,  9.35it/s]
2022-03-21 03:33:44,231 - INFO - tqdm - f1: 0.8460, accuracy: 0.9006, batch_loss: 0.1573, loss: 0.2686 ||:  41%|####      | 4600/11253 [08:44<12:39,  8.76it/s]
2022-03-21 03:33:54,284 - INFO - tqdm - f1: 0.8459, accuracy: 0.9004, batch_loss: 0.1695, loss: 0.2689 ||:  42%|####1     | 4689/11253 [08:54<13:13,  8.28it/s]
2022-03-21 03:34:04,361 - INFO - tqdm - f1: 0.8460, accuracy: 0.9006, batch_loss: 0.1779, loss: 0.2688 ||:  42%|####2     | 4776/11253 [09:04<11:49,  9.12it/s]
2022-03-21 03:34:14,382 - INFO - tqdm - f1: 0.8460, accuracy: 0.9004, batch_loss: 0.2156, loss: 0.2690 ||:  43%|####3     | 4866/11253 [09:14<11:37,  9.16it/s]
2022-03-21 03:34:24,517 - INFO - tqdm - f1: 0.8464, accuracy: 0.9006, batch_loss: 0.0725, loss: 0.2687 ||:  44%|####4     | 4956/11253 [09:24<16:23,  6.40it/s]
2022-03-21 03:34:34,661 - INFO - tqdm - f1: 0.8460, accuracy: 0.9006, batch_loss: 0.2587, loss: 0.2689 ||:  45%|####4     | 5047/11253 [09:34<10:36,  9.75it/s]
2022-03-21 03:34:44,687 - INFO - tqdm - f1: 0.8459, accuracy: 0.9004, batch_loss: 0.1341, loss: 0.2691 ||:  46%|####5     | 5136/11253 [09:44<10:51,  9.39it/s]
2022-03-21 03:34:54,713 - INFO - tqdm - f1: 0.8463, accuracy: 0.9006, batch_loss: 0.1099, loss: 0.2692 ||:  46%|####6     | 5221/11253 [09:54<11:30,  8.73it/s]
2022-03-21 03:35:04,731 - INFO - tqdm - f1: 0.8463, accuracy: 0.9005, batch_loss: 0.2393, loss: 0.2695 ||:  47%|####7     | 5308/11253 [10:04<10:48,  9.17it/s]
2022-03-21 03:35:14,783 - INFO - tqdm - f1: 0.8461, accuracy: 0.9005, batch_loss: 0.2042, loss: 0.2695 ||:  48%|####7     | 5396/11253 [10:14<11:25,  8.55it/s]
2022-03-21 03:35:24,871 - INFO - tqdm - f1: 0.8462, accuracy: 0.9005, batch_loss: 0.4221, loss: 0.2697 ||:  49%|####8     | 5485/11253 [10:24<10:23,  9.24it/s]
2022-03-21 03:35:35,054 - INFO - tqdm - f1: 0.8460, accuracy: 0.9004, batch_loss: 0.4653, loss: 0.2698 ||:  50%|####9     | 5572/11253 [10:34<09:52,  9.58it/s]
2022-03-21 03:35:45,075 - INFO - tqdm - f1: 0.8459, accuracy: 0.9003, batch_loss: 0.5453, loss: 0.2704 ||:  50%|#####     | 5665/11253 [10:44<09:07, 10.20it/s]
2022-03-21 03:35:55,256 - INFO - tqdm - f1: 0.8460, accuracy: 0.9003, batch_loss: 0.2869, loss: 0.2703 ||:  51%|#####1    | 5753/11253 [10:55<09:53,  9.26it/s]
2022-03-21 03:36:05,290 - INFO - tqdm - f1: 0.8459, accuracy: 0.9002, batch_loss: 0.0901, loss: 0.2705 ||:  52%|#####1    | 5844/11253 [11:05<10:30,  8.57it/s]
2022-03-21 03:36:15,412 - INFO - tqdm - f1: 0.8458, accuracy: 0.9002, batch_loss: 0.3682, loss: 0.2707 ||:  53%|#####2    | 5934/11253 [11:15<09:59,  8.87it/s]
2022-03-21 03:36:25,474 - INFO - tqdm - f1: 0.8458, accuracy: 0.9002, batch_loss: 0.2441, loss: 0.2708 ||:  53%|#####3    | 6020/11253 [11:25<09:35,  9.09it/s]
2022-03-21 03:36:35,574 - INFO - tqdm - f1: 0.8457, accuracy: 0.9000, batch_loss: 0.2189, loss: 0.2710 ||:  54%|#####4    | 6108/11253 [11:35<09:34,  8.96it/s]
2022-03-21 03:36:45,595 - INFO - tqdm - f1: 0.8458, accuracy: 0.9000, batch_loss: 0.0836, loss: 0.2713 ||:  55%|#####5    | 6191/11253 [11:45<10:08,  8.32it/s]
2022-03-21 03:36:55,765 - INFO - tqdm - f1: 0.8458, accuracy: 0.9000, batch_loss: 0.5965, loss: 0.2715 ||:  56%|#####5    | 6281/11253 [11:55<08:30,  9.74it/s]
2022-03-21 03:37:05,856 - INFO - tqdm - f1: 0.8457, accuracy: 0.8999, batch_loss: 0.2855, loss: 0.2720 ||:  57%|#####6    | 6367/11253 [12:05<08:30,  9.58it/s]
2022-03-21 03:37:15,956 - INFO - tqdm - f1: 0.8458, accuracy: 0.8999, batch_loss: 0.1876, loss: 0.2718 ||:  57%|#####7    | 6456/11253 [12:15<09:43,  8.23it/s]
2022-03-21 03:37:25,981 - INFO - tqdm - f1: 0.8457, accuracy: 0.8998, batch_loss: 0.1001, loss: 0.2718 ||:  58%|#####8    | 6541/11253 [12:25<08:51,  8.87it/s]
2022-03-21 03:37:36,081 - INFO - tqdm - f1: 0.8457, accuracy: 0.8998, batch_loss: 0.2335, loss: 0.2718 ||:  59%|#####8    | 6632/11253 [12:35<07:47,  9.89it/s]
2022-03-21 03:37:46,285 - INFO - tqdm - f1: 0.8455, accuracy: 0.8996, batch_loss: 0.4750, loss: 0.2723 ||:  60%|#####9    | 6723/11253 [12:46<08:08,  9.27it/s]
2022-03-21 03:37:56,440 - INFO - tqdm - f1: 0.8458, accuracy: 0.8998, batch_loss: 0.1509, loss: 0.2718 ||:  61%|######    | 6816/11253 [12:56<07:46,  9.50it/s]
2022-03-21 03:38:06,543 - INFO - tqdm - f1: 0.8457, accuracy: 0.8998, batch_loss: 0.0334, loss: 0.2722 ||:  61%|######1   | 6906/11253 [13:06<07:45,  9.34it/s]
2022-03-21 03:38:16,643 - INFO - tqdm - f1: 0.8456, accuracy: 0.8998, batch_loss: 0.3271, loss: 0.2723 ||:  62%|######2   | 6993/11253 [13:16<08:41,  8.16it/s]
2022-03-21 03:38:26,724 - INFO - tqdm - f1: 0.8453, accuracy: 0.8996, batch_loss: 0.2676, loss: 0.2725 ||:  63%|######2   | 7082/11253 [13:26<08:22,  8.29it/s]
2022-03-21 03:38:36,828 - INFO - tqdm - f1: 0.8453, accuracy: 0.8996, batch_loss: 0.0644, loss: 0.2728 ||:  64%|######3   | 7167/11253 [13:36<07:26,  9.15it/s]
2022-03-21 03:38:46,851 - INFO - tqdm - f1: 0.8454, accuracy: 0.8997, batch_loss: 0.0148, loss: 0.2726 ||:  65%|######4   | 7259/11253 [13:46<07:22,  9.04it/s]
2022-03-21 03:38:56,862 - INFO - tqdm - f1: 0.8452, accuracy: 0.8995, batch_loss: 0.1677, loss: 0.2731 ||:  65%|######5   | 7347/11253 [13:56<07:21,  8.85it/s]
2022-03-21 03:39:06,919 - INFO - tqdm - f1: 0.8450, accuracy: 0.8993, batch_loss: 0.1760, loss: 0.2733 ||:  66%|######6   | 7437/11253 [14:06<07:22,  8.62it/s]
2022-03-21 03:39:17,017 - INFO - tqdm - f1: 0.8449, accuracy: 0.8993, batch_loss: 0.2266, loss: 0.2737 ||:  67%|######6   | 7524/11253 [14:16<06:50,  9.08it/s]
2022-03-21 03:39:27,055 - INFO - tqdm - f1: 0.8449, accuracy: 0.8991, batch_loss: 0.2005, loss: 0.2742 ||:  68%|######7   | 7616/11253 [14:26<06:01, 10.06it/s]
2022-03-21 03:39:37,211 - INFO - tqdm - f1: 0.8448, accuracy: 0.8992, batch_loss: 0.1395, loss: 0.2740 ||:  68%|######8   | 7703/11253 [14:37<10:14,  5.78it/s]
2022-03-21 03:39:47,387 - INFO - tqdm - f1: 0.8448, accuracy: 0.8992, batch_loss: 0.2536, loss: 0.2740 ||:  69%|######9   | 7796/11253 [14:47<05:55,  9.73it/s]
2022-03-21 03:39:57,389 - INFO - tqdm - f1: 0.8451, accuracy: 0.8993, batch_loss: 0.0751, loss: 0.2738 ||:  70%|#######   | 7887/11253 [14:57<06:33,  8.56it/s]
2022-03-21 03:40:07,494 - INFO - tqdm - f1: 0.8448, accuracy: 0.8992, batch_loss: 0.3878, loss: 0.2740 ||:  71%|#######   | 7975/11253 [15:07<06:00,  9.10it/s]
2022-03-21 03:40:17,592 - INFO - tqdm - f1: 0.8449, accuracy: 0.8992, batch_loss: 0.1999, loss: 0.2741 ||:  72%|#######1  | 8066/11253 [15:17<06:06,  8.69it/s]
2022-03-21 03:40:27,597 - INFO - tqdm - f1: 0.8450, accuracy: 0.8992, batch_loss: 0.1395, loss: 0.2742 ||:  72%|#######2  | 8152/11253 [15:27<05:48,  8.91it/s]
2022-03-21 03:40:37,737 - INFO - tqdm - f1: 0.8449, accuracy: 0.8992, batch_loss: 0.3729, loss: 0.2742 ||:  73%|#######3  | 8242/11253 [15:37<06:08,  8.16it/s]
2022-03-21 03:40:47,849 - INFO - tqdm - f1: 0.8451, accuracy: 0.8993, batch_loss: 0.2682, loss: 0.2739 ||:  74%|#######4  | 8328/11253 [15:47<05:52,  8.30it/s]
2022-03-21 03:40:58,001 - INFO - tqdm - f1: 0.8450, accuracy: 0.8993, batch_loss: 0.1127, loss: 0.2738 ||:  75%|#######4  | 8418/11253 [15:57<05:19,  8.89it/s]
2022-03-21 03:41:08,025 - INFO - tqdm - f1: 0.8450, accuracy: 0.8994, batch_loss: 0.2544, loss: 0.2738 ||:  76%|#######5  | 8505/11253 [16:07<04:44,  9.67it/s]
2022-03-21 03:41:18,033 - INFO - tqdm - f1: 0.8449, accuracy: 0.8993, batch_loss: 0.4217, loss: 0.2737 ||:  76%|#######6  | 8593/11253 [16:17<05:25,  8.18it/s]
2022-03-21 03:41:28,153 - INFO - tqdm - f1: 0.8452, accuracy: 0.8995, batch_loss: 0.1908, loss: 0.2734 ||:  77%|#######7  | 8679/11253 [16:27<07:46,  5.52it/s]
2022-03-21 03:41:38,184 - INFO - tqdm - f1: 0.8452, accuracy: 0.8994, batch_loss: 0.5999, loss: 0.2736 ||:  78%|#######7  | 8770/11253 [16:37<04:42,  8.79it/s]
2022-03-21 03:41:48,256 - INFO - tqdm - f1: 0.8451, accuracy: 0.8993, batch_loss: 0.2319, loss: 0.2738 ||:  79%|#######8  | 8861/11253 [16:48<04:07,  9.66it/s]
2022-03-21 03:41:58,356 - INFO - tqdm - f1: 0.8452, accuracy: 0.8994, batch_loss: 0.3557, loss: 0.2738 ||:  80%|#######9  | 8949/11253 [16:58<04:02,  9.50it/s]
2022-03-21 03:42:08,424 - INFO - tqdm - f1: 0.8453, accuracy: 0.8994, batch_loss: 0.3357, loss: 0.2740 ||:  80%|########  | 9040/11253 [17:08<04:04,  9.05it/s]
2022-03-21 03:42:18,493 - INFO - tqdm - f1: 0.8453, accuracy: 0.8994, batch_loss: 0.6402, loss: 0.2742 ||:  81%|########1 | 9128/11253 [17:18<03:57,  8.93it/s]
2022-03-21 03:42:28,581 - INFO - tqdm - f1: 0.8451, accuracy: 0.8993, batch_loss: 0.1764, loss: 0.2746 ||:  82%|########1 | 9218/11253 [17:28<04:02,  8.37it/s]
2022-03-21 03:42:38,696 - INFO - tqdm - f1: 0.8450, accuracy: 0.8992, batch_loss: 0.0868, loss: 0.2748 ||:  83%|########2 | 9303/11253 [17:38<03:41,  8.82it/s]
2022-03-21 03:42:48,833 - INFO - tqdm - f1: 0.8449, accuracy: 0.8991, batch_loss: 0.4064, loss: 0.2751 ||:  83%|########3 | 9392/11253 [17:48<03:58,  7.79it/s]
2022-03-21 03:42:59,005 - INFO - tqdm - f1: 0.8449, accuracy: 0.8990, batch_loss: 0.2167, loss: 0.2751 ||:  84%|########4 | 9479/11253 [17:58<03:20,  8.86it/s]
2022-03-21 03:43:09,010 - INFO - tqdm - f1: 0.8449, accuracy: 0.8990, batch_loss: 0.3097, loss: 0.2750 ||:  85%|########5 | 9566/11253 [18:08<03:22,  8.34it/s]
2022-03-21 03:43:19,042 - INFO - tqdm - f1: 0.8447, accuracy: 0.8989, batch_loss: 0.4375, loss: 0.2752 ||:  86%|########5 | 9657/11253 [18:18<02:46,  9.59it/s]
2022-03-21 03:43:29,059 - INFO - tqdm - f1: 0.8446, accuracy: 0.8988, batch_loss: 0.0391, loss: 0.2756 ||:  87%|########6 | 9743/11253 [18:28<02:40,  9.41it/s]
2022-03-21 03:43:39,166 - INFO - tqdm - f1: 0.8445, accuracy: 0.8987, batch_loss: 0.2645, loss: 0.2758 ||:  87%|########7 | 9832/11253 [18:38<02:35,  9.17it/s]
2022-03-21 03:43:49,241 - INFO - tqdm - f1: 0.8444, accuracy: 0.8986, batch_loss: 0.1406, loss: 0.2759 ||:  88%|########8 | 9918/11253 [18:49<02:23,  9.32it/s]
2022-03-21 03:43:59,334 - INFO - tqdm - f1: 0.8445, accuracy: 0.8987, batch_loss: 0.2052, loss: 0.2759 ||:  89%|########8 | 10010/11253 [18:59<02:00, 10.31it/s]
2022-03-21 03:44:09,336 - INFO - tqdm - f1: 0.8446, accuracy: 0.8988, batch_loss: 0.0612, loss: 0.2756 ||:  90%|########9 | 10098/11253 [19:09<02:00,  9.57it/s]
2022-03-21 03:44:19,350 - INFO - tqdm - f1: 0.8447, accuracy: 0.8988, batch_loss: 0.0523, loss: 0.2755 ||:  91%|######### | 10187/11253 [19:19<01:52,  9.52it/s]
2022-03-21 03:44:29,533 - INFO - tqdm - f1: 0.8449, accuracy: 0.8989, batch_loss: 0.2842, loss: 0.2755 ||:  91%|#########1| 10274/11253 [19:29<01:39,  9.87it/s]
2022-03-21 03:44:39,632 - INFO - tqdm - f1: 0.8448, accuracy: 0.8989, batch_loss: 0.4837, loss: 0.2755 ||:  92%|#########2| 10364/11253 [19:39<01:37,  9.16it/s]
2022-03-21 03:44:49,810 - INFO - tqdm - f1: 0.8450, accuracy: 0.8989, batch_loss: 0.0711, loss: 0.2756 ||:  93%|#########2| 10449/11253 [19:49<02:31,  5.29it/s]
2022-03-21 03:44:59,881 - INFO - tqdm - f1: 0.8453, accuracy: 0.8990, batch_loss: 0.2870, loss: 0.2756 ||:  94%|#########3| 10541/11253 [19:59<01:25,  8.37it/s]
2022-03-21 03:45:09,903 - INFO - tqdm - f1: 0.8452, accuracy: 0.8990, batch_loss: 0.1909, loss: 0.2757 ||:  94%|#########4| 10630/11253 [20:09<01:14,  8.35it/s]
2022-03-21 03:45:19,924 - INFO - tqdm - f1: 0.8451, accuracy: 0.8989, batch_loss: 0.0719, loss: 0.2759 ||:  95%|#########5| 10716/11253 [20:19<01:02,  8.54it/s]
2022-03-21 03:45:30,088 - INFO - tqdm - f1: 0.8453, accuracy: 0.8990, batch_loss: 0.1627, loss: 0.2756 ||:  96%|#########6| 10806/11253 [20:29<00:53,  8.39it/s]
2022-03-21 03:45:40,259 - INFO - tqdm - f1: 0.8454, accuracy: 0.8990, batch_loss: 0.3661, loss: 0.2756 ||:  97%|#########6| 10890/11253 [20:40<00:43,  8.41it/s]
2022-03-21 03:45:50,309 - INFO - tqdm - f1: 0.8456, accuracy: 0.8991, batch_loss: 0.1226, loss: 0.2755 ||:  98%|#########7| 10979/11253 [20:50<00:33,  8.23it/s]
2022-03-21 03:46:00,404 - INFO - tqdm - f1: 0.8455, accuracy: 0.8991, batch_loss: 0.1397, loss: 0.2757 ||:  98%|#########8| 11064/11253 [21:00<00:20,  9.17it/s]
2022-03-21 03:46:10,544 - INFO - tqdm - f1: 0.8454, accuracy: 0.8990, batch_loss: 0.0521, loss: 0.2757 ||:  99%|#########9| 11157/11253 [21:10<00:11,  8.68it/s]
2022-03-21 03:46:14,997 - INFO - tqdm - f1: 0.8454, accuracy: 0.8990, batch_loss: 0.2198, loss: 0.2758 ||: 100%|#########9| 11198/11253 [21:14<00:05,  9.64it/s]
2022-03-21 03:46:15,111 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.4424, loss: 0.2758 ||: 100%|#########9| 11199/11253 [21:14<00:05,  9.43it/s]
2022-03-21 03:46:15,223 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.2468, loss: 0.2758 ||: 100%|#########9| 11200/11253 [21:15<00:05,  9.30it/s]
2022-03-21 03:46:15,435 - INFO - tqdm - f1: 0.8454, accuracy: 0.8990, batch_loss: 0.0710, loss: 0.2758 ||: 100%|#########9| 11202/11253 [21:15<00:05,  9.36it/s]
2022-03-21 03:46:15,550 - INFO - tqdm - f1: 0.8454, accuracy: 0.8990, batch_loss: 0.1954, loss: 0.2758 ||: 100%|#########9| 11203/11253 [21:15<00:05,  9.19it/s]
2022-03-21 03:46:15,788 - INFO - tqdm - f1: 0.8454, accuracy: 0.8990, batch_loss: 0.3165, loss: 0.2758 ||: 100%|#########9| 11205/11253 [21:15<00:05,  8.88it/s]
2022-03-21 03:46:15,937 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.5871, loss: 0.2759 ||: 100%|#########9| 11206/11253 [21:15<00:05,  8.29it/s]
2022-03-21 03:46:16,075 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.6462, loss: 0.2759 ||: 100%|#########9| 11207/11253 [21:15<00:05,  8.01it/s]
2022-03-21 03:46:16,187 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.4413, loss: 0.2759 ||: 100%|#########9| 11208/11253 [21:15<00:05,  8.23it/s]
2022-03-21 03:46:16,336 - INFO - tqdm - f1: 0.8453, accuracy: 0.8989, batch_loss: 0.4527, loss: 0.2759 ||: 100%|#########9| 11209/11253 [21:16<00:05,  7.76it/s]
2022-03-21 03:46:16,537 - INFO - tqdm - f1: 0.8453, accuracy: 0.8989, batch_loss: 0.3720, loss: 0.2759 ||: 100%|#########9| 11211/11253 [21:16<00:04,  8.58it/s]
2022-03-21 03:46:16,648 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.2148, loss: 0.2759 ||: 100%|#########9| 11212/11253 [21:16<00:04,  8.68it/s]
2022-03-21 03:46:16,749 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.4709, loss: 0.2759 ||: 100%|#########9| 11213/11253 [21:16<00:04,  8.96it/s]
2022-03-21 03:46:16,888 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.1798, loss: 0.2759 ||: 100%|#########9| 11214/11253 [21:16<00:04,  8.40it/s]
2022-03-21 03:46:17,027 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.1622, loss: 0.2759 ||: 100%|#########9| 11215/11253 [21:16<00:04,  8.04it/s]
2022-03-21 03:46:17,143 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.6360, loss: 0.2759 ||: 100%|#########9| 11216/11253 [21:16<00:04,  8.20it/s]
2022-03-21 03:46:17,251 - INFO - tqdm - f1: 0.8453, accuracy: 0.8989, batch_loss: 0.1252, loss: 0.2759 ||: 100%|#########9| 11217/11253 [21:17<00:04,  8.48it/s]
2022-03-21 03:46:17,429 - INFO - tqdm - f1: 0.8453, accuracy: 0.8989, batch_loss: 0.4951, loss: 0.2760 ||: 100%|#########9| 11219/11253 [21:17<00:03,  9.52it/s]
2022-03-21 03:46:17,531 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.1384, loss: 0.2759 ||: 100%|#########9| 11220/11253 [21:17<00:03,  9.59it/s]
2022-03-21 03:46:17,723 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.4643, loss: 0.2760 ||: 100%|#########9| 11221/11253 [21:17<00:04,  7.88it/s]
2022-03-21 03:46:17,964 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.2559, loss: 0.2760 ||: 100%|#########9| 11222/11253 [21:17<00:04,  6.35it/s]
2022-03-21 03:46:18,154 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.0269, loss: 0.2759 ||: 100%|#########9| 11223/11253 [21:17<00:04,  6.00it/s]
2022-03-21 03:46:18,366 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.2521, loss: 0.2759 ||: 100%|#########9| 11224/11253 [21:18<00:05,  5.57it/s]
2022-03-21 03:46:18,549 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.3054, loss: 0.2759 ||: 100%|#########9| 11225/11253 [21:18<00:05,  5.54it/s]
2022-03-21 03:46:18,739 - INFO - tqdm - f1: 0.8453, accuracy: 0.8989, batch_loss: 0.4101, loss: 0.2760 ||: 100%|#########9| 11226/11253 [21:18<00:04,  5.45it/s]
2022-03-21 03:46:18,932 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.2757, loss: 0.2760 ||: 100%|#########9| 11227/11253 [21:18<00:04,  5.37it/s]
2022-03-21 03:46:19,060 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.5168, loss: 0.2760 ||: 100%|#########9| 11229/11253 [21:18<00:03,  7.67it/s]
2022-03-21 03:46:19,212 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.1226, loss: 0.2760 ||: 100%|#########9| 11231/11253 [21:19<00:02,  9.18it/s]
2022-03-21 03:46:19,320 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.1482, loss: 0.2760 ||: 100%|#########9| 11232/11253 [21:19<00:02,  9.21it/s]
2022-03-21 03:46:19,432 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.3103, loss: 0.2760 ||: 100%|#########9| 11233/11253 [21:19<00:02,  9.13it/s]
2022-03-21 03:46:19,545 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.2665, loss: 0.2760 ||: 100%|#########9| 11234/11253 [21:19<00:02,  9.06it/s]
2022-03-21 03:46:19,655 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.2206, loss: 0.2760 ||: 100%|#########9| 11235/11253 [21:19<00:01,  9.06it/s]
2022-03-21 03:46:19,811 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.1910, loss: 0.2760 ||: 100%|#########9| 11236/11253 [21:19<00:02,  8.15it/s]
2022-03-21 03:46:19,921 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.4326, loss: 0.2760 ||: 100%|#########9| 11237/11253 [21:19<00:01,  8.39it/s]
2022-03-21 03:46:20,030 - INFO - tqdm - f1: 0.8453, accuracy: 0.8989, batch_loss: 0.2658, loss: 0.2760 ||: 100%|#########9| 11238/11253 [21:19<00:01,  8.61it/s]
2022-03-21 03:46:20,165 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.0177, loss: 0.2759 ||: 100%|#########9| 11239/11253 [21:19<00:01,  8.21it/s]
2022-03-21 03:46:20,280 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.1484, loss: 0.2759 ||: 100%|#########9| 11240/11253 [21:20<00:01,  8.35it/s]
2022-03-21 03:46:20,392 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.2215, loss: 0.2759 ||: 100%|#########9| 11241/11253 [21:20<00:01,  8.52it/s]
2022-03-21 03:46:20,535 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.0166, loss: 0.2759 ||: 100%|#########9| 11242/11253 [21:20<00:01,  8.00it/s]
2022-03-21 03:46:20,742 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.2808, loss: 0.2759 ||: 100%|#########9| 11244/11253 [21:20<00:01,  8.68it/s]
2022-03-21 03:46:20,869 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.1746, loss: 0.2759 ||: 100%|#########9| 11245/11253 [21:20<00:00,  8.47it/s]
2022-03-21 03:46:20,976 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.3462, loss: 0.2759 ||: 100%|#########9| 11246/11253 [21:20<00:00,  8.68it/s]
2022-03-21 03:46:21,080 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.5711, loss: 0.2759 ||: 100%|#########9| 11247/11253 [21:20<00:00,  8.92it/s]
2022-03-21 03:46:21,192 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.0972, loss: 0.2759 ||: 100%|#########9| 11248/11253 [21:20<00:00,  8.91it/s]
2022-03-21 03:46:21,296 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.8990, loss: 0.2760 ||: 100%|#########9| 11249/11253 [21:21<00:00,  9.11it/s]
2022-03-21 03:46:21,402 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.1718, loss: 0.2760 ||: 100%|#########9| 11250/11253 [21:21<00:00,  9.19it/s]
2022-03-21 03:46:21,597 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.0709, loss: 0.2759 ||: 100%|#########9| 11252/11253 [21:21<00:00,  9.64it/s]
2022-03-21 03:46:21,735 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.1926, loss: 0.2759 ||: 100%|##########| 11253/11253 [21:21<00:00,  8.94it/s]
2022-03-21 03:46:21,802 - INFO - tqdm - f1: 0.8454, accuracy: 0.8989, batch_loss: 0.1926, loss: 0.2759 ||: 100%|##########| 11253/11253 [21:21<00:00,  8.78it/s]
2022-03-21 03:46:21,814 - INFO - allennlp.training.trainer - Validating
2022-03-21 03:46:21,817 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 03:46:31,863 - INFO - tqdm - f1: 0.8093, accuracy: 0.8723, batch_loss: 0.6731, loss: 0.3691 ||:  10%|9         | 182/1889 [00:10<01:38, 17.34it/s]
2022-03-21 03:46:41,916 - INFO - tqdm - f1: 0.8094, accuracy: 0.8707, batch_loss: 0.0726, loss: 0.3806 ||:  19%|#9        | 364/1889 [00:20<01:25, 17.84it/s]
2022-03-21 03:46:51,991 - INFO - tqdm - f1: 0.8185, accuracy: 0.8755, batch_loss: 0.4062, loss: 0.3741 ||:  29%|##9       | 548/1889 [00:30<01:26, 15.53it/s]
2022-03-21 03:47:02,001 - INFO - tqdm - f1: 0.8182, accuracy: 0.8753, batch_loss: 0.4118, loss: 0.3775 ||:  38%|###8      | 720/1889 [00:40<01:16, 15.30it/s]
2022-03-21 03:47:12,131 - INFO - tqdm - f1: 0.8191, accuracy: 0.8763, batch_loss: 0.1046, loss: 0.3736 ||:  48%|####7     | 903/1889 [00:50<00:49, 19.88it/s]
2022-03-21 03:47:22,269 - INFO - tqdm - f1: 0.8199, accuracy: 0.8759, batch_loss: 0.0968, loss: 0.3697 ||:  57%|#####7    | 1083/1889 [01:00<00:41, 19.20it/s]
2022-03-21 03:47:32,364 - INFO - tqdm - f1: 0.8210, accuracy: 0.8770, batch_loss: 0.3885, loss: 0.3678 ||:  67%|######7   | 1269/1889 [01:10<00:33, 18.72it/s]
2022-03-21 03:47:42,383 - INFO - tqdm - f1: 0.8220, accuracy: 0.8778, batch_loss: 0.2836, loss: 0.3662 ||:  76%|#######6  | 1444/1889 [01:20<00:35, 12.59it/s]
2022-03-21 03:47:52,401 - INFO - tqdm - f1: 0.8203, accuracy: 0.8773, batch_loss: 0.1876, loss: 0.3672 ||:  86%|########5 | 1624/1889 [01:30<00:14, 18.54it/s]
2022-03-21 03:48:02,509 - INFO - tqdm - f1: 0.8194, accuracy: 0.8763, batch_loss: 0.1319, loss: 0.3688 ||:  96%|#########5| 1807/1889 [01:40<00:05, 15.06it/s]
2022-03-21 03:48:06,683 - INFO - tqdm - f1: 0.8189, accuracy: 0.8760, batch_loss: 0.1129, loss: 0.3688 ||: 100%|#########9| 1880/1889 [01:44<00:00, 18.66it/s]
2022-03-21 03:48:06,798 - INFO - tqdm - f1: 0.8189, accuracy: 0.8760, batch_loss: 0.3203, loss: 0.3688 ||: 100%|#########9| 1882/1889 [01:44<00:00, 18.30it/s]
2022-03-21 03:48:06,933 - INFO - tqdm - f1: 0.8188, accuracy: 0.8760, batch_loss: 0.8335, loss: 0.3692 ||: 100%|#########9| 1884/1889 [01:45<00:00, 17.26it/s]
2022-03-21 03:48:07,033 - INFO - tqdm - f1: 0.8187, accuracy: 0.8759, batch_loss: 0.4413, loss: 0.3692 ||: 100%|#########9| 1886/1889 [01:45<00:00, 17.93it/s]
2022-03-21 03:48:07,144 - INFO - tqdm - f1: 0.8187, accuracy: 0.8759, batch_loss: 0.1088, loss: 0.3690 ||: 100%|#########9| 1888/1889 [01:45<00:00, 17.92it/s]
2022-03-21 03:48:07,226 - INFO - tqdm - f1: 0.8187, accuracy: 0.8759, batch_loss: 0.2021, loss: 0.3689 ||: 100%|##########| 1889/1889 [01:45<00:00, 17.92it/s]
2022-03-21 03:48:07,237 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 03:48:07,238 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.899  |     0.876
2022-03-21 03:48:07,240 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.845  |     0.819
2022-03-21 03:48:07,241 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 03:48:07,243 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.276  |     0.369
2022-03-21 03:48:07,244 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8639.090  |       N/A
2022-03-21 03:48:07,245 - INFO - allennlp.training.trainer - Epoch duration: 0:23:07.057298
2022-03-21 03:48:07,247 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:09:30
2022-03-21 03:48:07,248 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-21 03:48:07,250 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 03:48:07,255 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 03:48:07,261 - INFO - allennlp.training.trainer - Training
2022-03-21 03:48:07,263 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 03:48:17,360 - INFO - tqdm - f1: 0.8842, accuracy: 0.9255, batch_loss: 0.3194, loss: 0.2293 ||:   1%|          | 83/11253 [00:10<20:44,  8.98it/s]
2022-03-21 03:48:27,430 - INFO - tqdm - f1: 0.8761, accuracy: 0.9205, batch_loss: 0.1867, loss: 0.2328 ||:   2%|1         | 169/11253 [00:20<20:58,  8.81it/s]
2022-03-21 03:48:37,474 - INFO - tqdm - f1: 0.8626, accuracy: 0.9148, batch_loss: 0.1739, loss: 0.2350 ||:   2%|2         | 262/11253 [00:30<19:07,  9.58it/s]
2022-03-21 03:48:47,662 - INFO - tqdm - f1: 0.8635, accuracy: 0.9162, batch_loss: 0.4174, loss: 0.2341 ||:   3%|3         | 347/11253 [00:40<37:58,  4.79it/s]
2022-03-21 03:48:57,754 - INFO - tqdm - f1: 0.8665, accuracy: 0.9161, batch_loss: 0.1566, loss: 0.2331 ||:   4%|3         | 438/11253 [00:50<20:56,  8.60it/s]
2022-03-21 03:49:07,927 - INFO - tqdm - f1: 0.8631, accuracy: 0.9140, batch_loss: 0.1938, loss: 0.2380 ||:   5%|4         | 530/11253 [01:00<18:28,  9.67it/s]
2022-03-21 03:49:18,013 - INFO - tqdm - f1: 0.8637, accuracy: 0.9148, batch_loss: 0.1366, loss: 0.2374 ||:   5%|5         | 617/11253 [01:10<18:39,  9.50it/s]
2022-03-21 03:49:28,124 - INFO - tqdm - f1: 0.8644, accuracy: 0.9146, batch_loss: 0.6489, loss: 0.2372 ||:   6%|6         | 708/11253 [01:20<18:11,  9.66it/s]
2022-03-21 03:49:38,247 - INFO - tqdm - f1: 0.8656, accuracy: 0.9145, batch_loss: 0.5158, loss: 0.2361 ||:   7%|7         | 794/11253 [01:30<17:56,  9.72it/s]
2022-03-21 03:49:48,265 - INFO - tqdm - f1: 0.8654, accuracy: 0.9146, batch_loss: 0.2553, loss: 0.2351 ||:   8%|7         | 886/11253 [01:41<19:23,  8.91it/s]
2022-03-21 03:49:58,306 - INFO - tqdm - f1: 0.8662, accuracy: 0.9150, batch_loss: 0.1115, loss: 0.2343 ||:   9%|8         | 971/11253 [01:51<19:24,  8.83it/s]
2022-03-21 03:50:08,478 - INFO - tqdm - f1: 0.8661, accuracy: 0.9147, batch_loss: 0.4486, loss: 0.2346 ||:   9%|9         | 1062/11253 [02:01<17:50,  9.52it/s]
2022-03-21 03:50:18,623 - INFO - tqdm - f1: 0.8651, accuracy: 0.9138, batch_loss: 0.4374, loss: 0.2360 ||:  10%|#         | 1149/11253 [02:11<18:18,  9.20it/s]
2022-03-21 03:50:28,629 - INFO - tqdm - f1: 0.8658, accuracy: 0.9144, batch_loss: 0.1704, loss: 0.2355 ||:  11%|#1        | 1239/11253 [02:21<16:57,  9.85it/s]
2022-03-21 03:50:38,804 - INFO - tqdm - f1: 0.8654, accuracy: 0.9145, batch_loss: 0.1301, loss: 0.2356 ||:  12%|#1        | 1329/11253 [02:31<27:30,  6.01it/s]
2022-03-21 03:50:48,867 - INFO - tqdm - f1: 0.8639, accuracy: 0.9134, batch_loss: 0.3087, loss: 0.2382 ||:  13%|#2        | 1420/11253 [02:41<17:08,  9.56it/s]
2022-03-21 03:50:58,964 - INFO - tqdm - f1: 0.8640, accuracy: 0.9139, batch_loss: 0.0497, loss: 0.2366 ||:  13%|#3        | 1508/11253 [02:51<20:06,  8.08it/s]
2022-03-21 03:51:09,013 - INFO - tqdm - f1: 0.8643, accuracy: 0.9140, batch_loss: 0.4081, loss: 0.2364 ||:  14%|#4        | 1594/11253 [03:01<17:33,  9.16it/s]
2022-03-21 03:51:19,052 - INFO - tqdm - f1: 0.8634, accuracy: 0.9132, batch_loss: 0.1814, loss: 0.2383 ||:  15%|#4        | 1684/11253 [03:11<19:18,  8.26it/s]
2022-03-21 03:51:29,121 - INFO - tqdm - f1: 0.8641, accuracy: 0.9139, batch_loss: 0.3581, loss: 0.2362 ||:  16%|#5        | 1768/11253 [03:21<19:34,  8.07it/s]
2022-03-21 03:51:39,151 - INFO - tqdm - f1: 0.8646, accuracy: 0.9145, batch_loss: 0.4128, loss: 0.2351 ||:  17%|#6        | 1859/11253 [03:31<16:52,  9.28it/s]
2022-03-21 03:51:49,209 - INFO - tqdm - f1: 0.8640, accuracy: 0.9141, batch_loss: 0.2641, loss: 0.2358 ||:  17%|#7        | 1946/11253 [03:41<17:49,  8.70it/s]
2022-03-21 03:51:59,238 - INFO - tqdm - f1: 0.8648, accuracy: 0.9146, batch_loss: 0.4597, loss: 0.2345 ||:  18%|#8        | 2038/11253 [03:51<16:28,  9.32it/s]
2022-03-21 03:52:09,364 - INFO - tqdm - f1: 0.8649, accuracy: 0.9146, batch_loss: 0.5190, loss: 0.2345 ||:  19%|#8        | 2126/11253 [04:02<15:35,  9.75it/s]
2022-03-21 03:52:19,381 - INFO - tqdm - f1: 0.8645, accuracy: 0.9143, batch_loss: 0.3698, loss: 0.2354 ||:  20%|#9        | 2215/11253 [04:12<18:44,  8.04it/s]
2022-03-21 03:52:29,465 - INFO - tqdm - f1: 0.8645, accuracy: 0.9144, batch_loss: 0.1482, loss: 0.2356 ||:  20%|##        | 2306/11253 [04:22<16:01,  9.31it/s]
2022-03-21 03:52:39,619 - INFO - tqdm - f1: 0.8639, accuracy: 0.9138, batch_loss: 0.2894, loss: 0.2359 ||:  21%|##1       | 2394/11253 [04:32<14:46,  9.99it/s]
2022-03-21 03:52:49,624 - INFO - tqdm - f1: 0.8636, accuracy: 0.9136, batch_loss: 0.5208, loss: 0.2367 ||:  22%|##2       | 2482/11253 [04:42<17:05,  8.55it/s]
2022-03-21 03:52:59,722 - INFO - tqdm - f1: 0.8632, accuracy: 0.9134, batch_loss: 0.0550, loss: 0.2373 ||:  23%|##2       | 2567/11253 [04:52<15:33,  9.30it/s]
2022-03-21 03:53:09,787 - INFO - tqdm - f1: 0.8626, accuracy: 0.9132, batch_loss: 0.2204, loss: 0.2375 ||:  24%|##3       | 2656/11253 [05:02<15:34,  9.20it/s]
2022-03-21 03:53:19,830 - INFO - tqdm - f1: 0.8628, accuracy: 0.9132, batch_loss: 0.1728, loss: 0.2372 ||:  24%|##4       | 2741/11253 [05:12<15:56,  8.90it/s]
2022-03-21 03:53:29,874 - INFO - tqdm - f1: 0.8628, accuracy: 0.9136, batch_loss: 0.1619, loss: 0.2359 ||:  25%|##5       | 2832/11253 [05:22<14:54,  9.41it/s]
2022-03-21 03:53:39,970 - INFO - tqdm - f1: 0.8630, accuracy: 0.9139, batch_loss: 0.1318, loss: 0.2353 ||:  26%|##5       | 2919/11253 [05:32<15:09,  9.16it/s]
2022-03-21 03:53:50,038 - INFO - tqdm - f1: 0.8628, accuracy: 0.9137, batch_loss: 0.1651, loss: 0.2359 ||:  27%|##6       | 3011/11253 [05:42<15:39,  8.77it/s]
2022-03-21 03:54:00,127 - INFO - tqdm - f1: 0.8624, accuracy: 0.9132, batch_loss: 0.2938, loss: 0.2372 ||:  28%|##7       | 3099/11253 [05:52<18:11,  7.47it/s]
2022-03-21 03:54:10,129 - INFO - tqdm - f1: 0.8624, accuracy: 0.9131, batch_loss: 0.6015, loss: 0.2373 ||:  28%|##8       | 3190/11253 [06:02<14:50,  9.06it/s]
2022-03-21 03:54:20,194 - INFO - tqdm - f1: 0.8629, accuracy: 0.9133, batch_loss: 0.2607, loss: 0.2369 ||:  29%|##9       | 3280/11253 [06:12<15:07,  8.79it/s]
2022-03-21 03:54:30,336 - INFO - tqdm - f1: 0.8628, accuracy: 0.9134, batch_loss: 0.2734, loss: 0.2367 ||:  30%|##9       | 3366/11253 [06:23<13:14,  9.93it/s]
2022-03-21 03:54:40,520 - INFO - tqdm - f1: 0.8629, accuracy: 0.9133, batch_loss: 0.1036, loss: 0.2371 ||:  31%|###       | 3458/11253 [06:33<14:44,  8.81it/s]
2022-03-21 03:54:50,524 - INFO - tqdm - f1: 0.8628, accuracy: 0.9131, batch_loss: 0.3228, loss: 0.2379 ||:  32%|###1      | 3545/11253 [06:43<13:56,  9.22it/s]
2022-03-21 03:55:00,546 - INFO - tqdm - f1: 0.8624, accuracy: 0.9129, batch_loss: 0.1735, loss: 0.2381 ||:  32%|###2      | 3635/11253 [06:53<12:41, 10.00it/s]
2022-03-21 03:55:10,634 - INFO - tqdm - f1: 0.8627, accuracy: 0.9129, batch_loss: 0.2781, loss: 0.2384 ||:  33%|###3      | 3723/11253 [07:03<14:21,  8.74it/s]
2022-03-21 03:55:20,681 - INFO - tqdm - f1: 0.8625, accuracy: 0.9129, batch_loss: 0.3906, loss: 0.2383 ||:  34%|###3      | 3813/11253 [07:13<12:58,  9.56it/s]
2022-03-21 03:55:30,731 - INFO - tqdm - f1: 0.8624, accuracy: 0.9128, batch_loss: 0.6200, loss: 0.2387 ||:  35%|###4      | 3899/11253 [07:23<12:43,  9.64it/s]
2022-03-21 03:55:40,802 - INFO - tqdm - f1: 0.8627, accuracy: 0.9131, batch_loss: 0.0339, loss: 0.2386 ||:  35%|###5      | 3988/11253 [07:33<14:14,  8.50it/s]
2022-03-21 03:55:50,972 - INFO - tqdm - f1: 0.8626, accuracy: 0.9130, batch_loss: 0.5394, loss: 0.2387 ||:  36%|###6      | 4077/11253 [07:43<18:08,  6.59it/s]
2022-03-21 03:56:01,079 - INFO - tqdm - f1: 0.8629, accuracy: 0.9132, batch_loss: 0.3036, loss: 0.2384 ||:  37%|###7      | 4164/11253 [07:53<12:30,  9.45it/s]
2022-03-21 03:56:11,147 - INFO - tqdm - f1: 0.8628, accuracy: 0.9131, batch_loss: 0.4479, loss: 0.2392 ||:  38%|###7      | 4254/11253 [08:03<12:00,  9.71it/s]
2022-03-21 03:56:21,201 - INFO - tqdm - f1: 0.8630, accuracy: 0.9132, batch_loss: 0.3117, loss: 0.2391 ||:  39%|###8      | 4340/11253 [08:13<13:38,  8.45it/s]
2022-03-21 03:56:31,305 - INFO - tqdm - f1: 0.8632, accuracy: 0.9132, batch_loss: 0.2803, loss: 0.2392 ||:  39%|###9      | 4428/11253 [08:24<14:01,  8.11it/s]
2022-03-21 03:56:41,352 - INFO - tqdm - f1: 0.8630, accuracy: 0.9132, batch_loss: 0.4037, loss: 0.2395 ||:  40%|####      | 4512/11253 [08:34<13:08,  8.55it/s]
2022-03-21 03:56:51,405 - INFO - tqdm - f1: 0.8630, accuracy: 0.9132, batch_loss: 0.0527, loss: 0.2396 ||:  41%|####      | 4602/11253 [08:44<12:46,  8.68it/s]
2022-03-21 03:57:01,550 - INFO - tqdm - f1: 0.8631, accuracy: 0.9132, batch_loss: 0.2088, loss: 0.2401 ||:  42%|####1     | 4691/11253 [08:54<10:54, 10.03it/s]
2022-03-21 03:57:11,721 - INFO - tqdm - f1: 0.8628, accuracy: 0.9130, batch_loss: 0.1587, loss: 0.2405 ||:  42%|####2     | 4782/11253 [09:04<11:58,  9.00it/s]
2022-03-21 03:57:21,724 - INFO - tqdm - f1: 0.8629, accuracy: 0.9131, batch_loss: 0.5782, loss: 0.2403 ||:  43%|####3     | 4868/11253 [09:14<11:29,  9.25it/s]
2022-03-21 03:57:31,831 - INFO - tqdm - f1: 0.8627, accuracy: 0.9130, batch_loss: 0.2962, loss: 0.2406 ||:  44%|####4     | 4956/11253 [09:24<11:14,  9.33it/s]
2022-03-21 03:57:41,935 - INFO - tqdm - f1: 0.8628, accuracy: 0.9131, batch_loss: 0.2960, loss: 0.2401 ||:  45%|####4     | 5045/11253 [09:34<13:27,  7.69it/s]
2022-03-21 03:57:51,959 - INFO - tqdm - f1: 0.8628, accuracy: 0.9131, batch_loss: 0.1638, loss: 0.2402 ||:  46%|####5     | 5131/11253 [09:44<12:02,  8.48it/s]
2022-03-21 03:58:02,067 - INFO - tqdm - f1: 0.8629, accuracy: 0.9131, batch_loss: 0.3182, loss: 0.2403 ||:  46%|####6     | 5219/11253 [09:54<11:25,  8.80it/s]
2022-03-21 03:58:12,115 - INFO - tqdm - f1: 0.8628, accuracy: 0.9131, batch_loss: 0.0632, loss: 0.2403 ||:  47%|####7     | 5307/11253 [10:04<11:01,  8.99it/s]
2022-03-21 03:58:22,221 - INFO - tqdm - f1: 0.8627, accuracy: 0.9131, batch_loss: 0.0061, loss: 0.2402 ||:  48%|####7     | 5399/11253 [10:14<11:14,  8.67it/s]
2022-03-21 03:58:32,241 - INFO - tqdm - f1: 0.8626, accuracy: 0.9130, batch_loss: 0.0901, loss: 0.2404 ||:  49%|####8     | 5486/11253 [10:24<10:28,  9.18it/s]
2022-03-21 03:58:42,344 - INFO - tqdm - f1: 0.8627, accuracy: 0.9130, batch_loss: 0.5286, loss: 0.2406 ||:  50%|####9     | 5574/11253 [10:35<11:24,  8.30it/s]
2022-03-21 03:58:52,408 - INFO - tqdm - f1: 0.8628, accuracy: 0.9131, batch_loss: 0.3105, loss: 0.2403 ||:  50%|#####     | 5660/11253 [10:45<11:07,  8.38it/s]
2022-03-21 03:59:02,498 - INFO - tqdm - f1: 0.8630, accuracy: 0.9130, batch_loss: 0.0886, loss: 0.2404 ||:  51%|#####1    | 5752/11253 [10:55<10:30,  8.72it/s]
2022-03-21 03:59:12,623 - INFO - tqdm - f1: 0.8630, accuracy: 0.9132, batch_loss: 0.3768, loss: 0.2400 ||:  52%|#####1    | 5838/11253 [11:05<11:51,  7.61it/s]
2022-03-21 03:59:22,679 - INFO - tqdm - f1: 0.8631, accuracy: 0.9131, batch_loss: 0.0440, loss: 0.2402 ||:  53%|#####2    | 5927/11253 [11:15<11:09,  7.96it/s]
2022-03-21 03:59:32,724 - INFO - tqdm - f1: 0.8629, accuracy: 0.9130, batch_loss: 0.5134, loss: 0.2404 ||:  53%|#####3    | 6017/11253 [11:25<10:24,  8.38it/s]
2022-03-21 03:59:42,882 - INFO - tqdm - f1: 0.8633, accuracy: 0.9132, batch_loss: 0.0795, loss: 0.2401 ||:  54%|#####4    | 6103/11253 [11:35<10:13,  8.40it/s]
2022-03-21 03:59:52,975 - INFO - tqdm - f1: 0.8633, accuracy: 0.9131, batch_loss: 0.1595, loss: 0.2405 ||:  55%|#####5    | 6194/11253 [11:45<09:01,  9.34it/s]
2022-03-21 04:00:03,004 - INFO - tqdm - f1: 0.8631, accuracy: 0.9130, batch_loss: 0.0808, loss: 0.2407 ||:  56%|#####5    | 6277/11253 [11:55<09:19,  8.90it/s]
2022-03-21 04:00:13,159 - INFO - tqdm - f1: 0.8628, accuracy: 0.9127, batch_loss: 0.5013, loss: 0.2412 ||:  57%|#####6    | 6368/11253 [12:05<08:37,  9.45it/s]
2022-03-21 04:00:23,181 - INFO - tqdm - f1: 0.8627, accuracy: 0.9126, batch_loss: 0.3536, loss: 0.2418 ||:  57%|#####7    | 6453/11253 [12:15<09:17,  8.61it/s]
2022-03-21 04:00:33,302 - INFO - tqdm - f1: 0.8626, accuracy: 0.9125, batch_loss: 0.4785, loss: 0.2418 ||:  58%|#####8    | 6544/11253 [12:26<07:54,  9.92it/s]
2022-03-21 04:00:43,414 - INFO - tqdm - f1: 0.8623, accuracy: 0.9124, batch_loss: 0.0385, loss: 0.2420 ||:  59%|#####8    | 6632/11253 [12:36<08:33,  9.00it/s]
2022-03-21 04:00:53,505 - INFO - tqdm - f1: 0.8623, accuracy: 0.9124, batch_loss: 0.3832, loss: 0.2418 ||:  60%|#####9    | 6724/11253 [12:46<07:58,  9.46it/s]
2022-03-21 04:01:03,723 - INFO - tqdm - f1: 0.8621, accuracy: 0.9123, batch_loss: 0.4958, loss: 0.2422 ||:  61%|######    | 6814/11253 [12:56<11:54,  6.22it/s]
2022-03-21 04:01:13,764 - INFO - tqdm - f1: 0.8620, accuracy: 0.9122, batch_loss: 0.8448, loss: 0.2423 ||:  61%|######1   | 6902/11253 [13:06<07:32,  9.61it/s]
2022-03-21 04:01:23,783 - INFO - tqdm - f1: 0.8618, accuracy: 0.9120, batch_loss: 0.4849, loss: 0.2425 ||:  62%|######2   | 6992/11253 [13:16<07:29,  9.47it/s]
2022-03-21 04:01:33,933 - INFO - tqdm - f1: 0.8616, accuracy: 0.9119, batch_loss: 0.0714, loss: 0.2426 ||:  63%|######2   | 7079/11253 [13:26<07:23,  9.41it/s]
2022-03-21 04:01:44,003 - INFO - tqdm - f1: 0.8616, accuracy: 0.9118, batch_loss: 0.1808, loss: 0.2428 ||:  64%|######3   | 7169/11253 [13:36<07:14,  9.39it/s]
2022-03-21 04:01:54,180 - INFO - tqdm - f1: 0.8616, accuracy: 0.9118, batch_loss: 0.8583, loss: 0.2429 ||:  64%|######4   | 7257/11253 [13:46<06:47,  9.81it/s]
2022-03-21 04:02:04,295 - INFO - tqdm - f1: 0.8618, accuracy: 0.9119, batch_loss: 0.0505, loss: 0.2428 ||:  65%|######5   | 7346/11253 [13:57<07:36,  8.57it/s]
2022-03-21 04:02:14,476 - INFO - tqdm - f1: 0.8619, accuracy: 0.9119, batch_loss: 0.1425, loss: 0.2426 ||:  66%|######6   | 7436/11253 [14:07<06:42,  9.47it/s]
2022-03-21 04:02:24,700 - INFO - tqdm - f1: 0.8618, accuracy: 0.9119, batch_loss: 0.4277, loss: 0.2427 ||:  67%|######6   | 7529/11253 [14:17<07:14,  8.56it/s]
2022-03-21 04:02:34,758 - INFO - tqdm - f1: 0.8617, accuracy: 0.9118, batch_loss: 0.0676, loss: 0.2429 ||:  68%|######7   | 7616/11253 [14:27<07:28,  8.10it/s]
2022-03-21 04:02:44,860 - INFO - tqdm - f1: 0.8614, accuracy: 0.9116, batch_loss: 0.4763, loss: 0.2433 ||:  69%|######8   | 7709/11253 [14:37<06:27,  9.14it/s]
2022-03-21 04:02:54,909 - INFO - tqdm - f1: 0.8613, accuracy: 0.9115, batch_loss: 0.1977, loss: 0.2433 ||:  69%|######9   | 7798/11253 [14:47<05:57,  9.66it/s]
2022-03-21 04:03:04,942 - INFO - tqdm - f1: 0.8611, accuracy: 0.9113, batch_loss: 0.1947, loss: 0.2437 ||:  70%|#######   | 7886/11253 [14:57<06:29,  8.64it/s]
2022-03-21 04:03:15,040 - INFO - tqdm - f1: 0.8610, accuracy: 0.9113, batch_loss: 0.8600, loss: 0.2436 ||:  71%|#######   | 7975/11253 [15:07<05:47,  9.43it/s]
2022-03-21 04:03:25,071 - INFO - tqdm - f1: 0.8608, accuracy: 0.9113, batch_loss: 0.2378, loss: 0.2438 ||:  72%|#######1  | 8062/11253 [15:17<05:48,  9.16it/s]
2022-03-21 04:03:35,164 - INFO - tqdm - f1: 0.8608, accuracy: 0.9112, batch_loss: 0.3027, loss: 0.2442 ||:  72%|#######2  | 8153/11253 [15:27<05:19,  9.71it/s]
2022-03-21 04:03:45,274 - INFO - tqdm - f1: 0.8607, accuracy: 0.9111, batch_loss: 0.2836, loss: 0.2442 ||:  73%|#######3  | 8239/11253 [15:38<05:51,  8.57it/s]
2022-03-21 04:03:55,417 - INFO - tqdm - f1: 0.8606, accuracy: 0.9111, batch_loss: 0.0824, loss: 0.2442 ||:  74%|#######4  | 8329/11253 [15:48<05:33,  8.77it/s]
2022-03-21 04:04:05,452 - INFO - tqdm - f1: 0.8605, accuracy: 0.9110, batch_loss: 0.3559, loss: 0.2446 ||:  75%|#######4  | 8414/11253 [15:58<05:15,  9.00it/s]
2022-03-21 04:04:15,473 - INFO - tqdm - f1: 0.8604, accuracy: 0.9109, batch_loss: 0.2157, loss: 0.2448 ||:  76%|#######5  | 8500/11253 [16:08<05:06,  8.98it/s]
2022-03-21 04:04:25,477 - INFO - tqdm - f1: 0.8607, accuracy: 0.9110, batch_loss: 0.2844, loss: 0.2448 ||:  76%|#######6  | 8584/11253 [16:18<08:27,  5.26it/s]
2022-03-21 04:04:35,536 - INFO - tqdm - f1: 0.8605, accuracy: 0.9109, batch_loss: 0.1304, loss: 0.2449 ||:  77%|#######7  | 8676/11253 [16:28<04:33,  9.43it/s]
2022-03-21 04:04:45,547 - INFO - tqdm - f1: 0.8605, accuracy: 0.9109, batch_loss: 0.0122, loss: 0.2449 ||:  78%|#######7  | 8765/11253 [16:38<04:46,  8.69it/s]
2022-03-21 04:04:55,597 - INFO - tqdm - f1: 0.8605, accuracy: 0.9109, batch_loss: 0.2338, loss: 0.2447 ||:  79%|#######8  | 8847/11253 [16:48<04:34,  8.77it/s]
2022-03-21 04:05:05,655 - INFO - tqdm - f1: 0.8604, accuracy: 0.9109, batch_loss: 0.0849, loss: 0.2448 ||:  79%|#######9  | 8936/11253 [16:58<04:16,  9.04it/s]
2022-03-21 04:05:15,759 - INFO - tqdm - f1: 0.8606, accuracy: 0.9110, batch_loss: 0.0313, loss: 0.2448 ||:  80%|########  | 9021/11253 [17:08<04:27,  8.36it/s]
2022-03-21 04:05:25,862 - INFO - tqdm - f1: 0.8607, accuracy: 0.9110, batch_loss: 0.2397, loss: 0.2448 ||:  81%|########  | 9110/11253 [17:18<04:02,  8.84it/s]
2022-03-21 04:05:35,989 - INFO - tqdm - f1: 0.8606, accuracy: 0.9110, batch_loss: 0.5288, loss: 0.2447 ||:  82%|########1 | 9197/11253 [17:28<03:40,  9.31it/s]
2022-03-21 04:05:45,992 - INFO - tqdm - f1: 0.8603, accuracy: 0.9108, batch_loss: 0.4136, loss: 0.2453 ||:  83%|########2 | 9288/11253 [17:38<03:38,  8.99it/s]
2022-03-21 04:05:56,159 - INFO - tqdm - f1: 0.8602, accuracy: 0.9107, batch_loss: 0.4808, loss: 0.2457 ||:  83%|########3 | 9376/11253 [17:48<03:16,  9.56it/s]
2022-03-21 04:06:06,174 - INFO - tqdm - f1: 0.8602, accuracy: 0.9106, batch_loss: 0.2247, loss: 0.2458 ||:  84%|########4 | 9467/11253 [17:58<03:06,  9.58it/s]
2022-03-21 04:06:16,317 - INFO - tqdm - f1: 0.8602, accuracy: 0.9106, batch_loss: 0.2725, loss: 0.2459 ||:  85%|########4 | 9558/11253 [18:09<04:19,  6.54it/s]
2022-03-21 04:06:26,390 - INFO - tqdm - f1: 0.8602, accuracy: 0.9106, batch_loss: 0.1756, loss: 0.2458 ||:  86%|########5 | 9646/11253 [18:19<03:00,  8.89it/s]
2022-03-21 04:06:36,425 - INFO - tqdm - f1: 0.8602, accuracy: 0.9106, batch_loss: 0.1119, loss: 0.2459 ||:  87%|########6 | 9736/11253 [18:29<02:52,  8.79it/s]
2022-03-21 04:06:46,456 - INFO - tqdm - f1: 0.8601, accuracy: 0.9106, batch_loss: 0.4725, loss: 0.2459 ||:  87%|########7 | 9824/11253 [18:39<02:38,  9.01it/s]
2022-03-21 04:06:56,555 - INFO - tqdm - f1: 0.8601, accuracy: 0.9106, batch_loss: 0.0307, loss: 0.2461 ||:  88%|########8 | 9916/11253 [18:49<02:22,  9.41it/s]
2022-03-21 04:07:06,627 - INFO - tqdm - f1: 0.8599, accuracy: 0.9104, batch_loss: 0.3815, loss: 0.2464 ||:  89%|########8 | 10005/11253 [18:59<02:23,  8.70it/s]
2022-03-21 04:07:16,711 - INFO - tqdm - f1: 0.8599, accuracy: 0.9104, batch_loss: 0.3020, loss: 0.2464 ||:  90%|########9 | 10096/11253 [19:09<02:08,  8.99it/s]
2022-03-21 04:07:26,712 - INFO - tqdm - f1: 0.8599, accuracy: 0.9105, batch_loss: 0.1203, loss: 0.2463 ||:  90%|######### | 10182/11253 [19:19<01:50,  9.73it/s]
2022-03-21 04:07:36,758 - INFO - tqdm - f1: 0.8600, accuracy: 0.9106, batch_loss: 0.0642, loss: 0.2463 ||:  91%|#########1| 10271/11253 [19:29<01:58,  8.31it/s]
2022-03-21 04:07:46,860 - INFO - tqdm - f1: 0.8598, accuracy: 0.9105, batch_loss: 0.1066, loss: 0.2465 ||:  92%|#########2| 10356/11253 [19:39<01:42,  8.71it/s]
2022-03-21 04:07:56,885 - INFO - tqdm - f1: 0.8597, accuracy: 0.9103, batch_loss: 0.1095, loss: 0.2467 ||:  93%|#########2| 10443/11253 [19:49<01:37,  8.34it/s]
2022-03-21 04:08:06,938 - INFO - tqdm - f1: 0.8596, accuracy: 0.9102, batch_loss: 0.0872, loss: 0.2468 ||:  94%|#########3| 10528/11253 [19:59<02:20,  5.16it/s]
2022-03-21 04:08:16,964 - INFO - tqdm - f1: 0.8594, accuracy: 0.9101, batch_loss: 0.5556, loss: 0.2469 ||:  94%|#########4| 10621/11253 [20:09<01:06,  9.50it/s]
2022-03-21 04:08:27,009 - INFO - tqdm - f1: 0.8592, accuracy: 0.9100, batch_loss: 0.3136, loss: 0.2472 ||:  95%|#########5| 10712/11253 [20:19<01:01,  8.79it/s]
2022-03-21 04:08:37,114 - INFO - tqdm - f1: 0.8591, accuracy: 0.9099, batch_loss: 0.1061, loss: 0.2473 ||:  96%|#########5| 10796/11253 [20:29<00:52,  8.72it/s]
2022-03-21 04:08:47,180 - INFO - tqdm - f1: 0.8588, accuracy: 0.9098, batch_loss: 0.4489, loss: 0.2477 ||:  97%|#########6| 10887/11253 [20:39<00:40,  8.96it/s]
2022-03-21 04:08:57,297 - INFO - tqdm - f1: 0.8588, accuracy: 0.9098, batch_loss: 0.1910, loss: 0.2475 ||:  97%|#########7| 10971/11253 [20:50<00:32,  8.59it/s]
2022-03-21 04:09:07,318 - INFO - tqdm - f1: 0.8589, accuracy: 0.9098, batch_loss: 0.0771, loss: 0.2476 ||:  98%|#########8| 11059/11253 [21:00<00:21,  9.04it/s]
2022-03-21 04:09:17,532 - INFO - tqdm - f1: 0.8588, accuracy: 0.9098, batch_loss: 0.0724, loss: 0.2476 ||:  99%|#########9| 11144/11253 [21:10<00:12,  8.55it/s]
2022-03-21 04:09:23,709 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.0105, loss: 0.2476 ||: 100%|#########9| 11197/11253 [21:16<00:06,  9.05it/s]
2022-03-21 04:09:23,852 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.2291, loss: 0.2476 ||: 100%|#########9| 11198/11253 [21:16<00:06,  8.48it/s]
2022-03-21 04:09:23,964 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.1888, loss: 0.2476 ||: 100%|#########9| 11199/11253 [21:16<00:06,  8.58it/s]
2022-03-21 04:09:24,082 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.5068, loss: 0.2476 ||: 100%|#########9| 11200/11253 [21:16<00:06,  8.56it/s]
2022-03-21 04:09:24,270 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.1675, loss: 0.2476 ||: 100%|#########9| 11202/11253 [21:17<00:05,  9.34it/s]
2022-03-21 04:09:24,391 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.3874, loss: 0.2476 ||: 100%|#########9| 11203/11253 [21:17<00:05,  9.06it/s]
2022-03-21 04:09:24,500 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.0567, loss: 0.2476 ||: 100%|#########9| 11204/11253 [21:17<00:05,  9.08it/s]
2022-03-21 04:09:24,602 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.0636, loss: 0.2475 ||: 100%|#########9| 11205/11253 [21:17<00:05,  9.28it/s]
2022-03-21 04:09:24,797 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.2063, loss: 0.2476 ||: 100%|#########9| 11207/11253 [21:17<00:04,  9.67it/s]
2022-03-21 04:09:24,909 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.0417, loss: 0.2475 ||: 100%|#########9| 11208/11253 [21:17<00:04,  9.47it/s]
2022-03-21 04:09:25,051 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.0623, loss: 0.2475 ||: 100%|#########9| 11209/11253 [21:17<00:05,  8.71it/s]
2022-03-21 04:09:25,191 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.0467, loss: 0.2475 ||: 100%|#########9| 11210/11253 [21:17<00:05,  8.24it/s]
2022-03-21 04:09:25,297 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.5008, loss: 0.2475 ||: 100%|#########9| 11211/11253 [21:18<00:04,  8.54it/s]
2022-03-21 04:09:25,407 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.1271, loss: 0.2475 ||: 100%|#########9| 11212/11253 [21:18<00:04,  8.70it/s]
2022-03-21 04:09:25,614 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.1163, loss: 0.2475 ||: 100%|#########9| 11214/11253 [21:18<00:04,  9.09it/s]
2022-03-21 04:09:25,735 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.3120, loss: 0.2475 ||: 100%|#########9| 11215/11253 [21:18<00:04,  8.88it/s]
2022-03-21 04:09:25,867 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.2250, loss: 0.2475 ||: 100%|#########9| 11216/11253 [21:18<00:04,  8.50it/s]
2022-03-21 04:09:26,005 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.1451, loss: 0.2475 ||: 100%|#########9| 11217/11253 [21:18<00:04,  8.12it/s]
2022-03-21 04:09:26,146 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.0080, loss: 0.2475 ||: 100%|#########9| 11218/11253 [21:18<00:04,  7.82it/s]
2022-03-21 04:09:26,258 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.1993, loss: 0.2475 ||: 100%|#########9| 11219/11253 [21:18<00:04,  8.09it/s]
2022-03-21 04:09:26,364 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.0949, loss: 0.2474 ||: 100%|#########9| 11220/11253 [21:19<00:03,  8.44it/s]
2022-03-21 04:09:26,553 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.6071, loss: 0.2475 ||: 100%|#########9| 11222/11253 [21:19<00:03,  9.30it/s]
2022-03-21 04:09:26,665 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.1718, loss: 0.2475 ||: 100%|#########9| 11223/11253 [21:19<00:03,  9.20it/s]
2022-03-21 04:09:26,783 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.4664, loss: 0.2475 ||: 100%|#########9| 11224/11253 [21:19<00:03,  9.00it/s]
2022-03-21 04:09:26,898 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.2962, loss: 0.2475 ||: 100%|#########9| 11225/11253 [21:19<00:03,  8.91it/s]
2022-03-21 04:09:27,026 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.0118, loss: 0.2475 ||: 100%|#########9| 11226/11253 [21:19<00:03,  8.59it/s]
2022-03-21 04:09:27,134 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.0634, loss: 0.2475 ||: 100%|#########9| 11227/11253 [21:19<00:02,  8.76it/s]
2022-03-21 04:09:27,272 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.0773, loss: 0.2474 ||: 100%|#########9| 11228/11253 [21:20<00:03,  8.26it/s]
2022-03-21 04:09:27,380 - INFO - tqdm - f1: 0.8590, accuracy: 0.9100, batch_loss: 0.0402, loss: 0.2474 ||: 100%|#########9| 11229/11253 [21:20<00:02,  8.54it/s]
2022-03-21 04:09:27,492 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.4291, loss: 0.2474 ||: 100%|#########9| 11230/11253 [21:20<00:02,  8.65it/s]
2022-03-21 04:09:27,624 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.3182, loss: 0.2475 ||: 100%|#########9| 11231/11253 [21:20<00:02,  8.30it/s]
2022-03-21 04:09:27,731 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.3470, loss: 0.2475 ||: 100%|#########9| 11232/11253 [21:20<00:02,  8.59it/s]
2022-03-21 04:09:27,832 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.5170, loss: 0.2475 ||: 100%|#########9| 11233/11253 [21:20<00:02,  8.93it/s]
2022-03-21 04:09:27,977 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.3961, loss: 0.2475 ||: 100%|#########9| 11234/11253 [21:20<00:02,  8.21it/s]
2022-03-21 04:09:28,117 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.2742, loss: 0.2475 ||: 100%|#########9| 11235/11253 [21:20<00:02,  7.86it/s]
2022-03-21 04:09:28,224 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.2688, loss: 0.2475 ||: 100%|#########9| 11236/11253 [21:20<00:02,  8.26it/s]
2022-03-21 04:09:28,466 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.1852, loss: 0.2475 ||: 100%|#########9| 11238/11253 [21:21<00:01,  8.26it/s]
2022-03-21 04:09:28,603 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.1195, loss: 0.2475 ||: 100%|#########9| 11239/11253 [21:21<00:01,  8.00it/s]
2022-03-21 04:09:28,748 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.3789, loss: 0.2475 ||: 100%|#########9| 11240/11253 [21:21<00:01,  7.68it/s]
2022-03-21 04:09:28,882 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.1437, loss: 0.2475 ||: 100%|#########9| 11241/11253 [21:21<00:01,  7.62it/s]
2022-03-21 04:09:29,036 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.0621, loss: 0.2475 ||: 100%|#########9| 11242/11253 [21:21<00:01,  7.27it/s]
2022-03-21 04:09:29,188 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.1010, loss: 0.2474 ||: 100%|#########9| 11243/11253 [21:21<00:01,  7.05it/s]
2022-03-21 04:09:29,320 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.1011, loss: 0.2474 ||: 100%|#########9| 11244/11253 [21:22<00:01,  7.20it/s]
2022-03-21 04:09:29,431 - INFO - tqdm - f1: 0.8590, accuracy: 0.9100, batch_loss: 0.1853, loss: 0.2474 ||: 100%|#########9| 11245/11253 [21:22<00:01,  7.64it/s]
2022-03-21 04:09:29,534 - INFO - tqdm - f1: 0.8590, accuracy: 0.9100, batch_loss: 0.2590, loss: 0.2474 ||: 100%|#########9| 11246/11253 [21:22<00:00,  8.15it/s]
2022-03-21 04:09:29,769 - INFO - tqdm - f1: 0.8590, accuracy: 0.9100, batch_loss: 0.0606, loss: 0.2474 ||: 100%|#########9| 11248/11253 [21:22<00:00,  8.33it/s]
2022-03-21 04:09:29,927 - INFO - tqdm - f1: 0.8590, accuracy: 0.9100, batch_loss: 0.0536, loss: 0.2474 ||: 100%|#########9| 11249/11253 [21:22<00:00,  7.72it/s]
2022-03-21 04:09:30,031 - INFO - tqdm - f1: 0.8590, accuracy: 0.9100, batch_loss: 0.1789, loss: 0.2474 ||: 100%|#########9| 11250/11253 [21:22<00:00,  8.14it/s]
2022-03-21 04:09:30,158 - INFO - tqdm - f1: 0.8590, accuracy: 0.9100, batch_loss: 0.3204, loss: 0.2474 ||: 100%|#########9| 11251/11253 [21:22<00:00,  8.06it/s]
2022-03-21 04:09:30,351 - INFO - tqdm - f1: 0.8590, accuracy: 0.9100, batch_loss: 0.2180, loss: 0.2474 ||: 100%|##########| 11253/11253 [21:23<00:00,  8.93it/s]
2022-03-21 04:09:30,418 - INFO - tqdm - f1: 0.8590, accuracy: 0.9100, batch_loss: 0.2180, loss: 0.2474 ||: 100%|##########| 11253/11253 [21:23<00:00,  8.77it/s]
2022-03-21 04:09:30,438 - INFO - allennlp.training.trainer - Validating
2022-03-21 04:09:30,440 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 04:09:40,499 - INFO - tqdm - f1: 0.8232, accuracy: 0.8759, batch_loss: 0.4045, loss: 0.3929 ||:   9%|9         | 177/1889 [00:10<01:28, 19.35it/s]
2022-03-21 04:09:50,506 - INFO - tqdm - f1: 0.8195, accuracy: 0.8740, batch_loss: 0.3753, loss: 0.3947 ||:  18%|#8        | 348/1889 [00:20<01:32, 16.66it/s]
2022-03-21 04:10:00,587 - INFO - tqdm - f1: 0.8151, accuracy: 0.8710, batch_loss: 0.8409, loss: 0.4026 ||:  28%|##7       | 527/1889 [00:30<01:10, 19.22it/s]
2022-03-21 04:10:10,636 - INFO - tqdm - f1: 0.8167, accuracy: 0.8722, batch_loss: 0.2351, loss: 0.3991 ||:  37%|###7      | 708/1889 [00:40<01:07, 17.38it/s]
2022-03-21 04:10:20,797 - INFO - tqdm - f1: 0.8192, accuracy: 0.8743, batch_loss: 0.2509, loss: 0.3904 ||:  47%|####6     | 887/1889 [00:50<00:56, 17.76it/s]
2022-03-21 04:10:30,888 - INFO - tqdm - f1: 0.8182, accuracy: 0.8739, batch_loss: 0.5826, loss: 0.3890 ||:  57%|#####6    | 1068/1889 [01:00<00:47, 17.38it/s]
2022-03-21 04:10:40,903 - INFO - tqdm - f1: 0.8171, accuracy: 0.8728, batch_loss: 0.5787, loss: 0.3934 ||:  65%|######5   | 1237/1889 [01:10<00:40, 15.96it/s]
2022-03-21 04:10:51,007 - INFO - tqdm - f1: 0.8184, accuracy: 0.8740, batch_loss: 0.2597, loss: 0.3901 ||:  75%|#######4  | 1416/1889 [01:20<00:28, 16.34it/s]
2022-03-21 04:11:01,086 - INFO - tqdm - f1: 0.8181, accuracy: 0.8739, batch_loss: 0.3446, loss: 0.3919 ||:  84%|########4 | 1587/1889 [01:30<00:17, 16.81it/s]
2022-03-21 04:11:11,091 - INFO - tqdm - f1: 0.8191, accuracy: 0.8745, batch_loss: 0.1774, loss: 0.3902 ||:  93%|#########3| 1764/1889 [01:40<00:07, 17.50it/s]
2022-03-21 04:11:17,823 - INFO - tqdm - f1: 0.8191, accuracy: 0.8742, batch_loss: 0.1271, loss: 0.3909 ||: 100%|#########9| 1881/1889 [01:47<00:00, 17.85it/s]
2022-03-21 04:11:17,943 - INFO - tqdm - f1: 0.8191, accuracy: 0.8742, batch_loss: 0.1100, loss: 0.3909 ||: 100%|#########9| 1883/1889 [01:47<00:00, 17.57it/s]
2022-03-21 04:11:18,048 - INFO - tqdm - f1: 0.8190, accuracy: 0.8742, batch_loss: 0.1917, loss: 0.3911 ||: 100%|#########9| 1885/1889 [01:47<00:00, 17.91it/s]
2022-03-21 04:11:18,198 - INFO - tqdm - f1: 0.8190, accuracy: 0.8741, batch_loss: 0.4434, loss: 0.3911 ||: 100%|#########9| 1887/1889 [01:47<00:00, 16.48it/s]
2022-03-21 04:11:18,314 - INFO - tqdm - f1: 0.8190, accuracy: 0.8742, batch_loss: 0.0502, loss: 0.3911 ||: 100%|##########| 1889/1889 [01:47<00:00, 16.66it/s]
2022-03-21 04:11:18,326 - INFO - tqdm - f1: 0.8190, accuracy: 0.8742, batch_loss: 0.0502, loss: 0.3911 ||: 100%|##########| 1889/1889 [01:47<00:00, 17.51it/s]
2022-03-21 04:11:18,346 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-21 04:11:18,348 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-21 04:11:19,720 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-21 04:11:19,723 - INFO - allennlp.training.util - Iterating over dataset
2022-03-21 04:11:19,726 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-21 04:11:19,770 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 04:11:19,772 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 04:11:29,738 - INFO - tqdm - f1: 0.83, accuracy: 0.88, loss: 0.36 ||: : 170it [00:10, 16.39it/s]
2022-03-21 04:11:39,816 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.37 ||: : 343it [00:20, 16.71it/s]
2022-03-21 04:11:49,887 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.38 ||: : 523it [00:30, 16.48it/s]
2022-03-21 04:11:59,996 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.38 ||: : 698it [00:40, 16.44it/s]
2022-03-21 04:12:10,043 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.37 ||: : 876it [00:50, 16.23it/s]
2022-03-21 04:12:20,112 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.37 ||: : 1055it [01:00, 19.90it/s]
2022-03-21 04:12:30,222 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.38 ||: : 1230it [01:10, 16.86it/s]
2022-03-21 04:12:40,279 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.38 ||: : 1398it [01:20, 16.15it/s]
2022-03-21 04:12:50,352 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.38 ||: : 1581it [01:30, 19.48it/s]
2022-03-21 04:13:00,408 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.37 ||: : 1745it [01:40, 18.26it/s]
2022-03-21 04:13:08,100 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 1,
  "peak_worker_0_memory_MB": 8639.08984375,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "1:26:20.244932",
  "training_start_epoch": 0,
  "training_epochs": 3,
  "epoch": 3,
  "training_f1": 0.8453839778900146,
  "training_accuracy": 0.8989002443901355,
  "training_loss": 0.2759333128530999,
  "training_worker_0_memory_MB": 8639.08984375,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.8186813712120056,
  "validation_accuracy": 0.875943333774659,
  "validation_loss": 0.3688787445093196,
  "best_validation_f1": 0.8199103236198425,
  "best_validation_accuracy": 0.8756785383291408,
  "best_validation_loss": 0.35224555137647584,
  "test_f1": 0.8116758227348327,
  "test_accuracy": 0.8669985067197611,
  "test_loss": 0.3745906613416171
}
2022-03-21 04:13:08,317 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/rct-20k_base_hyper_small_seed_97/model.tar.gz
