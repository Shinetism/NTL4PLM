2022-03-20 21:23:42,810 - INFO - allennlp.common.params - random_seed = 47
2022-03-20 21:23:42,810 - INFO - allennlp.common.params - numpy_seed = 47
2022-03-20 21:23:42,810 - INFO - allennlp.common.params - pytorch_seed = 47
2022-03-20 21:23:42,811 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-20 21:23:42,812 - INFO - allennlp.common.params - type = default
2022-03-20 21:23:42,812 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-20 21:23:42,812 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-20 21:23:42,813 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-20 21:23:42,813 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-20 21:23:42,813 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-20 21:23:42,813 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-20 21:23:42,813 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-20 21:23:55,289 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-20 21:23:55,289 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-20 21:23:55,290 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-20 21:23:55,290 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-20 21:23:55,290 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-20 21:23:55,290 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-20 21:23:55,290 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-20 21:23:55,290 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-20 21:23:55,290 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-20 21:23:55,291 - INFO - allennlp.common.params - train_data_path = datasets/chemprot/train.jsonl
2022-03-20 21:23:55,291 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7fbe81a3c250>
2022-03-20 21:23:55,291 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-20 21:23:55,291 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-20 21:23:55,292 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-20 21:23:55,292 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-20 21:23:55,292 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-20 21:23:55,292 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-20 21:23:55,292 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-20 21:23:55,292 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-20 21:23:55,292 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-20 21:23:55,293 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-20 21:23:55,293 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-20 21:23:55,293 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-20 21:23:55,293 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-20 21:23:55,293 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-20 21:23:55,293 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-20 21:23:55,293 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-20 21:23:55,293 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-20 21:23:55,293 - INFO - allennlp.common.params - validation_data_path = datasets/chemprot/dev.jsonl
2022-03-20 21:23:55,293 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-20 21:23:55,294 - INFO - allennlp.common.params - test_data_path = datasets/chemprot/test.jsonl
2022-03-20 21:23:55,294 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-20 21:23:55,294 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-20 21:23:55,294 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-20 21:23:55,294 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-20 21:23:55,294 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-20 21:23:55,294 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-20 21:23:55,294 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-20 21:23:55,294 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-20 21:23:55,294 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-20 21:23:55,295 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-20 21:23:55,295 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-20 21:23:55,295 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-20 21:23:55,295 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-20 21:23:55,295 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-20 21:23:55,295 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-20 21:23:55,295 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-20 21:23:55,296 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-20 21:23:57,008 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-20 21:23:57,009 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-20 21:23:57,009 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-20 21:23:57,009 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-20 21:23:57,009 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-20 21:23:57,009 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-20 21:23:57,009 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-20 21:23:57,009 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-20 21:23:57,009 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-20 21:23:57,009 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-20 21:23:57,010 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-20 21:23:57,010 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-20 21:23:57,010 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-20 21:23:57,010 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-20 21:23:57,010 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-20 21:23:57,966 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-20 21:23:57,966 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-20 21:23:57,966 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-20 21:23:57,966 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-20 21:23:57,966 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-20 21:23:57,967 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-20 21:23:57,967 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-20 21:23:57,967 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-20 21:23:57,967 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-20 21:23:57,967 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-20 21:23:57,967 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-20 21:23:57,967 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-20 21:23:57,967 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-20 21:23:57,967 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-20 21:23:57,967 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-20 21:23:59,523 - INFO - allennlp.common.params - type = from_instances
2022-03-20 21:23:59,523 - INFO - allennlp.common.params - min_count = None
2022-03-20 21:23:59,523 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-20 21:23:59,523 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-20 21:23:59,523 - INFO - allennlp.common.params - pretrained_files = None
2022-03-20 21:23:59,523 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-20 21:23:59,524 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-20 21:23:59,524 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-20 21:23:59,524 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-20 21:23:59,524 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-20 21:23:59,524 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-20 21:23:59,524 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-20 21:23:59,601 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-20 21:23:59,601 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-20 21:23:59,602 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-20 21:23:59,602 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-20 21:23:59,602 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-20 21:23:59,602 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-20 21:23:59,602 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-20 21:23:59,602 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-20 21:23:59,602 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-20 21:23:59,602 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-20 21:23:59,602 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-20 21:23:59,602 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-20 21:23:59,602 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-20 21:24:05,285 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-20 21:24:05,285 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-20 21:24:05,286 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-20 21:24:05,286 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-20 21:24:05,286 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-20 21:24:05,286 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-20 21:24:05,286 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-20 21:24:05,286 - INFO - allennlp.common.params - type = tanh
2022-03-20 21:24:05,287 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-20 21:24:05,290 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-20 21:24:05,290 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-20 21:24:05,290 - INFO - allennlp.common.params - model.num_labels = None
2022-03-20 21:24:05,291 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-20 21:24:05,291 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fbe81a566d0>
2022-03-20 21:24:05,291 - INFO - allennlp.common.params - model.regularizer = None
2022-03-20 21:24:05,291 - INFO - allennlp.common.params - model.track_weights = False
2022-03-20 21:24:05,291 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-20 21:24:05,291 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-20 21:24:05,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-20 21:24:05,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-20 21:24:05,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-20 21:24:05,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-20 21:24:05,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-20 21:24:05,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-20 21:24:05,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-20 21:24:05,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-20 21:24:05,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-20 21:24:05,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-20 21:24:05,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-20 21:24:05,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-20 21:24:05,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-20 21:24:05,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-20 21:24:05,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-20 21:24:05,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-20 21:24:05,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-20 21:24:06,614 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-20 21:24:06,615 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-20 21:24:06,615 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-20 21:24:06,615 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-20 21:24:06,616 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-20 21:24:06,616 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-20 21:24:06,616 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-20 21:24:06,616 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-20 21:24:06,616 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-20 21:24:06,616 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-20 21:24:06,616 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-20 21:24:06,616 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-20 21:24:06,616 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-20 21:24:06,616 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-20 21:24:06,616 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-20 21:24:06,616 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-20 21:24:06,616 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-20 21:24:13,774 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-20 21:24:13,774 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-20 21:24:13,775 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-20 21:24:13,775 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-20 21:24:13,775 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-20 21:24:13,775 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-20 21:24:13,776 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-20 21:24:13,776 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias'], {'weight_decay': 0}
2022-03-20 21:24:13,776 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight'], {}
2022-03-20 21:24:13,777 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-20 21:24:13,777 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125246221
2022-03-20 21:24:13,778 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-20 21:24:13,778 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-20 21:24:13,778 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-20 21:24:13,778 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-20 21:24:13,778 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-20 21:24:13,778 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-20 21:24:13,778 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-20 21:24:13,778 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-20 21:24:13,778 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-20 21:24:13,778 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-20 21:24:13,778 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-20 21:24:13,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-20 21:24:13,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-20 21:24:13,781 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-20 21:24:13,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-20 21:24:13,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-20 21:24:13,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-20 21:24:13,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-20 21:24:13,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-20 21:24:13,787 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-20 21:24:13,787 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-20 21:24:13,787 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-20 21:24:13,787 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-20 21:24:13,787 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-20 21:24:13,787 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-20 21:24:13,787 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-20 21:24:13,787 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-20 21:24:13,787 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-20 21:24:13,787 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-20 21:24:13,787 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-20 21:24:13,787 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-20 21:24:13,787 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-20 21:24:13,789 - INFO - allennlp.training.trainer - Beginning training.
2022-03-20 21:24:13,789 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-20 21:24:13,789 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.9G
2022-03-20 21:24:13,789 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 21:24:13,790 - INFO - allennlp.training.trainer - Training
2022-03-20 21:24:13,790 - INFO - tqdm - 0%|          | 0/261 [00:00<?, ?it/s]
2022-03-20 21:24:13,793 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-20 21:24:13,793 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-20 21:24:23,805 - INFO - tqdm - f1: 0.0522, accuracy: 0.3686, batch_loss: 1.7041, loss: 2.0564 ||:  23%|##2       | 59/261 [00:10<00:42,  4.80it/s]
2022-03-20 21:24:33,827 - INFO - tqdm - f1: 0.1256, accuracy: 0.4402, batch_loss: 0.8578, loss: 1.7831 ||:  52%|#####2    | 137/261 [00:20<00:30,  4.07it/s]
2022-03-20 21:24:44,097 - INFO - tqdm - f1: 0.2082, accuracy: 0.5079, batch_loss: 1.5152, loss: 1.5445 ||:  84%|########3 | 218/261 [00:30<00:10,  4.07it/s]
2022-03-20 21:24:48,922 - INFO - tqdm - f1: 0.2513, accuracy: 0.5391, batch_loss: 0.5807, loss: 1.4423 ||: 100%|#########9| 260/261 [00:35<00:00, 10.01it/s]
2022-03-20 21:24:49,011 - INFO - tqdm - f1: 0.2515, accuracy: 0.5397, batch_loss: 1.0263, loss: 1.4407 ||: 100%|##########| 261/261 [00:35<00:00,  7.41it/s]
2022-03-20 21:24:49,018 - INFO - allennlp.training.trainer - Validating
2022-03-20 21:24:49,019 - INFO - tqdm - 0%|          | 0/152 [00:00<?, ?it/s]
2022-03-20 21:24:49,022 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-20 21:24:49,022 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-20 21:24:58,906 - INFO - tqdm - f1: 0.4125, accuracy: 0.7091, batch_loss: 1.3018, loss: 0.9136 ||: 100%|##########| 152/152 [00:09<00:00, 15.37it/s]
2022-03-20 21:24:58,915 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/chemprot_base_hyper_small_seed_47/best.th'.
2022-03-20 21:24:59,495 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 21:24:59,495 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.540  |     0.709
2022-03-20 21:24:59,496 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.251  |     0.412
2022-03-20 21:24:59,496 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 21:24:59,496 - INFO - allennlp.training.callbacks.console_logger - loss               |     1.441  |     0.914
2022-03-20 21:24:59,496 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  6000.906  |       N/A
2022-03-20 21:24:59,496 - INFO - allennlp.training.trainer - Epoch duration: 0:00:45.707033
2022-03-20 21:24:59,496 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:06:51
2022-03-20 21:24:59,496 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-20 21:24:59,496 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.0G
2022-03-20 21:24:59,497 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 21:24:59,497 - INFO - allennlp.training.trainer - Training
2022-03-20 21:24:59,498 - INFO - tqdm - 0%|          | 0/261 [00:00<?, ?it/s]
2022-03-20 21:25:09,525 - INFO - tqdm - f1: 0.4420, accuracy: 0.7633, batch_loss: 0.9167, loss: 0.7529 ||:  29%|##8       | 75/261 [00:10<00:17, 10.36it/s]
2022-03-20 21:25:19,607 - INFO - tqdm - f1: 0.4581, accuracy: 0.7753, batch_loss: 0.8237, loss: 0.7238 ||:  58%|#####8    | 152/261 [00:20<00:10, 10.41it/s]
2022-03-20 21:25:29,678 - INFO - tqdm - f1: 0.4694, accuracy: 0.7840, batch_loss: 0.6726, loss: 0.7011 ||:  88%|########7 | 229/261 [00:30<00:03,  9.98it/s]
2022-03-20 21:25:33,683 - INFO - tqdm - f1: 0.4773, accuracy: 0.7868, batch_loss: 0.5082, loss: 0.6937 ||: 100%|##########| 261/261 [00:34<00:00, 10.12it/s]
2022-03-20 21:25:33,685 - INFO - tqdm - f1: 0.4773, accuracy: 0.7868, batch_loss: 0.5082, loss: 0.6937 ||: 100%|##########| 261/261 [00:34<00:00,  7.63it/s]
2022-03-20 21:25:33,692 - INFO - allennlp.training.trainer - Validating
2022-03-20 21:25:33,693 - INFO - tqdm - 0%|          | 0/152 [00:00<?, ?it/s]
2022-03-20 21:25:43,598 - INFO - tqdm - f1: 0.5000, accuracy: 0.8158, batch_loss: 0.0950, loss: 0.6543 ||: 100%|##########| 152/152 [00:09<00:00, 15.35it/s]
2022-03-20 21:25:43,606 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/chemprot_base_hyper_small_seed_47/best.th'.
2022-03-20 21:25:44,162 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 21:25:44,162 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.787  |     0.816
2022-03-20 21:25:44,162 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.477  |     0.500
2022-03-20 21:25:44,162 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 21:25:44,162 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.694  |     0.654
2022-03-20 21:25:44,162 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  6145.977  |       N/A
2022-03-20 21:25:44,162 - INFO - allennlp.training.trainer - Epoch duration: 0:00:44.666082
2022-03-20 21:25:44,162 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:06:01
2022-03-20 21:25:44,163 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-20 21:25:44,163 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.0G
2022-03-20 21:25:44,163 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 21:25:44,164 - INFO - allennlp.training.trainer - Training
2022-03-20 21:25:44,164 - INFO - tqdm - 0%|          | 0/261 [00:00<?, ?it/s]
2022-03-20 21:25:54,233 - INFO - tqdm - f1: 0.5422, accuracy: 0.8355, batch_loss: 0.3541, loss: 0.5037 ||:  29%|##9       | 76/261 [00:10<00:20,  9.25it/s]
2022-03-20 21:26:04,255 - INFO - tqdm - f1: 0.5385, accuracy: 0.8370, batch_loss: 0.5684, loss: 0.5101 ||:  57%|#####7    | 150/261 [00:20<00:13,  8.30it/s]
2022-03-20 21:26:14,329 - INFO - tqdm - f1: 0.5517, accuracy: 0.8462, batch_loss: 0.2341, loss: 0.4899 ||:  87%|########6 | 226/261 [00:30<00:04,  7.64it/s]
2022-03-20 21:26:18,460 - INFO - tqdm - f1: 0.5541, accuracy: 0.8478, batch_loss: 0.3660, loss: 0.4898 ||: 100%|#########9| 260/261 [00:34<00:00,  9.93it/s]
2022-03-20 21:26:18,547 - INFO - tqdm - f1: 0.5542, accuracy: 0.8479, batch_loss: 0.5495, loss: 0.4901 ||: 100%|##########| 261/261 [00:34<00:00,  7.59it/s]
2022-03-20 21:26:18,554 - INFO - allennlp.training.trainer - Validating
2022-03-20 21:26:18,555 - INFO - tqdm - 0%|          | 0/152 [00:00<?, ?it/s]
2022-03-20 21:26:28,447 - INFO - tqdm - f1: 0.5092, accuracy: 0.8043, batch_loss: 0.8622, loss: 0.6698 ||: 100%|##########| 152/152 [00:09<00:00, 15.37it/s]
2022-03-20 21:26:28,455 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/chemprot_base_hyper_small_seed_47/best.th'.
2022-03-20 21:26:29,008 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 21:26:29,008 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.848  |     0.804
2022-03-20 21:26:29,008 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.554  |     0.509
2022-03-20 21:26:29,008 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 21:26:29,008 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.490  |     0.670
2022-03-20 21:26:29,008 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  6146.125  |       N/A
2022-03-20 21:26:29,008 - INFO - allennlp.training.trainer - Epoch duration: 0:00:44.845783
2022-03-20 21:26:29,008 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:05:15
2022-03-20 21:26:29,008 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-20 21:26:29,009 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.0G
2022-03-20 21:26:29,009 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 21:26:29,010 - INFO - allennlp.training.trainer - Training
2022-03-20 21:26:29,010 - INFO - tqdm - 0%|          | 0/261 [00:00<?, ?it/s]
2022-03-20 21:26:39,030 - INFO - tqdm - f1: 0.6240, accuracy: 0.8931, batch_loss: 0.6154, loss: 0.3538 ||:  29%|##9       | 76/261 [00:10<00:17, 10.43it/s]
2022-03-20 21:26:49,197 - INFO - tqdm - f1: 0.6176, accuracy: 0.8959, batch_loss: 0.1449, loss: 0.3435 ||:  59%|#####8    | 153/261 [00:20<00:12,  8.91it/s]
2022-03-20 21:26:59,207 - INFO - tqdm - f1: 0.6247, accuracy: 0.8993, batch_loss: 0.5373, loss: 0.3351 ||:  89%|########8 | 232/261 [00:30<00:02,  9.76it/s]
2022-03-20 21:27:02,755 - INFO - tqdm - f1: 0.6237, accuracy: 0.8993, batch_loss: 0.6152, loss: 0.3391 ||: 100%|#########9| 260/261 [00:33<00:00, 10.29it/s]
2022-03-20 21:27:02,848 - INFO - tqdm - f1: 0.6240, accuracy: 0.8995, batch_loss: 0.2409, loss: 0.3387 ||: 100%|##########| 261/261 [00:33<00:00,  7.71it/s]
2022-03-20 21:27:02,863 - INFO - allennlp.training.trainer - Validating
2022-03-20 21:27:02,864 - INFO - tqdm - 0%|          | 0/152 [00:00<?, ?it/s]
2022-03-20 21:27:12,622 - INFO - tqdm - f1: 0.5217, accuracy: 0.8150, batch_loss: 0.2836, loss: 0.6523 ||: 100%|##########| 152/152 [00:09<00:00, 19.42it/s]
2022-03-20 21:27:12,623 - INFO - tqdm - f1: 0.5217, accuracy: 0.8150, batch_loss: 0.2836, loss: 0.6523 ||: 100%|##########| 152/152 [00:09<00:00, 15.58it/s]
2022-03-20 21:27:12,630 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/chemprot_base_hyper_small_seed_47/best.th'.
2022-03-20 21:27:13,174 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 21:27:13,174 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.899  |     0.815
2022-03-20 21:27:13,174 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.624  |     0.522
2022-03-20 21:27:13,174 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 21:27:13,174 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.339  |     0.652
2022-03-20 21:27:13,174 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  6146.359  |       N/A
2022-03-20 21:27:13,174 - INFO - allennlp.training.trainer - Epoch duration: 0:00:44.165862
2022-03-20 21:27:13,174 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:29
2022-03-20 21:27:13,174 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-20 21:27:13,175 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.0G
2022-03-20 21:27:13,175 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 21:27:13,176 - INFO - allennlp.training.trainer - Training
2022-03-20 21:27:13,176 - INFO - tqdm - 0%|          | 0/261 [00:00<?, ?it/s]
2022-03-20 21:27:23,246 - INFO - tqdm - f1: 0.6400, accuracy: 0.9263, batch_loss: 0.2155, loss: 0.2528 ||:  30%|##9       | 78/261 [00:10<00:18,  9.84it/s]
2022-03-20 21:27:33,387 - INFO - tqdm - f1: 0.6688, accuracy: 0.9292, batch_loss: 0.2842, loss: 0.2489 ||:  61%|######    | 158/261 [00:20<00:11,  8.99it/s]
2022-03-20 21:27:43,551 - INFO - tqdm - f1: 0.6678, accuracy: 0.9260, batch_loss: 0.1161, loss: 0.2500 ||:  91%|######### | 237/261 [00:30<00:02,  8.09it/s]
2022-03-20 21:27:46,675 - INFO - tqdm - f1: 0.6674, accuracy: 0.9246, batch_loss: 0.1648, loss: 0.2561 ||: 100%|#########9| 260/261 [00:33<00:00,  6.98it/s]
2022-03-20 21:27:46,762 - INFO - tqdm - f1: 0.6671, accuracy: 0.9244, batch_loss: 0.4796, loss: 0.2569 ||: 100%|##########| 261/261 [00:33<00:00,  7.77it/s]
2022-03-20 21:27:46,770 - INFO - allennlp.training.trainer - Validating
2022-03-20 21:27:46,771 - INFO - tqdm - 0%|          | 0/152 [00:00<?, ?it/s]
2022-03-20 21:27:56,593 - INFO - tqdm - f1: 0.5397, accuracy: 0.8109, batch_loss: 0.3086, loss: 0.7164 ||: 100%|##########| 152/152 [00:09<00:00, 12.67it/s]
2022-03-20 21:27:56,594 - INFO - tqdm - f1: 0.5397, accuracy: 0.8109, batch_loss: 0.3086, loss: 0.7164 ||: 100%|##########| 152/152 [00:09<00:00, 15.47it/s]
2022-03-20 21:27:56,602 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/chemprot_base_hyper_small_seed_47/best.th'.
2022-03-20 21:27:57,152 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 21:27:57,152 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.924  |     0.811
2022-03-20 21:27:57,153 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.667  |     0.540
2022-03-20 21:27:57,153 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 21:27:57,153 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.257  |     0.716
2022-03-20 21:27:57,153 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  6146.488  |       N/A
2022-03-20 21:27:57,153 - INFO - allennlp.training.trainer - Epoch duration: 0:00:43.978341
2022-03-20 21:27:57,153 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:43
2022-03-20 21:27:57,153 - INFO - allennlp.training.trainer - Epoch 5/9
2022-03-20 21:27:57,153 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.0G
2022-03-20 21:27:57,153 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 21:27:57,154 - INFO - allennlp.training.trainer - Training
2022-03-20 21:27:57,154 - INFO - tqdm - 0%|          | 0/261 [00:00<?, ?it/s]
2022-03-20 21:28:07,189 - INFO - tqdm - f1: 0.6741, accuracy: 0.9343, batch_loss: 0.5438, loss: 0.2036 ||:  30%|##9       | 77/261 [00:10<00:25,  7.08it/s]
2022-03-20 21:28:17,255 - INFO - tqdm - f1: 0.7159, accuracy: 0.9353, batch_loss: 0.2661, loss: 0.2105 ||:  59%|#####9    | 155/261 [00:20<00:18,  5.87it/s]
2022-03-20 21:28:27,367 - INFO - tqdm - f1: 0.7072, accuracy: 0.9326, batch_loss: 0.0312, loss: 0.2194 ||:  90%|########9 | 234/261 [00:30<00:05,  4.91it/s]
2022-03-20 21:28:30,663 - INFO - tqdm - f1: 0.7033, accuracy: 0.9323, batch_loss: 0.1560, loss: 0.2181 ||: 100%|#########9| 260/261 [00:33<00:00,  4.09it/s]
2022-03-20 21:28:30,752 - INFO - tqdm - f1: 0.7030, accuracy: 0.9324, batch_loss: 0.1574, loss: 0.2179 ||: 100%|##########| 261/261 [00:33<00:00,  7.77it/s]
2022-03-20 21:28:30,758 - INFO - allennlp.training.trainer - Validating
2022-03-20 21:28:30,759 - INFO - tqdm - 0%|          | 0/152 [00:00<?, ?it/s]
2022-03-20 21:28:39,586 - INFO - tqdm - f1: 0.5237, accuracy: 0.8183, batch_loss: 0.5006, loss: 0.8068 ||: 100%|##########| 152/152 [00:08<00:00, 24.10it/s]
2022-03-20 21:28:39,587 - INFO - tqdm - f1: 0.5237, accuracy: 0.8183, batch_loss: 0.5006, loss: 0.8068 ||: 100%|##########| 152/152 [00:08<00:00, 17.22it/s]
2022-03-20 21:28:39,594 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 21:28:39,594 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.932  |     0.818
2022-03-20 21:28:39,594 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.703  |     0.524
2022-03-20 21:28:39,594 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 21:28:39,594 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.218  |     0.807
2022-03-20 21:28:39,594 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  6146.523  |       N/A
2022-03-20 21:28:39,594 - INFO - allennlp.training.trainer - Epoch duration: 0:00:42.441484
2022-03-20 21:28:39,594 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:57
2022-03-20 21:28:39,595 - INFO - allennlp.training.trainer - Epoch 6/9
2022-03-20 21:28:39,595 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.0G
2022-03-20 21:28:39,595 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 21:28:39,595 - INFO - allennlp.training.trainer - Training
2022-03-20 21:28:39,596 - INFO - tqdm - 0%|          | 0/261 [00:00<?, ?it/s]
2022-03-20 21:28:49,609 - INFO - tqdm - f1: 0.7858, accuracy: 0.9651, batch_loss: 0.0975, loss: 0.1191 ||:  30%|##9       | 77/261 [00:10<00:16, 11.10it/s]
2022-03-20 21:28:59,667 - INFO - tqdm - f1: 0.7587, accuracy: 0.9540, batch_loss: 0.0132, loss: 0.1477 ||:  59%|#####9    | 154/261 [00:20<00:10,  9.81it/s]
2022-03-20 21:29:09,709 - INFO - tqdm - f1: 0.7815, accuracy: 0.9490, batch_loss: 0.2488, loss: 0.1621 ||:  89%|########8 | 232/261 [00:30<00:02, 10.18it/s]
2022-03-20 21:29:13,264 - INFO - tqdm - f1: 0.7757, accuracy: 0.9485, batch_loss: 0.2984, loss: 0.1677 ||: 100%|#########9| 260/261 [00:33<00:00,  9.81it/s]
2022-03-20 21:29:13,369 - INFO - tqdm - f1: 0.7753, accuracy: 0.9484, batch_loss: 0.0894, loss: 0.1674 ||: 100%|##########| 261/261 [00:33<00:00,  7.73it/s]
2022-03-20 21:29:13,376 - INFO - allennlp.training.trainer - Validating
2022-03-20 21:29:13,377 - INFO - tqdm - 0%|          | 0/152 [00:00<?, ?it/s]
2022-03-20 21:29:23,279 - INFO - tqdm - f1: 0.5372, accuracy: 0.8228, batch_loss: 0.0499, loss: 0.7375 ||: 100%|##########| 152/152 [00:09<00:00, 15.35it/s]
2022-03-20 21:29:23,288 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 21:29:23,288 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.948  |     0.823
2022-03-20 21:29:23,288 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.775  |     0.537
2022-03-20 21:29:23,288 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 21:29:23,288 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.167  |     0.738
2022-03-20 21:29:23,288 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  6146.523  |       N/A
2022-03-20 21:29:23,288 - INFO - allennlp.training.trainer - Epoch duration: 0:00:43.693415
2022-03-20 21:29:23,288 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:12
2022-03-20 21:29:23,288 - INFO - allennlp.training.trainer - Epoch 7/9
2022-03-20 21:29:23,288 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.0G
2022-03-20 21:29:23,288 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 21:29:23,289 - INFO - allennlp.training.trainer - Training
2022-03-20 21:29:23,289 - INFO - tqdm - 0%|          | 0/261 [00:00<?, ?it/s]
2022-03-20 21:29:33,316 - INFO - tqdm - f1: 0.8396, accuracy: 0.9671, batch_loss: 0.2351, loss: 0.1232 ||:  29%|##9       | 76/261 [00:10<00:31,  5.81it/s]
2022-03-20 21:29:43,371 - INFO - tqdm - f1: 0.8330, accuracy: 0.9645, batch_loss: 0.0250, loss: 0.1286 ||:  58%|#####8    | 152/261 [00:20<00:20,  5.33it/s]
2022-03-20 21:29:53,461 - INFO - tqdm - f1: 0.8266, accuracy: 0.9606, batch_loss: 0.1334, loss: 0.1401 ||:  88%|########7 | 229/261 [00:30<00:08,  3.90it/s]
2022-03-20 21:29:57,413 - INFO - tqdm - f1: 0.8272, accuracy: 0.9592, batch_loss: 0.0160, loss: 0.1447 ||: 100%|##########| 261/261 [00:34<00:00,  6.47it/s]
2022-03-20 21:29:57,415 - INFO - tqdm - f1: 0.8272, accuracy: 0.9592, batch_loss: 0.0160, loss: 0.1447 ||: 100%|##########| 261/261 [00:34<00:00,  7.65it/s]
2022-03-20 21:29:57,422 - INFO - allennlp.training.trainer - Validating
2022-03-20 21:29:57,422 - INFO - tqdm - 0%|          | 0/152 [00:00<?, ?it/s]
2022-03-20 21:30:07,497 - INFO - tqdm - f1: 0.5311, accuracy: 0.8244, batch_loss: 0.8010, loss: 0.8336 ||:  97%|#########7| 148/152 [00:10<00:00,  7.52it/s]
2022-03-20 21:30:07,705 - INFO - tqdm - f1: 0.5314, accuracy: 0.8253, batch_loss: 0.5512, loss: 0.8317 ||: 100%|##########| 152/152 [00:10<00:00,  9.74it/s]
2022-03-20 21:30:07,707 - INFO - tqdm - f1: 0.5314, accuracy: 0.8253, batch_loss: 0.5512, loss: 0.8317 ||: 100%|##########| 152/152 [00:10<00:00, 14.78it/s]
2022-03-20 21:30:07,714 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-20 21:30:07,714 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-20 21:30:08,063 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-20 21:30:08,064 - INFO - allennlp.training.util - Iterating over dataset
2022-03-20 21:30:08,065 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-20 21:30:08,069 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-20 21:30:08,069 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-20 21:30:18,070 - INFO - tqdm - f1: 0.51, accuracy: 0.79, loss: 0.78 ||: : 146it [00:10,  7.41it/s]
2022-03-20 21:30:22,254 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 4,
  "peak_worker_0_memory_MB": 6146.5234375,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "0:05:09.496912",
  "training_start_epoch": 0,
  "training_epochs": 6,
  "epoch": 6,
  "training_f1": 0.7753461461800796,
  "training_accuracy": 0.9484288798272967,
  "training_loss": 0.16740841645447688,
  "training_worker_0_memory_MB": 6146.5234375,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.5371886861438935,
  "validation_accuracy": 0.822826534816646,
  "validation_loss": 0.7375070189959124,
  "best_validation_f1": 0.5397226374882919,
  "best_validation_accuracy": 0.8108776266996292,
  "best_validation_loss": 0.7164017872786835,
  "test_f1": 0.5017031772205462,
  "test_accuracy": 0.7829345632747189,
  "test_loss": 0.8029216701757111
}
2022-03-20 21:30:22,287 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/chemprot_base_hyper_small_seed_47/model.tar.gz
