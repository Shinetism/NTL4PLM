2022-03-22 00:51:22,360 - INFO - allennlp.common.params - random_seed = 97
2022-03-22 00:51:22,363 - INFO - allennlp.common.params - numpy_seed = 97
2022-03-22 00:51:22,365 - INFO - allennlp.common.params - pytorch_seed = 97
2022-03-22 00:51:22,372 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-22 00:51:22,374 - INFO - allennlp.common.params - type = default
2022-03-22 00:51:22,376 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-22 00:51:22,378 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-22 00:51:22,380 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-22 00:51:22,381 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-22 00:51:22,383 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-22 00:51:22,384 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-22 00:51:22,386 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-22 00:51:34,990 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-22 00:51:34,996 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-22 00:51:34,998 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-22 00:51:35,000 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-22 00:51:35,001 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-22 00:51:35,003 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-22 00:51:35,005 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-22 00:51:35,007 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-22 00:51:35,008 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-22 00:51:35,010 - INFO - allennlp.common.params - train_data_path = datasets/amazon/train.jsonl
2022-03-22 00:51:35,013 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f5c8ba83110>
2022-03-22 00:51:35,015 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-22 00:51:35,016 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-22 00:51:35,018 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-22 00:51:35,020 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-22 00:51:35,022 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-22 00:51:35,023 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-22 00:51:35,025 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-22 00:51:35,026 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-22 00:51:35,029 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-22 00:51:35,031 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-22 00:51:35,033 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-22 00:51:35,034 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-22 00:51:35,036 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-22 00:51:35,037 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-22 00:51:35,041 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-22 00:51:35,044 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-22 00:51:35,045 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-22 00:51:35,047 - INFO - allennlp.common.params - validation_data_path = datasets/amazon/dev.jsonl
2022-03-22 00:51:35,048 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-22 00:51:35,050 - INFO - allennlp.common.params - test_data_path = datasets/amazon/test.jsonl
2022-03-22 00:51:35,051 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-22 00:51:35,052 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-22 00:51:35,054 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-22 00:51:35,056 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-22 00:51:35,057 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-22 00:51:35,059 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-22 00:51:35,060 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-22 00:51:35,062 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-22 00:51:35,063 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-22 00:51:35,065 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-22 00:51:35,066 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-22 00:51:35,068 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-22 00:51:35,070 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-22 00:51:35,071 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-22 00:51:35,073 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-22 00:51:35,074 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-22 00:51:35,077 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-22 00:51:45,175 - INFO - tqdm - loading instances: 9103it [00:10, 770.20it/s]
2022-03-22 00:51:55,607 - INFO - tqdm - loading instances: 18727it [00:20, 371.00it/s]
2022-03-22 00:52:05,656 - INFO - tqdm - loading instances: 28648it [00:30, 971.35it/s]
2022-03-22 00:52:16,750 - INFO - tqdm - loading instances: 37752it [00:41, 198.08it/s]
2022-03-22 00:52:27,773 - INFO - tqdm - loading instances: 47573it [00:52, 171.40it/s]
2022-03-22 00:52:37,781 - INFO - tqdm - loading instances: 58177it [01:02, 1051.31it/s]
2022-03-22 00:52:47,790 - INFO - tqdm - loading instances: 66251it [01:12, 1019.94it/s]
2022-03-22 00:52:59,660 - INFO - tqdm - loading instances: 75081it [01:24, 99.29it/s]
2022-03-22 00:53:09,689 - INFO - tqdm - loading instances: 85370it [01:34, 1001.90it/s]
2022-03-22 00:53:22,001 - INFO - tqdm - loading instances: 94309it [01:46, 90.08it/s]
2022-03-22 00:53:32,086 - INFO - tqdm - loading instances: 104797it [01:57, 1025.05it/s]
2022-03-22 00:53:42,188 - INFO - tqdm - loading instances: 115041it [02:07, 919.80it/s]
2022-03-22 00:53:42,387 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-22 00:53:42,390 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-22 00:53:42,392 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-22 00:53:42,393 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-22 00:53:42,395 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-22 00:53:42,397 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-22 00:53:42,398 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-22 00:53:42,400 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-22 00:53:42,401 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-22 00:53:42,403 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-22 00:53:42,405 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-22 00:53:42,407 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-22 00:53:42,408 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-22 00:53:42,409 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-22 00:53:42,411 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-22 00:53:52,485 - INFO - tqdm - loading instances: 4973it [00:10, 934.64it/s]
2022-03-22 00:53:52,521 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-22 00:53:52,523 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-22 00:53:52,525 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-22 00:53:52,526 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-22 00:53:52,528 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-22 00:53:52,529 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-22 00:53:52,531 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-22 00:53:52,532 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-22 00:53:52,534 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-22 00:53:52,536 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-22 00:53:52,537 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-22 00:53:52,539 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-22 00:53:52,540 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-22 00:53:52,542 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-22 00:53:52,544 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-22 00:54:02,599 - INFO - tqdm - loading instances: 9877it [00:10, 995.34it/s]
2022-03-22 00:54:12,659 - INFO - tqdm - loading instances: 20052it [00:20, 1016.70it/s]
2022-03-22 00:54:17,618 - INFO - allennlp.common.params - type = from_instances
2022-03-22 00:54:17,625 - INFO - allennlp.common.params - min_count = None
2022-03-22 00:54:17,627 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-22 00:54:17,629 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-22 00:54:17,631 - INFO - allennlp.common.params - pretrained_files = None
2022-03-22 00:54:17,635 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-22 00:54:17,637 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-22 00:54:17,639 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-22 00:54:17,640 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-22 00:54:17,642 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-22 00:54:17,643 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-22 00:54:17,645 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-22 00:54:20,162 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-22 00:54:20,169 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-22 00:54:20,171 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-22 00:54:20,173 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-22 00:54:20,174 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-22 00:54:20,176 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-22 00:54:20,177 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-22 00:54:20,179 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-22 00:54:20,181 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-22 00:54:20,183 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-22 00:54:20,184 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-22 00:54:20,186 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-22 00:54:20,187 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-22 00:54:26,388 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-22 00:54:26,395 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-22 00:54:26,397 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-22 00:54:26,400 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-22 00:54:26,401 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-22 00:54:26,403 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-22 00:54:26,407 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-22 00:54:26,409 - INFO - allennlp.common.params - type = tanh
2022-03-22 00:54:26,410 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-22 00:54:26,419 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-22 00:54:26,421 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-22 00:54:26,423 - INFO - allennlp.common.params - model.num_labels = None
2022-03-22 00:54:26,424 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-22 00:54:26,426 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f5c8ba971d0>
2022-03-22 00:54:26,428 - INFO - allennlp.common.params - model.regularizer = None
2022-03-22 00:54:26,429 - INFO - allennlp.common.params - model.track_weights = False
2022-03-22 00:54:26,431 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-22 00:54:26,434 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-22 00:54:26,437 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-22 00:54:26,439 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-22 00:54:26,440 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-22 00:54:26,442 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-22 00:54:26,444 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-22 00:54:26,445 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-22 00:54:26,447 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-22 00:54:26,449 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-22 00:54:26,450 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-22 00:54:26,452 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-22 00:54:26,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-22 00:54:26,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-22 00:54:26,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-22 00:54:26,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-22 00:54:26,461 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-22 00:54:26,463 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-22 00:54:26,464 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-22 00:54:26,466 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-22 00:54:26,467 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-22 00:54:26,469 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-22 00:54:26,471 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-22 00:54:26,472 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-22 00:54:26,474 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-22 00:54:26,475 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-22 00:54:26,476 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-22 00:54:26,478 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-22 00:54:26,480 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-22 00:54:26,481 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-22 00:54:26,483 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-22 00:54:26,484 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-22 00:54:26,486 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-22 00:54:26,487 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-22 00:54:26,489 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-22 00:54:26,491 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-22 00:54:26,492 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-22 00:54:26,494 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-22 00:54:26,495 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-22 00:54:26,497 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-22 00:54:26,498 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-22 00:54:26,500 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-22 00:54:26,501 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-22 00:54:26,503 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-22 00:54:26,504 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-22 00:54:26,506 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-22 00:54:26,507 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-22 00:54:26,509 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-22 00:54:26,510 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-22 00:54:26,512 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-22 00:54:26,513 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-22 00:54:26,515 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-22 00:54:26,516 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-22 00:54:26,517 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-22 00:54:26,519 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-22 00:54:26,520 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-22 00:54:26,522 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-22 00:54:26,523 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-22 00:54:26,525 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-22 00:54:26,526 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-22 00:54:26,528 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-22 00:54:26,529 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-22 00:54:26,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-22 00:54:26,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-22 00:54:26,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-22 00:54:26,536 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-22 00:54:26,537 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-22 00:54:26,539 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-22 00:54:26,540 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-22 00:54:26,542 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-22 00:54:26,543 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-22 00:54:26,545 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-22 00:54:26,546 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-22 00:54:26,548 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-22 00:54:26,549 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-22 00:54:26,551 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-22 00:54:26,552 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-22 00:54:26,554 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-22 00:54:26,555 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-22 00:54:26,559 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-22 00:54:26,560 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-22 00:54:26,562 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-22 00:54:26,563 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-22 00:54:26,565 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-22 00:54:26,567 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-22 00:54:26,568 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-22 00:54:26,570 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-22 00:54:26,571 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-22 00:54:26,574 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-22 00:54:26,576 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-22 00:54:26,579 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-22 00:54:26,580 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-22 00:54:26,582 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-22 00:54:26,583 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-22 00:54:26,584 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-22 00:54:26,586 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-22 00:54:26,587 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-22 00:54:26,589 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-22 00:54:26,590 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-22 00:54:26,592 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-22 00:54:26,593 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-22 00:54:26,595 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-22 00:54:26,596 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-22 00:54:26,598 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-22 00:54:26,600 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-22 00:54:26,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-22 00:54:26,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-22 00:54:26,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-22 00:54:26,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-22 00:54:26,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-22 00:54:26,609 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-22 00:54:26,611 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-22 00:54:26,612 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-22 00:54:26,615 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-22 00:54:26,616 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-22 00:54:26,618 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-22 00:54:26,619 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-22 00:54:26,620 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-22 00:54:26,622 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-22 00:54:26,623 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-22 00:54:26,625 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-22 00:54:26,626 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-22 00:54:26,628 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-22 00:54:26,629 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-22 00:54:26,631 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-22 00:54:26,632 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-22 00:54:26,634 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-22 00:54:26,636 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-22 00:54:26,637 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-22 00:54:26,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-22 00:54:26,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-22 00:54:26,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-22 00:54:26,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-22 00:54:26,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-22 00:54:26,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-22 00:54:26,648 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-22 00:54:26,649 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-22 00:54:26,651 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-22 00:54:26,654 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-22 00:54:26,655 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-22 00:54:26,657 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-22 00:54:26,659 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-22 00:54:26,660 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-22 00:54:26,662 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-22 00:54:26,663 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-22 00:54:26,665 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-22 00:54:26,666 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-22 00:54:26,668 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-22 00:54:26,669 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-22 00:54:26,671 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-22 00:54:26,672 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-22 00:54:26,674 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-22 00:54:26,675 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-22 00:54:26,677 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-22 00:54:26,678 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-22 00:54:26,680 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-22 00:54:26,682 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-22 00:54:26,683 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-22 00:54:26,684 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-22 00:54:26,686 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-22 00:54:26,687 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-22 00:54:26,689 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-22 00:54:26,692 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-22 00:54:26,693 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-22 00:54:26,695 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-22 00:54:26,697 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-22 00:54:26,698 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-22 00:54:26,700 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-22 00:54:26,701 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-22 00:54:26,703 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-22 00:54:26,704 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-22 00:54:26,706 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-22 00:54:26,707 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-22 00:54:26,708 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-22 00:54:26,710 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-22 00:54:26,711 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-22 00:54:26,713 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-22 00:54:26,714 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-22 00:54:26,716 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-22 00:54:26,717 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-22 00:54:26,719 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-22 00:54:26,720 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-22 00:54:26,722 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-22 00:54:26,723 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-22 00:54:26,725 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-22 00:54:26,727 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-22 00:54:26,728 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-22 00:54:26,731 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-22 00:54:26,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-22 00:54:26,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-22 00:54:26,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-22 00:54:26,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-22 00:54:26,740 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-22 00:54:26,742 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-22 00:54:26,743 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-22 00:54:26,745 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-22 00:54:26,747 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-22 00:54:26,748 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-22 00:54:26,750 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-22 00:54:26,751 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-22 00:54:26,753 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-22 00:54:26,755 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-22 00:54:26,756 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-22 00:54:26,758 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-22 00:54:26,759 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-22 00:54:26,761 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-22 00:54:43,060 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-22 00:54:43,067 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-22 00:54:43,070 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-22 00:54:43,072 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-22 00:54:43,073 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-22 00:54:43,075 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-22 00:54:43,077 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-22 00:54:43,079 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-22 00:54:43,083 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-22 00:54:43,085 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-22 00:54:43,089 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-22 00:54:43,092 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-22 00:54:43,094 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-22 00:54:43,096 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-22 00:54:43,097 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-22 00:54:43,099 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-22 00:54:43,101 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-22 00:54:51,551 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-22 00:54:51,559 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-22 00:54:51,561 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-22 00:54:51,562 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-22 00:54:51,564 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-22 00:54:51,566 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-22 00:54:51,570 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-22 00:54:51,571 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight'], {'weight_decay': 0}
2022-03-22 00:54:51,574 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight'], {}
2022-03-22 00:54:51,577 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-22 00:54:51,579 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125237762
2022-03-22 00:54:51,582 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-22 00:54:51,584 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-22 00:54:51,586 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-22 00:54:51,588 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-22 00:54:51,590 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-22 00:54:51,592 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-22 00:54:51,593 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-22 00:54:51,595 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-22 00:54:51,597 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-22 00:54:51,599 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-22 00:54:51,600 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-22 00:54:51,602 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-22 00:54:51,604 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-22 00:54:51,606 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-22 00:54:51,608 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-22 00:54:51,609 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-22 00:54:51,611 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-22 00:54:51,612 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-22 00:54:51,614 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-22 00:54:51,615 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-22 00:54:51,617 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-22 00:54:51,619 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-22 00:54:51,620 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-22 00:54:51,622 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-22 00:54:51,623 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-22 00:54:51,625 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-22 00:54:51,626 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-22 00:54:51,628 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-22 00:54:51,629 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-22 00:54:51,631 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-22 00:54:51,632 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-22 00:54:51,634 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-22 00:54:51,635 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-22 00:54:51,637 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-22 00:54:51,638 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-22 00:54:51,639 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-22 00:54:51,641 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-22 00:54:51,642 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-22 00:54:51,645 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-22 00:54:51,646 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-22 00:54:51,648 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-22 00:54:51,649 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-22 00:54:51,650 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-22 00:54:51,652 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-22 00:54:51,653 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-22 00:54:51,654 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-22 00:54:51,656 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-22 00:54:51,657 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-22 00:54:51,659 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-22 00:54:51,660 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-22 00:54:51,662 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-22 00:54:51,663 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-22 00:54:51,664 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-22 00:54:51,666 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-22 00:54:51,667 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-22 00:54:51,669 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-22 00:54:51,671 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-22 00:54:51,673 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-22 00:54:51,674 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-22 00:54:51,675 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-22 00:54:51,677 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-22 00:54:51,678 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-22 00:54:51,680 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-22 00:54:51,681 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-22 00:54:51,683 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-22 00:54:51,684 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-22 00:54:51,686 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-22 00:54:51,687 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-22 00:54:51,688 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-22 00:54:51,690 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-22 00:54:51,691 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-22 00:54:51,692 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-22 00:54:51,694 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-22 00:54:51,695 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-22 00:54:51,696 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-22 00:54:51,698 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-22 00:54:51,699 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-22 00:54:51,701 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-22 00:54:51,702 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-22 00:54:51,703 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-22 00:54:51,705 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-22 00:54:51,706 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-22 00:54:51,708 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-22 00:54:51,709 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-22 00:54:51,711 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-22 00:54:51,712 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-22 00:54:51,713 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-22 00:54:51,715 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-22 00:54:51,716 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-22 00:54:51,718 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-22 00:54:51,720 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-22 00:54:51,721 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-22 00:54:51,723 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-22 00:54:51,724 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-22 00:54:51,725 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-22 00:54:51,727 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-22 00:54:51,728 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-22 00:54:51,730 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-22 00:54:51,731 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-22 00:54:51,733 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-22 00:54:51,734 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-22 00:54:51,735 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-22 00:54:51,737 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-22 00:54:51,738 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-22 00:54:51,740 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-22 00:54:51,741 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-22 00:54:51,742 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-22 00:54:51,744 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-22 00:54:51,745 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-22 00:54:51,747 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-22 00:54:51,748 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-22 00:54:51,750 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-22 00:54:51,751 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-22 00:54:51,753 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-22 00:54:51,754 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-22 00:54:51,756 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-22 00:54:51,758 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-22 00:54:51,759 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-22 00:54:51,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-22 00:54:51,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-22 00:54:51,764 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-22 00:54:51,765 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-22 00:54:51,766 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-22 00:54:51,768 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-22 00:54:51,769 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-22 00:54:51,770 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-22 00:54:51,772 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-22 00:54:51,773 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-22 00:54:51,775 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-22 00:54:51,776 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-22 00:54:51,778 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-22 00:54:51,779 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-22 00:54:51,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-22 00:54:51,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-22 00:54:51,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-22 00:54:51,785 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-22 00:54:51,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-22 00:54:51,787 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-22 00:54:51,789 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-22 00:54:51,790 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-22 00:54:51,792 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-22 00:54:51,794 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-22 00:54:51,795 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-22 00:54:51,797 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-22 00:54:51,798 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-22 00:54:51,799 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-22 00:54:51,801 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-22 00:54:51,802 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-22 00:54:51,803 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-22 00:54:51,805 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-22 00:54:51,806 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-22 00:54:51,808 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-22 00:54:51,809 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-22 00:54:51,810 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-22 00:54:51,812 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-22 00:54:51,813 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-22 00:54:51,816 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-22 00:54:51,817 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-22 00:54:51,819 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-22 00:54:51,820 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-22 00:54:51,822 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-22 00:54:51,823 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-22 00:54:51,824 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-22 00:54:51,826 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-22 00:54:51,827 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-22 00:54:51,829 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-22 00:54:51,830 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-22 00:54:51,833 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-22 00:54:51,834 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-22 00:54:51,835 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-22 00:54:51,837 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-22 00:54:51,838 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-22 00:54:51,839 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-22 00:54:51,841 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-22 00:54:51,842 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-22 00:54:51,844 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-22 00:54:51,845 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-22 00:54:51,846 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-22 00:54:51,848 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-22 00:54:51,850 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-22 00:54:51,851 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-22 00:54:51,853 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-22 00:54:51,854 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-22 00:54:51,855 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-22 00:54:51,857 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-22 00:54:51,858 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-22 00:54:51,860 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-22 00:54:51,861 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-22 00:54:51,863 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-22 00:54:51,864 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-22 00:54:51,866 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-22 00:54:51,867 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-22 00:54:51,869 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-22 00:54:51,871 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-22 00:54:51,872 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-22 00:54:51,873 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-22 00:54:51,875 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-22 00:54:51,876 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-22 00:54:51,878 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-22 00:54:51,879 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-22 00:54:51,881 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-22 00:54:51,882 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-22 00:54:51,883 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-22 00:54:51,885 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-22 00:54:51,886 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-22 00:54:51,888 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-22 00:54:51,890 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-22 00:54:51,891 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-22 00:54:51,893 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-22 00:54:51,894 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-22 00:54:51,896 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-22 00:54:51,901 - INFO - allennlp.training.trainer - Beginning training.
2022-03-22 00:54:51,902 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-22 00:54:51,904 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-22 00:54:51,906 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-22 00:54:51,908 - INFO - allennlp.training.trainer - Training
2022-03-22 00:54:51,909 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-22 00:54:52,058 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-22 00:54:52,061 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-22 00:55:02,063 - INFO - tqdm - f1: 0.4796, accuracy: 0.7723, batch_loss: 0.2564, loss: 0.5074 ||:   0%|          | 28/7204 [00:10<32:37,  3.67it/s]
2022-03-22 00:55:12,135 - INFO - tqdm - f1: 0.4783, accuracy: 0.8322, batch_loss: 0.3675, loss: 0.4270 ||:   1%|1         | 73/7204 [00:20<26:28,  4.49it/s]
2022-03-22 00:55:22,208 - INFO - tqdm - f1: 0.4701, accuracy: 0.8339, batch_loss: 0.2948, loss: 0.4256 ||:   2%|1         | 117/7204 [00:30<23:10,  5.10it/s]
2022-03-22 00:55:32,312 - INFO - tqdm - f1: 0.4722, accuracy: 0.8383, batch_loss: 0.3336, loss: 0.4155 ||:   2%|2         | 160/7204 [00:40<26:20,  4.46it/s]
2022-03-22 00:55:42,461 - INFO - tqdm - f1: 0.4714, accuracy: 0.8450, batch_loss: 0.6117, loss: 0.4018 ||:   3%|2         | 204/7204 [00:50<24:54,  4.68it/s]
2022-03-22 00:55:52,572 - INFO - tqdm - f1: 0.4685, accuracy: 0.8434, batch_loss: 0.5185, loss: 0.4037 ||:   3%|3         | 247/7204 [01:00<23:48,  4.87it/s]
2022-03-22 00:56:02,603 - INFO - tqdm - f1: 0.4688, accuracy: 0.8487, batch_loss: 0.5559, loss: 0.3948 ||:   4%|4         | 290/7204 [01:10<33:45,  3.41it/s]
2022-03-22 00:56:12,854 - INFO - tqdm - f1: 0.4834, accuracy: 0.8463, batch_loss: 0.3555, loss: 0.3943 ||:   5%|4         | 337/7204 [01:20<27:44,  4.13it/s]
2022-03-22 00:56:22,943 - INFO - tqdm - f1: 0.4817, accuracy: 0.8487, batch_loss: 0.4448, loss: 0.3865 ||:   5%|5         | 380/7204 [01:31<24:38,  4.62it/s]
2022-03-22 00:56:33,140 - INFO - tqdm - f1: 0.4807, accuracy: 0.8516, batch_loss: 0.1404, loss: 0.3799 ||:   6%|5         | 424/7204 [01:41<31:57,  3.54it/s]
2022-03-22 00:56:43,247 - INFO - tqdm - f1: 0.4794, accuracy: 0.8532, batch_loss: 0.4327, loss: 0.3760 ||:   7%|6         | 471/7204 [01:51<27:41,  4.05it/s]
2022-03-22 00:56:53,405 - INFO - tqdm - f1: 0.4904, accuracy: 0.8518, batch_loss: 0.4395, loss: 0.3758 ||:   7%|7         | 517/7204 [02:01<26:16,  4.24it/s]
2022-03-22 00:57:03,630 - INFO - tqdm - f1: 0.5007, accuracy: 0.8512, batch_loss: 0.2394, loss: 0.3743 ||:   8%|7         | 561/7204 [02:11<25:08,  4.40it/s]
2022-03-22 00:57:13,772 - INFO - tqdm - f1: 0.5046, accuracy: 0.8524, batch_loss: 0.4782, loss: 0.3709 ||:   8%|8         | 602/7204 [02:21<21:38,  5.09it/s]
2022-03-22 00:57:23,954 - INFO - tqdm - f1: 0.5079, accuracy: 0.8511, batch_loss: 0.1492, loss: 0.3711 ||:   9%|9         | 649/7204 [02:32<24:20,  4.49it/s]
2022-03-22 00:57:34,230 - INFO - tqdm - f1: 0.5102, accuracy: 0.8515, batch_loss: 0.3165, loss: 0.3696 ||:  10%|9         | 695/7204 [02:42<30:44,  3.53it/s]
2022-03-22 00:57:44,351 - INFO - tqdm - f1: 0.5105, accuracy: 0.8529, batch_loss: 0.4551, loss: 0.3676 ||:  10%|#         | 740/7204 [02:52<21:33,  5.00it/s]
2022-03-22 00:57:54,428 - INFO - tqdm - f1: 0.5182, accuracy: 0.8538, batch_loss: 0.0366, loss: 0.3640 ||:  11%|#         | 782/7204 [03:02<28:26,  3.76it/s]
2022-03-22 00:58:04,674 - INFO - tqdm - f1: 0.5187, accuracy: 0.8551, batch_loss: 0.3449, loss: 0.3627 ||:  11%|#1        | 826/7204 [03:12<28:58,  3.67it/s]
2022-03-22 00:58:14,699 - INFO - tqdm - f1: 0.5185, accuracy: 0.8550, batch_loss: 0.1592, loss: 0.3616 ||:  12%|#2        | 867/7204 [03:22<27:39,  3.82it/s]
2022-03-22 00:58:24,818 - INFO - tqdm - f1: 0.5195, accuracy: 0.8543, batch_loss: 0.1828, loss: 0.3633 ||:  13%|#2        | 913/7204 [03:32<19:43,  5.31it/s]
2022-03-22 00:58:35,008 - INFO - tqdm - f1: 0.5191, accuracy: 0.8541, batch_loss: 0.4868, loss: 0.3622 ||:  13%|#3        | 957/7204 [03:43<21:21,  4.88it/s]
2022-03-22 00:58:45,018 - INFO - tqdm - f1: 0.5191, accuracy: 0.8544, batch_loss: 0.2849, loss: 0.3615 ||:  14%|#3        | 998/7204 [03:53<21:02,  4.92it/s]
2022-03-22 00:58:55,231 - INFO - tqdm - f1: 0.5213, accuracy: 0.8543, batch_loss: 0.5516, loss: 0.3616 ||:  14%|#4        | 1043/7204 [04:03<21:07,  4.86it/s]
2022-03-22 00:59:05,387 - INFO - tqdm - f1: 0.5218, accuracy: 0.8546, batch_loss: 0.3211, loss: 0.3614 ||:  15%|#5        | 1086/7204 [04:13<27:39,  3.69it/s]
2022-03-22 00:59:15,442 - INFO - tqdm - f1: 0.5249, accuracy: 0.8543, batch_loss: 0.1774, loss: 0.3618 ||:  16%|#5        | 1131/7204 [04:23<24:32,  4.13it/s]
2022-03-22 00:59:25,469 - INFO - tqdm - f1: 0.5262, accuracy: 0.8543, batch_loss: 0.2714, loss: 0.3616 ||:  16%|#6        | 1175/7204 [04:33<25:19,  3.97it/s]
2022-03-22 00:59:35,620 - INFO - tqdm - f1: 0.5244, accuracy: 0.8545, batch_loss: 0.2553, loss: 0.3607 ||:  17%|#6        | 1215/7204 [04:43<28:18,  3.53it/s]
2022-03-22 00:59:45,625 - INFO - tqdm - f1: 0.5229, accuracy: 0.8539, batch_loss: 0.3969, loss: 0.3616 ||:  17%|#7        | 1258/7204 [04:53<17:17,  5.73it/s]
2022-03-22 00:59:55,686 - INFO - tqdm - f1: 0.5218, accuracy: 0.8539, batch_loss: 0.0589, loss: 0.3607 ||:  18%|#8        | 1301/7204 [05:03<29:20,  3.35it/s]
2022-03-22 01:00:05,972 - INFO - tqdm - f1: 0.5221, accuracy: 0.8541, batch_loss: 0.2211, loss: 0.3599 ||:  19%|#8        | 1346/7204 [05:14<25:34,  3.82it/s]
2022-03-22 01:00:16,105 - INFO - tqdm - f1: 0.5231, accuracy: 0.8542, batch_loss: 0.3749, loss: 0.3598 ||:  19%|#9        | 1391/7204 [05:24<19:41,  4.92it/s]
2022-03-22 01:00:26,292 - INFO - tqdm - f1: 0.5251, accuracy: 0.8542, batch_loss: 0.2564, loss: 0.3592 ||:  20%|#9        | 1438/7204 [05:34<21:40,  4.43it/s]
2022-03-22 01:00:36,303 - INFO - tqdm - f1: 0.5291, accuracy: 0.8545, batch_loss: 0.6385, loss: 0.3578 ||:  21%|##        | 1479/7204 [05:44<21:11,  4.50it/s]
2022-03-22 01:00:46,353 - INFO - tqdm - f1: 0.5294, accuracy: 0.8541, batch_loss: 0.2984, loss: 0.3581 ||:  21%|##1       | 1523/7204 [05:54<22:08,  4.28it/s]
2022-03-22 01:00:56,514 - INFO - tqdm - f1: 0.5320, accuracy: 0.8548, batch_loss: 0.2582, loss: 0.3566 ||:  22%|##1       | 1566/7204 [06:04<20:30,  4.58it/s]
2022-03-22 01:01:06,691 - INFO - tqdm - f1: 0.5340, accuracy: 0.8549, batch_loss: 0.2420, loss: 0.3558 ||:  22%|##2       | 1610/7204 [06:14<19:33,  4.77it/s]
2022-03-22 01:01:16,738 - INFO - tqdm - f1: 0.5369, accuracy: 0.8558, batch_loss: 0.0771, loss: 0.3540 ||:  23%|##2       | 1651/7204 [06:24<21:22,  4.33it/s]
2022-03-22 01:01:27,003 - INFO - tqdm - f1: 0.5390, accuracy: 0.8561, batch_loss: 0.0249, loss: 0.3531 ||:  24%|##3       | 1694/7204 [06:35<24:58,  3.68it/s]
2022-03-22 01:01:37,091 - INFO - tqdm - f1: 0.5390, accuracy: 0.8557, batch_loss: 0.2856, loss: 0.3533 ||:  24%|##4       | 1736/7204 [06:45<22:31,  4.04it/s]
2022-03-22 01:01:47,099 - INFO - tqdm - f1: 0.5404, accuracy: 0.8561, batch_loss: 0.3730, loss: 0.3532 ||:  25%|##4       | 1779/7204 [06:55<19:46,  4.57it/s]
2022-03-22 01:01:57,125 - INFO - tqdm - f1: 0.5418, accuracy: 0.8560, batch_loss: 0.3567, loss: 0.3529 ||:  25%|##5       | 1825/7204 [07:05<17:34,  5.10it/s]
2022-03-22 01:02:07,233 - INFO - tqdm - f1: 0.5425, accuracy: 0.8569, batch_loss: 0.4956, loss: 0.3510 ||:  26%|##5       | 1870/7204 [07:15<18:27,  4.81it/s]
2022-03-22 01:02:17,311 - INFO - tqdm - f1: 0.5454, accuracy: 0.8571, batch_loss: 0.3977, loss: 0.3505 ||:  27%|##6       | 1914/7204 [07:25<20:27,  4.31it/s]
2022-03-22 01:02:27,401 - INFO - tqdm - f1: 0.5488, accuracy: 0.8573, batch_loss: 0.2797, loss: 0.3502 ||:  27%|##7       | 1955/7204 [07:35<19:09,  4.56it/s]
2022-03-22 01:02:37,652 - INFO - tqdm - f1: 0.5488, accuracy: 0.8574, batch_loss: 0.0165, loss: 0.3493 ||:  28%|##7       | 1998/7204 [07:45<23:09,  3.75it/s]
2022-03-22 01:02:47,673 - INFO - tqdm - f1: 0.5477, accuracy: 0.8578, batch_loss: 0.1103, loss: 0.3482 ||:  28%|##8       | 2043/7204 [07:55<20:03,  4.29it/s]
2022-03-22 01:02:57,878 - INFO - tqdm - f1: 0.5501, accuracy: 0.8577, batch_loss: 0.1447, loss: 0.3482 ||:  29%|##8       | 2087/7204 [08:05<20:12,  4.22it/s]
2022-03-22 01:03:08,039 - INFO - tqdm - f1: 0.5526, accuracy: 0.8582, batch_loss: 0.4830, loss: 0.3478 ||:  30%|##9       | 2132/7204 [08:16<16:34,  5.10it/s]
2022-03-22 01:03:18,161 - INFO - tqdm - f1: 0.5549, accuracy: 0.8587, batch_loss: 0.2039, loss: 0.3471 ||:  30%|###       | 2176/7204 [08:26<20:12,  4.15it/s]
2022-03-22 01:03:28,319 - INFO - tqdm - f1: 0.5547, accuracy: 0.8585, batch_loss: 0.1267, loss: 0.3472 ||:  31%|###       | 2221/7204 [08:36<25:04,  3.31it/s]
2022-03-22 01:03:38,459 - INFO - tqdm - f1: 0.5550, accuracy: 0.8586, batch_loss: 0.4224, loss: 0.3468 ||:  31%|###1      | 2266/7204 [08:46<17:14,  4.78it/s]
2022-03-22 01:03:48,518 - INFO - tqdm - f1: 0.5553, accuracy: 0.8589, batch_loss: 0.9550, loss: 0.3462 ||:  32%|###2      | 2307/7204 [08:56<19:48,  4.12it/s]
2022-03-22 01:03:58,591 - INFO - tqdm - f1: 0.5566, accuracy: 0.8591, batch_loss: 0.2999, loss: 0.3457 ||:  33%|###2      | 2353/7204 [09:06<14:41,  5.50it/s]
2022-03-22 01:04:08,652 - INFO - tqdm - f1: 0.5557, accuracy: 0.8590, batch_loss: 0.0681, loss: 0.3456 ||:  33%|###3      | 2394/7204 [09:16<21:36,  3.71it/s]
2022-03-22 01:04:18,771 - INFO - tqdm - f1: 0.5558, accuracy: 0.8593, batch_loss: 0.1557, loss: 0.3447 ||:  34%|###3      | 2433/7204 [09:26<27:23,  2.90it/s]
2022-03-22 01:04:28,819 - INFO - tqdm - f1: 0.5563, accuracy: 0.8594, batch_loss: 0.3102, loss: 0.3445 ||:  34%|###4      | 2477/7204 [09:36<22:08,  3.56it/s]
2022-03-22 01:04:39,005 - INFO - tqdm - f1: 0.5575, accuracy: 0.8597, batch_loss: 0.1822, loss: 0.3437 ||:  35%|###4      | 2521/7204 [09:47<24:49,  3.14it/s]
2022-03-22 01:04:49,222 - INFO - tqdm - f1: 0.5577, accuracy: 0.8595, batch_loss: 0.1622, loss: 0.3439 ||:  36%|###5      | 2569/7204 [09:57<21:33,  3.58it/s]
2022-03-22 01:04:59,341 - INFO - tqdm - f1: 0.5579, accuracy: 0.8595, batch_loss: 0.3115, loss: 0.3437 ||:  36%|###6      | 2616/7204 [10:07<15:44,  4.86it/s]
2022-03-22 01:05:09,430 - INFO - tqdm - f1: 0.5574, accuracy: 0.8595, batch_loss: 0.0894, loss: 0.3435 ||:  37%|###6      | 2660/7204 [10:17<19:31,  3.88it/s]
2022-03-22 01:05:19,450 - INFO - tqdm - f1: 0.5575, accuracy: 0.8595, batch_loss: 0.6052, loss: 0.3433 ||:  38%|###7      | 2704/7204 [10:27<14:38,  5.12it/s]
2022-03-22 01:05:29,718 - INFO - tqdm - f1: 0.5578, accuracy: 0.8599, batch_loss: 0.2068, loss: 0.3421 ||:  38%|###8      | 2748/7204 [10:37<21:30,  3.45it/s]
2022-03-22 01:05:39,867 - INFO - tqdm - f1: 0.5578, accuracy: 0.8598, batch_loss: 0.4308, loss: 0.3420 ||:  39%|###8      | 2792/7204 [10:47<19:22,  3.80it/s]
2022-03-22 01:05:49,974 - INFO - tqdm - f1: 0.5588, accuracy: 0.8600, batch_loss: 0.2033, loss: 0.3421 ||:  39%|###9      | 2837/7204 [10:58<19:01,  3.83it/s]
2022-03-22 01:06:00,163 - INFO - tqdm - f1: 0.5593, accuracy: 0.8602, batch_loss: 0.2913, loss: 0.3417 ||:  40%|###9      | 2879/7204 [11:08<23:08,  3.12it/s]
2022-03-22 01:06:10,243 - INFO - tqdm - f1: 0.5599, accuracy: 0.8599, batch_loss: 0.2610, loss: 0.3418 ||:  41%|####      | 2925/7204 [11:18<15:57,  4.47it/s]
2022-03-22 01:06:20,378 - INFO - tqdm - f1: 0.5605, accuracy: 0.8600, batch_loss: 0.5358, loss: 0.3417 ||:  41%|####1     | 2967/7204 [11:28<18:59,  3.72it/s]
2022-03-22 01:06:30,467 - INFO - tqdm - f1: 0.5604, accuracy: 0.8602, batch_loss: 0.3687, loss: 0.3413 ||:  42%|####1     | 3009/7204 [11:38<17:01,  4.11it/s]
2022-03-22 01:06:40,535 - INFO - tqdm - f1: 0.5603, accuracy: 0.8602, batch_loss: 0.0647, loss: 0.3411 ||:  42%|####2     | 3053/7204 [11:48<18:31,  3.74it/s]
2022-03-22 01:06:50,722 - INFO - tqdm - f1: 0.5609, accuracy: 0.8601, batch_loss: 0.5114, loss: 0.3412 ||:  43%|####3     | 3100/7204 [11:58<16:20,  4.19it/s]
2022-03-22 01:07:00,862 - INFO - tqdm - f1: 0.5613, accuracy: 0.8603, batch_loss: 0.4276, loss: 0.3407 ||:  44%|####3     | 3145/7204 [12:08<15:24,  4.39it/s]
2022-03-22 01:07:10,962 - INFO - tqdm - f1: 0.5617, accuracy: 0.8601, batch_loss: 0.5151, loss: 0.3410 ||:  44%|####4     | 3192/7204 [12:19<12:46,  5.24it/s]
2022-03-22 01:07:20,963 - INFO - tqdm - f1: 0.5622, accuracy: 0.8599, batch_loss: 0.3076, loss: 0.3414 ||:  45%|####4     | 3237/7204 [12:29<13:37,  4.85it/s]
2022-03-22 01:07:31,176 - INFO - tqdm - f1: 0.5617, accuracy: 0.8599, batch_loss: 0.0752, loss: 0.3413 ||:  46%|####5     | 3280/7204 [12:39<18:30,  3.53it/s]
2022-03-22 01:07:41,355 - INFO - tqdm - f1: 0.5619, accuracy: 0.8600, batch_loss: 0.3294, loss: 0.3413 ||:  46%|####6     | 3336/7204 [12:49<06:45,  9.53it/s]
2022-03-22 01:07:51,387 - INFO - tqdm - f1: 0.5648, accuracy: 0.8602, batch_loss: 0.3657, loss: 0.3408 ||:  47%|####7     | 3417/7204 [12:59<09:12,  6.86it/s]
2022-03-22 01:08:01,425 - INFO - tqdm - f1: 0.5652, accuracy: 0.8601, batch_loss: 0.0997, loss: 0.3407 ||:  48%|####8     | 3483/7204 [13:09<08:38,  7.18it/s]
2022-03-22 01:08:11,459 - INFO - tqdm - f1: 0.5650, accuracy: 0.8605, batch_loss: 0.2169, loss: 0.3400 ||:  49%|####9     | 3539/7204 [13:19<09:15,  6.60it/s]
2022-03-22 01:08:21,683 - INFO - tqdm - f1: 0.5663, accuracy: 0.8604, batch_loss: 0.0875, loss: 0.3401 ||:  50%|####9     | 3593/7204 [13:29<13:22,  4.50it/s]
2022-03-22 01:08:31,706 - INFO - tqdm - f1: 0.5672, accuracy: 0.8603, batch_loss: 0.3623, loss: 0.3402 ||:  50%|#####     | 3638/7204 [13:39<11:24,  5.21it/s]
2022-03-22 01:08:41,897 - INFO - tqdm - f1: 0.5686, accuracy: 0.8603, batch_loss: 0.3078, loss: 0.3400 ||:  51%|#####1    | 3678/7204 [13:49<14:22,  4.09it/s]
2022-03-22 01:08:52,264 - INFO - tqdm - f1: 0.5687, accuracy: 0.8603, batch_loss: 0.1886, loss: 0.3399 ||:  52%|#####1    | 3723/7204 [14:00<15:28,  3.75it/s]
2022-03-22 01:09:02,424 - INFO - tqdm - f1: 0.5697, accuracy: 0.8604, batch_loss: 0.4748, loss: 0.3394 ||:  52%|#####2    | 3763/7204 [14:10<13:54,  4.13it/s]
2022-03-22 01:09:12,691 - INFO - tqdm - f1: 0.5708, accuracy: 0.8604, batch_loss: 0.3201, loss: 0.3394 ||:  53%|#####2    | 3806/7204 [14:20<15:31,  3.65it/s]
2022-03-22 01:09:22,745 - INFO - tqdm - f1: 0.5715, accuracy: 0.8604, batch_loss: 0.1242, loss: 0.3394 ||:  53%|#####3    | 3850/7204 [14:30<09:33,  5.85it/s]
2022-03-22 01:09:32,825 - INFO - tqdm - f1: 0.5720, accuracy: 0.8604, batch_loss: 0.4247, loss: 0.3397 ||:  54%|#####4    | 3892/7204 [14:40<14:26,  3.82it/s]
2022-03-22 01:09:42,834 - INFO - tqdm - f1: 0.5716, accuracy: 0.8606, batch_loss: 0.1316, loss: 0.3393 ||:  55%|#####4    | 3932/7204 [14:50<12:33,  4.34it/s]
2022-03-22 01:09:53,030 - INFO - tqdm - f1: 0.5723, accuracy: 0.8606, batch_loss: 0.2509, loss: 0.3392 ||:  55%|#####5    | 3979/7204 [15:01<12:34,  4.27it/s]
2022-03-22 01:10:03,116 - INFO - tqdm - f1: 0.5721, accuracy: 0.8604, batch_loss: 0.2340, loss: 0.3392 ||:  56%|#####5    | 4023/7204 [15:11<11:51,  4.47it/s]
2022-03-22 01:10:13,270 - INFO - tqdm - f1: 0.5738, accuracy: 0.8605, batch_loss: 0.1026, loss: 0.3389 ||:  56%|#####6    | 4067/7204 [15:21<14:25,  3.62it/s]
2022-03-22 01:10:23,278 - INFO - tqdm - f1: 0.5734, accuracy: 0.8605, batch_loss: 0.4225, loss: 0.3388 ||:  57%|#####7    | 4109/7204 [15:31<10:22,  4.97it/s]
2022-03-22 01:10:33,416 - INFO - tqdm - f1: 0.5731, accuracy: 0.8604, batch_loss: 0.3916, loss: 0.3389 ||:  58%|#####7    | 4152/7204 [15:41<13:33,  3.75it/s]
2022-03-22 01:10:43,628 - INFO - tqdm - f1: 0.5737, accuracy: 0.8602, batch_loss: 0.3527, loss: 0.3392 ||:  58%|#####8    | 4201/7204 [15:51<10:07,  4.95it/s]
2022-03-22 01:10:53,855 - INFO - tqdm - f1: 0.5751, accuracy: 0.8603, batch_loss: 0.2819, loss: 0.3393 ||:  59%|#####8    | 4248/7204 [16:01<10:24,  4.73it/s]
2022-03-22 01:11:03,880 - INFO - tqdm - f1: 0.5762, accuracy: 0.8604, batch_loss: 0.4317, loss: 0.3389 ||:  60%|#####9    | 4293/7204 [16:11<09:32,  5.08it/s]
2022-03-22 01:11:13,947 - INFO - tqdm - f1: 0.5764, accuracy: 0.8605, batch_loss: 0.5361, loss: 0.3385 ||:  60%|######    | 4335/7204 [16:22<09:42,  4.93it/s]
2022-03-22 01:11:24,191 - INFO - tqdm - f1: 0.5767, accuracy: 0.8606, batch_loss: 0.1244, loss: 0.3383 ||:  61%|######    | 4379/7204 [16:32<14:43,  3.20it/s]
2022-03-22 01:11:34,398 - INFO - tqdm - f1: 0.5767, accuracy: 0.8606, batch_loss: 0.2237, loss: 0.3384 ||:  61%|######1   | 4425/7204 [16:42<10:04,  4.60it/s]
2022-03-22 01:11:44,533 - INFO - tqdm - f1: 0.5776, accuracy: 0.8605, batch_loss: 0.2173, loss: 0.3384 ||:  62%|######2   | 4470/7204 [16:52<11:41,  3.90it/s]
2022-03-22 01:11:54,649 - INFO - tqdm - f1: 0.5776, accuracy: 0.8604, batch_loss: 0.4549, loss: 0.3386 ||:  63%|######2   | 4511/7204 [17:02<13:50,  3.24it/s]
2022-03-22 01:12:04,650 - INFO - tqdm - f1: 0.5777, accuracy: 0.8603, batch_loss: 0.6063, loss: 0.3387 ||:  63%|######3   | 4557/7204 [17:12<08:18,  5.31it/s]
2022-03-22 01:12:14,762 - INFO - tqdm - f1: 0.5785, accuracy: 0.8604, batch_loss: 0.3796, loss: 0.3386 ||:  64%|######3   | 4601/7204 [17:22<09:20,  4.65it/s]
2022-03-22 01:12:24,821 - INFO - tqdm - f1: 0.5790, accuracy: 0.8605, batch_loss: 0.0501, loss: 0.3382 ||:  64%|######4   | 4643/7204 [17:32<10:32,  4.05it/s]
2022-03-22 01:12:34,858 - INFO - tqdm - f1: 0.5798, accuracy: 0.8607, batch_loss: 0.3736, loss: 0.3377 ||:  65%|######5   | 4683/7204 [17:42<11:09,  3.77it/s]
2022-03-22 01:12:44,884 - INFO - tqdm - f1: 0.5805, accuracy: 0.8605, batch_loss: 0.3090, loss: 0.3378 ||:  66%|######5   | 4730/7204 [17:52<09:25,  4.37it/s]
2022-03-22 01:12:55,038 - INFO - tqdm - f1: 0.5819, accuracy: 0.8606, batch_loss: 0.4394, loss: 0.3377 ||:  66%|######6   | 4774/7204 [18:03<07:58,  5.08it/s]
2022-03-22 01:13:05,070 - INFO - tqdm - f1: 0.5837, accuracy: 0.8606, batch_loss: 0.0855, loss: 0.3374 ||:  67%|######6   | 4817/7204 [18:13<08:35,  4.63it/s]
2022-03-22 01:13:15,146 - INFO - tqdm - f1: 0.5839, accuracy: 0.8604, batch_loss: 0.3425, loss: 0.3379 ||:  67%|######7   | 4861/7204 [18:23<08:22,  4.66it/s]
2022-03-22 01:13:25,328 - INFO - tqdm - f1: 0.5846, accuracy: 0.8606, batch_loss: 0.1279, loss: 0.3374 ||:  68%|######8   | 4903/7204 [18:33<10:21,  3.70it/s]
2022-03-22 01:13:35,572 - INFO - tqdm - f1: 0.5849, accuracy: 0.8608, batch_loss: 0.2364, loss: 0.3370 ||:  69%|######8   | 4949/7204 [18:43<09:49,  3.83it/s]
2022-03-22 01:13:45,617 - INFO - tqdm - f1: 0.5852, accuracy: 0.8608, batch_loss: 0.4388, loss: 0.3369 ||:  69%|######9   | 4997/7204 [18:53<09:03,  4.06it/s]
2022-03-22 01:13:55,619 - INFO - tqdm - f1: 0.5860, accuracy: 0.8606, batch_loss: 0.2746, loss: 0.3372 ||:  70%|#######   | 5044/7204 [19:03<08:40,  4.15it/s]
2022-03-22 01:14:05,704 - INFO - tqdm - f1: 0.5865, accuracy: 0.8606, batch_loss: 0.2431, loss: 0.3370 ||:  71%|#######   | 5087/7204 [19:13<07:39,  4.61it/s]
2022-03-22 01:14:15,947 - INFO - tqdm - f1: 0.5862, accuracy: 0.8606, batch_loss: 0.7876, loss: 0.3369 ||:  71%|#######1  | 5129/7204 [19:24<10:03,  3.44it/s]
2022-03-22 01:14:25,967 - INFO - tqdm - f1: 0.5865, accuracy: 0.8606, batch_loss: 0.1312, loss: 0.3366 ||:  72%|#######1  | 5167/7204 [19:34<09:47,  3.47it/s]
2022-03-22 01:14:36,012 - INFO - tqdm - f1: 0.5867, accuracy: 0.8607, batch_loss: 0.5530, loss: 0.3362 ||:  72%|#######2  | 5208/7204 [19:44<06:42,  4.96it/s]
2022-03-22 01:14:46,184 - INFO - tqdm - f1: 0.5869, accuracy: 0.8606, batch_loss: 0.2143, loss: 0.3363 ||:  73%|#######2  | 5251/7204 [19:54<08:55,  3.64it/s]
2022-03-22 01:14:56,286 - INFO - tqdm - f1: 0.5871, accuracy: 0.8608, batch_loss: 0.1324, loss: 0.3360 ||:  73%|#######3  | 5294/7204 [20:04<07:24,  4.29it/s]
2022-03-22 01:15:06,485 - INFO - tqdm - f1: 0.5879, accuracy: 0.8608, batch_loss: 0.3102, loss: 0.3359 ||:  74%|#######4  | 5338/7204 [20:14<07:34,  4.10it/s]
2022-03-22 01:15:16,721 - INFO - tqdm - f1: 0.5888, accuracy: 0.8608, batch_loss: 0.0622, loss: 0.3359 ||:  75%|#######4  | 5382/7204 [20:24<06:30,  4.66it/s]
2022-03-22 01:15:26,812 - INFO - tqdm - f1: 0.5890, accuracy: 0.8609, batch_loss: 0.3586, loss: 0.3357 ||:  75%|#######5  | 5428/7204 [20:34<07:01,  4.22it/s]
2022-03-22 01:15:36,851 - INFO - tqdm - f1: 0.5891, accuracy: 0.8611, batch_loss: 0.3120, loss: 0.3355 ||:  76%|#######5  | 5472/7204 [20:44<06:11,  4.66it/s]
2022-03-22 01:15:47,034 - INFO - tqdm - f1: 0.5894, accuracy: 0.8610, batch_loss: 0.4130, loss: 0.3356 ||:  77%|#######6  | 5514/7204 [20:55<07:23,  3.81it/s]
2022-03-22 01:15:57,054 - INFO - tqdm - f1: 0.5893, accuracy: 0.8610, batch_loss: 0.2903, loss: 0.3356 ||:  77%|#######7  | 5557/7204 [21:05<05:24,  5.07it/s]
2022-03-22 01:16:07,274 - INFO - tqdm - f1: 0.5900, accuracy: 0.8610, batch_loss: 0.2281, loss: 0.3355 ||:  78%|#######7  | 5604/7204 [21:15<04:56,  5.40it/s]
2022-03-22 01:16:17,281 - INFO - tqdm - f1: 0.5901, accuracy: 0.8610, batch_loss: 0.4519, loss: 0.3355 ||:  78%|#######8  | 5648/7204 [21:25<05:39,  4.59it/s]
2022-03-22 01:16:27,715 - INFO - tqdm - f1: 0.5902, accuracy: 0.8611, batch_loss: 0.0659, loss: 0.3353 ||:  79%|#######8  | 5690/7204 [21:35<07:38,  3.30it/s]
2022-03-22 01:16:37,860 - INFO - tqdm - f1: 0.5904, accuracy: 0.8612, batch_loss: 0.2563, loss: 0.3350 ||:  80%|#######9  | 5737/7204 [21:45<04:35,  5.32it/s]
2022-03-22 01:16:48,080 - INFO - tqdm - f1: 0.5900, accuracy: 0.8610, batch_loss: 0.3921, loss: 0.3353 ||:  80%|########  | 5786/7204 [21:56<06:29,  3.64it/s]
2022-03-22 01:16:58,082 - INFO - tqdm - f1: 0.5909, accuracy: 0.8611, batch_loss: 0.1612, loss: 0.3350 ||:  81%|########  | 5829/7204 [22:06<05:25,  4.22it/s]
2022-03-22 01:17:08,182 - INFO - tqdm - f1: 0.5912, accuracy: 0.8611, batch_loss: 0.4994, loss: 0.3351 ||:  82%|########1 | 5874/7204 [22:16<04:55,  4.50it/s]
2022-03-22 01:17:18,207 - INFO - tqdm - f1: 0.5910, accuracy: 0.8611, batch_loss: 0.2410, loss: 0.3349 ||:  82%|########2 | 5914/7204 [22:26<05:45,  3.73it/s]
2022-03-22 01:17:28,272 - INFO - tqdm - f1: 0.5911, accuracy: 0.8612, batch_loss: 0.2264, loss: 0.3347 ||:  83%|########2 | 5955/7204 [22:36<05:46,  3.60it/s]
2022-03-22 01:17:38,353 - INFO - tqdm - f1: 0.5912, accuracy: 0.8613, batch_loss: 0.4798, loss: 0.3345 ||:  83%|########3 | 5997/7204 [22:46<04:51,  4.14it/s]
2022-03-22 01:17:48,565 - INFO - tqdm - f1: 0.5920, accuracy: 0.8612, batch_loss: 0.3639, loss: 0.3346 ||:  84%|########3 | 6046/7204 [22:56<04:00,  4.82it/s]
2022-03-22 01:17:58,696 - INFO - tqdm - f1: 0.5927, accuracy: 0.8614, batch_loss: 0.4360, loss: 0.3344 ||:  84%|########4 | 6087/7204 [23:06<04:23,  4.24it/s]
2022-03-22 01:18:08,716 - INFO - tqdm - f1: 0.5925, accuracy: 0.8614, batch_loss: 0.5338, loss: 0.3343 ||:  85%|########5 | 6131/7204 [23:16<03:36,  4.95it/s]
2022-03-22 01:18:18,726 - INFO - tqdm - f1: 0.5928, accuracy: 0.8616, batch_loss: 0.3690, loss: 0.3341 ||:  86%|########5 | 6172/7204 [23:26<04:04,  4.21it/s]
2022-03-22 01:18:28,850 - INFO - tqdm - f1: 0.5929, accuracy: 0.8614, batch_loss: 0.6729, loss: 0.3342 ||:  86%|########6 | 6214/7204 [23:36<04:30,  3.66it/s]
2022-03-22 01:18:39,112 - INFO - tqdm - f1: 0.5928, accuracy: 0.8615, batch_loss: 0.3263, loss: 0.3339 ||:  87%|########6 | 6258/7204 [23:47<03:23,  4.64it/s]
2022-03-22 01:18:49,191 - INFO - tqdm - f1: 0.5932, accuracy: 0.8616, batch_loss: 0.3548, loss: 0.3337 ||:  87%|########7 | 6301/7204 [23:57<03:07,  4.82it/s]
2022-03-22 01:18:59,502 - INFO - tqdm - f1: 0.5938, accuracy: 0.8618, batch_loss: 0.2473, loss: 0.3334 ||:  88%|########8 | 6347/7204 [24:07<03:38,  3.92it/s]
2022-03-22 01:19:09,741 - INFO - tqdm - f1: 0.5946, accuracy: 0.8616, batch_loss: 0.4036, loss: 0.3336 ||:  89%|########8 | 6396/7204 [24:17<02:42,  4.98it/s]
2022-03-22 01:19:19,766 - INFO - tqdm - f1: 0.5946, accuracy: 0.8618, batch_loss: 0.3318, loss: 0.3333 ||:  89%|########9 | 6438/7204 [24:27<02:36,  4.88it/s]
2022-03-22 01:19:29,919 - INFO - tqdm - f1: 0.5945, accuracy: 0.8619, batch_loss: 0.4066, loss: 0.3331 ||:  90%|########9 | 6480/7204 [24:38<03:08,  3.85it/s]
2022-03-22 01:19:40,124 - INFO - tqdm - f1: 0.5948, accuracy: 0.8619, batch_loss: 0.1457, loss: 0.3332 ||:  91%|######### | 6524/7204 [24:48<02:48,  4.04it/s]
2022-03-22 01:19:50,164 - INFO - tqdm - f1: 0.5954, accuracy: 0.8618, batch_loss: 0.1468, loss: 0.3334 ||:  91%|#########1| 6569/7204 [24:58<03:28,  3.04it/s]
2022-03-22 01:20:00,365 - INFO - tqdm - f1: 0.5954, accuracy: 0.8619, batch_loss: 0.2791, loss: 0.3330 ||:  92%|#########1| 6609/7204 [25:08<02:24,  4.13it/s]
2022-03-22 01:20:10,443 - INFO - tqdm - f1: 0.5958, accuracy: 0.8618, batch_loss: 0.6159, loss: 0.3331 ||:  92%|#########2| 6653/7204 [25:18<02:20,  3.91it/s]
2022-03-22 01:20:20,525 - INFO - tqdm - f1: 0.5957, accuracy: 0.8617, batch_loss: 0.2712, loss: 0.3332 ||:  93%|#########2| 6696/7204 [25:28<02:37,  3.23it/s]
2022-03-22 01:20:30,636 - INFO - tqdm - f1: 0.5952, accuracy: 0.8616, batch_loss: 0.3699, loss: 0.3334 ||:  94%|#########3| 6742/7204 [25:38<01:32,  5.00it/s]
2022-03-22 01:20:40,904 - INFO - tqdm - f1: 0.5952, accuracy: 0.8618, batch_loss: 0.0287, loss: 0.3328 ||:  94%|#########4| 6784/7204 [25:48<01:59,  3.53it/s]
2022-03-22 01:20:51,062 - INFO - tqdm - f1: 0.5957, accuracy: 0.8618, batch_loss: 0.4302, loss: 0.3328 ||:  95%|#########4| 6828/7204 [25:59<01:28,  4.24it/s]
2022-03-22 01:21:01,136 - INFO - tqdm - f1: 0.5962, accuracy: 0.8620, batch_loss: 0.0355, loss: 0.3324 ||:  95%|#########5| 6870/7204 [26:09<01:43,  3.23it/s]
2022-03-22 01:21:11,227 - INFO - tqdm - f1: 0.5961, accuracy: 0.8621, batch_loss: 0.5381, loss: 0.3322 ||:  96%|#########5| 6907/7204 [26:19<01:23,  3.55it/s]
2022-03-22 01:21:21,283 - INFO - tqdm - f1: 0.5963, accuracy: 0.8621, batch_loss: 0.8860, loss: 0.3322 ||:  96%|#########6| 6949/7204 [26:29<01:06,  3.81it/s]
2022-03-22 01:21:31,319 - INFO - tqdm - f1: 0.5963, accuracy: 0.8622, batch_loss: 0.3663, loss: 0.3321 ||:  97%|#########7| 6990/7204 [26:39<00:53,  3.99it/s]
2022-03-22 01:21:41,468 - INFO - tqdm - f1: 0.5964, accuracy: 0.8621, batch_loss: 0.2823, loss: 0.3323 ||:  98%|#########7| 7035/7204 [26:49<00:41,  4.09it/s]
2022-03-22 01:21:51,481 - INFO - tqdm - f1: 0.5969, accuracy: 0.8620, batch_loss: 0.0640, loss: 0.3324 ||:  98%|#########8| 7080/7204 [26:59<00:32,  3.78it/s]
2022-03-22 01:22:01,550 - INFO - tqdm - f1: 0.5973, accuracy: 0.8621, batch_loss: 0.3406, loss: 0.3323 ||:  99%|#########8| 7127/7204 [27:09<00:17,  4.50it/s]
2022-03-22 01:22:11,034 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.3571, loss: 0.3323 ||: 100%|#########9| 7168/7204 [27:19<00:11,  3.14it/s]
2022-03-22 01:22:11,211 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.4608, loss: 0.3323 ||: 100%|#########9| 7169/7204 [27:19<00:09,  3.62it/s]
2022-03-22 01:22:11,454 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.3105, loss: 0.3323 ||: 100%|#########9| 7170/7204 [27:19<00:09,  3.75it/s]
2022-03-22 01:22:11,622 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.1671, loss: 0.3323 ||: 100%|#########9| 7171/7204 [27:19<00:07,  4.22it/s]
2022-03-22 01:22:11,835 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.3814, loss: 0.3323 ||: 100%|#########9| 7172/7204 [27:19<00:07,  4.36it/s]
2022-03-22 01:22:12,102 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.0977, loss: 0.3322 ||: 100%|#########9| 7173/7204 [27:20<00:07,  4.15it/s]
2022-03-22 01:22:12,228 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.2448, loss: 0.3322 ||: 100%|#########9| 7174/7204 [27:20<00:06,  4.85it/s]
2022-03-22 01:22:12,450 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.3467, loss: 0.3322 ||: 100%|#########9| 7175/7204 [27:20<00:06,  4.74it/s]
2022-03-22 01:22:12,673 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.4189, loss: 0.3322 ||: 100%|#########9| 7176/7204 [27:20<00:06,  4.66it/s]
2022-03-22 01:22:12,941 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.2036, loss: 0.3322 ||: 100%|#########9| 7177/7204 [27:21<00:06,  4.34it/s]
2022-03-22 01:22:13,139 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.5323, loss: 0.3322 ||: 100%|#########9| 7178/7204 [27:21<00:05,  4.53it/s]
2022-03-22 01:22:13,420 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.3465, loss: 0.3322 ||: 100%|#########9| 7179/7204 [27:21<00:05,  4.19it/s]
2022-03-22 01:22:13,596 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.3571, loss: 0.3323 ||: 100%|#########9| 7180/7204 [27:21<00:05,  4.54it/s]
2022-03-22 01:22:13,808 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.3734, loss: 0.3323 ||: 100%|#########9| 7181/7204 [27:21<00:05,  4.60it/s]
2022-03-22 01:22:14,161 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.4081, loss: 0.3323 ||: 100%|#########9| 7182/7204 [27:22<00:05,  3.87it/s]
2022-03-22 01:22:14,330 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.3880, loss: 0.3323 ||: 100%|#########9| 7183/7204 [27:22<00:04,  4.32it/s]
2022-03-22 01:22:14,554 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.1841, loss: 0.3323 ||: 100%|#########9| 7184/7204 [27:22<00:04,  4.36it/s]
2022-03-22 01:22:14,793 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.4141, loss: 0.3323 ||: 100%|#########9| 7185/7204 [27:22<00:04,  4.31it/s]
2022-03-22 01:22:14,917 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.5382, loss: 0.3323 ||: 100%|#########9| 7186/7204 [27:23<00:03,  5.00it/s]
2022-03-22 01:22:15,254 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.0862, loss: 0.3323 ||: 100%|#########9| 7187/7204 [27:23<00:04,  4.15it/s]
2022-03-22 01:22:15,476 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.2029, loss: 0.3322 ||: 100%|#########9| 7188/7204 [27:23<00:03,  4.25it/s]
2022-03-22 01:22:15,603 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.3854, loss: 0.3323 ||: 100%|#########9| 7189/7204 [27:23<00:03,  4.93it/s]
2022-03-22 01:22:15,866 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.2965, loss: 0.3322 ||: 100%|#########9| 7190/7204 [27:23<00:03,  4.53it/s]
2022-03-22 01:22:16,085 - INFO - tqdm - f1: 0.5974, accuracy: 0.8621, batch_loss: 0.5834, loss: 0.3323 ||: 100%|#########9| 7191/7204 [27:24<00:02,  4.54it/s]
2022-03-22 01:22:16,250 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.4029, loss: 0.3323 ||: 100%|#########9| 7192/7204 [27:24<00:02,  4.91it/s]
2022-03-22 01:22:16,434 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.2869, loss: 0.3323 ||: 100%|#########9| 7193/7204 [27:24<00:02,  5.05it/s]
2022-03-22 01:22:16,642 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.5539, loss: 0.3323 ||: 100%|#########9| 7194/7204 [27:24<00:02,  4.98it/s]
2022-03-22 01:22:16,804 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.3625, loss: 0.3323 ||: 100%|#########9| 7195/7204 [27:24<00:01,  5.29it/s]
2022-03-22 01:22:17,017 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.4341, loss: 0.3323 ||: 100%|#########9| 7196/7204 [27:25<00:01,  5.09it/s]
2022-03-22 01:22:17,339 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.0842, loss: 0.3323 ||: 100%|#########9| 7197/7204 [27:25<00:01,  4.27it/s]
2022-03-22 01:22:17,668 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.4601, loss: 0.3323 ||: 100%|#########9| 7198/7204 [27:25<00:01,  3.81it/s]
2022-03-22 01:22:17,823 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.1855, loss: 0.3323 ||: 100%|#########9| 7199/7204 [27:25<00:01,  4.34it/s]
2022-03-22 01:22:18,112 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.1184, loss: 0.3323 ||: 100%|#########9| 7200/7204 [27:26<00:00,  4.04it/s]
2022-03-22 01:22:18,243 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.4509, loss: 0.3323 ||: 100%|#########9| 7201/7204 [27:26<00:00,  4.70it/s]
2022-03-22 01:22:18,493 - INFO - tqdm - f1: 0.5975, accuracy: 0.8621, batch_loss: 0.1626, loss: 0.3323 ||: 100%|#########9| 7202/7204 [27:26<00:00,  4.46it/s]
2022-03-22 01:22:18,902 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.0435, loss: 0.3322 ||: 100%|#########9| 7203/7204 [27:26<00:00,  3.58it/s]
2022-03-22 01:22:19,129 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.2453, loss: 0.3322 ||: 100%|##########| 7204/7204 [27:27<00:00,  3.79it/s]
2022-03-22 01:22:19,183 - INFO - tqdm - f1: 0.5975, accuracy: 0.8622, batch_loss: 0.2453, loss: 0.3322 ||: 100%|##########| 7204/7204 [27:27<00:00,  4.37it/s]
2022-03-22 01:22:19,217 - INFO - allennlp.training.trainer - Validating
2022-03-22 01:22:19,220 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-22 01:22:19,228 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-22 01:22:19,230 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-22 01:22:29,446 - INFO - tqdm - f1: 0.5640, accuracy: 0.8718, batch_loss: 0.2481, loss: 0.3195 ||:  32%|###1      | 99/313 [00:10<00:21, 10.12it/s]
2022-03-22 01:22:39,495 - INFO - tqdm - f1: 0.5860, accuracy: 0.8714, batch_loss: 0.6368, loss: 0.3137 ||:  61%|######1   | 192/313 [00:20<00:14,  8.45it/s]
2022-03-22 01:22:49,557 - INFO - tqdm - f1: 0.5790, accuracy: 0.8642, batch_loss: 0.1701, loss: 0.3188 ||:  92%|#########2| 289/313 [00:30<00:01, 12.45it/s]
2022-03-22 01:22:52,173 - INFO - tqdm - f1: 0.5765, accuracy: 0.8648, batch_loss: 0.6952, loss: 0.3174 ||: 100%|#########9| 312/313 [00:32<00:00,  9.13it/s]
2022-03-22 01:22:52,295 - INFO - tqdm - f1: 0.5759, accuracy: 0.8644, batch_loss: 0.4598, loss: 0.3179 ||: 100%|##########| 313/313 [00:33<00:00,  8.89it/s]
2022-03-22 01:22:52,299 - INFO - tqdm - f1: 0.5759, accuracy: 0.8644, batch_loss: 0.4598, loss: 0.3179 ||: 100%|##########| 313/313 [00:33<00:00,  9.46it/s]
2022-03-22 01:22:52,336 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/amazon_base_hyper_small_seed_97/best.th'.
2022-03-22 01:22:54,988 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-22 01:22:54,991 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.862  |     0.864
2022-03-22 01:22:54,992 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.598  |     0.576
2022-03-22 01:22:54,994 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-22 01:22:54,996 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.332  |     0.318
2022-03-22 01:22:55,001 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13517.281  |       N/A
2022-03-22 01:22:55,003 - INFO - allennlp.training.trainer - Epoch duration: 0:28:03.100424
2022-03-22 01:22:55,005 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:12:27
2022-03-22 01:22:55,007 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-22 01:22:55,008 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-22 01:22:55,010 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-22 01:22:55,013 - INFO - allennlp.training.trainer - Training
2022-03-22 01:22:55,015 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-22 01:23:05,231 - INFO - tqdm - f1: 0.5872, accuracy: 0.8693, batch_loss: 0.1549, loss: 0.3137 ||:   1%|          | 44/7204 [00:10<26:17,  4.54it/s]
2022-03-22 01:23:15,238 - INFO - tqdm - f1: 0.6184, accuracy: 0.8824, batch_loss: 0.1285, loss: 0.2718 ||:   1%|1         | 84/7204 [00:20<27:26,  4.32it/s]
2022-03-22 01:23:25,369 - INFO - tqdm - f1: 0.6419, accuracy: 0.8788, batch_loss: 0.3495, loss: 0.2780 ||:   2%|1         | 130/7204 [00:30<25:12,  4.68it/s]
2022-03-22 01:23:35,438 - INFO - tqdm - f1: 0.6490, accuracy: 0.8783, batch_loss: 0.5724, loss: 0.2792 ||:   2%|2         | 173/7204 [00:40<25:03,  4.68it/s]
2022-03-22 01:23:45,770 - INFO - tqdm - f1: 0.6428, accuracy: 0.8776, batch_loss: 0.1840, loss: 0.2851 ||:   3%|3         | 217/7204 [00:50<35:09,  3.31it/s]
2022-03-22 01:23:55,832 - INFO - tqdm - f1: 0.6438, accuracy: 0.8743, batch_loss: 0.1334, loss: 0.2917 ||:   4%|3         | 263/7204 [01:00<26:10,  4.42it/s]
2022-03-22 01:24:05,917 - INFO - tqdm - f1: 0.6366, accuracy: 0.8727, batch_loss: 0.2095, loss: 0.2921 ||:   4%|4         | 304/7204 [01:10<26:48,  4.29it/s]
2022-03-22 01:24:15,949 - INFO - tqdm - f1: 0.6408, accuracy: 0.8737, batch_loss: 0.2004, loss: 0.2902 ||:   5%|4         | 345/7204 [01:20<28:42,  3.98it/s]
2022-03-22 01:24:26,043 - INFO - tqdm - f1: 0.6432, accuracy: 0.8735, batch_loss: 0.2682, loss: 0.2909 ||:   5%|5         | 387/7204 [01:31<23:57,  4.74it/s]
2022-03-22 01:24:36,095 - INFO - tqdm - f1: 0.6465, accuracy: 0.8731, batch_loss: 0.2271, loss: 0.2927 ||:   6%|6         | 433/7204 [01:41<22:00,  5.13it/s]
2022-03-22 01:24:46,096 - INFO - tqdm - f1: 0.6502, accuracy: 0.8712, batch_loss: 0.1505, loss: 0.2976 ||:   7%|6         | 480/7204 [01:51<23:22,  4.79it/s]
2022-03-22 01:24:56,119 - INFO - tqdm - f1: 0.6508, accuracy: 0.8737, batch_loss: 0.1543, loss: 0.2950 ||:   7%|7         | 520/7204 [02:01<39:06,  2.85it/s]
2022-03-22 01:25:06,240 - INFO - tqdm - f1: 0.6524, accuracy: 0.8733, batch_loss: 0.3566, loss: 0.2969 ||:   8%|7         | 562/7204 [02:11<22:50,  4.84it/s]
2022-03-22 01:25:16,508 - INFO - tqdm - f1: 0.6515, accuracy: 0.8728, batch_loss: 0.4055, loss: 0.2983 ||:   8%|8         | 606/7204 [02:21<31:51,  3.45it/s]
2022-03-22 01:25:26,623 - INFO - tqdm - f1: 0.6538, accuracy: 0.8724, batch_loss: 0.3839, loss: 0.2990 ||:   9%|9         | 654/7204 [02:31<21:27,  5.09it/s]
2022-03-22 01:25:36,770 - INFO - tqdm - f1: 0.6605, accuracy: 0.8745, batch_loss: 0.0871, loss: 0.2963 ||:  10%|9         | 693/7204 [02:41<29:53,  3.63it/s]
2022-03-22 01:25:46,893 - INFO - tqdm - f1: 0.6622, accuracy: 0.8746, batch_loss: 0.3513, loss: 0.2957 ||:  10%|#         | 736/7204 [02:51<27:35,  3.91it/s]
2022-03-22 01:25:57,136 - INFO - tqdm - f1: 0.6653, accuracy: 0.8739, batch_loss: 0.1874, loss: 0.2967 ||:  11%|#1        | 822/7204 [03:02<17:18,  6.14it/s]
2022-03-22 01:26:07,150 - INFO - tqdm - f1: 0.6664, accuracy: 0.8735, batch_loss: 0.6254, loss: 0.2981 ||:  12%|#2        | 876/7204 [03:12<16:09,  6.52it/s]
2022-03-22 01:26:17,361 - INFO - tqdm - f1: 0.6653, accuracy: 0.8729, batch_loss: 0.0149, loss: 0.2997 ||:  13%|#3        | 942/7204 [03:22<23:50,  4.38it/s]
2022-03-22 01:26:27,647 - INFO - tqdm - f1: 0.6687, accuracy: 0.8734, batch_loss: 0.4664, loss: 0.3004 ||:  14%|#3        | 998/7204 [03:32<23:15,  4.45it/s]
2022-03-22 01:26:37,668 - INFO - tqdm - f1: 0.6701, accuracy: 0.8741, batch_loss: 0.2769, loss: 0.2994 ||:  14%|#4        | 1043/7204 [03:42<26:47,  3.83it/s]
2022-03-22 01:26:47,735 - INFO - tqdm - f1: 0.6712, accuracy: 0.8749, batch_loss: 0.0684, loss: 0.2973 ||:  15%|#5        | 1085/7204 [03:52<26:26,  3.86it/s]
2022-03-22 01:26:57,855 - INFO - tqdm - f1: 0.6714, accuracy: 0.8743, batch_loss: 0.3268, loss: 0.2987 ||:  16%|#5        | 1132/7204 [04:02<23:59,  4.22it/s]
2022-03-22 01:27:07,972 - INFO - tqdm - f1: 0.6765, accuracy: 0.8744, batch_loss: 0.2721, loss: 0.2980 ||:  16%|#6        | 1178/7204 [04:12<18:17,  5.49it/s]
2022-03-22 01:27:18,156 - INFO - tqdm - f1: 0.6781, accuracy: 0.8745, batch_loss: 0.4153, loss: 0.2980 ||:  17%|#6        | 1222/7204 [04:23<21:18,  4.68it/s]
2022-03-22 01:27:28,350 - INFO - tqdm - f1: 0.6767, accuracy: 0.8749, batch_loss: 0.3125, loss: 0.2978 ||:  18%|#7        | 1264/7204 [04:33<25:16,  3.92it/s]
2022-03-22 01:27:38,436 - INFO - tqdm - f1: 0.6760, accuracy: 0.8741, batch_loss: 0.4728, loss: 0.2990 ||:  18%|#8        | 1309/7204 [04:43<21:34,  4.55it/s]
2022-03-22 01:27:48,602 - INFO - tqdm - f1: 0.6778, accuracy: 0.8750, batch_loss: 0.0835, loss: 0.2984 ||:  19%|#8        | 1352/7204 [04:53<19:26,  5.02it/s]
2022-03-22 01:27:58,829 - INFO - tqdm - f1: 0.6783, accuracy: 0.8752, batch_loss: 0.2619, loss: 0.2987 ||:  19%|#9        | 1396/7204 [05:03<22:32,  4.29it/s]
2022-03-22 01:28:08,893 - INFO - tqdm - f1: 0.6770, accuracy: 0.8756, batch_loss: 0.2888, loss: 0.2977 ||:  20%|##        | 1441/7204 [05:13<27:02,  3.55it/s]
2022-03-22 01:28:18,940 - INFO - tqdm - f1: 0.6754, accuracy: 0.8750, batch_loss: 0.6070, loss: 0.2983 ||:  21%|##        | 1488/7204 [05:23<22:39,  4.20it/s]
2022-03-22 01:28:29,086 - INFO - tqdm - f1: 0.6739, accuracy: 0.8750, batch_loss: 0.3523, loss: 0.2981 ||:  21%|##1       | 1533/7204 [05:34<17:25,  5.43it/s]
2022-03-22 01:28:39,117 - INFO - tqdm - f1: 0.6746, accuracy: 0.8751, batch_loss: 0.3609, loss: 0.2983 ||:  22%|##1       | 1578/7204 [05:44<18:39,  5.02it/s]
2022-03-22 01:28:49,160 - INFO - tqdm - f1: 0.6751, accuracy: 0.8750, batch_loss: 0.2241, loss: 0.2990 ||:  23%|##2       | 1622/7204 [05:54<21:38,  4.30it/s]
2022-03-22 01:28:59,198 - INFO - tqdm - f1: 0.6725, accuracy: 0.8745, batch_loss: 0.0559, loss: 0.2989 ||:  23%|##3       | 1664/7204 [06:04<22:41,  4.07it/s]
2022-03-22 01:29:09,335 - INFO - tqdm - f1: 0.6729, accuracy: 0.8738, batch_loss: 0.4527, loss: 0.3002 ||:  24%|##3       | 1709/7204 [06:14<20:34,  4.45it/s]
2022-03-22 01:29:19,554 - INFO - tqdm - f1: 0.6736, accuracy: 0.8740, batch_loss: 0.1674, loss: 0.2998 ||:  24%|##4       | 1754/7204 [06:24<21:30,  4.22it/s]
2022-03-22 01:29:29,842 - INFO - tqdm - f1: 0.6755, accuracy: 0.8745, batch_loss: 0.0731, loss: 0.2984 ||:  25%|##4       | 1797/7204 [06:34<25:04,  3.59it/s]
2022-03-22 01:29:39,895 - INFO - tqdm - f1: 0.6760, accuracy: 0.8741, batch_loss: 0.3850, loss: 0.2986 ||:  26%|##5       | 1839/7204 [06:44<19:56,  4.48it/s]
2022-03-22 01:29:49,990 - INFO - tqdm - f1: 0.6753, accuracy: 0.8745, batch_loss: 0.0401, loss: 0.2975 ||:  26%|##6       | 1882/7204 [06:54<23:41,  3.74it/s]
2022-03-22 01:30:00,059 - INFO - tqdm - f1: 0.6764, accuracy: 0.8752, batch_loss: 0.0618, loss: 0.2963 ||:  27%|##6       | 1926/7204 [07:05<19:39,  4.48it/s]
2022-03-22 01:30:10,082 - INFO - tqdm - f1: 0.6768, accuracy: 0.8750, batch_loss: 0.1247, loss: 0.2965 ||:  27%|##7       | 1968/7204 [07:15<29:15,  2.98it/s]
2022-03-22 01:30:20,499 - INFO - tqdm - f1: 0.6762, accuracy: 0.8751, batch_loss: 0.0777, loss: 0.2963 ||:  28%|##7       | 2015/7204 [07:25<26:01,  3.32it/s]
2022-03-22 01:30:30,621 - INFO - tqdm - f1: 0.6769, accuracy: 0.8753, batch_loss: 0.2062, loss: 0.2957 ||:  29%|##8       | 2057/7204 [07:35<20:09,  4.26it/s]
2022-03-22 01:30:40,662 - INFO - tqdm - f1: 0.6768, accuracy: 0.8754, batch_loss: 0.1836, loss: 0.2961 ||:  29%|##9       | 2101/7204 [07:45<16:52,  5.04it/s]
2022-03-22 01:30:50,778 - INFO - tqdm - f1: 0.6776, accuracy: 0.8756, batch_loss: 0.1831, loss: 0.2957 ||:  30%|##9       | 2145/7204 [07:55<18:15,  4.62it/s]
2022-03-22 01:31:00,821 - INFO - tqdm - f1: 0.6783, accuracy: 0.8752, batch_loss: 0.2010, loss: 0.2960 ||:  30%|###       | 2191/7204 [08:05<15:45,  5.30it/s]
2022-03-22 01:31:10,940 - INFO - tqdm - f1: 0.6781, accuracy: 0.8753, batch_loss: 0.2136, loss: 0.2963 ||:  31%|###1      | 2236/7204 [08:15<21:39,  3.82it/s]
2022-03-22 01:31:21,062 - INFO - tqdm - f1: 0.6787, accuracy: 0.8755, batch_loss: 0.0996, loss: 0.2956 ||:  32%|###1      | 2275/7204 [08:26<20:51,  3.94it/s]
2022-03-22 01:31:31,194 - INFO - tqdm - f1: 0.6776, accuracy: 0.8747, batch_loss: 0.3990, loss: 0.2971 ||:  32%|###2      | 2322/7204 [08:36<17:09,  4.74it/s]
2022-03-22 01:31:41,295 - INFO - tqdm - f1: 0.6765, accuracy: 0.8746, batch_loss: 0.2237, loss: 0.2975 ||:  33%|###2      | 2368/7204 [08:46<13:46,  5.85it/s]
2022-03-22 01:31:51,345 - INFO - tqdm - f1: 0.6764, accuracy: 0.8745, batch_loss: 0.7460, loss: 0.2979 ||:  33%|###3      | 2413/7204 [08:56<17:24,  4.59it/s]
2022-03-22 01:32:01,519 - INFO - tqdm - f1: 0.6756, accuracy: 0.8744, batch_loss: 0.2682, loss: 0.2982 ||:  34%|###4      | 2455/7204 [09:06<16:17,  4.86it/s]
2022-03-22 01:32:11,555 - INFO - tqdm - f1: 0.6754, accuracy: 0.8742, batch_loss: 0.4130, loss: 0.2986 ||:  35%|###4      | 2495/7204 [09:16<17:12,  4.56it/s]
2022-03-22 01:32:21,715 - INFO - tqdm - f1: 0.6759, accuracy: 0.8740, batch_loss: 0.1932, loss: 0.2990 ||:  35%|###5      | 2543/7204 [09:26<19:04,  4.07it/s]
2022-03-22 01:32:31,796 - INFO - tqdm - f1: 0.6762, accuracy: 0.8740, batch_loss: 0.0217, loss: 0.2991 ||:  36%|###5      | 2589/7204 [09:36<20:00,  3.84it/s]
2022-03-22 01:32:42,071 - INFO - tqdm - f1: 0.6768, accuracy: 0.8742, batch_loss: 0.1951, loss: 0.2990 ||:  37%|###6      | 2633/7204 [09:47<20:52,  3.65it/s]
2022-03-22 01:32:52,339 - INFO - tqdm - f1: 0.6772, accuracy: 0.8741, batch_loss: 0.2809, loss: 0.2992 ||:  37%|###7      | 2676/7204 [09:57<20:09,  3.74it/s]
2022-03-22 01:33:02,409 - INFO - tqdm - f1: 0.6779, accuracy: 0.8744, batch_loss: 0.2247, loss: 0.2991 ||:  38%|###7      | 2720/7204 [10:07<15:28,  4.83it/s]
2022-03-22 01:33:12,495 - INFO - tqdm - f1: 0.6780, accuracy: 0.8745, batch_loss: 0.1283, loss: 0.2989 ||:  38%|###8      | 2764/7204 [10:17<21:02,  3.52it/s]
2022-03-22 01:33:22,635 - INFO - tqdm - f1: 0.6779, accuracy: 0.8746, batch_loss: 0.3808, loss: 0.2988 ||:  39%|###8      | 2809/7204 [10:27<15:03,  4.87it/s]
2022-03-22 01:33:32,728 - INFO - tqdm - f1: 0.6773, accuracy: 0.8746, batch_loss: 0.2048, loss: 0.2990 ||:  40%|###9      | 2850/7204 [10:37<18:31,  3.92it/s]
2022-03-22 01:33:43,044 - INFO - tqdm - f1: 0.6774, accuracy: 0.8746, batch_loss: 0.1365, loss: 0.2989 ||:  40%|####      | 2894/7204 [10:48<19:57,  3.60it/s]
2022-03-22 01:33:53,123 - INFO - tqdm - f1: 0.6781, accuracy: 0.8743, batch_loss: 0.3035, loss: 0.2991 ||:  41%|####      | 2939/7204 [10:58<15:07,  4.70it/s]
2022-03-22 01:34:03,384 - INFO - tqdm - f1: 0.6790, accuracy: 0.8742, batch_loss: 0.0298, loss: 0.2991 ||:  41%|####1     | 2985/7204 [11:08<17:35,  4.00it/s]
2022-03-22 01:34:13,431 - INFO - tqdm - f1: 0.6792, accuracy: 0.8746, batch_loss: 0.3457, loss: 0.2990 ||:  42%|####2     | 3028/7204 [11:18<15:28,  4.50it/s]
2022-03-22 01:34:23,468 - INFO - tqdm - f1: 0.6797, accuracy: 0.8748, batch_loss: 0.1914, loss: 0.2986 ||:  43%|####2     | 3070/7204 [11:28<18:04,  3.81it/s]
2022-03-22 01:34:33,474 - INFO - tqdm - f1: 0.6791, accuracy: 0.8750, batch_loss: 0.5743, loss: 0.2984 ||:  43%|####3     | 3112/7204 [11:38<15:59,  4.27it/s]
2022-03-22 01:34:43,678 - INFO - tqdm - f1: 0.6783, accuracy: 0.8749, batch_loss: 0.3598, loss: 0.2984 ||:  44%|####3     | 3158/7204 [11:48<15:56,  4.23it/s]
2022-03-22 01:34:53,752 - INFO - tqdm - f1: 0.6783, accuracy: 0.8749, batch_loss: 0.5592, loss: 0.2984 ||:  44%|####4     | 3200/7204 [11:58<12:35,  5.30it/s]
2022-03-22 01:35:03,999 - INFO - tqdm - f1: 0.6775, accuracy: 0.8749, batch_loss: 0.0769, loss: 0.2982 ||:  45%|####5     | 3246/7204 [12:08<16:56,  3.90it/s]
2022-03-22 01:35:14,334 - INFO - tqdm - f1: 0.6764, accuracy: 0.8749, batch_loss: 0.3577, loss: 0.2982 ||:  46%|####5     | 3288/7204 [12:19<21:35,  3.02it/s]
2022-03-22 01:35:24,546 - INFO - tqdm - f1: 0.6763, accuracy: 0.8748, batch_loss: 0.0815, loss: 0.2983 ||:  46%|####6     | 3335/7204 [12:29<17:56,  3.59it/s]
2022-03-22 01:35:34,724 - INFO - tqdm - f1: 0.6760, accuracy: 0.8748, batch_loss: 0.1982, loss: 0.2984 ||:  47%|####6     | 3379/7204 [12:39<16:48,  3.79it/s]
2022-03-22 01:35:44,770 - INFO - tqdm - f1: 0.6759, accuracy: 0.8748, batch_loss: 0.4103, loss: 0.2986 ||:  47%|####7     | 3418/7204 [12:49<13:27,  4.69it/s]
2022-03-22 01:35:54,908 - INFO - tqdm - f1: 0.6765, accuracy: 0.8748, batch_loss: 0.1705, loss: 0.2987 ||:  48%|####8     | 3466/7204 [12:59<13:35,  4.59it/s]
2022-03-22 01:36:04,965 - INFO - tqdm - f1: 0.6762, accuracy: 0.8750, batch_loss: 0.4671, loss: 0.2983 ||:  49%|####8     | 3507/7204 [13:09<14:49,  4.15it/s]
2022-03-22 01:36:15,248 - INFO - tqdm - f1: 0.6769, accuracy: 0.8750, batch_loss: 0.1112, loss: 0.2984 ||:  49%|####9     | 3550/7204 [13:20<17:18,  3.52it/s]
2022-03-22 01:36:25,529 - INFO - tqdm - f1: 0.6764, accuracy: 0.8748, batch_loss: 0.1277, loss: 0.2986 ||:  50%|####9     | 3595/7204 [13:30<17:14,  3.49it/s]
2022-03-22 01:36:35,661 - INFO - tqdm - f1: 0.6766, accuracy: 0.8748, batch_loss: 0.2213, loss: 0.2983 ||:  51%|#####     | 3639/7204 [13:40<15:04,  3.94it/s]
2022-03-22 01:36:45,807 - INFO - tqdm - f1: 0.6764, accuracy: 0.8750, batch_loss: 0.3121, loss: 0.2983 ||:  51%|#####1    | 3683/7204 [13:50<13:19,  4.40it/s]
2022-03-22 01:36:56,040 - INFO - tqdm - f1: 0.6760, accuracy: 0.8751, batch_loss: 0.5117, loss: 0.2983 ||:  52%|#####1    | 3725/7204 [14:01<16:24,  3.53it/s]
2022-03-22 01:37:06,144 - INFO - tqdm - f1: 0.6762, accuracy: 0.8752, batch_loss: 0.0445, loss: 0.2980 ||:  52%|#####2    | 3770/7204 [14:11<15:10,  3.77it/s]
2022-03-22 01:37:16,149 - INFO - tqdm - f1: 0.6769, accuracy: 0.8753, batch_loss: 0.3285, loss: 0.2978 ||:  53%|#####2    | 3813/7204 [14:21<13:09,  4.29it/s]
2022-03-22 01:37:26,237 - INFO - tqdm - f1: 0.6769, accuracy: 0.8751, batch_loss: 0.1554, loss: 0.2978 ||:  54%|#####3    | 3857/7204 [14:31<11:51,  4.70it/s]
2022-03-22 01:37:36,482 - INFO - tqdm - f1: 0.6774, accuracy: 0.8752, batch_loss: 0.5629, loss: 0.2978 ||:  54%|#####4    | 3905/7204 [14:41<13:56,  3.94it/s]
2022-03-22 01:37:46,650 - INFO - tqdm - f1: 0.6770, accuracy: 0.8752, batch_loss: 0.1552, loss: 0.2976 ||:  55%|#####4    | 3944/7204 [14:51<18:54,  2.87it/s]
2022-03-22 01:37:56,761 - INFO - tqdm - f1: 0.6765, accuracy: 0.8751, batch_loss: 0.3589, loss: 0.2975 ||:  55%|#####5    | 3989/7204 [15:01<13:37,  3.93it/s]
2022-03-22 01:38:06,841 - INFO - tqdm - f1: 0.6769, accuracy: 0.8751, batch_loss: 0.1850, loss: 0.2974 ||:  56%|#####5    | 4031/7204 [15:11<11:19,  4.67it/s]
2022-03-22 01:38:17,044 - INFO - tqdm - f1: 0.6772, accuracy: 0.8752, batch_loss: 0.2521, loss: 0.2972 ||:  57%|#####6    | 4075/7204 [15:22<12:43,  4.10it/s]
2022-03-22 01:38:27,299 - INFO - tqdm - f1: 0.6773, accuracy: 0.8754, batch_loss: 0.1731, loss: 0.2970 ||:  57%|#####7    | 4117/7204 [15:32<14:05,  3.65it/s]
2022-03-22 01:38:37,514 - INFO - tqdm - f1: 0.6772, accuracy: 0.8754, batch_loss: 0.0981, loss: 0.2970 ||:  58%|#####7    | 4164/7204 [15:42<13:06,  3.87it/s]
2022-03-22 01:38:47,691 - INFO - tqdm - f1: 0.6776, accuracy: 0.8754, batch_loss: 0.1011, loss: 0.2971 ||:  58%|#####8    | 4208/7204 [15:52<12:25,  4.02it/s]
2022-03-22 01:38:57,764 - INFO - tqdm - f1: 0.6777, accuracy: 0.8755, batch_loss: 0.0189, loss: 0.2969 ||:  59%|#####9    | 4252/7204 [16:02<13:27,  3.66it/s]
2022-03-22 01:39:08,057 - INFO - tqdm - f1: 0.6768, accuracy: 0.8752, batch_loss: 0.1611, loss: 0.2971 ||:  60%|#####9    | 4295/7204 [16:13<14:37,  3.31it/s]
2022-03-22 01:39:18,083 - INFO - tqdm - f1: 0.6767, accuracy: 0.8751, batch_loss: 0.2601, loss: 0.2973 ||:  60%|######    | 4339/7204 [16:23<12:24,  3.85it/s]
2022-03-22 01:39:28,243 - INFO - tqdm - f1: 0.6768, accuracy: 0.8751, batch_loss: 0.3034, loss: 0.2974 ||:  61%|######    | 4382/7204 [16:33<10:33,  4.46it/s]
2022-03-22 01:39:38,429 - INFO - tqdm - f1: 0.6772, accuracy: 0.8751, batch_loss: 0.2922, loss: 0.2974 ||:  61%|######1   | 4427/7204 [16:43<10:04,  4.60it/s]
2022-03-22 01:39:48,579 - INFO - tqdm - f1: 0.6773, accuracy: 0.8754, batch_loss: 0.0354, loss: 0.2969 ||:  62%|######2   | 4467/7204 [16:53<12:54,  3.53it/s]
2022-03-22 01:39:58,650 - INFO - tqdm - f1: 0.6765, accuracy: 0.8752, batch_loss: 0.2904, loss: 0.2972 ||:  63%|######2   | 4511/7204 [17:03<09:43,  4.61it/s]
2022-03-22 01:40:08,857 - INFO - tqdm - f1: 0.6770, accuracy: 0.8752, batch_loss: 0.4560, loss: 0.2973 ||:  63%|######3   | 4554/7204 [17:13<10:11,  4.33it/s]
2022-03-22 01:40:19,007 - INFO - tqdm - f1: 0.6780, accuracy: 0.8751, batch_loss: 0.0982, loss: 0.2974 ||:  64%|######3   | 4598/7204 [17:23<12:01,  3.61it/s]
2022-03-22 01:40:29,317 - INFO - tqdm - f1: 0.6785, accuracy: 0.8749, batch_loss: 0.1457, loss: 0.2980 ||:  64%|######4   | 4644/7204 [17:34<10:29,  4.07it/s]
2022-03-22 01:40:39,375 - INFO - tqdm - f1: 0.6786, accuracy: 0.8748, batch_loss: 0.3702, loss: 0.2981 ||:  65%|######5   | 4695/7204 [17:44<09:03,  4.62it/s]
2022-03-22 01:40:49,555 - INFO - tqdm - f1: 0.6790, accuracy: 0.8749, batch_loss: 0.7337, loss: 0.2981 ||:  66%|######5   | 4737/7204 [17:54<08:12,  5.01it/s]
2022-03-22 01:40:59,862 - INFO - tqdm - f1: 0.6788, accuracy: 0.8748, batch_loss: 0.0962, loss: 0.2980 ||:  66%|######6   | 4782/7204 [18:04<10:39,  3.79it/s]
2022-03-22 01:41:09,870 - INFO - tqdm - f1: 0.6786, accuracy: 0.8747, batch_loss: 0.5867, loss: 0.2981 ||:  67%|######6   | 4823/7204 [18:14<07:33,  5.25it/s]
2022-03-22 01:41:20,039 - INFO - tqdm - f1: 0.6787, accuracy: 0.8747, batch_loss: 0.5548, loss: 0.2981 ||:  68%|######7   | 4870/7204 [18:25<08:23,  4.64it/s]
2022-03-22 01:41:30,238 - INFO - tqdm - f1: 0.6788, accuracy: 0.8747, batch_loss: 0.2795, loss: 0.2983 ||:  68%|######8   | 4913/7204 [18:35<09:53,  3.86it/s]
2022-03-22 01:41:40,501 - INFO - tqdm - f1: 0.6790, accuracy: 0.8747, batch_loss: 0.0764, loss: 0.2984 ||:  69%|######8   | 4957/7204 [18:45<09:24,  3.98it/s]
2022-03-22 01:41:50,797 - INFO - tqdm - f1: 0.6787, accuracy: 0.8746, batch_loss: 0.0788, loss: 0.2985 ||:  69%|######9   | 5002/7204 [18:55<10:24,  3.53it/s]
2022-03-22 01:42:00,912 - INFO - tqdm - f1: 0.6786, accuracy: 0.8747, batch_loss: 0.3470, loss: 0.2986 ||:  70%|#######   | 5045/7204 [19:05<08:20,  4.31it/s]
2022-03-22 01:42:10,943 - INFO - tqdm - f1: 0.6787, accuracy: 0.8748, batch_loss: 0.2334, loss: 0.2984 ||:  71%|#######   | 5089/7204 [19:15<08:33,  4.12it/s]
2022-03-22 01:42:20,955 - INFO - tqdm - f1: 0.6790, accuracy: 0.8749, batch_loss: 0.1718, loss: 0.2983 ||:  71%|#######1  | 5132/7204 [19:25<06:45,  5.11it/s]
2022-03-22 01:42:31,053 - INFO - tqdm - f1: 0.6790, accuracy: 0.8749, batch_loss: 0.7485, loss: 0.2984 ||:  72%|#######1  | 5175/7204 [19:36<06:43,  5.02it/s]
2022-03-22 01:42:41,257 - INFO - tqdm - f1: 0.6796, accuracy: 0.8749, batch_loss: 0.2455, loss: 0.2983 ||:  72%|#######2  | 5220/7204 [19:46<08:13,  4.02it/s]
2022-03-22 01:42:51,550 - INFO - tqdm - f1: 0.6789, accuracy: 0.8748, batch_loss: 0.1129, loss: 0.2983 ||:  73%|#######3  | 5265/7204 [19:56<08:42,  3.71it/s]
2022-03-22 01:43:01,608 - INFO - tqdm - f1: 0.6793, accuracy: 0.8750, batch_loss: 0.2412, loss: 0.2980 ||:  74%|#######3  | 5304/7204 [20:06<09:33,  3.31it/s]
2022-03-22 01:43:11,659 - INFO - tqdm - f1: 0.6792, accuracy: 0.8750, batch_loss: 0.2619, loss: 0.2980 ||:  74%|#######4  | 5349/7204 [20:16<08:33,  3.61it/s]
2022-03-22 01:43:21,767 - INFO - tqdm - f1: 0.6795, accuracy: 0.8751, batch_loss: 0.3786, loss: 0.2981 ||:  75%|#######4  | 5392/7204 [20:26<05:52,  5.15it/s]
2022-03-22 01:43:31,985 - INFO - tqdm - f1: 0.6799, accuracy: 0.8751, batch_loss: 0.3036, loss: 0.2981 ||:  75%|#######5  | 5439/7204 [20:36<08:05,  3.64it/s]
2022-03-22 01:43:42,242 - INFO - tqdm - f1: 0.6796, accuracy: 0.8752, batch_loss: 0.1269, loss: 0.2979 ||:  76%|#######6  | 5485/7204 [20:47<06:49,  4.19it/s]
2022-03-22 01:43:52,354 - INFO - tqdm - f1: 0.6804, accuracy: 0.8752, batch_loss: 0.5032, loss: 0.2980 ||:  77%|#######6  | 5531/7204 [20:57<05:33,  5.02it/s]
2022-03-22 01:44:02,657 - INFO - tqdm - f1: 0.6805, accuracy: 0.8753, batch_loss: 0.1497, loss: 0.2979 ||:  77%|#######7  | 5573/7204 [21:07<07:28,  3.64it/s]
2022-03-22 01:44:13,029 - INFO - tqdm - f1: 0.6802, accuracy: 0.8753, batch_loss: 0.1797, loss: 0.2979 ||:  78%|#######8  | 5652/7204 [21:18<03:07,  8.26it/s]
2022-03-22 01:44:23,103 - INFO - tqdm - f1: 0.6803, accuracy: 0.8754, batch_loss: 0.1554, loss: 0.2980 ||:  79%|#######9  | 5710/7204 [21:28<04:39,  5.34it/s]
2022-03-22 01:44:33,138 - INFO - tqdm - f1: 0.6804, accuracy: 0.8754, batch_loss: 0.2125, loss: 0.2980 ||:  80%|########  | 5767/7204 [21:38<04:04,  5.88it/s]
2022-03-22 01:44:43,205 - INFO - tqdm - f1: 0.6800, accuracy: 0.8752, batch_loss: 0.4318, loss: 0.2984 ||:  81%|########  | 5826/7204 [21:48<04:21,  5.28it/s]
2022-03-22 01:44:53,439 - INFO - tqdm - f1: 0.6800, accuracy: 0.8753, batch_loss: 0.6516, loss: 0.2984 ||:  81%|########1 | 5871/7204 [21:58<06:16,  3.54it/s]
2022-03-22 01:45:03,581 - INFO - tqdm - f1: 0.6799, accuracy: 0.8753, batch_loss: 0.2406, loss: 0.2982 ||:  82%|########2 | 5914/7204 [22:08<05:11,  4.14it/s]
2022-03-22 01:45:13,724 - INFO - tqdm - f1: 0.6791, accuracy: 0.8751, batch_loss: 0.2423, loss: 0.2986 ||:  83%|########2 | 5960/7204 [22:18<05:05,  4.07it/s]
2022-03-22 01:45:23,771 - INFO - tqdm - f1: 0.6789, accuracy: 0.8751, batch_loss: 0.1265, loss: 0.2985 ||:  83%|########3 | 6004/7204 [22:28<04:51,  4.12it/s]
2022-03-22 01:45:33,914 - INFO - tqdm - f1: 0.6788, accuracy: 0.8751, batch_loss: 0.1640, loss: 0.2984 ||:  84%|########3 | 6047/7204 [22:38<03:46,  5.11it/s]
2022-03-22 01:45:44,142 - INFO - tqdm - f1: 0.6785, accuracy: 0.8750, batch_loss: 0.1206, loss: 0.2986 ||:  85%|########4 | 6090/7204 [22:49<05:04,  3.65it/s]
2022-03-22 01:45:54,184 - INFO - tqdm - f1: 0.6792, accuracy: 0.8750, batch_loss: 0.0973, loss: 0.2989 ||:  85%|########5 | 6135/7204 [22:59<04:24,  4.05it/s]
2022-03-22 01:46:04,213 - INFO - tqdm - f1: 0.6793, accuracy: 0.8751, batch_loss: 0.2206, loss: 0.2988 ||:  86%|########5 | 6180/7204 [23:09<04:13,  4.04it/s]
2022-03-22 01:46:14,239 - INFO - tqdm - f1: 0.6795, accuracy: 0.8751, batch_loss: 0.3898, loss: 0.2987 ||:  86%|########6 | 6222/7204 [23:19<03:12,  5.10it/s]
2022-03-22 01:46:24,317 - INFO - tqdm - f1: 0.6794, accuracy: 0.8751, batch_loss: 0.2546, loss: 0.2988 ||:  87%|########7 | 6270/7204 [23:29<02:50,  5.47it/s]
2022-03-22 01:46:34,615 - INFO - tqdm - f1: 0.6791, accuracy: 0.8751, batch_loss: 0.1695, loss: 0.2986 ||:  88%|########7 | 6311/7204 [23:39<03:48,  3.91it/s]
2022-03-22 01:46:44,785 - INFO - tqdm - f1: 0.6791, accuracy: 0.8752, batch_loss: 0.1004, loss: 0.2984 ||:  88%|########8 | 6353/7204 [23:49<03:56,  3.59it/s]
2022-03-22 01:46:54,842 - INFO - tqdm - f1: 0.6790, accuracy: 0.8753, batch_loss: 0.1490, loss: 0.2984 ||:  89%|########8 | 6395/7204 [23:59<03:21,  4.01it/s]
2022-03-22 01:47:05,181 - INFO - tqdm - f1: 0.6786, accuracy: 0.8751, batch_loss: 0.1503, loss: 0.2986 ||:  89%|########9 | 6438/7204 [24:10<03:24,  3.74it/s]
2022-03-22 01:47:15,372 - INFO - tqdm - f1: 0.6786, accuracy: 0.8752, batch_loss: 0.5699, loss: 0.2983 ||:  90%|########9 | 6476/7204 [24:20<03:11,  3.80it/s]
2022-03-22 01:47:25,485 - INFO - tqdm - f1: 0.6785, accuracy: 0.8751, batch_loss: 0.3766, loss: 0.2985 ||:  91%|######### | 6521/7204 [24:30<02:42,  4.21it/s]
2022-03-22 01:47:35,522 - INFO - tqdm - f1: 0.6784, accuracy: 0.8752, batch_loss: 0.1645, loss: 0.2983 ||:  91%|#########1| 6565/7204 [24:40<02:12,  4.82it/s]
2022-03-22 01:47:45,761 - INFO - tqdm - f1: 0.6781, accuracy: 0.8752, batch_loss: 0.0277, loss: 0.2985 ||:  92%|#########1| 6607/7204 [24:50<03:02,  3.27it/s]
2022-03-22 01:47:55,878 - INFO - tqdm - f1: 0.6782, accuracy: 0.8753, batch_loss: 0.1022, loss: 0.2984 ||:  92%|#########2| 6647/7204 [25:00<02:44,  3.39it/s]
2022-03-22 01:48:05,984 - INFO - tqdm - f1: 0.6782, accuracy: 0.8753, batch_loss: 0.3148, loss: 0.2983 ||:  93%|#########2| 6690/7204 [25:10<02:04,  4.13it/s]
2022-03-22 01:48:16,008 - INFO - tqdm - f1: 0.6785, accuracy: 0.8754, batch_loss: 0.2614, loss: 0.2980 ||:  93%|#########3| 6731/7204 [25:20<02:10,  3.61it/s]
2022-03-22 01:48:26,205 - INFO - tqdm - f1: 0.6786, accuracy: 0.8754, batch_loss: 0.4287, loss: 0.2980 ||:  94%|#########4| 6778/7204 [25:31<01:26,  4.95it/s]
2022-03-22 01:48:36,370 - INFO - tqdm - f1: 0.6780, accuracy: 0.8753, batch_loss: 0.1862, loss: 0.2982 ||:  95%|#########4| 6821/7204 [25:41<01:39,  3.87it/s]
2022-03-22 01:48:46,580 - INFO - tqdm - f1: 0.6781, accuracy: 0.8754, batch_loss: 0.0471, loss: 0.2983 ||:  95%|#########5| 6866/7204 [25:51<01:30,  3.72it/s]
2022-03-22 01:48:56,689 - INFO - tqdm - f1: 0.6781, accuracy: 0.8755, batch_loss: 0.2699, loss: 0.2982 ||:  96%|#########5| 6908/7204 [26:01<01:01,  4.78it/s]
2022-03-22 01:49:06,721 - INFO - tqdm - f1: 0.6784, accuracy: 0.8755, batch_loss: 0.3713, loss: 0.2980 ||:  97%|#########6| 6953/7204 [26:11<00:52,  4.74it/s]
2022-03-22 01:49:16,906 - INFO - tqdm - f1: 0.6785, accuracy: 0.8755, batch_loss: 0.4062, loss: 0.2981 ||:  97%|#########7| 6997/7204 [26:21<00:42,  4.87it/s]
2022-03-22 01:49:27,149 - INFO - tqdm - f1: 0.6786, accuracy: 0.8756, batch_loss: 0.0391, loss: 0.2980 ||:  98%|#########7| 7037/7204 [26:32<00:55,  2.99it/s]
2022-03-22 01:49:37,323 - INFO - tqdm - f1: 0.6784, accuracy: 0.8755, batch_loss: 0.1575, loss: 0.2980 ||:  98%|#########8| 7081/7204 [26:42<00:26,  4.64it/s]
2022-03-22 01:49:47,451 - INFO - tqdm - f1: 0.6783, accuracy: 0.8755, batch_loss: 0.5757, loss: 0.2980 ||:  99%|#########8| 7119/7204 [26:52<00:21,  4.02it/s]
2022-03-22 01:49:57,680 - INFO - tqdm - f1: 0.6780, accuracy: 0.8753, batch_loss: 0.4518, loss: 0.2983 ||:  99%|#########9| 7156/7204 [27:02<00:16,  2.97it/s]
2022-03-22 01:50:01,119 - INFO - tqdm - f1: 0.6779, accuracy: 0.8753, batch_loss: 0.2779, loss: 0.2983 ||: 100%|#########9| 7168/7204 [27:06<00:11,  3.17it/s]
2022-03-22 01:50:01,388 - INFO - tqdm - f1: 0.6779, accuracy: 0.8754, batch_loss: 0.1148, loss: 0.2983 ||: 100%|#########9| 7169/7204 [27:06<00:10,  3.32it/s]
2022-03-22 01:50:01,645 - INFO - tqdm - f1: 0.6780, accuracy: 0.8754, batch_loss: 0.1345, loss: 0.2982 ||: 100%|#########9| 7170/7204 [27:06<00:09,  3.47it/s]
2022-03-22 01:50:01,849 - INFO - tqdm - f1: 0.6780, accuracy: 0.8754, batch_loss: 0.3047, loss: 0.2982 ||: 100%|#########9| 7171/7204 [27:06<00:08,  3.82it/s]
2022-03-22 01:50:02,319 - INFO - tqdm - f1: 0.6779, accuracy: 0.8754, batch_loss: 0.1038, loss: 0.2982 ||: 100%|#########9| 7172/7204 [27:07<00:10,  3.07it/s]
2022-03-22 01:50:02,486 - INFO - tqdm - f1: 0.6780, accuracy: 0.8754, batch_loss: 0.2383, loss: 0.2982 ||: 100%|#########9| 7173/7204 [27:07<00:08,  3.60it/s]
2022-03-22 01:50:02,968 - INFO - tqdm - f1: 0.6779, accuracy: 0.8754, batch_loss: 0.0711, loss: 0.2982 ||: 100%|#########9| 7174/7204 [27:07<00:10,  2.95it/s]
2022-03-22 01:50:03,198 - INFO - tqdm - f1: 0.6779, accuracy: 0.8754, batch_loss: 0.4341, loss: 0.2982 ||: 100%|#########9| 7175/7204 [27:08<00:08,  3.26it/s]
2022-03-22 01:50:03,437 - INFO - tqdm - f1: 0.6779, accuracy: 0.8754, batch_loss: 0.5090, loss: 0.2982 ||: 100%|#########9| 7176/7204 [27:08<00:08,  3.49it/s]
2022-03-22 01:50:03,653 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.5466, loss: 0.2982 ||: 100%|#########9| 7177/7204 [27:08<00:07,  3.79it/s]
2022-03-22 01:50:04,091 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.0339, loss: 0.2982 ||: 100%|#########9| 7178/7204 [27:09<00:08,  3.15it/s]
2022-03-22 01:50:04,321 - INFO - tqdm - f1: 0.6779, accuracy: 0.8754, batch_loss: 0.0432, loss: 0.2982 ||: 100%|#########9| 7179/7204 [27:09<00:07,  3.43it/s]
2022-03-22 01:50:04,707 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.1516, loss: 0.2982 ||: 100%|#########9| 7180/7204 [27:09<00:07,  3.13it/s]
2022-03-22 01:50:05,000 - INFO - tqdm - f1: 0.6779, accuracy: 0.8754, batch_loss: 0.1531, loss: 0.2981 ||: 100%|#########9| 7181/7204 [27:09<00:07,  3.21it/s]
2022-03-22 01:50:05,220 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.4806, loss: 0.2982 ||: 100%|#########9| 7182/7204 [27:10<00:06,  3.52it/s]
2022-03-22 01:50:05,739 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.1200, loss: 0.2981 ||: 100%|#########9| 7183/7204 [27:10<00:07,  2.82it/s]
2022-03-22 01:50:06,030 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.3614, loss: 0.2981 ||: 100%|#########9| 7184/7204 [27:11<00:06,  2.98it/s]
2022-03-22 01:50:06,331 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.5061, loss: 0.2982 ||: 100%|#########9| 7185/7204 [27:11<00:06,  3.07it/s]
2022-03-22 01:50:06,444 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.3324, loss: 0.2982 ||: 100%|#########9| 7186/7204 [27:11<00:04,  3.82it/s]
2022-03-22 01:50:06,666 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.1351, loss: 0.2982 ||: 100%|#########9| 7187/7204 [27:11<00:04,  4.01it/s]
2022-03-22 01:50:07,030 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.2997, loss: 0.2982 ||: 100%|#########9| 7188/7204 [27:12<00:04,  3.52it/s]
2022-03-22 01:50:07,314 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.1606, loss: 0.2981 ||: 100%|#########9| 7189/7204 [27:12<00:04,  3.53it/s]
2022-03-22 01:50:07,706 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.1446, loss: 0.2981 ||: 100%|#########9| 7190/7204 [27:12<00:04,  3.16it/s]
2022-03-22 01:50:07,951 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.2426, loss: 0.2981 ||: 100%|#########9| 7191/7204 [27:12<00:03,  3.39it/s]
2022-03-22 01:50:08,221 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.2705, loss: 0.2981 ||: 100%|#########9| 7192/7204 [27:13<00:03,  3.58it/s]
2022-03-22 01:50:08,647 - INFO - tqdm - f1: 0.6778, accuracy: 0.8754, batch_loss: 0.5336, loss: 0.2981 ||: 100%|#########9| 7193/7204 [27:13<00:03,  3.02it/s]
2022-03-22 01:50:08,923 - INFO - tqdm - f1: 0.6777, accuracy: 0.8754, batch_loss: 0.6171, loss: 0.2982 ||: 100%|#########9| 7194/7204 [27:13<00:03,  3.17it/s]
2022-03-22 01:50:09,228 - INFO - tqdm - f1: 0.6777, accuracy: 0.8754, batch_loss: 0.1232, loss: 0.2982 ||: 100%|#########9| 7195/7204 [27:14<00:02,  3.21it/s]
2022-03-22 01:50:09,539 - INFO - tqdm - f1: 0.6777, accuracy: 0.8754, batch_loss: 0.2760, loss: 0.2982 ||: 100%|#########9| 7196/7204 [27:14<00:02,  3.21it/s]
2022-03-22 01:50:09,714 - INFO - tqdm - f1: 0.6777, accuracy: 0.8754, batch_loss: 0.1805, loss: 0.2981 ||: 100%|#########9| 7197/7204 [27:14<00:01,  3.69it/s]
2022-03-22 01:50:10,166 - INFO - tqdm - f1: 0.6776, accuracy: 0.8754, batch_loss: 0.0700, loss: 0.2981 ||: 100%|#########9| 7198/7204 [27:15<00:01,  3.08it/s]
2022-03-22 01:50:10,344 - INFO - tqdm - f1: 0.6777, accuracy: 0.8754, batch_loss: 0.2764, loss: 0.2981 ||: 100%|#########9| 7199/7204 [27:15<00:01,  3.56it/s]
2022-03-22 01:50:10,571 - INFO - tqdm - f1: 0.6777, accuracy: 0.8753, batch_loss: 0.6431, loss: 0.2982 ||: 100%|#########9| 7200/7204 [27:15<00:01,  3.78it/s]
2022-03-22 01:50:10,882 - INFO - tqdm - f1: 0.6777, accuracy: 0.8753, batch_loss: 0.2800, loss: 0.2981 ||: 100%|#########9| 7201/7204 [27:15<00:00,  3.59it/s]
2022-03-22 01:50:11,076 - INFO - tqdm - f1: 0.6776, accuracy: 0.8754, batch_loss: 0.1325, loss: 0.2981 ||: 100%|#########9| 7202/7204 [27:16<00:00,  3.95it/s]
2022-03-22 01:50:11,519 - INFO - tqdm - f1: 0.6776, accuracy: 0.8754, batch_loss: 0.3667, loss: 0.2981 ||: 100%|#########9| 7203/7204 [27:16<00:00,  3.22it/s]
2022-03-22 01:50:11,795 - INFO - tqdm - f1: 0.6776, accuracy: 0.8753, batch_loss: 0.4026, loss: 0.2982 ||: 100%|##########| 7204/7204 [27:16<00:00,  3.34it/s]
2022-03-22 01:50:11,994 - INFO - tqdm - f1: 0.6776, accuracy: 0.8753, batch_loss: 0.4026, loss: 0.2982 ||: 100%|##########| 7204/7204 [27:16<00:00,  4.40it/s]
2022-03-22 01:50:12,039 - INFO - allennlp.training.trainer - Validating
2022-03-22 01:50:12,046 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-22 01:50:22,188 - INFO - tqdm - f1: 0.7096, accuracy: 0.8767, batch_loss: 0.2635, loss: 0.3135 ||:  23%|##3       | 72/313 [00:10<00:37,  6.42it/s]
2022-03-22 01:50:32,255 - INFO - tqdm - f1: 0.6770, accuracy: 0.8746, batch_loss: 0.4924, loss: 0.3176 ||:  47%|####6     | 146/313 [00:20<00:23,  7.08it/s]
2022-03-22 01:50:42,347 - INFO - tqdm - f1: 0.6855, accuracy: 0.8758, batch_loss: 0.3354, loss: 0.3105 ||:  72%|#######1  | 224/313 [00:30<00:10,  8.09it/s]
2022-03-22 01:50:52,487 - INFO - tqdm - f1: 0.6795, accuracy: 0.8698, batch_loss: 0.3698, loss: 0.3174 ||:  97%|#########6| 303/313 [00:40<00:01,  6.98it/s]
2022-03-22 01:50:53,547 - INFO - tqdm - f1: 0.6792, accuracy: 0.8704, batch_loss: 0.3069, loss: 0.3159 ||: 100%|##########| 313/313 [00:41<00:00,  9.97it/s]
2022-03-22 01:50:53,552 - INFO - tqdm - f1: 0.6792, accuracy: 0.8704, batch_loss: 0.3069, loss: 0.3159 ||: 100%|##########| 313/313 [00:41<00:00,  7.54it/s]
2022-03-22 01:50:53,561 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/amazon_base_hyper_small_seed_97/best.th'.
2022-03-22 01:50:55,820 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-22 01:50:55,822 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.875  |     0.870
2022-03-22 01:50:55,824 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.678  |     0.679
2022-03-22 01:50:55,826 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-22 01:50:55,827 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.298  |     0.316
2022-03-22 01:50:55,828 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13611.996  |       N/A
2022-03-22 01:50:55,830 - INFO - allennlp.training.trainer - Epoch duration: 0:28:00.823119
2022-03-22 01:50:55,831 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:44:15
2022-03-22 01:50:55,832 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-22 01:50:55,834 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-22 01:50:55,836 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-22 01:50:55,838 - INFO - allennlp.training.trainer - Training
2022-03-22 01:50:55,840 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-22 01:51:05,893 - INFO - tqdm - f1: 0.7496, accuracy: 0.9000, batch_loss: 0.1024, loss: 0.2708 ||:   0%|          | 35/7204 [00:10<26:50,  4.45it/s]
2022-03-22 01:51:16,026 - INFO - tqdm - f1: 0.7504, accuracy: 0.8953, batch_loss: 0.1551, loss: 0.2664 ||:   1%|1         | 74/7204 [00:20<36:01,  3.30it/s]
2022-03-22 01:51:26,182 - INFO - tqdm - f1: 0.7411, accuracy: 0.8908, batch_loss: 0.1780, loss: 0.2732 ||:   2%|1         | 115/7204 [00:30<38:00,  3.11it/s]
2022-03-22 01:51:36,319 - INFO - tqdm - f1: 0.7351, accuracy: 0.8886, batch_loss: 0.4538, loss: 0.2707 ||:   2%|2         | 152/7204 [00:40<32:00,  3.67it/s]
2022-03-22 01:51:46,684 - INFO - tqdm - f1: 0.7388, accuracy: 0.8950, batch_loss: 0.0428, loss: 0.2669 ||:   3%|2         | 191/7204 [00:50<34:29,  3.39it/s]
2022-03-22 01:51:56,827 - INFO - tqdm - f1: 0.7380, accuracy: 0.8991, batch_loss: 0.2744, loss: 0.2552 ||:   3%|3         | 226/7204 [01:00<30:00,  3.88it/s]
2022-03-22 01:52:06,947 - INFO - tqdm - f1: 0.7403, accuracy: 0.8972, batch_loss: 0.1770, loss: 0.2593 ||:   4%|3         | 267/7204 [01:11<27:27,  4.21it/s]
2022-03-22 01:52:16,977 - INFO - tqdm - f1: 0.7420, accuracy: 0.8977, batch_loss: 0.1779, loss: 0.2607 ||:   4%|4         | 303/7204 [01:21<27:14,  4.22it/s]
2022-03-22 01:52:27,107 - INFO - tqdm - f1: 0.7380, accuracy: 0.8932, batch_loss: 0.5870, loss: 0.2659 ||:   5%|4         | 343/7204 [01:31<29:16,  3.91it/s]
2022-03-22 01:52:37,275 - INFO - tqdm - f1: 0.7444, accuracy: 0.8942, batch_loss: 0.4867, loss: 0.2632 ||:   5%|5         | 380/7204 [01:41<25:59,  4.38it/s]
2022-03-22 01:52:47,426 - INFO - tqdm - f1: 0.7432, accuracy: 0.8936, batch_loss: 0.2334, loss: 0.2683 ||:   6%|5         | 419/7204 [01:51<24:28,  4.62it/s]
2022-03-22 01:52:57,575 - INFO - tqdm - f1: 0.7433, accuracy: 0.8930, batch_loss: 0.7917, loss: 0.2695 ||:   6%|6         | 458/7204 [02:01<29:45,  3.78it/s]
2022-03-22 01:53:07,703 - INFO - tqdm - f1: 0.7439, accuracy: 0.8935, batch_loss: 0.4967, loss: 0.2692 ||:   7%|6         | 497/7204 [02:11<26:28,  4.22it/s]
2022-03-22 01:53:17,738 - INFO - tqdm - f1: 0.7479, accuracy: 0.8929, batch_loss: 0.2257, loss: 0.2708 ||:   7%|7         | 533/7204 [02:21<30:19,  3.67it/s]
2022-03-22 01:53:27,776 - INFO - tqdm - f1: 0.7475, accuracy: 0.8931, batch_loss: 0.4090, loss: 0.2722 ||:   8%|7         | 571/7204 [02:31<31:09,  3.55it/s]
2022-03-22 01:53:37,799 - INFO - tqdm - f1: 0.7456, accuracy: 0.8934, batch_loss: 0.4514, loss: 0.2721 ||:   8%|8         | 607/7204 [02:41<30:54,  3.56it/s]
2022-03-22 01:53:47,986 - INFO - tqdm - f1: 0.7440, accuracy: 0.8927, batch_loss: 0.3973, loss: 0.2719 ||:   9%|8         | 648/7204 [02:52<23:49,  4.59it/s]
2022-03-22 01:53:58,031 - INFO - tqdm - f1: 0.7427, accuracy: 0.8928, batch_loss: 0.1143, loss: 0.2697 ||:  10%|9         | 685/7204 [03:02<33:52,  3.21it/s]
2022-03-22 01:54:08,107 - INFO - tqdm - f1: 0.7435, accuracy: 0.8915, batch_loss: 0.0295, loss: 0.2721 ||:  10%|#         | 726/7204 [03:12<30:36,  3.53it/s]
2022-03-22 01:54:18,139 - INFO - tqdm - f1: 0.7464, accuracy: 0.8925, batch_loss: 0.2554, loss: 0.2720 ||:  11%|#         | 770/7204 [03:22<31:26,  3.41it/s]
2022-03-22 01:54:28,519 - INFO - tqdm - f1: 0.7491, accuracy: 0.8936, batch_loss: 0.0298, loss: 0.2691 ||:  11%|#1        | 808/7204 [03:32<34:28,  3.09it/s]
2022-03-22 01:54:38,728 - INFO - tqdm - f1: 0.7483, accuracy: 0.8936, batch_loss: 0.3743, loss: 0.2687 ||:  12%|#1        | 848/7204 [03:42<25:52,  4.09it/s]
2022-03-22 01:54:48,786 - INFO - tqdm - f1: 0.7503, accuracy: 0.8940, batch_loss: 0.2420, loss: 0.2673 ||:  12%|#2        | 889/7204 [03:52<25:28,  4.13it/s]
2022-03-22 01:54:58,825 - INFO - tqdm - f1: 0.7544, accuracy: 0.8942, batch_loss: 0.2112, loss: 0.2674 ||:  13%|#2        | 932/7204 [04:02<21:29,  4.87it/s]
2022-03-22 01:55:08,926 - INFO - tqdm - f1: 0.7543, accuracy: 0.8954, batch_loss: 0.0925, loss: 0.2652 ||:  13%|#3        | 970/7204 [04:13<30:14,  3.44it/s]
2022-03-22 01:55:19,043 - INFO - tqdm - f1: 0.7536, accuracy: 0.8946, batch_loss: 0.2691, loss: 0.2665 ||:  14%|#4        | 1009/7204 [04:23<30:03,  3.43it/s]
2022-03-22 01:55:29,133 - INFO - tqdm - f1: 0.7531, accuracy: 0.8954, batch_loss: 0.0739, loss: 0.2641 ||:  15%|#4        | 1048/7204 [04:33<21:22,  4.80it/s]
2022-03-22 01:55:39,441 - INFO - tqdm - f1: 0.7524, accuracy: 0.8957, batch_loss: 0.1307, loss: 0.2637 ||:  15%|#5        | 1090/7204 [04:43<30:42,  3.32it/s]
2022-03-22 01:55:49,620 - INFO - tqdm - f1: 0.7522, accuracy: 0.8960, batch_loss: 0.4643, loss: 0.2634 ||:  16%|#5        | 1131/7204 [04:53<23:14,  4.35it/s]
2022-03-22 01:55:59,944 - INFO - tqdm - f1: 0.7537, accuracy: 0.8967, batch_loss: 0.0771, loss: 0.2621 ||:  16%|#6        | 1172/7204 [05:04<31:55,  3.15it/s]
2022-03-22 01:56:10,029 - INFO - tqdm - f1: 0.7528, accuracy: 0.8968, batch_loss: 0.1805, loss: 0.2617 ||:  17%|#6        | 1210/7204 [05:14<32:44,  3.05it/s]
2022-03-22 01:56:20,116 - INFO - tqdm - f1: 0.7536, accuracy: 0.8970, batch_loss: 0.3282, loss: 0.2617 ||:  17%|#7        | 1251/7204 [05:24<28:56,  3.43it/s]
2022-03-22 01:56:30,352 - INFO - tqdm - f1: 0.7520, accuracy: 0.8976, batch_loss: 0.2058, loss: 0.2606 ||:  18%|#7        | 1291/7204 [05:34<30:08,  3.27it/s]
2022-03-22 01:56:40,375 - INFO - tqdm - f1: 0.7497, accuracy: 0.8961, batch_loss: 0.2180, loss: 0.2631 ||:  19%|#8        | 1334/7204 [05:44<26:17,  3.72it/s]
2022-03-22 01:56:50,610 - INFO - tqdm - f1: 0.7482, accuracy: 0.8950, batch_loss: 0.4677, loss: 0.2644 ||:  19%|#9        | 1375/7204 [05:54<21:20,  4.55it/s]
2022-03-22 01:57:00,682 - INFO - tqdm - f1: 0.7478, accuracy: 0.8947, batch_loss: 0.2090, loss: 0.2648 ||:  20%|#9        | 1416/7204 [06:04<21:55,  4.40it/s]
2022-03-22 01:57:10,896 - INFO - tqdm - f1: 0.7471, accuracy: 0.8942, batch_loss: 0.2771, loss: 0.2654 ||:  20%|##        | 1457/7204 [06:15<23:23,  4.10it/s]
2022-03-22 01:57:21,162 - INFO - tqdm - f1: 0.7463, accuracy: 0.8935, batch_loss: 0.0354, loss: 0.2669 ||:  21%|##        | 1499/7204 [06:25<30:02,  3.17it/s]
2022-03-22 01:57:31,274 - INFO - tqdm - f1: 0.7482, accuracy: 0.8933, batch_loss: 0.1861, loss: 0.2678 ||:  21%|##1       | 1541/7204 [06:35<21:12,  4.45it/s]
2022-03-22 01:57:41,601 - INFO - tqdm - f1: 0.7487, accuracy: 0.8936, batch_loss: 0.2591, loss: 0.2674 ||:  22%|##1       | 1578/7204 [06:45<28:40,  3.27it/s]
2022-03-22 01:57:51,744 - INFO - tqdm - f1: 0.7480, accuracy: 0.8934, batch_loss: 0.2920, loss: 0.2676 ||:  22%|##2       | 1618/7204 [06:55<18:48,  4.95it/s]
2022-03-22 01:58:01,922 - INFO - tqdm - f1: 0.7480, accuracy: 0.8940, batch_loss: 0.2355, loss: 0.2668 ||:  23%|##3       | 1658/7204 [07:06<22:17,  4.15it/s]
2022-03-22 01:58:11,970 - INFO - tqdm - f1: 0.7473, accuracy: 0.8936, batch_loss: 0.3287, loss: 0.2677 ||:  24%|##3       | 1696/7204 [07:16<21:28,  4.27it/s]
2022-03-22 01:58:22,039 - INFO - tqdm - f1: 0.7475, accuracy: 0.8942, batch_loss: 0.1006, loss: 0.2666 ||:  24%|##4       | 1735/7204 [07:26<25:43,  3.54it/s]
2022-03-22 01:58:32,075 - INFO - tqdm - f1: 0.7482, accuracy: 0.8946, batch_loss: 0.3121, loss: 0.2658 ||:  25%|##4       | 1771/7204 [07:36<21:26,  4.22it/s]
2022-03-22 01:58:42,206 - INFO - tqdm - f1: 0.7476, accuracy: 0.8948, batch_loss: 0.3507, loss: 0.2653 ||:  25%|##5       | 1809/7204 [07:46<21:24,  4.20it/s]
2022-03-22 01:58:52,409 - INFO - tqdm - f1: 0.7462, accuracy: 0.8944, batch_loss: 0.5599, loss: 0.2656 ||:  26%|##5       | 1849/7204 [07:56<19:16,  4.63it/s]
2022-03-22 01:59:02,709 - INFO - tqdm - f1: 0.7471, accuracy: 0.8943, batch_loss: 0.0240, loss: 0.2659 ||:  26%|##6       | 1891/7204 [08:06<26:20,  3.36it/s]
2022-03-22 01:59:12,776 - INFO - tqdm - f1: 0.7466, accuracy: 0.8946, batch_loss: 0.2332, loss: 0.2655 ||:  27%|##6       | 1931/7204 [08:16<20:53,  4.21it/s]
2022-03-22 01:59:22,981 - INFO - tqdm - f1: 0.7465, accuracy: 0.8945, batch_loss: 0.1199, loss: 0.2653 ||:  27%|##7       | 1970/7204 [08:27<22:46,  3.83it/s]
2022-03-22 01:59:33,001 - INFO - tqdm - f1: 0.7458, accuracy: 0.8945, batch_loss: 0.1690, loss: 0.2650 ||:  28%|##7       | 2008/7204 [08:37<20:09,  4.30it/s]
2022-03-22 01:59:43,063 - INFO - tqdm - f1: 0.7459, accuracy: 0.8947, batch_loss: 0.5271, loss: 0.2649 ||:  28%|##8       | 2045/7204 [08:47<23:36,  3.64it/s]
2022-03-22 01:59:53,245 - INFO - tqdm - f1: 0.7454, accuracy: 0.8948, batch_loss: 0.3630, loss: 0.2644 ||:  29%|##8       | 2085/7204 [08:57<19:27,  4.38it/s]
2022-03-22 02:00:03,425 - INFO - tqdm - f1: 0.7453, accuracy: 0.8945, batch_loss: 0.4671, loss: 0.2643 ||:  30%|##9       | 2127/7204 [09:07<20:52,  4.05it/s]
2022-03-22 02:00:13,643 - INFO - tqdm - f1: 0.7452, accuracy: 0.8940, batch_loss: 0.3872, loss: 0.2649 ||:  30%|###       | 2169/7204 [09:17<20:51,  4.02it/s]
2022-03-22 02:00:23,779 - INFO - tqdm - f1: 0.7448, accuracy: 0.8937, batch_loss: 0.1252, loss: 0.2653 ||:  31%|###       | 2208/7204 [09:27<27:21,  3.04it/s]
2022-03-22 02:00:33,944 - INFO - tqdm - f1: 0.7446, accuracy: 0.8936, batch_loss: 0.5631, loss: 0.2654 ||:  31%|###1      | 2249/7204 [09:38<23:12,  3.56it/s]
2022-03-22 02:00:43,971 - INFO - tqdm - f1: 0.7448, accuracy: 0.8937, batch_loss: 0.0457, loss: 0.2655 ||:  32%|###1      | 2289/7204 [09:48<22:18,  3.67it/s]
2022-03-22 02:00:53,988 - INFO - tqdm - f1: 0.7442, accuracy: 0.8935, batch_loss: 0.0806, loss: 0.2660 ||:  32%|###2      | 2330/7204 [09:58<19:14,  4.22it/s]
2022-03-22 02:01:04,084 - INFO - tqdm - f1: 0.7440, accuracy: 0.8935, batch_loss: 0.5353, loss: 0.2660 ||:  33%|###2      | 2372/7204 [10:08<20:14,  3.98it/s]
2022-03-22 02:01:14,346 - INFO - tqdm - f1: 0.7446, accuracy: 0.8935, batch_loss: 0.1118, loss: 0.2658 ||:  33%|###3      | 2413/7204 [10:18<19:38,  4.06it/s]
2022-03-22 02:01:24,572 - INFO - tqdm - f1: 0.7442, accuracy: 0.8929, batch_loss: 0.1266, loss: 0.2667 ||:  34%|###4      | 2455/7204 [10:28<21:02,  3.76it/s]
2022-03-22 02:01:34,916 - INFO - tqdm - f1: 0.7431, accuracy: 0.8925, batch_loss: 0.0573, loss: 0.2675 ||:  35%|###4      | 2494/7204 [10:39<25:00,  3.14it/s]
2022-03-22 02:01:45,002 - INFO - tqdm - f1: 0.7429, accuracy: 0.8928, batch_loss: 0.1527, loss: 0.2672 ||:  35%|###5      | 2534/7204 [10:49<15:50,  4.91it/s]
2022-03-22 02:01:55,156 - INFO - tqdm - f1: 0.7434, accuracy: 0.8927, batch_loss: 0.3218, loss: 0.2676 ||:  36%|###6      | 2601/7204 [10:59<09:25,  8.14it/s]
2022-03-22 02:02:05,248 - INFO - tqdm - f1: 0.7439, accuracy: 0.8927, batch_loss: 0.7131, loss: 0.2676 ||:  37%|###7      | 2667/7204 [11:09<10:46,  7.02it/s]
2022-03-22 02:02:15,454 - INFO - tqdm - f1: 0.7442, accuracy: 0.8925, batch_loss: 0.4890, loss: 0.2680 ||:  38%|###7      | 2719/7204 [11:19<18:17,  4.09it/s]
2022-03-22 02:02:25,637 - INFO - tqdm - f1: 0.7438, accuracy: 0.8924, batch_loss: 0.2795, loss: 0.2682 ||:  38%|###8      | 2771/7204 [11:29<14:23,  5.13it/s]
2022-03-22 02:02:35,842 - INFO - tqdm - f1: 0.7443, accuracy: 0.8925, batch_loss: 0.5157, loss: 0.2682 ||:  39%|###9      | 2827/7204 [11:40<16:08,  4.52it/s]
2022-03-22 02:02:45,984 - INFO - tqdm - f1: 0.7439, accuracy: 0.8925, batch_loss: 0.0496, loss: 0.2681 ||:  40%|###9      | 2870/7204 [11:50<14:44,  4.90it/s]
2022-03-22 02:02:56,204 - INFO - tqdm - f1: 0.7429, accuracy: 0.8921, batch_loss: 0.2741, loss: 0.2690 ||:  40%|####      | 2915/7204 [12:00<16:00,  4.47it/s]
2022-03-22 02:03:06,220 - INFO - tqdm - f1: 0.7426, accuracy: 0.8920, batch_loss: 0.1169, loss: 0.2691 ||:  41%|####1     | 2961/7204 [12:10<12:34,  5.62it/s]
2022-03-22 02:03:16,577 - INFO - tqdm - f1: 0.7433, accuracy: 0.8921, batch_loss: 0.3651, loss: 0.2690 ||:  42%|####1     | 3008/7204 [12:20<19:08,  3.65it/s]
2022-03-22 02:03:26,789 - INFO - tqdm - f1: 0.7424, accuracy: 0.8917, batch_loss: 0.1873, loss: 0.2693 ||:  42%|####2     | 3052/7204 [12:30<14:55,  4.64it/s]
2022-03-22 02:03:36,849 - INFO - tqdm - f1: 0.7422, accuracy: 0.8917, batch_loss: 0.2750, loss: 0.2694 ||:  43%|####2     | 3093/7204 [12:41<15:19,  4.47it/s]
2022-03-22 02:03:46,896 - INFO - tqdm - f1: 0.7423, accuracy: 0.8919, batch_loss: 0.1867, loss: 0.2691 ||:  43%|####3     | 3133/7204 [12:51<13:53,  4.89it/s]
2022-03-22 02:03:56,905 - INFO - tqdm - f1: 0.7427, accuracy: 0.8917, batch_loss: 0.2107, loss: 0.2695 ||:  44%|####4     | 3178/7204 [13:01<13:56,  4.81it/s]
2022-03-22 02:04:06,981 - INFO - tqdm - f1: 0.7424, accuracy: 0.8914, batch_loss: 0.0675, loss: 0.2698 ||:  45%|####4     | 3221/7204 [13:11<16:27,  4.03it/s]
2022-03-22 02:04:17,044 - INFO - tqdm - f1: 0.7420, accuracy: 0.8912, batch_loss: 0.4000, loss: 0.2700 ||:  45%|####5     | 3269/7204 [13:21<16:48,  3.90it/s]
2022-03-22 02:04:27,216 - INFO - tqdm - f1: 0.7408, accuracy: 0.8907, batch_loss: 0.2439, loss: 0.2704 ||:  46%|####6     | 3314/7204 [13:31<15:55,  4.07it/s]
2022-03-22 02:04:37,301 - INFO - tqdm - f1: 0.7402, accuracy: 0.8904, batch_loss: 0.2069, loss: 0.2706 ||:  47%|####6     | 3357/7204 [13:41<14:46,  4.34it/s]
2022-03-22 02:04:47,543 - INFO - tqdm - f1: 0.7400, accuracy: 0.8905, batch_loss: 0.1394, loss: 0.2704 ||:  47%|####7     | 3395/7204 [13:51<20:54,  3.04it/s]
2022-03-22 02:04:57,636 - INFO - tqdm - f1: 0.7404, accuracy: 0.8904, batch_loss: 0.1507, loss: 0.2706 ||:  48%|####7     | 3439/7204 [14:01<16:20,  3.84it/s]
2022-03-22 02:05:07,740 - INFO - tqdm - f1: 0.7404, accuracy: 0.8902, batch_loss: 0.4987, loss: 0.2709 ||:  48%|####8     | 3479/7204 [14:11<14:45,  4.21it/s]
2022-03-22 02:05:17,924 - INFO - tqdm - f1: 0.7401, accuracy: 0.8904, batch_loss: 0.0448, loss: 0.2705 ||:  49%|####8     | 3522/7204 [14:22<14:43,  4.17it/s]
2022-03-22 02:05:27,981 - INFO - tqdm - f1: 0.7400, accuracy: 0.8903, batch_loss: 0.2031, loss: 0.2705 ||:  50%|####9     | 3566/7204 [14:32<14:38,  4.14it/s]
2022-03-22 02:05:38,090 - INFO - tqdm - f1: 0.7396, accuracy: 0.8900, batch_loss: 0.2319, loss: 0.2711 ||:  50%|#####     | 3609/7204 [14:42<15:01,  3.99it/s]
2022-03-22 02:05:48,416 - INFO - tqdm - f1: 0.7397, accuracy: 0.8901, batch_loss: 0.0842, loss: 0.2705 ||:  51%|#####     | 3651/7204 [14:52<18:01,  3.29it/s]
2022-03-22 02:05:58,522 - INFO - tqdm - f1: 0.7397, accuracy: 0.8901, batch_loss: 0.2168, loss: 0.2704 ||:  51%|#####1    | 3696/7204 [15:02<12:25,  4.71it/s]
2022-03-22 02:06:08,551 - INFO - tqdm - f1: 0.7401, accuracy: 0.8901, batch_loss: 0.1566, loss: 0.2702 ||:  52%|#####1    | 3734/7204 [15:12<14:28,  4.00it/s]
2022-03-22 02:06:18,648 - INFO - tqdm - f1: 0.7407, accuracy: 0.8902, batch_loss: 0.2213, loss: 0.2705 ||:  52%|#####2    | 3780/7204 [15:22<14:47,  3.86it/s]
2022-03-22 02:06:28,651 - INFO - tqdm - f1: 0.7402, accuracy: 0.8900, batch_loss: 0.1579, loss: 0.2708 ||:  53%|#####3    | 3821/7204 [15:32<14:07,  3.99it/s]
2022-03-22 02:06:38,913 - INFO - tqdm - f1: 0.7401, accuracy: 0.8900, batch_loss: 0.0790, loss: 0.2705 ||:  54%|#####3    | 3861/7204 [15:43<14:44,  3.78it/s]
2022-03-22 02:06:48,976 - INFO - tqdm - f1: 0.7402, accuracy: 0.8902, batch_loss: 0.0752, loss: 0.2700 ||:  54%|#####4    | 3901/7204 [15:53<18:01,  3.05it/s]
2022-03-22 02:06:59,001 - INFO - tqdm - f1: 0.7402, accuracy: 0.8903, batch_loss: 0.6096, loss: 0.2700 ||:  55%|#####4    | 3939/7204 [16:03<12:09,  4.48it/s]
2022-03-22 02:07:09,015 - INFO - tqdm - f1: 0.7401, accuracy: 0.8901, batch_loss: 0.1839, loss: 0.2704 ||:  55%|#####5    | 3980/7204 [16:13<13:40,  3.93it/s]
2022-03-22 02:07:19,086 - INFO - tqdm - f1: 0.7400, accuracy: 0.8902, batch_loss: 0.4048, loss: 0.2702 ||:  56%|#####5    | 4019/7204 [16:23<13:26,  3.95it/s]
2022-03-22 02:07:29,151 - INFO - tqdm - f1: 0.7399, accuracy: 0.8902, batch_loss: 0.3925, loss: 0.2702 ||:  56%|#####6    | 4062/7204 [16:33<13:14,  3.95it/s]
2022-03-22 02:07:39,209 - INFO - tqdm - f1: 0.7395, accuracy: 0.8900, batch_loss: 0.4105, loss: 0.2707 ||:  57%|#####6    | 4103/7204 [16:43<12:48,  4.04it/s]
2022-03-22 02:07:49,273 - INFO - tqdm - f1: 0.7396, accuracy: 0.8900, batch_loss: 0.3894, loss: 0.2707 ||:  57%|#####7    | 4142/7204 [16:53<12:45,  4.00it/s]
2022-03-22 02:07:59,335 - INFO - tqdm - f1: 0.7404, accuracy: 0.8902, batch_loss: 0.0465, loss: 0.2705 ||:  58%|#####8    | 4186/7204 [17:03<12:48,  3.93it/s]
2022-03-22 02:08:09,465 - INFO - tqdm - f1: 0.7400, accuracy: 0.8900, batch_loss: 0.4156, loss: 0.2707 ||:  59%|#####8    | 4227/7204 [17:13<11:46,  4.21it/s]
2022-03-22 02:08:19,491 - INFO - tqdm - f1: 0.7391, accuracy: 0.8898, batch_loss: 0.5724, loss: 0.2708 ||:  59%|#####9    | 4265/7204 [17:23<11:31,  4.25it/s]
2022-03-22 02:08:29,597 - INFO - tqdm - f1: 0.7388, accuracy: 0.8897, batch_loss: 0.1017, loss: 0.2706 ||:  60%|#####9    | 4306/7204 [17:33<10:48,  4.47it/s]
2022-03-22 02:08:39,728 - INFO - tqdm - f1: 0.7388, accuracy: 0.8896, batch_loss: 0.2019, loss: 0.2711 ||:  60%|######    | 4349/7204 [17:43<12:42,  3.74it/s]
2022-03-22 02:08:49,746 - INFO - tqdm - f1: 0.7391, accuracy: 0.8896, batch_loss: 0.0256, loss: 0.2711 ||:  61%|######    | 4391/7204 [17:53<16:04,  2.92it/s]
2022-03-22 02:08:59,931 - INFO - tqdm - f1: 0.7389, accuracy: 0.8897, batch_loss: 0.1812, loss: 0.2709 ||:  62%|######1   | 4433/7204 [18:04<12:52,  3.59it/s]
2022-03-22 02:09:10,031 - INFO - tqdm - f1: 0.7390, accuracy: 0.8894, batch_loss: 0.4934, loss: 0.2713 ||:  62%|######2   | 4476/7204 [18:14<10:28,  4.34it/s]
2022-03-22 02:09:20,235 - INFO - tqdm - f1: 0.7386, accuracy: 0.8894, batch_loss: 0.3418, loss: 0.2710 ||:  63%|######2   | 4516/7204 [18:24<10:39,  4.21it/s]
2022-03-22 02:09:30,364 - INFO - tqdm - f1: 0.7389, accuracy: 0.8895, batch_loss: 0.1817, loss: 0.2712 ||:  63%|######3   | 4556/7204 [18:34<13:28,  3.27it/s]
2022-03-22 02:09:40,586 - INFO - tqdm - f1: 0.7390, accuracy: 0.8895, batch_loss: 0.4530, loss: 0.2710 ||:  64%|######3   | 4597/7204 [18:44<11:09,  3.89it/s]
2022-03-22 02:09:50,772 - INFO - tqdm - f1: 0.7388, accuracy: 0.8891, batch_loss: 0.3433, loss: 0.2717 ||:  64%|######4   | 4639/7204 [18:54<09:24,  4.55it/s]
2022-03-22 02:10:00,956 - INFO - tqdm - f1: 0.7389, accuracy: 0.8891, batch_loss: 0.0558, loss: 0.2716 ||:  65%|######4   | 4682/7204 [19:05<09:38,  4.36it/s]
2022-03-22 02:10:11,003 - INFO - tqdm - f1: 0.7389, accuracy: 0.8891, batch_loss: 0.7045, loss: 0.2714 ||:  66%|######5   | 4724/7204 [19:15<08:54,  4.64it/s]
2022-03-22 02:10:21,054 - INFO - tqdm - f1: 0.7387, accuracy: 0.8891, batch_loss: 0.1635, loss: 0.2712 ||:  66%|######6   | 4760/7204 [19:25<10:12,  3.99it/s]
2022-03-22 02:10:31,117 - INFO - tqdm - f1: 0.7388, accuracy: 0.8891, batch_loss: 0.1854, loss: 0.2714 ||:  67%|######6   | 4800/7204 [19:35<12:40,  3.16it/s]
2022-03-22 02:10:41,127 - INFO - tqdm - f1: 0.7388, accuracy: 0.8891, batch_loss: 0.0507, loss: 0.2713 ||:  67%|######7   | 4840/7204 [19:45<09:36,  4.10it/s]
2022-03-22 02:10:51,237 - INFO - tqdm - f1: 0.7387, accuracy: 0.8892, batch_loss: 0.2946, loss: 0.2711 ||:  68%|######7   | 4880/7204 [19:55<08:36,  4.50it/s]
2022-03-22 02:11:01,499 - INFO - tqdm - f1: 0.7387, accuracy: 0.8891, batch_loss: 0.2196, loss: 0.2714 ||:  68%|######8   | 4925/7204 [20:05<09:58,  3.81it/s]
2022-03-22 02:11:11,647 - INFO - tqdm - f1: 0.7384, accuracy: 0.8891, batch_loss: 0.6636, loss: 0.2714 ||:  69%|######8   | 4967/7204 [20:15<08:34,  4.35it/s]
2022-03-22 02:11:21,816 - INFO - tqdm - f1: 0.7384, accuracy: 0.8887, batch_loss: 0.2499, loss: 0.2717 ||:  70%|######9   | 5008/7204 [20:25<09:43,  3.77it/s]
2022-03-22 02:11:31,981 - INFO - tqdm - f1: 0.7384, accuracy: 0.8888, batch_loss: 0.3425, loss: 0.2715 ||:  70%|#######   | 5048/7204 [20:36<09:16,  3.87it/s]
2022-03-22 02:11:42,030 - INFO - tqdm - f1: 0.7388, accuracy: 0.8890, batch_loss: 0.2116, loss: 0.2711 ||:  71%|#######   | 5090/7204 [20:46<08:19,  4.23it/s]
2022-03-22 02:11:52,129 - INFO - tqdm - f1: 0.7386, accuracy: 0.8889, batch_loss: 0.7879, loss: 0.2712 ||:  71%|#######1  | 5127/7204 [20:56<06:43,  5.15it/s]
2022-03-22 02:12:02,387 - INFO - tqdm - f1: 0.7382, accuracy: 0.8888, batch_loss: 0.4627, loss: 0.2712 ||:  72%|#######1  | 5167/7204 [21:06<08:12,  4.14it/s]
2022-03-22 02:12:12,632 - INFO - tqdm - f1: 0.7381, accuracy: 0.8888, batch_loss: 0.0120, loss: 0.2711 ||:  72%|#######2  | 5209/7204 [21:16<07:31,  4.42it/s]
2022-03-22 02:12:23,008 - INFO - tqdm - f1: 0.7377, accuracy: 0.8888, batch_loss: 0.0548, loss: 0.2710 ||:  73%|#######2  | 5251/7204 [21:27<10:37,  3.06it/s]
2022-03-22 02:12:33,120 - INFO - tqdm - f1: 0.7378, accuracy: 0.8888, batch_loss: 0.1162, loss: 0.2711 ||:  73%|#######3  | 5291/7204 [21:37<09:24,  3.39it/s]
2022-03-22 02:12:43,180 - INFO - tqdm - f1: 0.7376, accuracy: 0.8887, batch_loss: 0.2515, loss: 0.2712 ||:  74%|#######4  | 5332/7204 [21:47<07:22,  4.23it/s]
2022-03-22 02:12:53,239 - INFO - tqdm - f1: 0.7373, accuracy: 0.8887, batch_loss: 0.5284, loss: 0.2711 ||:  75%|#######4  | 5374/7204 [21:57<06:12,  4.91it/s]
2022-03-22 02:13:03,249 - INFO - tqdm - f1: 0.7370, accuracy: 0.8886, batch_loss: 0.3218, loss: 0.2711 ||:  75%|#######5  | 5414/7204 [22:07<07:03,  4.22it/s]
2022-03-22 02:13:13,471 - INFO - tqdm - f1: 0.7370, accuracy: 0.8886, batch_loss: 0.0983, loss: 0.2713 ||:  76%|#######5  | 5453/7204 [22:17<07:33,  3.86it/s]
2022-03-22 02:13:23,718 - INFO - tqdm - f1: 0.7371, accuracy: 0.8888, batch_loss: 0.1699, loss: 0.2710 ||:  76%|#######6  | 5490/7204 [22:27<09:27,  3.02it/s]
2022-03-22 02:13:33,895 - INFO - tqdm - f1: 0.7369, accuracy: 0.8887, batch_loss: 0.6090, loss: 0.2711 ||:  77%|#######6  | 5534/7204 [22:38<06:21,  4.38it/s]
2022-03-22 02:13:44,022 - INFO - tqdm - f1: 0.7371, accuracy: 0.8887, batch_loss: 0.1026, loss: 0.2711 ||:  77%|#######7  | 5576/7204 [22:48<07:51,  3.45it/s]
2022-03-22 02:13:54,115 - INFO - tqdm - f1: 0.7370, accuracy: 0.8887, batch_loss: 0.1432, loss: 0.2712 ||:  78%|#######7  | 5616/7204 [22:58<05:52,  4.51it/s]
2022-03-22 02:14:04,420 - INFO - tqdm - f1: 0.7369, accuracy: 0.8886, batch_loss: 0.0293, loss: 0.2713 ||:  79%|#######8  | 5657/7204 [23:08<08:33,  3.01it/s]
2022-03-22 02:14:14,664 - INFO - tqdm - f1: 0.7370, accuracy: 0.8886, batch_loss: 0.2750, loss: 0.2711 ||:  79%|#######9  | 5695/7204 [23:18<07:00,  3.59it/s]
2022-03-22 02:14:24,900 - INFO - tqdm - f1: 0.7371, accuracy: 0.8887, batch_loss: 0.1944, loss: 0.2710 ||:  80%|#######9  | 5735/7204 [23:29<07:39,  3.20it/s]
2022-03-22 02:14:34,970 - INFO - tqdm - f1: 0.7369, accuracy: 0.8886, batch_loss: 0.1153, loss: 0.2711 ||:  80%|########  | 5776/7204 [23:39<05:49,  4.09it/s]
2022-03-22 02:14:45,139 - INFO - tqdm - f1: 0.7369, accuracy: 0.8885, batch_loss: 0.2992, loss: 0.2713 ||:  81%|########  | 5818/7204 [23:49<05:47,  3.99it/s]
2022-03-22 02:14:55,399 - INFO - tqdm - f1: 0.7373, accuracy: 0.8887, batch_loss: 0.0400, loss: 0.2711 ||:  81%|########1 | 5858/7204 [23:59<06:26,  3.48it/s]
2022-03-22 02:15:05,729 - INFO - tqdm - f1: 0.7373, accuracy: 0.8888, batch_loss: 0.5052, loss: 0.2708 ||:  82%|########1 | 5894/7204 [24:09<06:21,  3.43it/s]
2022-03-22 02:15:15,736 - INFO - tqdm - f1: 0.7372, accuracy: 0.8887, batch_loss: 0.2401, loss: 0.2709 ||:  82%|########2 | 5935/7204 [24:19<05:26,  3.89it/s]
2022-03-22 02:15:25,815 - INFO - tqdm - f1: 0.7375, accuracy: 0.8888, batch_loss: 0.2077, loss: 0.2708 ||:  83%|########2 | 5975/7204 [24:29<04:44,  4.31it/s]
2022-03-22 02:15:35,818 - INFO - tqdm - f1: 0.7374, accuracy: 0.8888, batch_loss: 0.4742, loss: 0.2708 ||:  83%|########3 | 6010/7204 [24:39<05:38,  3.52it/s]
2022-03-22 02:15:45,885 - INFO - tqdm - f1: 0.7373, accuracy: 0.8889, batch_loss: 0.2079, loss: 0.2708 ||:  84%|########4 | 6052/7204 [24:50<03:56,  4.88it/s]
2022-03-22 02:15:55,958 - INFO - tqdm - f1: 0.7373, accuracy: 0.8890, batch_loss: 0.1314, loss: 0.2705 ||:  84%|########4 | 6087/7204 [25:00<04:45,  3.92it/s]
2022-03-22 02:16:06,155 - INFO - tqdm - f1: 0.7372, accuracy: 0.8890, batch_loss: 0.5130, loss: 0.2703 ||:  85%|########5 | 6127/7204 [25:10<04:44,  3.79it/s]
2022-03-22 02:16:16,474 - INFO - tqdm - f1: 0.7371, accuracy: 0.8890, batch_loss: 0.0514, loss: 0.2703 ||:  86%|########5 | 6164/7204 [25:20<05:55,  2.92it/s]
2022-03-22 02:16:26,530 - INFO - tqdm - f1: 0.7372, accuracy: 0.8892, batch_loss: 0.2376, loss: 0.2701 ||:  86%|########6 | 6200/7204 [25:30<03:32,  4.73it/s]
2022-03-22 02:16:36,560 - INFO - tqdm - f1: 0.7373, accuracy: 0.8893, batch_loss: 0.4428, loss: 0.2699 ||:  87%|########6 | 6240/7204 [25:40<03:52,  4.14it/s]
2022-03-22 02:16:46,613 - INFO - tqdm - f1: 0.7374, accuracy: 0.8893, batch_loss: 0.3795, loss: 0.2700 ||:  87%|########7 | 6284/7204 [25:50<03:23,  4.51it/s]
2022-03-22 02:16:56,808 - INFO - tqdm - f1: 0.7375, accuracy: 0.8894, batch_loss: 0.3519, loss: 0.2697 ||:  88%|########7 | 6322/7204 [26:00<03:51,  3.81it/s]
2022-03-22 02:17:06,965 - INFO - tqdm - f1: 0.7373, accuracy: 0.8894, batch_loss: 0.4592, loss: 0.2697 ||:  88%|########8 | 6362/7204 [26:11<03:05,  4.53it/s]
2022-03-22 02:17:17,120 - INFO - tqdm - f1: 0.7372, accuracy: 0.8893, batch_loss: 0.4399, loss: 0.2700 ||:  89%|########8 | 6401/7204 [26:21<02:53,  4.62it/s]
2022-03-22 02:17:27,356 - INFO - tqdm - f1: 0.7372, accuracy: 0.8894, batch_loss: 0.2074, loss: 0.2699 ||:  89%|########9 | 6440/7204 [26:31<03:40,  3.47it/s]
2022-03-22 02:17:37,366 - INFO - tqdm - f1: 0.7372, accuracy: 0.8893, batch_loss: 0.2555, loss: 0.2700 ||:  90%|######### | 6484/7204 [26:41<02:24,  4.98it/s]
2022-03-22 02:17:47,619 - INFO - tqdm - f1: 0.7371, accuracy: 0.8893, batch_loss: 0.2492, loss: 0.2701 ||:  91%|######### | 6525/7204 [26:51<03:07,  3.63it/s]
2022-03-22 02:17:57,681 - INFO - tqdm - f1: 0.7369, accuracy: 0.8892, batch_loss: 0.1854, loss: 0.2704 ||:  91%|#########1| 6564/7204 [27:01<03:04,  3.47it/s]
2022-03-22 02:18:07,723 - INFO - tqdm - f1: 0.7371, accuracy: 0.8892, batch_loss: 0.0163, loss: 0.2703 ||:  92%|#########1| 6604/7204 [27:11<03:05,  3.24it/s]
2022-03-22 02:18:17,898 - INFO - tqdm - f1: 0.7371, accuracy: 0.8891, batch_loss: 0.1319, loss: 0.2707 ||:  92%|#########2| 6649/7204 [27:22<02:21,  3.93it/s]
2022-03-22 02:18:28,007 - INFO - tqdm - f1: 0.7372, accuracy: 0.8892, batch_loss: 0.2088, loss: 0.2705 ||:  93%|#########2| 6685/7204 [27:32<02:37,  3.30it/s]
2022-03-22 02:18:38,106 - INFO - tqdm - f1: 0.7375, accuracy: 0.8893, batch_loss: 0.0641, loss: 0.2702 ||:  93%|#########3| 6724/7204 [27:42<02:03,  3.89it/s]
2022-03-22 02:18:48,267 - INFO - tqdm - f1: 0.7375, accuracy: 0.8893, batch_loss: 0.1990, loss: 0.2703 ||:  94%|#########3| 6762/7204 [27:52<02:11,  3.35it/s]
2022-03-22 02:18:58,515 - INFO - tqdm - f1: 0.7374, accuracy: 0.8894, batch_loss: 0.2820, loss: 0.2701 ||:  94%|#########4| 6801/7204 [28:02<01:44,  3.85it/s]
2022-03-22 02:19:08,533 - INFO - tqdm - f1: 0.7376, accuracy: 0.8895, batch_loss: 0.0338, loss: 0.2700 ||:  95%|#########4| 6843/7204 [28:12<01:21,  4.45it/s]
2022-03-22 02:19:18,801 - INFO - tqdm - f1: 0.7373, accuracy: 0.8895, batch_loss: 0.1457, loss: 0.2699 ||:  96%|#########5| 6883/7204 [28:22<01:35,  3.35it/s]
2022-03-22 02:19:29,017 - INFO - tqdm - f1: 0.7375, accuracy: 0.8895, batch_loss: 0.2260, loss: 0.2698 ||:  96%|#########6| 6924/7204 [28:33<01:04,  4.37it/s]
2022-03-22 02:19:39,234 - INFO - tqdm - f1: 0.7375, accuracy: 0.8895, batch_loss: 0.0879, loss: 0.2697 ||:  97%|#########6| 6967/7204 [28:43<00:55,  4.26it/s]
2022-03-22 02:19:49,262 - INFO - tqdm - f1: 0.7375, accuracy: 0.8895, batch_loss: 0.0828, loss: 0.2699 ||:  97%|#########7| 7021/7204 [28:53<00:18,  9.67it/s]
2022-03-22 02:19:59,309 - INFO - tqdm - f1: 0.7376, accuracy: 0.8896, batch_loss: 0.1604, loss: 0.2697 ||:  98%|#########8| 7092/7204 [29:03<00:18,  6.03it/s]
2022-03-22 02:20:09,382 - INFO - tqdm - f1: 0.7374, accuracy: 0.8897, batch_loss: 0.2621, loss: 0.2695 ||:  99%|#########9| 7144/7204 [29:13<00:10,  5.72it/s]
2022-03-22 02:20:14,064 - INFO - tqdm - f1: 0.7371, accuracy: 0.8897, batch_loss: 0.2607, loss: 0.2696 ||: 100%|#########9| 7168/7204 [29:18<00:05,  6.54it/s]
2022-03-22 02:20:14,206 - INFO - tqdm - f1: 0.7372, accuracy: 0.8897, batch_loss: 0.1223, loss: 0.2695 ||: 100%|#########9| 7169/7204 [29:18<00:05,  6.67it/s]
2022-03-22 02:20:14,388 - INFO - tqdm - f1: 0.7372, accuracy: 0.8897, batch_loss: 0.2634, loss: 0.2695 ||: 100%|#########9| 7170/7204 [29:18<00:05,  6.27it/s]
2022-03-22 02:20:14,535 - INFO - tqdm - f1: 0.7372, accuracy: 0.8897, batch_loss: 0.5158, loss: 0.2696 ||: 100%|#########9| 7171/7204 [29:18<00:05,  6.43it/s]
2022-03-22 02:20:14,725 - INFO - tqdm - f1: 0.7372, accuracy: 0.8897, batch_loss: 0.6822, loss: 0.2696 ||: 100%|#########9| 7172/7204 [29:18<00:05,  6.03it/s]
2022-03-22 02:20:14,856 - INFO - tqdm - f1: 0.7372, accuracy: 0.8897, batch_loss: 0.3575, loss: 0.2696 ||: 100%|#########9| 7173/7204 [29:19<00:04,  6.43it/s]
2022-03-22 02:20:15,184 - INFO - tqdm - f1: 0.7372, accuracy: 0.8897, batch_loss: 0.0484, loss: 0.2696 ||: 100%|#########9| 7174/7204 [29:19<00:06,  4.83it/s]
2022-03-22 02:20:15,531 - INFO - tqdm - f1: 0.7372, accuracy: 0.8897, batch_loss: 0.0502, loss: 0.2696 ||: 100%|#########9| 7175/7204 [29:19<00:07,  4.02it/s]
2022-03-22 02:20:15,961 - INFO - tqdm - f1: 0.7372, accuracy: 0.8897, batch_loss: 0.1720, loss: 0.2696 ||: 100%|#########9| 7176/7204 [29:20<00:08,  3.29it/s]
2022-03-22 02:20:16,315 - INFO - tqdm - f1: 0.7372, accuracy: 0.8897, batch_loss: 0.0751, loss: 0.2695 ||: 100%|#########9| 7177/7204 [29:20<00:08,  3.14it/s]
2022-03-22 02:20:16,618 - INFO - tqdm - f1: 0.7372, accuracy: 0.8897, batch_loss: 0.1427, loss: 0.2695 ||: 100%|#########9| 7178/7204 [29:20<00:08,  3.19it/s]
2022-03-22 02:20:16,760 - INFO - tqdm - f1: 0.7372, accuracy: 0.8897, batch_loss: 0.1228, loss: 0.2695 ||: 100%|#########9| 7179/7204 [29:20<00:06,  3.81it/s]
2022-03-22 02:20:16,947 - INFO - tqdm - f1: 0.7372, accuracy: 0.8897, batch_loss: 0.1985, loss: 0.2695 ||: 100%|#########9| 7180/7204 [29:21<00:05,  4.17it/s]
2022-03-22 02:20:17,124 - INFO - tqdm - f1: 0.7373, accuracy: 0.8897, batch_loss: 0.2928, loss: 0.2695 ||: 100%|#########9| 7181/7204 [29:21<00:05,  4.53it/s]
2022-03-22 02:20:17,342 - INFO - tqdm - f1: 0.7373, accuracy: 0.8897, batch_loss: 0.3990, loss: 0.2695 ||: 100%|#########9| 7182/7204 [29:21<00:04,  4.55it/s]
2022-03-22 02:20:17,504 - INFO - tqdm - f1: 0.7373, accuracy: 0.8897, batch_loss: 0.1394, loss: 0.2695 ||: 100%|#########9| 7183/7204 [29:21<00:04,  4.98it/s]
2022-03-22 02:20:17,770 - INFO - tqdm - f1: 0.7373, accuracy: 0.8897, batch_loss: 0.3441, loss: 0.2695 ||: 100%|#########9| 7184/7204 [29:21<00:04,  4.50it/s]
2022-03-22 02:20:17,950 - INFO - tqdm - f1: 0.7373, accuracy: 0.8897, batch_loss: 0.2328, loss: 0.2695 ||: 100%|#########9| 7185/7204 [29:22<00:03,  4.78it/s]
2022-03-22 02:20:18,233 - INFO - tqdm - f1: 0.7373, accuracy: 0.8898, batch_loss: 0.1055, loss: 0.2695 ||: 100%|#########9| 7186/7204 [29:22<00:04,  4.32it/s]
2022-03-22 02:20:18,381 - INFO - tqdm - f1: 0.7373, accuracy: 0.8897, batch_loss: 0.4164, loss: 0.2695 ||: 100%|#########9| 7187/7204 [29:22<00:03,  4.84it/s]
2022-03-22 02:20:18,666 - INFO - tqdm - f1: 0.7373, accuracy: 0.8898, batch_loss: 0.0397, loss: 0.2695 ||: 100%|#########9| 7188/7204 [29:22<00:03,  4.34it/s]
2022-03-22 02:20:18,799 - INFO - tqdm - f1: 0.7373, accuracy: 0.8897, batch_loss: 0.5608, loss: 0.2695 ||: 100%|#########9| 7189/7204 [29:22<00:03,  4.98it/s]
2022-03-22 02:20:18,929 - INFO - tqdm - f1: 0.7373, accuracy: 0.8898, batch_loss: 0.0899, loss: 0.2695 ||: 100%|#########9| 7190/7204 [29:23<00:02,  5.56it/s]
2022-03-22 02:20:19,063 - INFO - tqdm - f1: 0.7374, accuracy: 0.8898, batch_loss: 0.1389, loss: 0.2695 ||: 100%|#########9| 7191/7204 [29:23<00:02,  6.03it/s]
2022-03-22 02:20:19,217 - INFO - tqdm - f1: 0.7374, accuracy: 0.8898, batch_loss: 0.3057, loss: 0.2695 ||: 100%|#########9| 7192/7204 [29:23<00:01,  6.16it/s]
2022-03-22 02:20:19,375 - INFO - tqdm - f1: 0.7374, accuracy: 0.8898, batch_loss: 0.3699, loss: 0.2695 ||: 100%|#########9| 7193/7204 [29:23<00:01,  6.20it/s]
2022-03-22 02:20:19,732 - INFO - tqdm - f1: 0.7373, accuracy: 0.8898, batch_loss: 0.4495, loss: 0.2695 ||: 100%|#########9| 7194/7204 [29:23<00:02,  4.55it/s]
2022-03-22 02:20:19,872 - INFO - tqdm - f1: 0.7374, accuracy: 0.8898, batch_loss: 0.3406, loss: 0.2695 ||: 100%|#########9| 7195/7204 [29:24<00:01,  5.11it/s]
2022-03-22 02:20:20,120 - INFO - tqdm - f1: 0.7375, accuracy: 0.8898, batch_loss: 0.1327, loss: 0.2695 ||: 100%|#########9| 7196/7204 [29:24<00:01,  4.73it/s]
2022-03-22 02:20:20,351 - INFO - tqdm - f1: 0.7374, accuracy: 0.8898, batch_loss: 0.5165, loss: 0.2695 ||: 100%|#########9| 7197/7204 [29:24<00:01,  4.60it/s]
2022-03-22 02:20:20,536 - INFO - tqdm - f1: 0.7375, accuracy: 0.8898, batch_loss: 0.2004, loss: 0.2695 ||: 100%|#########9| 7198/7204 [29:24<00:01,  4.82it/s]
2022-03-22 02:20:20,722 - INFO - tqdm - f1: 0.7375, accuracy: 0.8898, batch_loss: 0.2016, loss: 0.2695 ||: 100%|#########9| 7199/7204 [29:24<00:01,  4.97it/s]
2022-03-22 02:20:20,937 - INFO - tqdm - f1: 0.7375, accuracy: 0.8898, batch_loss: 0.1275, loss: 0.2695 ||: 100%|#########9| 7200/7204 [29:25<00:00,  4.87it/s]
2022-03-22 02:20:21,098 - INFO - tqdm - f1: 0.7375, accuracy: 0.8898, batch_loss: 0.2232, loss: 0.2695 ||: 100%|#########9| 7201/7204 [29:25<00:00,  5.21it/s]
2022-03-22 02:20:21,210 - INFO - tqdm - f1: 0.7375, accuracy: 0.8898, batch_loss: 0.3983, loss: 0.2695 ||: 100%|#########9| 7202/7204 [29:25<00:00,  5.95it/s]
2022-03-22 02:20:21,331 - INFO - tqdm - f1: 0.7375, accuracy: 0.8898, batch_loss: 0.2335, loss: 0.2695 ||: 100%|#########9| 7203/7204 [29:25<00:00,  6.50it/s]
2022-03-22 02:20:21,445 - INFO - tqdm - f1: 0.7375, accuracy: 0.8897, batch_loss: 0.6534, loss: 0.2695 ||: 100%|##########| 7204/7204 [29:25<00:00,  7.04it/s]
2022-03-22 02:20:21,568 - INFO - tqdm - f1: 0.7375, accuracy: 0.8897, batch_loss: 0.6534, loss: 0.2695 ||: 100%|##########| 7204/7204 [29:25<00:00,  4.08it/s]
2022-03-22 02:20:21,583 - INFO - allennlp.training.trainer - Validating
2022-03-22 02:20:21,589 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-22 02:20:31,730 - INFO - tqdm - f1: 0.6594, accuracy: 0.8788, batch_loss: 0.4526, loss: 0.3052 ||:  32%|###1      | 100/313 [00:10<00:22,  9.62it/s]
2022-03-22 02:20:41,889 - INFO - tqdm - f1: 0.6549, accuracy: 0.8697, batch_loss: 0.2668, loss: 0.3335 ||:  57%|#####6    | 178/313 [00:20<00:14,  9.42it/s]
2022-03-22 02:20:51,985 - INFO - tqdm - f1: 0.6623, accuracy: 0.8703, batch_loss: 0.2426, loss: 0.3398 ||:  85%|########4 | 265/313 [00:30<00:04, 10.12it/s]
2022-03-22 02:20:58,400 - INFO - tqdm - f1: 0.6637, accuracy: 0.8710, batch_loss: 0.4233, loss: 0.3381 ||: 100%|#########9| 312/313 [00:36<00:00,  5.20it/s]
2022-03-22 02:20:58,548 - INFO - tqdm - f1: 0.6639, accuracy: 0.8710, batch_loss: 0.2662, loss: 0.3378 ||: 100%|##########| 313/313 [00:36<00:00,  5.57it/s]
2022-03-22 02:20:58,553 - INFO - tqdm - f1: 0.6639, accuracy: 0.8710, batch_loss: 0.2662, loss: 0.3378 ||: 100%|##########| 313/313 [00:36<00:00,  8.47it/s]
2022-03-22 02:20:58,678 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-22 02:20:58,681 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.890  |     0.871
2022-03-22 02:20:58,683 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.737  |     0.664
2022-03-22 02:20:58,686 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-22 02:20:58,689 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.270  |     0.338
2022-03-22 02:20:58,691 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13613.066  |       N/A
2022-03-22 02:20:58,692 - INFO - allennlp.training.trainer - Epoch duration: 0:30:02.859899
2022-03-22 02:20:58,694 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:20:55
2022-03-22 02:20:58,695 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-22 02:20:58,697 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-22 02:20:58,698 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-22 02:20:58,700 - INFO - allennlp.training.trainer - Training
2022-03-22 02:20:58,702 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-22 02:21:08,767 - INFO - tqdm - f1: 0.7996, accuracy: 0.9028, batch_loss: 0.3054, loss: 0.2601 ||:   0%|          | 27/7204 [00:10<34:05,  3.51it/s]
2022-03-22 02:21:18,860 - INFO - tqdm - f1: 0.7629, accuracy: 0.8994, batch_loss: 0.2408, loss: 0.2392 ||:   1%|          | 64/7204 [00:20<33:33,  3.55it/s]
2022-03-22 02:21:29,022 - INFO - tqdm - f1: 0.7837, accuracy: 0.9078, batch_loss: 0.2005, loss: 0.2309 ||:   1%|1         | 99/7204 [00:30<33:38,  3.52it/s]
2022-03-22 02:21:39,168 - INFO - tqdm - f1: 0.7738, accuracy: 0.9007, batch_loss: 0.1968, loss: 0.2444 ||:   2%|1         | 136/7204 [00:40<28:00,  4.21it/s]
2022-03-22 02:21:49,410 - INFO - tqdm - f1: 0.7871, accuracy: 0.9057, batch_loss: 0.0412, loss: 0.2388 ||:   2%|2         | 175/7204 [00:50<33:46,  3.47it/s]
2022-03-22 02:21:59,443 - INFO - tqdm - f1: 0.7890, accuracy: 0.9057, batch_loss: 0.2512, loss: 0.2390 ||:   3%|2         | 212/7204 [01:00<32:44,  3.56it/s]
2022-03-22 02:22:09,571 - INFO - tqdm - f1: 0.7866, accuracy: 0.9078, batch_loss: 0.0382, loss: 0.2320 ||:   3%|3         | 248/7204 [01:10<24:49,  4.67it/s]
2022-03-22 02:22:19,631 - INFO - tqdm - f1: 0.7897, accuracy: 0.9094, batch_loss: 0.0134, loss: 0.2276 ||:   4%|3         | 285/7204 [01:20<33:13,  3.47it/s]
2022-03-22 02:22:29,648 - INFO - tqdm - f1: 0.7910, accuracy: 0.9107, batch_loss: 0.1551, loss: 0.2258 ||:   4%|4         | 324/7204 [01:30<28:42,  4.00it/s]
2022-03-22 02:22:39,707 - INFO - tqdm - f1: 0.7927, accuracy: 0.9104, batch_loss: 0.7436, loss: 0.2268 ||:   5%|5         | 364/7204 [01:41<20:32,  5.55it/s]
2022-03-22 02:22:49,712 - INFO - tqdm - f1: 0.7893, accuracy: 0.9087, batch_loss: 0.0942, loss: 0.2296 ||:   6%|5         | 403/7204 [01:51<29:07,  3.89it/s]
2022-03-22 02:23:00,221 - INFO - tqdm - f1: 0.7858, accuracy: 0.9089, batch_loss: 0.0692, loss: 0.2289 ||:   6%|6         | 442/7204 [02:01<36:34,  3.08it/s]
2022-03-22 02:23:10,332 - INFO - tqdm - f1: 0.7917, accuracy: 0.9097, batch_loss: 0.3103, loss: 0.2294 ||:   7%|6         | 483/7204 [02:11<29:31,  3.79it/s]
2022-03-22 02:23:20,360 - INFO - tqdm - f1: 0.7925, accuracy: 0.9094, batch_loss: 0.1673, loss: 0.2283 ||:   7%|7         | 519/7204 [02:21<31:53,  3.49it/s]
2022-03-22 02:23:30,464 - INFO - tqdm - f1: 0.7951, accuracy: 0.9089, batch_loss: 0.0152, loss: 0.2307 ||:   8%|7         | 558/7204 [02:31<25:26,  4.35it/s]
2022-03-22 02:23:40,661 - INFO - tqdm - f1: 0.7972, accuracy: 0.9097, batch_loss: 0.0606, loss: 0.2306 ||:   8%|8         | 597/7204 [02:41<30:36,  3.60it/s]
2022-03-22 02:23:50,818 - INFO - tqdm - f1: 0.7978, accuracy: 0.9099, batch_loss: 0.0561, loss: 0.2309 ||:   9%|8         | 635/7204 [02:52<32:33,  3.36it/s]
2022-03-22 02:24:00,851 - INFO - tqdm - f1: 0.7958, accuracy: 0.9095, batch_loss: 0.1120, loss: 0.2330 ||:   9%|9         | 672/7204 [03:02<32:47,  3.32it/s]
2022-03-22 02:24:10,995 - INFO - tqdm - f1: 0.7937, accuracy: 0.9078, batch_loss: 0.1244, loss: 0.2351 ||:  10%|9         | 713/7204 [03:12<27:14,  3.97it/s]
2022-03-22 02:24:21,222 - INFO - tqdm - f1: 0.7946, accuracy: 0.9082, batch_loss: 0.3930, loss: 0.2349 ||:  10%|#         | 751/7204 [03:22<32:09,  3.34it/s]
2022-03-22 02:24:31,417 - INFO - tqdm - f1: 0.7929, accuracy: 0.9075, batch_loss: 0.1421, loss: 0.2366 ||:  11%|#         | 790/7204 [03:32<27:09,  3.94it/s]
2022-03-22 02:24:41,544 - INFO - tqdm - f1: 0.7929, accuracy: 0.9079, batch_loss: 0.1313, loss: 0.2354 ||:  11%|#1        | 827/7204 [03:42<35:19,  3.01it/s]
2022-03-22 02:24:51,631 - INFO - tqdm - f1: 0.7942, accuracy: 0.9081, batch_loss: 0.1477, loss: 0.2337 ||:  12%|#2        | 868/7204 [03:52<24:29,  4.31it/s]
2022-03-22 02:25:01,869 - INFO - tqdm - f1: 0.7936, accuracy: 0.9074, batch_loss: 0.2838, loss: 0.2347 ||:  13%|#2        | 910/7204 [04:03<29:43,  3.53it/s]
2022-03-22 02:25:11,922 - INFO - tqdm - f1: 0.7953, accuracy: 0.9086, batch_loss: 0.1320, loss: 0.2329 ||:  13%|#3        | 955/7204 [04:13<23:28,  4.44it/s]
2022-03-22 02:25:22,090 - INFO - tqdm - f1: 0.7947, accuracy: 0.9087, batch_loss: 0.2455, loss: 0.2338 ||:  14%|#3        | 997/7204 [04:23<27:44,  3.73it/s]
2022-03-22 02:25:32,313 - INFO - tqdm - f1: 0.7946, accuracy: 0.9078, batch_loss: 0.0484, loss: 0.2358 ||:  14%|#4        | 1044/7204 [04:33<26:37,  3.85it/s]
2022-03-22 02:25:42,367 - INFO - tqdm - f1: 0.7974, accuracy: 0.9085, batch_loss: 0.3903, loss: 0.2338 ||:  15%|#5        | 1088/7204 [04:43<20:59,  4.86it/s]
2022-03-22 02:25:52,418 - INFO - tqdm - f1: 0.7982, accuracy: 0.9090, batch_loss: 0.2144, loss: 0.2329 ||:  16%|#5        | 1132/7204 [04:53<19:58,  5.06it/s]
2022-03-22 02:26:02,778 - INFO - tqdm - f1: 0.7984, accuracy: 0.9092, batch_loss: 0.4856, loss: 0.2321 ||:  16%|#6        | 1176/7204 [05:04<28:52,  3.48it/s]
2022-03-22 02:26:12,796 - INFO - tqdm - f1: 0.7993, accuracy: 0.9087, batch_loss: 0.1340, loss: 0.2329 ||:  17%|#6        | 1221/7204 [05:14<20:50,  4.79it/s]
2022-03-22 02:26:22,825 - INFO - tqdm - f1: 0.7977, accuracy: 0.9079, batch_loss: 0.3310, loss: 0.2344 ||:  18%|#7        | 1265/7204 [05:24<23:35,  4.20it/s]
2022-03-22 02:26:33,131 - INFO - tqdm - f1: 0.7989, accuracy: 0.9082, batch_loss: 0.0177, loss: 0.2332 ||:  18%|#8        | 1310/7204 [05:34<25:58,  3.78it/s]
2022-03-22 02:26:43,148 - INFO - tqdm - f1: 0.7996, accuracy: 0.9082, batch_loss: 0.3107, loss: 0.2328 ||:  19%|#8        | 1353/7204 [05:44<18:57,  5.14it/s]
2022-03-22 02:26:53,461 - INFO - tqdm - f1: 0.7991, accuracy: 0.9082, batch_loss: 0.2817, loss: 0.2330 ||:  19%|#9        | 1398/7204 [05:54<24:15,  3.99it/s]
2022-03-22 02:27:03,606 - INFO - tqdm - f1: 0.7985, accuracy: 0.9077, batch_loss: 0.1436, loss: 0.2336 ||:  20%|##        | 1442/7204 [06:04<17:37,  5.45it/s]
2022-03-22 02:27:13,677 - INFO - tqdm - f1: 0.7978, accuracy: 0.9074, batch_loss: 0.0870, loss: 0.2342 ||:  21%|##        | 1485/7204 [06:14<26:46,  3.56it/s]
2022-03-22 02:27:23,717 - INFO - tqdm - f1: 0.7994, accuracy: 0.9082, batch_loss: 0.4778, loss: 0.2333 ||:  21%|##1       | 1531/7204 [06:25<18:58,  4.98it/s]
2022-03-22 02:27:34,069 - INFO - tqdm - f1: 0.7992, accuracy: 0.9081, batch_loss: 0.0333, loss: 0.2338 ||:  22%|##1       | 1577/7204 [06:35<24:44,  3.79it/s]
2022-03-22 02:27:44,253 - INFO - tqdm - f1: 0.7996, accuracy: 0.9080, batch_loss: 0.1181, loss: 0.2339 ||:  23%|##2       | 1621/7204 [06:45<25:30,  3.65it/s]
2022-03-22 02:27:54,549 - INFO - tqdm - f1: 0.8001, accuracy: 0.9079, batch_loss: 0.0237, loss: 0.2338 ||:  23%|##3       | 1665/7204 [06:55<21:52,  4.22it/s]
2022-03-22 02:28:04,881 - INFO - tqdm - f1: 0.7994, accuracy: 0.9077, batch_loss: 0.0378, loss: 0.2346 ||:  24%|##3       | 1712/7204 [07:06<27:15,  3.36it/s]
2022-03-22 02:28:14,957 - INFO - tqdm - f1: 0.7989, accuracy: 0.9075, batch_loss: 0.2152, loss: 0.2352 ||:  24%|##4       | 1755/7204 [07:16<22:46,  3.99it/s]
2022-03-22 02:28:25,178 - INFO - tqdm - f1: 0.7999, accuracy: 0.9076, batch_loss: 0.1861, loss: 0.2351 ||:  25%|##4       | 1799/7204 [07:26<20:15,  4.45it/s]
2022-03-22 02:28:35,204 - INFO - tqdm - f1: 0.7995, accuracy: 0.9077, batch_loss: 0.2542, loss: 0.2351 ||:  26%|##5       | 1842/7204 [07:36<16:34,  5.39it/s]
2022-03-22 02:28:45,313 - INFO - tqdm - f1: 0.7996, accuracy: 0.9082, batch_loss: 0.1796, loss: 0.2341 ||:  26%|##6       | 1885/7204 [07:46<19:37,  4.52it/s]
2022-03-22 02:28:55,519 - INFO - tqdm - f1: 0.7995, accuracy: 0.9082, batch_loss: 0.3179, loss: 0.2338 ||:  27%|##6       | 1927/7204 [07:56<18:56,  4.64it/s]
2022-03-22 02:29:05,590 - INFO - tqdm - f1: 0.7982, accuracy: 0.9083, batch_loss: 0.0441, loss: 0.2338 ||:  27%|##7       | 1969/7204 [08:06<21:57,  3.97it/s]
2022-03-22 02:29:15,971 - INFO - tqdm - f1: 0.7979, accuracy: 0.9083, batch_loss: 0.0585, loss: 0.2339 ||:  28%|##7       | 2012/7204 [08:17<23:26,  3.69it/s]
2022-03-22 02:29:26,092 - INFO - tqdm - f1: 0.7979, accuracy: 0.9081, batch_loss: 0.2330, loss: 0.2347 ||:  29%|##8       | 2059/7204 [08:27<17:18,  4.95it/s]
2022-03-22 02:29:36,139 - INFO - tqdm - f1: 0.7973, accuracy: 0.9081, batch_loss: 0.1714, loss: 0.2345 ||:  29%|##9       | 2103/7204 [08:37<21:30,  3.95it/s]
2022-03-22 02:29:46,321 - INFO - tqdm - f1: 0.7965, accuracy: 0.9076, batch_loss: 0.3792, loss: 0.2351 ||:  30%|##9       | 2145/7204 [08:47<18:05,  4.66it/s]
2022-03-22 02:29:56,362 - INFO - tqdm - f1: 0.7967, accuracy: 0.9070, batch_loss: 0.2643, loss: 0.2356 ||:  30%|###       | 2191/7204 [08:57<15:23,  5.43it/s]
2022-03-22 02:30:06,571 - INFO - tqdm - f1: 0.7965, accuracy: 0.9070, batch_loss: 0.1927, loss: 0.2359 ||:  31%|###       | 2233/7204 [09:07<22:35,  3.67it/s]
2022-03-22 02:30:16,579 - INFO - tqdm - f1: 0.7972, accuracy: 0.9072, batch_loss: 0.0803, loss: 0.2361 ||:  32%|###1      | 2277/7204 [09:17<20:18,  4.04it/s]
2022-03-22 02:30:26,591 - INFO - tqdm - f1: 0.7964, accuracy: 0.9072, batch_loss: 0.1266, loss: 0.2360 ||:  32%|###2      | 2319/7204 [09:27<17:30,  4.65it/s]
2022-03-22 02:30:36,840 - INFO - tqdm - f1: 0.7962, accuracy: 0.9073, batch_loss: 0.1377, loss: 0.2360 ||:  33%|###2      | 2365/7204 [09:38<20:06,  4.01it/s]
2022-03-22 02:30:46,865 - INFO - tqdm - f1: 0.7961, accuracy: 0.9075, batch_loss: 0.4000, loss: 0.2357 ||:  33%|###3      | 2409/7204 [09:48<16:33,  4.82it/s]
2022-03-22 02:30:56,909 - INFO - tqdm - f1: 0.7955, accuracy: 0.9075, batch_loss: 0.0800, loss: 0.2353 ||:  34%|###3      | 2448/7204 [09:58<19:30,  4.06it/s]
2022-03-22 02:31:06,915 - INFO - tqdm - f1: 0.7954, accuracy: 0.9075, batch_loss: 0.4484, loss: 0.2350 ||:  35%|###4      | 2488/7204 [10:08<16:41,  4.71it/s]
2022-03-22 02:31:17,121 - INFO - tqdm - f1: 0.7952, accuracy: 0.9074, batch_loss: 0.2995, loss: 0.2351 ||:  35%|###5      | 2536/7204 [10:18<17:51,  4.36it/s]
2022-03-22 02:31:27,180 - INFO - tqdm - f1: 0.7957, accuracy: 0.9076, batch_loss: 0.0869, loss: 0.2349 ||:  36%|###5      | 2582/7204 [10:28<14:42,  5.24it/s]
2022-03-22 02:31:37,402 - INFO - tqdm - f1: 0.7958, accuracy: 0.9074, batch_loss: 0.0349, loss: 0.2357 ||:  36%|###6      | 2629/7204 [10:38<20:55,  3.64it/s]
2022-03-22 02:31:47,521 - INFO - tqdm - f1: 0.7959, accuracy: 0.9072, batch_loss: 0.1425, loss: 0.2361 ||:  37%|###7      | 2675/7204 [10:48<19:54,  3.79it/s]
2022-03-22 02:31:57,541 - INFO - tqdm - f1: 0.7959, accuracy: 0.9069, batch_loss: 0.5803, loss: 0.2369 ||:  38%|###7      | 2721/7204 [10:58<15:31,  4.81it/s]
2022-03-22 02:32:07,712 - INFO - tqdm - f1: 0.7953, accuracy: 0.9069, batch_loss: 0.1396, loss: 0.2365 ||:  38%|###8      | 2763/7204 [11:09<19:31,  3.79it/s]
2022-03-22 02:32:17,878 - INFO - tqdm - f1: 0.7957, accuracy: 0.9071, batch_loss: 0.3209, loss: 0.2364 ||:  39%|###8      | 2806/7204 [11:19<13:40,  5.36it/s]
2022-03-22 02:32:28,040 - INFO - tqdm - f1: 0.7956, accuracy: 0.9068, batch_loss: 0.2581, loss: 0.2366 ||:  40%|###9      | 2848/7204 [11:29<15:00,  4.84it/s]
2022-03-22 02:32:38,252 - INFO - tqdm - f1: 0.7950, accuracy: 0.9069, batch_loss: 0.0268, loss: 0.2365 ||:  40%|####      | 2889/7204 [11:39<20:58,  3.43it/s]
2022-03-22 02:32:48,400 - INFO - tqdm - f1: 0.7951, accuracy: 0.9071, batch_loss: 0.0193, loss: 0.2363 ||:  41%|####      | 2929/7204 [11:49<22:32,  3.16it/s]
2022-03-22 02:32:58,493 - INFO - tqdm - f1: 0.7957, accuracy: 0.9070, batch_loss: 0.1164, loss: 0.2365 ||:  41%|####1     | 2975/7204 [11:59<21:08,  3.33it/s]
2022-03-22 02:33:08,525 - INFO - tqdm - f1: 0.7960, accuracy: 0.9071, batch_loss: 0.2982, loss: 0.2361 ||:  42%|####1     | 3016/7204 [12:09<17:57,  3.89it/s]
2022-03-22 02:33:18,595 - INFO - tqdm - f1: 0.7954, accuracy: 0.9068, batch_loss: 0.3967, loss: 0.2365 ||:  42%|####2     | 3061/7204 [12:19<14:12,  4.86it/s]
2022-03-22 02:33:28,654 - INFO - tqdm - f1: 0.7957, accuracy: 0.9072, batch_loss: 0.1005, loss: 0.2362 ||:  43%|####3     | 3102/7204 [12:29<15:07,  4.52it/s]
2022-03-22 02:33:38,688 - INFO - tqdm - f1: 0.7954, accuracy: 0.9069, batch_loss: 0.2181, loss: 0.2367 ||:  44%|####3     | 3150/7204 [12:39<13:01,  5.19it/s]
2022-03-22 02:33:48,804 - INFO - tqdm - f1: 0.7949, accuracy: 0.9071, batch_loss: 0.0581, loss: 0.2363 ||:  44%|####4     | 3191/7204 [12:50<16:57,  3.95it/s]
2022-03-22 02:33:58,896 - INFO - tqdm - f1: 0.7951, accuracy: 0.9072, batch_loss: 0.1277, loss: 0.2359 ||:  45%|####4     | 3234/7204 [13:00<13:20,  4.96it/s]
2022-03-22 02:34:08,906 - INFO - tqdm - f1: 0.7948, accuracy: 0.9074, batch_loss: 0.1853, loss: 0.2356 ||:  45%|####5     | 3273/7204 [13:10<18:50,  3.48it/s]
2022-03-22 02:34:19,073 - INFO - tqdm - f1: 0.7946, accuracy: 0.9073, batch_loss: 0.3711, loss: 0.2356 ||:  46%|####6     | 3320/7204 [13:20<12:36,  5.13it/s]
2022-03-22 02:34:29,109 - INFO - tqdm - f1: 0.7944, accuracy: 0.9074, batch_loss: 0.4723, loss: 0.2357 ||:  47%|####6     | 3365/7204 [13:30<15:39,  4.08it/s]
2022-03-22 02:34:39,154 - INFO - tqdm - f1: 0.7940, accuracy: 0.9074, batch_loss: 0.4074, loss: 0.2356 ||:  47%|####7     | 3406/7204 [13:40<14:28,  4.37it/s]
2022-03-22 02:34:49,208 - INFO - tqdm - f1: 0.7942, accuracy: 0.9076, batch_loss: 0.1513, loss: 0.2351 ||:  48%|####7     | 3446/7204 [13:50<15:04,  4.15it/s]
2022-03-22 02:34:59,318 - INFO - tqdm - f1: 0.7941, accuracy: 0.9075, batch_loss: 0.0322, loss: 0.2353 ||:  48%|####8     | 3488/7204 [14:00<15:03,  4.11it/s]
2022-03-22 02:35:09,441 - INFO - tqdm - f1: 0.7944, accuracy: 0.9075, batch_loss: 0.0988, loss: 0.2357 ||:  49%|####9     | 3534/7204 [14:10<13:47,  4.43it/s]
2022-03-22 02:35:19,539 - INFO - tqdm - f1: 0.7943, accuracy: 0.9074, batch_loss: 0.3174, loss: 0.2359 ||:  50%|####9     | 3579/7204 [14:20<14:33,  4.15it/s]
2022-03-22 02:35:29,632 - INFO - tqdm - f1: 0.7942, accuracy: 0.9073, batch_loss: 0.3106, loss: 0.2359 ||:  50%|#####     | 3624/7204 [14:30<12:20,  4.84it/s]
2022-03-22 02:35:39,680 - INFO - tqdm - f1: 0.7943, accuracy: 0.9072, batch_loss: 0.2670, loss: 0.2357 ||:  51%|#####     | 3670/7204 [14:40<13:23,  4.40it/s]
2022-03-22 02:35:50,001 - INFO - tqdm - f1: 0.7936, accuracy: 0.9070, batch_loss: 0.0543, loss: 0.2362 ||:  52%|#####1    | 3713/7204 [14:51<18:30,  3.14it/s]
2022-03-22 02:36:00,026 - INFO - tqdm - f1: 0.7936, accuracy: 0.9071, batch_loss: 0.2965, loss: 0.2361 ||:  52%|#####2    | 3754/7204 [15:01<12:03,  4.77it/s]
2022-03-22 02:36:10,175 - INFO - tqdm - f1: 0.7939, accuracy: 0.9073, batch_loss: 0.1102, loss: 0.2358 ||:  53%|#####2    | 3801/7204 [15:11<11:01,  5.14it/s]
2022-03-22 02:36:20,250 - INFO - tqdm - f1: 0.7939, accuracy: 0.9072, batch_loss: 0.3091, loss: 0.2361 ||:  53%|#####3    | 3848/7204 [15:21<11:37,  4.81it/s]
2022-03-22 02:36:30,268 - INFO - tqdm - f1: 0.7938, accuracy: 0.9072, batch_loss: 0.0175, loss: 0.2359 ||:  54%|#####3    | 3889/7204 [15:31<17:45,  3.11it/s]
2022-03-22 02:36:40,430 - INFO - tqdm - f1: 0.7940, accuracy: 0.9073, batch_loss: 0.5172, loss: 0.2359 ||:  55%|#####4    | 3934/7204 [15:41<12:08,  4.49it/s]
2022-03-22 02:36:50,602 - INFO - tqdm - f1: 0.7942, accuracy: 0.9074, batch_loss: 0.1320, loss: 0.2359 ||:  55%|#####5    | 3978/7204 [15:51<13:11,  4.08it/s]
2022-03-22 02:37:00,752 - INFO - tqdm - f1: 0.7942, accuracy: 0.9073, batch_loss: 0.2375, loss: 0.2359 ||:  56%|#####5    | 4023/7204 [16:02<14:11,  3.74it/s]
2022-03-22 02:37:10,753 - INFO - tqdm - f1: 0.7942, accuracy: 0.9075, batch_loss: 0.2590, loss: 0.2356 ||:  56%|#####6    | 4063/7204 [16:12<11:35,  4.52it/s]
2022-03-22 02:37:20,902 - INFO - tqdm - f1: 0.7945, accuracy: 0.9076, batch_loss: 0.0547, loss: 0.2354 ||:  57%|#####7    | 4110/7204 [16:22<12:54,  4.00it/s]
2022-03-22 02:37:31,008 - INFO - tqdm - f1: 0.7946, accuracy: 0.9077, batch_loss: 0.2332, loss: 0.2351 ||:  58%|#####7    | 4152/7204 [16:32<11:58,  4.25it/s]
2022-03-22 02:37:41,144 - INFO - tqdm - f1: 0.7947, accuracy: 0.9077, batch_loss: 0.0350, loss: 0.2352 ||:  58%|#####8    | 4194/7204 [16:42<15:58,  3.14it/s]
2022-03-22 02:37:51,205 - INFO - tqdm - f1: 0.7952, accuracy: 0.9078, batch_loss: 0.8789, loss: 0.2351 ||:  59%|#####8    | 4237/7204 [16:52<10:35,  4.67it/s]
2022-03-22 02:38:01,325 - INFO - tqdm - f1: 0.7950, accuracy: 0.9078, batch_loss: 0.0450, loss: 0.2351 ||:  59%|#####9    | 4280/7204 [17:02<11:30,  4.23it/s]
2022-03-22 02:38:11,372 - INFO - tqdm - f1: 0.7945, accuracy: 0.9077, batch_loss: 0.3683, loss: 0.2353 ||:  61%|######    | 4360/7204 [17:12<04:44, 10.01it/s]
2022-03-22 02:38:21,672 - INFO - tqdm - f1: 0.7944, accuracy: 0.9075, batch_loss: 0.0770, loss: 0.2352 ||:  61%|######1   | 4416/7204 [17:22<09:39,  4.81it/s]
2022-03-22 02:38:31,702 - INFO - tqdm - f1: 0.7948, accuracy: 0.9074, batch_loss: 0.0959, loss: 0.2355 ||:  62%|######2   | 4478/7204 [17:32<09:18,  4.88it/s]
2022-03-22 02:38:41,803 - INFO - tqdm - f1: 0.7946, accuracy: 0.9074, batch_loss: 0.2639, loss: 0.2356 ||:  63%|######3   | 4541/7204 [17:43<08:20,  5.33it/s]
2022-03-22 02:38:52,045 - INFO - tqdm - f1: 0.7949, accuracy: 0.9077, batch_loss: 0.0246, loss: 0.2353 ||:  64%|######3   | 4588/7204 [17:53<11:37,  3.75it/s]
2022-03-22 02:39:02,316 - INFO - tqdm - f1: 0.7950, accuracy: 0.9079, batch_loss: 0.0377, loss: 0.2349 ||:  64%|######4   | 4631/7204 [18:03<12:23,  3.46it/s]
2022-03-22 02:39:12,584 - INFO - tqdm - f1: 0.7950, accuracy: 0.9078, batch_loss: 0.0935, loss: 0.2351 ||:  65%|######4   | 4675/7204 [18:13<11:57,  3.53it/s]
2022-03-22 02:39:22,735 - INFO - tqdm - f1: 0.7950, accuracy: 0.9078, batch_loss: 0.1778, loss: 0.2353 ||:  66%|######5   | 4720/7204 [18:24<07:46,  5.33it/s]
2022-03-22 02:39:32,912 - INFO - tqdm - f1: 0.7950, accuracy: 0.9080, batch_loss: 0.1527, loss: 0.2351 ||:  66%|######6   | 4762/7204 [18:34<08:07,  5.01it/s]
2022-03-22 02:39:43,087 - INFO - tqdm - f1: 0.7950, accuracy: 0.9080, batch_loss: 0.3959, loss: 0.2351 ||:  67%|######6   | 4807/7204 [18:44<09:17,  4.30it/s]
2022-03-22 02:39:53,099 - INFO - tqdm - f1: 0.7953, accuracy: 0.9079, batch_loss: 0.3728, loss: 0.2353 ||:  67%|######7   | 4850/7204 [18:54<10:11,  3.85it/s]
2022-03-22 02:40:03,227 - INFO - tqdm - f1: 0.7949, accuracy: 0.9079, batch_loss: 0.1437, loss: 0.2352 ||:  68%|######7   | 4894/7204 [19:04<08:01,  4.79it/s]
2022-03-22 02:40:13,334 - INFO - tqdm - f1: 0.7947, accuracy: 0.9079, batch_loss: 0.3301, loss: 0.2353 ||:  69%|######8   | 4939/7204 [19:14<08:32,  4.42it/s]
2022-03-22 02:40:23,439 - INFO - tqdm - f1: 0.7950, accuracy: 0.9079, batch_loss: 0.2622, loss: 0.2353 ||:  69%|######9   | 4980/7204 [19:24<07:58,  4.64it/s]
2022-03-22 02:40:33,826 - INFO - tqdm - f1: 0.7951, accuracy: 0.9080, batch_loss: 0.1012, loss: 0.2353 ||:  70%|######9   | 5022/7204 [19:35<09:22,  3.88it/s]
2022-03-22 02:40:43,893 - INFO - tqdm - f1: 0.7947, accuracy: 0.9079, batch_loss: 0.4375, loss: 0.2356 ||:  70%|#######   | 5065/7204 [19:45<09:38,  3.70it/s]
2022-03-22 02:40:53,988 - INFO - tqdm - f1: 0.7950, accuracy: 0.9080, batch_loss: 0.1376, loss: 0.2353 ||:  71%|#######   | 5110/7204 [19:55<07:37,  4.58it/s]
2022-03-22 02:41:04,170 - INFO - tqdm - f1: 0.7947, accuracy: 0.9079, batch_loss: 0.1106, loss: 0.2356 ||:  72%|#######1  | 5153/7204 [20:05<07:43,  4.43it/s]
2022-03-22 02:41:14,189 - INFO - tqdm - f1: 0.7946, accuracy: 0.9079, batch_loss: 0.0439, loss: 0.2356 ||:  72%|#######2  | 5198/7204 [20:15<07:02,  4.75it/s]
2022-03-22 02:41:24,300 - INFO - tqdm - f1: 0.7948, accuracy: 0.9080, batch_loss: 0.0895, loss: 0.2352 ||:  73%|#######2  | 5241/7204 [20:25<09:32,  3.43it/s]
2022-03-22 02:41:34,637 - INFO - tqdm - f1: 0.7945, accuracy: 0.9078, batch_loss: 0.0124, loss: 0.2354 ||:  73%|#######3  | 5287/7204 [20:35<07:42,  4.14it/s]
2022-03-22 02:41:44,663 - INFO - tqdm - f1: 0.7945, accuracy: 0.9079, batch_loss: 0.4508, loss: 0.2353 ||:  74%|#######3  | 5330/7204 [20:45<07:10,  4.36it/s]
2022-03-22 02:41:54,711 - INFO - tqdm - f1: 0.7944, accuracy: 0.9079, batch_loss: 0.4055, loss: 0.2353 ||:  75%|#######4  | 5372/7204 [20:56<07:32,  4.04it/s]
2022-03-22 02:42:04,896 - INFO - tqdm - f1: 0.7943, accuracy: 0.9078, batch_loss: 0.0849, loss: 0.2353 ||:  75%|#######5  | 5415/7204 [21:06<06:27,  4.61it/s]
2022-03-22 02:42:15,079 - INFO - tqdm - f1: 0.7941, accuracy: 0.9077, batch_loss: 0.4106, loss: 0.2356 ||:  76%|#######5  | 5460/7204 [21:16<07:16,  3.99it/s]
2022-03-22 02:42:25,298 - INFO - tqdm - f1: 0.7939, accuracy: 0.9078, batch_loss: 0.1807, loss: 0.2355 ||:  76%|#######6  | 5504/7204 [21:26<07:05,  3.99it/s]
2022-03-22 02:42:35,690 - INFO - tqdm - f1: 0.7941, accuracy: 0.9079, batch_loss: 0.0258, loss: 0.2352 ||:  77%|#######6  | 5547/7204 [21:36<07:40,  3.60it/s]
2022-03-22 02:42:45,718 - INFO - tqdm - f1: 0.7938, accuracy: 0.9078, batch_loss: 0.3441, loss: 0.2354 ||:  78%|#######7  | 5590/7204 [21:47<06:27,  4.17it/s]
2022-03-22 02:42:55,829 - INFO - tqdm - f1: 0.7932, accuracy: 0.9076, batch_loss: 0.3787, loss: 0.2356 ||:  78%|#######8  | 5633/7204 [21:57<05:31,  4.74it/s]
2022-03-22 02:43:06,070 - INFO - tqdm - f1: 0.7928, accuracy: 0.9075, batch_loss: 0.1305, loss: 0.2356 ||:  79%|#######8  | 5676/7204 [22:07<05:43,  4.45it/s]
2022-03-22 02:43:16,186 - INFO - tqdm - f1: 0.7928, accuracy: 0.9075, batch_loss: 0.4424, loss: 0.2357 ||:  79%|#######9  | 5722/7204 [22:17<05:43,  4.32it/s]
2022-03-22 02:43:26,336 - INFO - tqdm - f1: 0.7928, accuracy: 0.9074, batch_loss: 0.2856, loss: 0.2356 ||:  80%|########  | 5765/7204 [22:27<06:02,  3.97it/s]
2022-03-22 02:43:36,562 - INFO - tqdm - f1: 0.7929, accuracy: 0.9075, batch_loss: 0.0136, loss: 0.2354 ||:  81%|########  | 5809/7204 [22:37<05:51,  3.97it/s]
2022-03-22 02:43:46,767 - INFO - tqdm - f1: 0.7929, accuracy: 0.9076, batch_loss: 0.3136, loss: 0.2351 ||:  81%|########1 | 5850/7204 [22:48<05:15,  4.29it/s]
2022-03-22 02:43:56,917 - INFO - tqdm - f1: 0.7929, accuracy: 0.9076, batch_loss: 0.0405, loss: 0.2352 ||:  82%|########1 | 5895/7204 [22:58<03:35,  6.08it/s]
2022-03-22 02:44:07,001 - INFO - tqdm - f1: 0.7926, accuracy: 0.9075, batch_loss: 0.2077, loss: 0.2353 ||:  82%|########2 | 5940/7204 [23:08<05:14,  4.01it/s]
2022-03-22 02:44:17,123 - INFO - tqdm - f1: 0.7928, accuracy: 0.9076, batch_loss: 0.1976, loss: 0.2353 ||:  83%|########3 | 5986/7204 [23:18<04:23,  4.63it/s]
2022-03-22 02:44:27,145 - INFO - tqdm - f1: 0.7928, accuracy: 0.9076, batch_loss: 0.0938, loss: 0.2354 ||:  84%|########3 | 6029/7204 [23:28<04:45,  4.11it/s]
2022-03-22 02:44:37,237 - INFO - tqdm - f1: 0.7929, accuracy: 0.9076, batch_loss: 0.3430, loss: 0.2352 ||:  84%|########4 | 6073/7204 [23:38<04:37,  4.07it/s]
2022-03-22 02:44:47,321 - INFO - tqdm - f1: 0.7930, accuracy: 0.9076, batch_loss: 0.3778, loss: 0.2352 ||:  85%|########4 | 6116/7204 [23:48<03:54,  4.65it/s]
2022-03-22 02:44:57,413 - INFO - tqdm - f1: 0.7932, accuracy: 0.9078, batch_loss: 0.4027, loss: 0.2349 ||:  85%|########5 | 6156/7204 [23:58<03:44,  4.67it/s]
2022-03-22 02:45:07,533 - INFO - tqdm - f1: 0.7931, accuracy: 0.9078, batch_loss: 0.1243, loss: 0.2349 ||:  86%|########6 | 6199/7204 [24:08<04:10,  4.01it/s]
2022-03-22 02:45:17,617 - INFO - tqdm - f1: 0.7929, accuracy: 0.9077, batch_loss: 0.0985, loss: 0.2350 ||:  87%|########6 | 6241/7204 [24:18<03:51,  4.16it/s]
2022-03-22 02:45:27,797 - INFO - tqdm - f1: 0.7930, accuracy: 0.9077, batch_loss: 0.5429, loss: 0.2351 ||:  87%|########7 | 6283/7204 [24:29<03:14,  4.73it/s]
2022-03-22 02:45:37,991 - INFO - tqdm - f1: 0.7930, accuracy: 0.9077, batch_loss: 0.0391, loss: 0.2352 ||:  88%|########7 | 6326/7204 [24:39<04:15,  3.44it/s]
2022-03-22 02:45:48,129 - INFO - tqdm - f1: 0.7928, accuracy: 0.9078, batch_loss: 0.1300, loss: 0.2348 ||:  88%|########8 | 6366/7204 [24:49<04:25,  3.16it/s]
2022-03-22 02:45:58,275 - INFO - tqdm - f1: 0.7927, accuracy: 0.9077, batch_loss: 0.0974, loss: 0.2351 ||:  89%|########8 | 6409/7204 [24:59<03:04,  4.32it/s]
2022-03-22 02:46:08,366 - INFO - tqdm - f1: 0.7926, accuracy: 0.9076, batch_loss: 0.2039, loss: 0.2352 ||:  90%|########9 | 6453/7204 [25:09<02:37,  4.76it/s]
2022-03-22 02:46:18,501 - INFO - tqdm - f1: 0.7924, accuracy: 0.9076, batch_loss: 0.5248, loss: 0.2352 ||:  90%|######### | 6497/7204 [25:19<02:12,  5.32it/s]
2022-03-22 02:46:28,604 - INFO - tqdm - f1: 0.7922, accuracy: 0.9074, batch_loss: 0.2728, loss: 0.2356 ||:  91%|######### | 6543/7204 [25:29<02:30,  4.39it/s]
2022-03-22 02:46:38,632 - INFO - tqdm - f1: 0.7922, accuracy: 0.9075, batch_loss: 0.1200, loss: 0.2354 ||:  91%|#########1| 6584/7204 [25:39<02:03,  5.00it/s]
2022-03-22 02:46:48,859 - INFO - tqdm - f1: 0.7921, accuracy: 0.9076, batch_loss: 0.7434, loss: 0.2353 ||:  92%|#########2| 6628/7204 [25:50<02:25,  3.96it/s]
2022-03-22 02:46:58,984 - INFO - tqdm - f1: 0.7921, accuracy: 0.9075, batch_loss: 0.2381, loss: 0.2355 ||:  93%|#########2| 6674/7204 [26:00<02:01,  4.35it/s]
2022-03-22 02:47:09,172 - INFO - tqdm - f1: 0.7919, accuracy: 0.9075, batch_loss: 0.2863, loss: 0.2355 ||:  93%|#########3| 6718/7204 [26:10<02:00,  4.03it/s]
2022-03-22 02:47:19,310 - INFO - tqdm - f1: 0.7918, accuracy: 0.9074, batch_loss: 0.6058, loss: 0.2356 ||:  94%|#########3| 6757/7204 [26:20<02:03,  3.62it/s]
2022-03-22 02:47:29,552 - INFO - tqdm - f1: 0.7918, accuracy: 0.9073, batch_loss: 0.0199, loss: 0.2356 ||:  94%|#########4| 6803/7204 [26:30<01:46,  3.77it/s]
2022-03-22 02:47:39,607 - INFO - tqdm - f1: 0.7918, accuracy: 0.9072, batch_loss: 0.1633, loss: 0.2360 ||:  95%|#########5| 6849/7204 [26:40<01:13,  4.85it/s]
2022-03-22 02:47:49,631 - INFO - tqdm - f1: 0.7916, accuracy: 0.9072, batch_loss: 0.0498, loss: 0.2358 ||:  96%|#########5| 6891/7204 [26:50<01:25,  3.67it/s]
2022-03-22 02:47:59,670 - INFO - tqdm - f1: 0.7916, accuracy: 0.9072, batch_loss: 0.5261, loss: 0.2357 ||:  96%|#########6| 6940/7204 [27:00<00:46,  5.64it/s]
2022-03-22 02:48:09,703 - INFO - tqdm - f1: 0.7916, accuracy: 0.9072, batch_loss: 0.3127, loss: 0.2356 ||:  97%|#########6| 6981/7204 [27:10<00:46,  4.76it/s]
2022-03-22 02:48:19,872 - INFO - tqdm - f1: 0.7915, accuracy: 0.9072, batch_loss: 0.0399, loss: 0.2357 ||:  97%|#########7| 7022/7204 [27:21<00:52,  3.46it/s]
2022-03-22 02:48:29,903 - INFO - tqdm - f1: 0.7913, accuracy: 0.9072, batch_loss: 0.3687, loss: 0.2359 ||:  98%|#########8| 7068/7204 [27:31<00:25,  5.27it/s]
2022-03-22 02:48:40,155 - INFO - tqdm - f1: 0.7912, accuracy: 0.9072, batch_loss: 0.0477, loss: 0.2360 ||:  99%|#########8| 7110/7204 [27:41<00:26,  3.55it/s]
2022-03-22 02:48:50,332 - INFO - tqdm - f1: 0.7914, accuracy: 0.9073, batch_loss: 0.4177, loss: 0.2358 ||:  99%|#########9| 7153/7204 [27:51<00:12,  4.20it/s]
2022-03-22 02:48:53,769 - INFO - tqdm - f1: 0.7914, accuracy: 0.9073, batch_loss: 0.2678, loss: 0.2358 ||: 100%|#########9| 7168/7204 [27:55<00:08,  4.23it/s]
2022-03-22 02:48:53,927 - INFO - tqdm - f1: 0.7914, accuracy: 0.9073, batch_loss: 0.1907, loss: 0.2358 ||: 100%|#########9| 7169/7204 [27:55<00:07,  4.70it/s]
2022-03-22 02:48:54,180 - INFO - tqdm - f1: 0.7914, accuracy: 0.9073, batch_loss: 0.1824, loss: 0.2358 ||: 100%|#########9| 7170/7204 [27:55<00:07,  4.45it/s]
2022-03-22 02:48:54,375 - INFO - tqdm - f1: 0.7914, accuracy: 0.9073, batch_loss: 0.3848, loss: 0.2358 ||: 100%|#########9| 7171/7204 [27:55<00:07,  4.63it/s]
2022-03-22 02:48:54,576 - INFO - tqdm - f1: 0.7914, accuracy: 0.9073, batch_loss: 0.4148, loss: 0.2358 ||: 100%|#########9| 7172/7204 [27:55<00:06,  4.73it/s]
2022-03-22 02:48:54,779 - INFO - tqdm - f1: 0.7914, accuracy: 0.9073, batch_loss: 0.1936, loss: 0.2358 ||: 100%|#########9| 7173/7204 [27:56<00:06,  4.78it/s]
2022-03-22 02:48:55,155 - INFO - tqdm - f1: 0.7914, accuracy: 0.9073, batch_loss: 0.1143, loss: 0.2358 ||: 100%|#########9| 7174/7204 [27:56<00:07,  3.86it/s]
2022-03-22 02:48:55,559 - INFO - tqdm - f1: 0.7914, accuracy: 0.9073, batch_loss: 0.3095, loss: 0.2358 ||: 100%|#########9| 7175/7204 [27:56<00:08,  3.30it/s]
2022-03-22 02:48:55,865 - INFO - tqdm - f1: 0.7914, accuracy: 0.9073, batch_loss: 0.0901, loss: 0.2358 ||: 100%|#########9| 7176/7204 [27:57<00:08,  3.30it/s]
2022-03-22 02:48:56,082 - INFO - tqdm - f1: 0.7913, accuracy: 0.9073, batch_loss: 0.3402, loss: 0.2358 ||: 100%|#########9| 7177/7204 [27:57<00:07,  3.60it/s]
2022-03-22 02:48:56,236 - INFO - tqdm - f1: 0.7913, accuracy: 0.9073, batch_loss: 0.3189, loss: 0.2358 ||: 100%|#########9| 7178/7204 [27:57<00:06,  4.16it/s]
2022-03-22 02:48:56,441 - INFO - tqdm - f1: 0.7913, accuracy: 0.9073, batch_loss: 0.2887, loss: 0.2358 ||: 100%|#########9| 7179/7204 [27:57<00:05,  4.35it/s]
2022-03-22 02:48:56,673 - INFO - tqdm - f1: 0.7913, accuracy: 0.9073, batch_loss: 0.2926, loss: 0.2358 ||: 100%|#########9| 7180/7204 [27:57<00:05,  4.34it/s]
2022-03-22 02:48:57,063 - INFO - tqdm - f1: 0.7913, accuracy: 0.9073, batch_loss: 0.1120, loss: 0.2358 ||: 100%|#########9| 7181/7204 [27:58<00:06,  3.59it/s]
2022-03-22 02:48:57,226 - INFO - tqdm - f1: 0.7913, accuracy: 0.9073, batch_loss: 0.3640, loss: 0.2358 ||: 100%|#########9| 7182/7204 [27:58<00:05,  4.10it/s]
2022-03-22 02:48:57,608 - INFO - tqdm - f1: 0.7913, accuracy: 0.9073, batch_loss: 0.0217, loss: 0.2358 ||: 100%|#########9| 7183/7204 [27:58<00:05,  3.51it/s]
2022-03-22 02:48:57,777 - INFO - tqdm - f1: 0.7912, accuracy: 0.9072, batch_loss: 0.4060, loss: 0.2358 ||: 100%|#########9| 7184/7204 [27:59<00:05,  4.00it/s]
2022-03-22 02:48:57,981 - INFO - tqdm - f1: 0.7912, accuracy: 0.9072, batch_loss: 0.2425, loss: 0.2358 ||: 100%|#########9| 7185/7204 [27:59<00:04,  4.23it/s]
2022-03-22 02:48:58,273 - INFO - tqdm - f1: 0.7912, accuracy: 0.9072, batch_loss: 0.3263, loss: 0.2358 ||: 100%|#########9| 7186/7204 [27:59<00:04,  3.95it/s]
2022-03-22 02:48:58,498 - INFO - tqdm - f1: 0.7912, accuracy: 0.9073, batch_loss: 0.0484, loss: 0.2358 ||: 100%|#########9| 7187/7204 [27:59<00:04,  4.09it/s]
2022-03-22 02:48:58,933 - INFO - tqdm - f1: 0.7912, accuracy: 0.9073, batch_loss: 0.0251, loss: 0.2358 ||: 100%|#########9| 7188/7204 [28:00<00:04,  3.31it/s]
2022-03-22 02:48:59,200 - INFO - tqdm - f1: 0.7912, accuracy: 0.9073, batch_loss: 0.0777, loss: 0.2358 ||: 100%|#########9| 7189/7204 [28:00<00:04,  3.43it/s]
2022-03-22 02:48:59,651 - INFO - tqdm - f1: 0.7912, accuracy: 0.9073, batch_loss: 0.0462, loss: 0.2357 ||: 100%|#########9| 7190/7204 [28:00<00:04,  2.95it/s]
2022-03-22 02:48:59,792 - INFO - tqdm - f1: 0.7912, accuracy: 0.9073, batch_loss: 0.2989, loss: 0.2357 ||: 100%|#########9| 7191/7204 [28:01<00:03,  3.57it/s]
2022-03-22 02:49:00,016 - INFO - tqdm - f1: 0.7912, accuracy: 0.9073, batch_loss: 0.1511, loss: 0.2357 ||: 100%|#########9| 7192/7204 [28:01<00:03,  3.80it/s]
2022-03-22 02:49:00,357 - INFO - tqdm - f1: 0.7912, accuracy: 0.9073, batch_loss: 0.1364, loss: 0.2357 ||: 100%|#########9| 7193/7204 [28:01<00:03,  3.49it/s]
2022-03-22 02:49:00,525 - INFO - tqdm - f1: 0.7912, accuracy: 0.9073, batch_loss: 0.2089, loss: 0.2357 ||: 100%|#########9| 7194/7204 [28:01<00:02,  3.99it/s]
2022-03-22 02:49:00,770 - INFO - tqdm - f1: 0.7912, accuracy: 0.9073, batch_loss: 0.0959, loss: 0.2357 ||: 100%|#########9| 7195/7204 [28:02<00:02,  4.01it/s]
2022-03-22 02:49:00,987 - INFO - tqdm - f1: 0.7912, accuracy: 0.9073, batch_loss: 0.2616, loss: 0.2357 ||: 100%|#########9| 7196/7204 [28:02<00:01,  4.18it/s]
2022-03-22 02:49:01,115 - INFO - tqdm - f1: 0.7911, accuracy: 0.9073, batch_loss: 0.5908, loss: 0.2357 ||: 100%|#########9| 7197/7204 [28:02<00:01,  4.85it/s]
2022-03-22 02:49:01,291 - INFO - tqdm - f1: 0.7911, accuracy: 0.9072, batch_loss: 0.4043, loss: 0.2358 ||: 100%|#########9| 7198/7204 [28:02<00:01,  5.08it/s]
2022-03-22 02:49:01,616 - INFO - tqdm - f1: 0.7911, accuracy: 0.9072, batch_loss: 0.3064, loss: 0.2358 ||: 100%|#########9| 7199/7204 [28:02<00:01,  4.25it/s]
2022-03-22 02:49:01,777 - INFO - tqdm - f1: 0.7911, accuracy: 0.9072, batch_loss: 0.3069, loss: 0.2358 ||: 100%|#########9| 7200/7204 [28:03<00:00,  4.70it/s]
2022-03-22 02:49:01,951 - INFO - tqdm - f1: 0.7911, accuracy: 0.9072, batch_loss: 0.3661, loss: 0.2358 ||: 100%|#########9| 7201/7204 [28:03<00:00,  4.97it/s]
2022-03-22 02:49:02,153 - INFO - tqdm - f1: 0.7911, accuracy: 0.9072, batch_loss: 0.1343, loss: 0.2358 ||: 100%|#########9| 7202/7204 [28:03<00:00,  4.96it/s]
2022-03-22 02:49:02,312 - INFO - tqdm - f1: 0.7911, accuracy: 0.9072, batch_loss: 0.2564, loss: 0.2358 ||: 100%|#########9| 7203/7204 [28:03<00:00,  5.29it/s]
2022-03-22 02:49:02,485 - INFO - tqdm - f1: 0.7911, accuracy: 0.9072, batch_loss: 0.4881, loss: 0.2358 ||: 100%|##########| 7204/7204 [28:03<00:00,  5.44it/s]
2022-03-22 02:49:02,539 - INFO - tqdm - f1: 0.7911, accuracy: 0.9072, batch_loss: 0.4881, loss: 0.2358 ||: 100%|##########| 7204/7204 [28:03<00:00,  4.28it/s]
2022-03-22 02:49:02,575 - INFO - allennlp.training.trainer - Validating
2022-03-22 02:49:02,583 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-22 02:49:12,900 - INFO - tqdm - f1: 0.6500, accuracy: 0.8711, batch_loss: 0.3633, loss: 0.3455 ||:  30%|###       | 95/313 [00:10<00:26,  8.16it/s]
2022-03-22 02:49:22,958 - INFO - tqdm - f1: 0.6625, accuracy: 0.8622, batch_loss: 0.3819, loss: 0.3627 ||:  61%|######1   | 191/313 [00:20<00:11, 10.76it/s]
2022-03-22 02:49:32,960 - INFO - tqdm - f1: 0.6738, accuracy: 0.8655, batch_loss: 0.1081, loss: 0.3531 ||:  92%|#########2| 288/313 [00:30<00:02,  9.10it/s]
2022-03-22 02:49:35,827 - INFO - tqdm - f1: 0.6744, accuracy: 0.8690, batch_loss: 0.2692, loss: 0.3469 ||: 100%|#########9| 312/313 [00:33<00:00,  7.82it/s]
2022-03-22 02:49:36,027 - INFO - tqdm - f1: 0.6740, accuracy: 0.8690, batch_loss: 0.5802, loss: 0.3476 ||: 100%|##########| 313/313 [00:33<00:00,  6.83it/s]
2022-03-22 02:49:36,031 - INFO - tqdm - f1: 0.6740, accuracy: 0.8690, batch_loss: 0.5802, loss: 0.3476 ||: 100%|##########| 313/313 [00:33<00:00,  9.36it/s]
2022-03-22 02:49:36,070 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-22 02:49:36,071 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.907  |     0.869
2022-03-22 02:49:36,073 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.791  |     0.674
2022-03-22 02:49:36,075 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-22 02:49:36,077 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.236  |     0.348
2022-03-22 02:49:36,079 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13613.066  |       N/A
2022-03-22 02:49:36,080 - INFO - allennlp.training.trainer - Epoch duration: 0:28:37.384996
2022-03-22 02:49:36,082 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:52:06
2022-03-22 02:49:36,083 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-22 02:49:36,085 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-22 02:49:36,087 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-22 02:49:36,090 - INFO - allennlp.training.trainer - Training
2022-03-22 02:49:36,091 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-22 02:49:46,471 - INFO - tqdm - f1: 0.8460, accuracy: 0.9273, batch_loss: 0.0071, loss: 0.1910 ||:   1%|          | 43/7204 [00:10<33:34,  3.55it/s]
2022-03-22 02:49:56,552 - INFO - tqdm - f1: 0.8484, accuracy: 0.9274, batch_loss: 0.2066, loss: 0.1973 ||:   1%|1         | 87/7204 [00:20<28:14,  4.20it/s]
2022-03-22 02:50:06,930 - INFO - tqdm - f1: 0.8528, accuracy: 0.9329, batch_loss: 0.0743, loss: 0.1924 ||:   2%|1         | 135/7204 [00:30<30:59,  3.80it/s]
2022-03-22 02:50:16,972 - INFO - tqdm - f1: 0.8509, accuracy: 0.9313, batch_loss: 0.0269, loss: 0.1973 ||:   2%|2         | 180/7204 [00:40<28:47,  4.07it/s]
2022-03-22 02:50:27,161 - INFO - tqdm - f1: 0.8586, accuracy: 0.9358, batch_loss: 0.3440, loss: 0.1842 ||:   3%|3         | 223/7204 [00:51<23:32,  4.94it/s]
2022-03-22 02:50:37,385 - INFO - tqdm - f1: 0.8509, accuracy: 0.9337, batch_loss: 0.0437, loss: 0.1893 ||:   4%|3         | 266/7204 [01:01<36:13,  3.19it/s]
2022-03-22 02:50:47,390 - INFO - tqdm - f1: 0.8482, accuracy: 0.9338, batch_loss: 0.1709, loss: 0.1858 ||:   4%|4         | 307/7204 [01:11<24:38,  4.66it/s]
2022-03-22 02:50:57,592 - INFO - tqdm - f1: 0.8502, accuracy: 0.9345, batch_loss: 0.1126, loss: 0.1862 ||:   5%|4         | 349/7204 [01:21<29:54,  3.82it/s]
2022-03-22 02:51:07,760 - INFO - tqdm - f1: 0.8509, accuracy: 0.9342, batch_loss: 0.1638, loss: 0.1851 ||:   5%|5         | 396/7204 [01:31<18:46,  6.04it/s]
2022-03-22 02:51:17,925 - INFO - tqdm - f1: 0.8489, accuracy: 0.9332, batch_loss: 0.0406, loss: 0.1857 ||:   6%|6         | 440/7204 [01:41<33:41,  3.35it/s]
2022-03-22 02:51:28,066 - INFO - tqdm - f1: 0.8510, accuracy: 0.9344, batch_loss: 0.1539, loss: 0.1830 ||:   7%|6         | 481/7204 [01:51<24:03,  4.66it/s]
2022-03-22 02:51:38,101 - INFO - tqdm - f1: 0.8468, accuracy: 0.9331, batch_loss: 0.2114, loss: 0.1817 ||:   7%|7         | 523/7204 [02:02<29:37,  3.76it/s]
2022-03-22 02:51:48,378 - INFO - tqdm - f1: 0.8458, accuracy: 0.9328, batch_loss: 0.1132, loss: 0.1833 ||:   8%|7         | 564/7204 [02:12<30:12,  3.66it/s]
2022-03-22 02:51:58,516 - INFO - tqdm - f1: 0.8462, accuracy: 0.9326, batch_loss: 0.2173, loss: 0.1834 ||:   8%|8         | 610/7204 [02:22<27:05,  4.06it/s]
2022-03-22 02:52:08,529 - INFO - tqdm - f1: 0.8437, accuracy: 0.9322, batch_loss: 0.2185, loss: 0.1836 ||:   9%|9         | 650/7204 [02:32<24:32,  4.45it/s]
2022-03-22 02:52:18,688 - INFO - tqdm - f1: 0.8415, accuracy: 0.9317, batch_loss: 0.0821, loss: 0.1854 ||:  10%|9         | 693/7204 [02:42<22:44,  4.77it/s]
2022-03-22 02:52:28,839 - INFO - tqdm - f1: 0.8437, accuracy: 0.9314, batch_loss: 0.1177, loss: 0.1858 ||:  10%|#         | 742/7204 [02:52<22:29,  4.79it/s]
2022-03-22 02:52:38,888 - INFO - tqdm - f1: 0.8440, accuracy: 0.9310, batch_loss: 0.0361, loss: 0.1870 ||:  11%|#         | 786/7204 [03:02<28:31,  3.75it/s]
2022-03-22 02:52:48,895 - INFO - tqdm - f1: 0.8401, accuracy: 0.9294, batch_loss: 0.0774, loss: 0.1904 ||:  12%|#1        | 830/7204 [03:12<22:39,  4.69it/s]
2022-03-22 02:52:58,967 - INFO - tqdm - f1: 0.8396, accuracy: 0.9296, batch_loss: 0.3114, loss: 0.1899 ||:  12%|#2        | 873/7204 [03:22<23:12,  4.55it/s]
2022-03-22 02:53:09,122 - INFO - tqdm - f1: 0.8383, accuracy: 0.9292, batch_loss: 0.0781, loss: 0.1902 ||:  13%|#2        | 915/7204 [03:33<28:55,  3.62it/s]
2022-03-22 02:53:19,219 - INFO - tqdm - f1: 0.8399, accuracy: 0.9298, batch_loss: 0.0604, loss: 0.1897 ||:  13%|#3        | 960/7204 [03:43<21:11,  4.91it/s]
2022-03-22 02:53:29,344 - INFO - tqdm - f1: 0.8402, accuracy: 0.9303, batch_loss: 0.1278, loss: 0.1886 ||:  14%|#3        | 1003/7204 [03:53<21:25,  4.82it/s]
2022-03-22 02:53:39,484 - INFO - tqdm - f1: 0.8424, accuracy: 0.9308, batch_loss: 0.1764, loss: 0.1874 ||:  15%|#4        | 1049/7204 [04:03<32:20,  3.17it/s]
2022-03-22 02:53:49,719 - INFO - tqdm - f1: 0.8426, accuracy: 0.9303, batch_loss: 0.3333, loss: 0.1882 ||:  15%|#5        | 1096/7204 [04:13<21:43,  4.69it/s]
2022-03-22 02:53:59,919 - INFO - tqdm - f1: 0.8427, accuracy: 0.9300, batch_loss: 0.2626, loss: 0.1895 ||:  16%|#5        | 1139/7204 [04:23<29:23,  3.44it/s]
2022-03-22 02:54:09,940 - INFO - tqdm - f1: 0.8421, accuracy: 0.9295, batch_loss: 0.1432, loss: 0.1908 ||:  16%|#6        | 1185/7204 [04:33<24:48,  4.04it/s]
2022-03-22 02:54:19,972 - INFO - tqdm - f1: 0.8432, accuracy: 0.9294, batch_loss: 0.1321, loss: 0.1917 ||:  17%|#7        | 1233/7204 [04:43<23:15,  4.28it/s]
2022-03-22 02:54:30,176 - INFO - tqdm - f1: 0.8427, accuracy: 0.9291, batch_loss: 0.0798, loss: 0.1924 ||:  18%|#7        | 1277/7204 [04:54<26:44,  3.69it/s]
2022-03-22 02:54:40,283 - INFO - tqdm - f1: 0.8436, accuracy: 0.9294, batch_loss: 0.0340, loss: 0.1915 ||:  18%|#8        | 1318/7204 [05:04<21:48,  4.50it/s]
2022-03-22 02:54:50,610 - INFO - tqdm - f1: 0.8424, accuracy: 0.9291, batch_loss: 0.0628, loss: 0.1923 ||:  19%|#8        | 1362/7204 [05:14<22:20,  4.36it/s]
2022-03-22 02:55:00,791 - INFO - tqdm - f1: 0.8430, accuracy: 0.9298, batch_loss: 0.0429, loss: 0.1907 ||:  19%|#9        | 1404/7204 [05:24<26:36,  3.63it/s]
2022-03-22 02:55:10,891 - INFO - tqdm - f1: 0.8434, accuracy: 0.9303, batch_loss: 0.1089, loss: 0.1897 ||:  20%|##        | 1446/7204 [05:34<19:57,  4.81it/s]
2022-03-22 02:55:21,093 - INFO - tqdm - f1: 0.8421, accuracy: 0.9299, batch_loss: 0.0663, loss: 0.1894 ||:  21%|##        | 1487/7204 [05:44<26:47,  3.56it/s]
2022-03-22 02:55:31,246 - INFO - tqdm - f1: 0.8422, accuracy: 0.9299, batch_loss: 0.1479, loss: 0.1899 ||:  21%|##1       | 1531/7204 [05:55<22:58,  4.12it/s]
2022-03-22 02:55:41,264 - INFO - tqdm - f1: 0.8420, accuracy: 0.9298, batch_loss: 0.1710, loss: 0.1904 ||:  22%|##1       | 1572/7204 [06:05<19:33,  4.80it/s]
2022-03-22 02:55:51,452 - INFO - tqdm - f1: 0.8420, accuracy: 0.9298, batch_loss: 0.0384, loss: 0.1900 ||:  22%|##2       | 1614/7204 [06:15<27:24,  3.40it/s]
2022-03-22 02:56:01,496 - INFO - tqdm - f1: 0.8409, accuracy: 0.9291, batch_loss: 0.2088, loss: 0.1910 ||:  23%|##3       | 1658/7204 [06:25<21:45,  4.25it/s]
2022-03-22 02:56:11,724 - INFO - tqdm - f1: 0.8402, accuracy: 0.9288, batch_loss: 0.1818, loss: 0.1918 ||:  24%|##3       | 1704/7204 [06:35<23:11,  3.95it/s]
2022-03-22 02:56:21,756 - INFO - tqdm - f1: 0.8412, accuracy: 0.9288, batch_loss: 0.3179, loss: 0.1915 ||:  25%|##4       | 1766/7204 [06:45<08:12, 11.04it/s]
2022-03-22 02:56:31,999 - INFO - tqdm - f1: 0.8411, accuracy: 0.9290, batch_loss: 0.0612, loss: 0.1908 ||:  25%|##5       | 1836/7204 [06:55<20:39,  4.33it/s]
2022-03-22 02:56:42,019 - INFO - tqdm - f1: 0.8414, accuracy: 0.9288, batch_loss: 0.3265, loss: 0.1909 ||:  26%|##6       | 1896/7204 [07:05<13:10,  6.72it/s]
2022-03-22 02:56:52,112 - INFO - tqdm - f1: 0.8419, accuracy: 0.9288, batch_loss: 0.1141, loss: 0.1910 ||:  27%|##7       | 1954/7204 [07:16<14:23,  6.08it/s]
2022-03-22 02:57:02,116 - INFO - tqdm - f1: 0.8412, accuracy: 0.9285, batch_loss: 0.2287, loss: 0.1916 ||:  28%|##7       | 2008/7204 [07:26<16:41,  5.19it/s]
2022-03-22 02:57:12,206 - INFO - tqdm - f1: 0.8410, accuracy: 0.9284, batch_loss: 0.0729, loss: 0.1913 ||:  28%|##8       | 2051/7204 [07:36<23:12,  3.70it/s]
2022-03-22 02:57:22,276 - INFO - tqdm - f1: 0.8410, accuracy: 0.9285, batch_loss: 0.3098, loss: 0.1913 ||:  29%|##9       | 2092/7204 [07:46<21:08,  4.03it/s]
2022-03-22 02:57:32,372 - INFO - tqdm - f1: 0.8405, accuracy: 0.9283, batch_loss: 0.3039, loss: 0.1918 ||:  30%|##9       | 2132/7204 [07:56<17:57,  4.71it/s]
2022-03-22 02:57:42,432 - INFO - tqdm - f1: 0.8407, accuracy: 0.9283, batch_loss: 0.0482, loss: 0.1925 ||:  30%|###       | 2175/7204 [08:06<26:03,  3.22it/s]
2022-03-22 02:57:52,476 - INFO - tqdm - f1: 0.8404, accuracy: 0.9281, batch_loss: 0.0780, loss: 0.1929 ||:  31%|###       | 2221/7204 [08:16<16:24,  5.06it/s]
2022-03-22 02:58:02,536 - INFO - tqdm - f1: 0.8406, accuracy: 0.9282, batch_loss: 0.4655, loss: 0.1926 ||:  31%|###1      | 2261/7204 [08:26<22:30,  3.66it/s]
2022-03-22 02:58:12,895 - INFO - tqdm - f1: 0.8403, accuracy: 0.9280, batch_loss: 0.0240, loss: 0.1930 ||:  32%|###2      | 2307/7204 [08:36<22:00,  3.71it/s]
2022-03-22 02:58:23,042 - INFO - tqdm - f1: 0.8402, accuracy: 0.9280, batch_loss: 0.0163, loss: 0.1929 ||:  33%|###2      | 2350/7204 [08:46<18:56,  4.27it/s]
2022-03-22 02:58:33,075 - INFO - tqdm - f1: 0.8396, accuracy: 0.9278, batch_loss: 0.1492, loss: 0.1934 ||:  33%|###3      | 2392/7204 [08:56<16:27,  4.87it/s]
2022-03-22 02:58:43,122 - INFO - tqdm - f1: 0.8392, accuracy: 0.9279, batch_loss: 0.0911, loss: 0.1930 ||:  34%|###3      | 2432/7204 [09:07<16:23,  4.85it/s]
2022-03-22 02:58:53,168 - INFO - tqdm - f1: 0.8397, accuracy: 0.9281, batch_loss: 0.1976, loss: 0.1928 ||:  34%|###4      | 2475/7204 [09:17<22:35,  3.49it/s]
2022-03-22 02:59:03,183 - INFO - tqdm - f1: 0.8399, accuracy: 0.9281, batch_loss: 0.3310, loss: 0.1928 ||:  35%|###4      | 2517/7204 [09:27<21:20,  3.66it/s]
2022-03-22 02:59:13,352 - INFO - tqdm - f1: 0.8393, accuracy: 0.9280, batch_loss: 0.8087, loss: 0.1936 ||:  36%|###5      | 2560/7204 [09:37<17:30,  4.42it/s]
2022-03-22 02:59:23,451 - INFO - tqdm - f1: 0.8388, accuracy: 0.9276, batch_loss: 0.1857, loss: 0.1939 ||:  36%|###6      | 2605/7204 [09:47<18:25,  4.16it/s]
2022-03-22 02:59:33,594 - INFO - tqdm - f1: 0.8387, accuracy: 0.9275, batch_loss: 0.2515, loss: 0.1941 ||:  37%|###6      | 2648/7204 [09:57<17:05,  4.44it/s]
2022-03-22 02:59:43,851 - INFO - tqdm - f1: 0.8392, accuracy: 0.9279, batch_loss: 0.0632, loss: 0.1935 ||:  37%|###7      | 2690/7204 [10:07<19:09,  3.93it/s]
2022-03-22 02:59:53,886 - INFO - tqdm - f1: 0.8386, accuracy: 0.9277, batch_loss: 0.3629, loss: 0.1941 ||:  38%|###7      | 2729/7204 [10:17<22:19,  3.34it/s]
2022-03-22 03:00:03,888 - INFO - tqdm - f1: 0.8383, accuracy: 0.9277, batch_loss: 0.3282, loss: 0.1938 ||:  39%|###8      | 2774/7204 [10:27<15:26,  4.78it/s]
2022-03-22 03:00:14,108 - INFO - tqdm - f1: 0.8381, accuracy: 0.9273, batch_loss: 0.0551, loss: 0.1945 ||:  39%|###9      | 2819/7204 [10:38<22:33,  3.24it/s]
2022-03-22 03:00:24,146 - INFO - tqdm - f1: 0.8381, accuracy: 0.9273, batch_loss: 0.0944, loss: 0.1942 ||:  40%|###9      | 2860/7204 [10:48<17:41,  4.09it/s]
2022-03-22 03:00:34,164 - INFO - tqdm - f1: 0.8378, accuracy: 0.9273, batch_loss: 0.3637, loss: 0.1942 ||:  40%|####      | 2901/7204 [10:58<14:27,  4.96it/s]
2022-03-22 03:00:44,176 - INFO - tqdm - f1: 0.8387, accuracy: 0.9274, batch_loss: 0.2725, loss: 0.1940 ||:  41%|####      | 2943/7204 [11:08<15:58,  4.44it/s]
2022-03-22 03:00:54,524 - INFO - tqdm - f1: 0.8379, accuracy: 0.9270, batch_loss: 0.0441, loss: 0.1951 ||:  41%|####1     | 2988/7204 [11:18<21:36,  3.25it/s]
2022-03-22 03:01:04,688 - INFO - tqdm - f1: 0.8375, accuracy: 0.9271, batch_loss: 0.3231, loss: 0.1950 ||:  42%|####2     | 3031/7204 [11:28<16:59,  4.09it/s]
2022-03-22 03:01:14,747 - INFO - tqdm - f1: 0.8380, accuracy: 0.9269, batch_loss: 0.1583, loss: 0.1954 ||:  43%|####2     | 3077/7204 [11:38<16:48,  4.09it/s]
2022-03-22 03:01:24,800 - INFO - tqdm - f1: 0.8383, accuracy: 0.9268, batch_loss: 0.3125, loss: 0.1957 ||:  43%|####3     | 3119/7204 [11:48<16:57,  4.01it/s]
2022-03-22 03:01:34,828 - INFO - tqdm - f1: 0.8382, accuracy: 0.9267, batch_loss: 0.1436, loss: 0.1962 ||:  44%|####3     | 3163/7204 [11:58<18:09,  3.71it/s]
2022-03-22 03:01:44,972 - INFO - tqdm - f1: 0.8382, accuracy: 0.9266, batch_loss: 0.1244, loss: 0.1963 ||:  45%|####4     | 3208/7204 [12:08<13:29,  4.93it/s]
2022-03-22 03:01:55,090 - INFO - tqdm - f1: 0.8379, accuracy: 0.9265, batch_loss: 0.4220, loss: 0.1964 ||:  45%|####5     | 3251/7204 [12:18<14:03,  4.69it/s]
2022-03-22 03:02:05,179 - INFO - tqdm - f1: 0.8377, accuracy: 0.9265, batch_loss: 0.5687, loss: 0.1966 ||:  46%|####5     | 3295/7204 [12:29<14:26,  4.51it/s]
2022-03-22 03:02:15,252 - INFO - tqdm - f1: 0.8382, accuracy: 0.9265, batch_loss: 0.3203, loss: 0.1969 ||:  46%|####6     | 3339/7204 [12:39<12:51,  5.01it/s]
2022-03-22 03:02:25,374 - INFO - tqdm - f1: 0.8380, accuracy: 0.9264, batch_loss: 0.1036, loss: 0.1973 ||:  47%|####6     | 3383/7204 [12:49<14:38,  4.35it/s]
2022-03-22 03:02:35,490 - INFO - tqdm - f1: 0.8374, accuracy: 0.9261, batch_loss: 0.2589, loss: 0.1980 ||:  48%|####7     | 3429/7204 [12:59<11:22,  5.53it/s]
2022-03-22 03:02:45,621 - INFO - tqdm - f1: 0.8375, accuracy: 0.9260, batch_loss: 0.4051, loss: 0.1983 ||:  48%|####8     | 3473/7204 [13:09<14:48,  4.20it/s]
2022-03-22 03:02:55,636 - INFO - tqdm - f1: 0.8373, accuracy: 0.9259, batch_loss: 0.0923, loss: 0.1986 ||:  49%|####8     | 3520/7204 [13:19<13:37,  4.50it/s]
2022-03-22 03:03:05,693 - INFO - tqdm - f1: 0.8376, accuracy: 0.9260, batch_loss: 0.2439, loss: 0.1986 ||:  50%|####9     | 3568/7204 [13:29<13:25,  4.52it/s]
2022-03-22 03:03:15,940 - INFO - tqdm - f1: 0.8379, accuracy: 0.9261, batch_loss: 0.0478, loss: 0.1982 ||:  50%|#####     | 3610/7204 [13:39<15:05,  3.97it/s]
2022-03-22 03:03:26,023 - INFO - tqdm - f1: 0.8378, accuracy: 0.9260, batch_loss: 0.3646, loss: 0.1982 ||:  51%|#####     | 3654/7204 [13:49<12:59,  4.56it/s]
2022-03-22 03:03:36,316 - INFO - tqdm - f1: 0.8378, accuracy: 0.9261, batch_loss: 0.1022, loss: 0.1982 ||:  51%|#####1    | 3695/7204 [14:00<16:16,  3.59it/s]
2022-03-22 03:03:46,676 - INFO - tqdm - f1: 0.8380, accuracy: 0.9259, batch_loss: 0.0306, loss: 0.1987 ||:  52%|#####1    | 3741/7204 [14:10<17:00,  3.39it/s]
2022-03-22 03:03:56,996 - INFO - tqdm - f1: 0.8381, accuracy: 0.9260, batch_loss: 0.1493, loss: 0.1985 ||:  52%|#####2    | 3782/7204 [14:20<15:06,  3.77it/s]
2022-03-22 03:04:07,084 - INFO - tqdm - f1: 0.8386, accuracy: 0.9262, batch_loss: 0.1885, loss: 0.1982 ||:  53%|#####3    | 3827/7204 [14:30<12:02,  4.68it/s]
2022-03-22 03:04:17,198 - INFO - tqdm - f1: 0.8388, accuracy: 0.9263, batch_loss: 0.1561, loss: 0.1982 ||:  54%|#####3    | 3873/7204 [14:41<14:02,  3.96it/s]
2022-03-22 03:04:27,357 - INFO - tqdm - f1: 0.8387, accuracy: 0.9262, batch_loss: 0.2792, loss: 0.1985 ||:  54%|#####4    | 3920/7204 [14:51<10:46,  5.08it/s]
2022-03-22 03:04:37,665 - INFO - tqdm - f1: 0.8389, accuracy: 0.9262, batch_loss: 0.0260, loss: 0.1986 ||:  55%|#####5    | 3964/7204 [15:01<15:36,  3.46it/s]
2022-03-22 03:04:47,921 - INFO - tqdm - f1: 0.8386, accuracy: 0.9261, batch_loss: 0.0277, loss: 0.1988 ||:  56%|#####5    | 4008/7204 [15:11<13:04,  4.07it/s]
2022-03-22 03:04:57,999 - INFO - tqdm - f1: 0.8386, accuracy: 0.9260, batch_loss: 0.1411, loss: 0.1992 ||:  56%|#####6    | 4051/7204 [15:21<14:54,  3.52it/s]
2022-03-22 03:05:08,227 - INFO - tqdm - f1: 0.8384, accuracy: 0.9259, batch_loss: 0.2508, loss: 0.1992 ||:  57%|#####6    | 4098/7204 [15:32<14:13,  3.64it/s]
2022-03-22 03:05:18,320 - INFO - tqdm - f1: 0.8386, accuracy: 0.9260, batch_loss: 0.0118, loss: 0.1990 ||:  57%|#####7    | 4137/7204 [15:42<13:45,  3.72it/s]
2022-03-22 03:05:28,379 - INFO - tqdm - f1: 0.8384, accuracy: 0.9261, batch_loss: 0.2340, loss: 0.1989 ||:  58%|#####8    | 4181/7204 [15:52<09:10,  5.49it/s]
2022-03-22 03:05:38,428 - INFO - tqdm - f1: 0.8385, accuracy: 0.9260, batch_loss: 0.3752, loss: 0.1990 ||:  59%|#####8    | 4225/7204 [16:02<10:34,  4.69it/s]
2022-03-22 03:05:48,625 - INFO - tqdm - f1: 0.8386, accuracy: 0.9261, batch_loss: 0.0972, loss: 0.1990 ||:  59%|#####9    | 4272/7204 [16:12<11:12,  4.36it/s]
2022-03-22 03:05:58,643 - INFO - tqdm - f1: 0.8386, accuracy: 0.9262, batch_loss: 0.0532, loss: 0.1986 ||:  60%|#####9    | 4318/7204 [16:22<10:42,  4.49it/s]
2022-03-22 03:06:08,964 - INFO - tqdm - f1: 0.8385, accuracy: 0.9261, batch_loss: 0.1699, loss: 0.1991 ||:  61%|######    | 4364/7204 [16:32<12:51,  3.68it/s]
2022-03-22 03:06:19,226 - INFO - tqdm - f1: 0.8383, accuracy: 0.9260, batch_loss: 0.2142, loss: 0.1993 ||:  61%|######1   | 4407/7204 [16:43<12:55,  3.60it/s]
2022-03-22 03:06:29,356 - INFO - tqdm - f1: 0.8377, accuracy: 0.9257, batch_loss: 0.1636, loss: 0.1997 ||:  62%|######1   | 4452/7204 [16:53<09:27,  4.85it/s]
2022-03-22 03:06:39,444 - INFO - tqdm - f1: 0.8378, accuracy: 0.9259, batch_loss: 0.0169, loss: 0.1993 ||:  62%|######2   | 4494/7204 [17:03<11:20,  3.99it/s]
2022-03-22 03:06:49,687 - INFO - tqdm - f1: 0.8379, accuracy: 0.9259, batch_loss: 0.1257, loss: 0.1991 ||:  63%|######3   | 4539/7204 [17:13<11:47,  3.76it/s]
2022-03-22 03:06:59,891 - INFO - tqdm - f1: 0.8379, accuracy: 0.9258, batch_loss: 0.1392, loss: 0.1993 ||:  64%|######3   | 4584/7204 [17:23<10:17,  4.24it/s]
2022-03-22 03:07:09,907 - INFO - tqdm - f1: 0.8378, accuracy: 0.9258, batch_loss: 0.2428, loss: 0.1994 ||:  64%|######4   | 4628/7204 [17:33<10:11,  4.21it/s]
2022-03-22 03:07:19,984 - INFO - tqdm - f1: 0.8379, accuracy: 0.9258, batch_loss: 0.2523, loss: 0.1996 ||:  65%|######4   | 4672/7204 [17:43<10:28,  4.03it/s]
2022-03-22 03:07:30,220 - INFO - tqdm - f1: 0.8377, accuracy: 0.9257, batch_loss: 0.0404, loss: 0.2000 ||:  65%|######5   | 4715/7204 [17:54<12:13,  3.39it/s]
2022-03-22 03:07:40,452 - INFO - tqdm - f1: 0.8375, accuracy: 0.9255, batch_loss: 0.5721, loss: 0.2004 ||:  66%|######6   | 4759/7204 [18:04<10:24,  3.92it/s]
2022-03-22 03:07:50,652 - INFO - tqdm - f1: 0.8375, accuracy: 0.9256, batch_loss: 0.0276, loss: 0.2001 ||:  67%|######6   | 4799/7204 [18:14<13:59,  2.87it/s]
2022-03-22 03:08:00,853 - INFO - tqdm - f1: 0.8375, accuracy: 0.9256, batch_loss: 0.4371, loss: 0.2002 ||:  67%|######7   | 4843/7204 [18:24<09:07,  4.31it/s]
2022-03-22 03:08:11,055 - INFO - tqdm - f1: 0.8377, accuracy: 0.9258, batch_loss: 0.0464, loss: 0.1999 ||:  68%|######7   | 4885/7204 [18:34<09:11,  4.21it/s]
2022-03-22 03:08:21,291 - INFO - tqdm - f1: 0.8372, accuracy: 0.9257, batch_loss: 0.1103, loss: 0.2001 ||:  68%|######8   | 4929/7204 [18:45<09:27,  4.01it/s]
2022-03-22 03:08:31,300 - INFO - tqdm - f1: 0.8372, accuracy: 0.9256, batch_loss: 0.1353, loss: 0.2001 ||:  69%|######9   | 4973/7204 [18:55<07:34,  4.91it/s]
2022-03-22 03:08:41,571 - INFO - tqdm - f1: 0.8373, accuracy: 0.9256, batch_loss: 0.1504, loss: 0.2002 ||:  70%|######9   | 5019/7204 [19:05<08:31,  4.27it/s]
2022-03-22 03:08:51,609 - INFO - tqdm - f1: 0.8373, accuracy: 0.9256, batch_loss: 0.1145, loss: 0.2002 ||:  70%|#######   | 5061/7204 [19:15<08:08,  4.39it/s]
2022-03-22 03:09:01,701 - INFO - tqdm - f1: 0.8370, accuracy: 0.9254, batch_loss: 0.2746, loss: 0.2007 ||:  71%|#######   | 5106/7204 [19:25<06:22,  5.49it/s]
2022-03-22 03:09:11,798 - INFO - tqdm - f1: 0.8370, accuracy: 0.9254, batch_loss: 0.0696, loss: 0.2009 ||:  72%|#######1  | 5153/7204 [19:35<06:25,  5.32it/s]
2022-03-22 03:09:21,867 - INFO - tqdm - f1: 0.8365, accuracy: 0.9252, batch_loss: 0.0958, loss: 0.2011 ||:  72%|#######2  | 5197/7204 [19:45<08:23,  3.99it/s]
2022-03-22 03:09:31,910 - INFO - tqdm - f1: 0.8364, accuracy: 0.9252, batch_loss: 0.3811, loss: 0.2010 ||:  73%|#######2  | 5238/7204 [19:55<08:12,  3.99it/s]
2022-03-22 03:09:42,070 - INFO - tqdm - f1: 0.8362, accuracy: 0.9250, batch_loss: 0.2550, loss: 0.2015 ||:  73%|#######3  | 5283/7204 [20:05<07:16,  4.41it/s]
2022-03-22 03:09:52,270 - INFO - tqdm - f1: 0.8361, accuracy: 0.9249, batch_loss: 0.1338, loss: 0.2017 ||:  74%|#######3  | 5328/7204 [20:16<08:49,  3.54it/s]
2022-03-22 03:10:02,423 - INFO - tqdm - f1: 0.8360, accuracy: 0.9247, batch_loss: 0.3734, loss: 0.2018 ||:  75%|#######4  | 5373/7204 [20:26<06:58,  4.37it/s]
2022-03-22 03:10:12,497 - INFO - tqdm - f1: 0.8358, accuracy: 0.9248, batch_loss: 0.0522, loss: 0.2017 ||:  75%|#######5  | 5415/7204 [20:36<08:24,  3.55it/s]
2022-03-22 03:10:22,610 - INFO - tqdm - f1: 0.8359, accuracy: 0.9248, batch_loss: 0.2084, loss: 0.2015 ||:  76%|#######5  | 5460/7204 [20:46<05:34,  5.21it/s]
2022-03-22 03:10:32,692 - INFO - tqdm - f1: 0.8357, accuracy: 0.9248, batch_loss: 0.2220, loss: 0.2016 ||:  76%|#######6  | 5503/7204 [20:56<06:22,  4.45it/s]
2022-03-22 03:10:42,702 - INFO - tqdm - f1: 0.8353, accuracy: 0.9247, batch_loss: 0.0164, loss: 0.2017 ||:  77%|#######6  | 5546/7204 [21:06<07:24,  3.73it/s]
2022-03-22 03:10:52,945 - INFO - tqdm - f1: 0.8350, accuracy: 0.9246, batch_loss: 0.0704, loss: 0.2019 ||:  78%|#######7  | 5594/7204 [21:16<05:55,  4.52it/s]
2022-03-22 03:11:03,079 - INFO - tqdm - f1: 0.8353, accuracy: 0.9246, batch_loss: 0.0693, loss: 0.2020 ||:  78%|#######8  | 5640/7204 [21:26<05:17,  4.92it/s]
2022-03-22 03:11:13,103 - INFO - tqdm - f1: 0.8353, accuracy: 0.9246, batch_loss: 0.1758, loss: 0.2022 ||:  79%|#######8  | 5683/7204 [21:37<04:51,  5.21it/s]
2022-03-22 03:11:23,153 - INFO - tqdm - f1: 0.8354, accuracy: 0.9246, batch_loss: 0.3399, loss: 0.2020 ||:  79%|#######9  | 5726/7204 [21:47<06:20,  3.89it/s]
2022-03-22 03:11:33,269 - INFO - tqdm - f1: 0.8353, accuracy: 0.9245, batch_loss: 0.1598, loss: 0.2021 ||:  80%|########  | 5773/7204 [21:57<06:28,  3.68it/s]
2022-03-22 03:11:43,318 - INFO - tqdm - f1: 0.8352, accuracy: 0.9245, batch_loss: 0.0578, loss: 0.2022 ||:  81%|########  | 5814/7204 [22:07<07:00,  3.31it/s]
2022-03-22 03:11:53,540 - INFO - tqdm - f1: 0.8353, accuracy: 0.9244, batch_loss: 0.1307, loss: 0.2023 ||:  81%|########1 | 5857/7204 [22:17<05:06,  4.39it/s]
2022-03-22 03:12:03,611 - INFO - tqdm - f1: 0.8352, accuracy: 0.9244, batch_loss: 0.1141, loss: 0.2023 ||:  82%|########1 | 5898/7204 [22:27<04:24,  4.93it/s]
2022-03-22 03:12:13,747 - INFO - tqdm - f1: 0.8353, accuracy: 0.9245, batch_loss: 0.0966, loss: 0.2021 ||:  83%|########2 | 5944/7204 [22:37<04:18,  4.87it/s]
2022-03-22 03:12:24,027 - INFO - tqdm - f1: 0.8353, accuracy: 0.9244, batch_loss: 0.3863, loss: 0.2023 ||:  83%|########3 | 5987/7204 [22:47<05:39,  3.59it/s]
2022-03-22 03:12:34,174 - INFO - tqdm - f1: 0.8355, accuracy: 0.9245, batch_loss: 0.4838, loss: 0.2021 ||:  84%|########3 | 6029/7204 [22:58<04:32,  4.32it/s]
2022-03-22 03:12:44,262 - INFO - tqdm - f1: 0.8353, accuracy: 0.9244, batch_loss: 0.1883, loss: 0.2022 ||:  84%|########4 | 6069/7204 [23:08<04:24,  4.29it/s]
2022-03-22 03:12:54,312 - INFO - tqdm - f1: 0.8355, accuracy: 0.9244, batch_loss: 0.3425, loss: 0.2024 ||:  85%|########4 | 6114/7204 [23:18<03:26,  5.27it/s]
2022-03-22 03:13:04,332 - INFO - tqdm - f1: 0.8354, accuracy: 0.9244, batch_loss: 0.1522, loss: 0.2024 ||:  85%|########5 | 6156/7204 [23:28<03:52,  4.52it/s]
2022-03-22 03:13:14,374 - INFO - tqdm - f1: 0.8352, accuracy: 0.9243, batch_loss: 0.0678, loss: 0.2027 ||:  86%|########6 | 6203/7204 [23:38<04:00,  4.17it/s]
2022-03-22 03:13:24,558 - INFO - tqdm - f1: 0.8350, accuracy: 0.9242, batch_loss: 0.5865, loss: 0.2027 ||:  87%|########6 | 6249/7204 [23:48<03:06,  5.11it/s]
2022-03-22 03:13:34,670 - INFO - tqdm - f1: 0.8351, accuracy: 0.9243, batch_loss: 0.0242, loss: 0.2025 ||:  87%|########7 | 6290/7204 [23:58<03:35,  4.23it/s]
2022-03-22 03:13:44,890 - INFO - tqdm - f1: 0.8351, accuracy: 0.9243, batch_loss: 0.0937, loss: 0.2026 ||:  88%|########7 | 6333/7204 [24:08<03:44,  3.89it/s]
2022-03-22 03:13:55,205 - INFO - tqdm - f1: 0.8352, accuracy: 0.9243, batch_loss: 0.6751, loss: 0.2025 ||:  89%|########8 | 6378/7204 [24:19<03:57,  3.48it/s]
2022-03-22 03:14:05,332 - INFO - tqdm - f1: 0.8351, accuracy: 0.9243, batch_loss: 0.1948, loss: 0.2024 ||:  89%|########9 | 6422/7204 [24:29<02:46,  4.70it/s]
2022-03-22 03:14:15,550 - INFO - tqdm - f1: 0.8347, accuracy: 0.9242, batch_loss: 0.0537, loss: 0.2027 ||:  90%|########9 | 6466/7204 [24:39<03:13,  3.81it/s]
2022-03-22 03:14:25,950 - INFO - tqdm - f1: 0.8350, accuracy: 0.9242, batch_loss: 0.0096, loss: 0.2026 ||:  90%|######### | 6514/7204 [24:49<03:06,  3.70it/s]
2022-03-22 03:14:35,951 - INFO - tqdm - f1: 0.8349, accuracy: 0.9242, batch_loss: 0.5373, loss: 0.2026 ||:  91%|######### | 6553/7204 [24:59<02:57,  3.66it/s]
2022-03-22 03:14:46,090 - INFO - tqdm - f1: 0.8349, accuracy: 0.9242, batch_loss: 0.2445, loss: 0.2025 ||:  92%|#########2| 6643/7204 [25:09<01:39,  5.63it/s]
2022-03-22 03:14:56,160 - INFO - tqdm - f1: 0.8347, accuracy: 0.9240, batch_loss: 0.0862, loss: 0.2027 ||:  93%|#########3| 6700/7204 [25:20<01:32,  5.45it/s]
2022-03-22 03:15:06,352 - INFO - tqdm - f1: 0.8345, accuracy: 0.9239, batch_loss: 0.1677, loss: 0.2029 ||:  94%|#########3| 6760/7204 [25:30<01:17,  5.71it/s]
2022-03-22 03:15:16,369 - INFO - tqdm - f1: 0.8344, accuracy: 0.9240, batch_loss: 0.0489, loss: 0.2027 ||:  95%|#########4| 6809/7204 [25:40<01:34,  4.17it/s]
2022-03-22 03:15:26,566 - INFO - tqdm - f1: 0.8343, accuracy: 0.9238, batch_loss: 0.1385, loss: 0.2028 ||:  95%|#########5| 6853/7204 [25:50<01:29,  3.93it/s]
2022-03-22 03:15:36,647 - INFO - tqdm - f1: 0.8344, accuracy: 0.9239, batch_loss: 0.0151, loss: 0.2027 ||:  96%|#########5| 6894/7204 [26:00<01:23,  3.70it/s]
2022-03-22 03:15:46,758 - INFO - tqdm - f1: 0.8345, accuracy: 0.9239, batch_loss: 0.1970, loss: 0.2027 ||:  96%|#########6| 6939/7204 [26:10<00:57,  4.65it/s]
2022-03-22 03:15:57,040 - INFO - tqdm - f1: 0.8345, accuracy: 0.9239, batch_loss: 0.0940, loss: 0.2026 ||:  97%|#########6| 6982/7204 [26:20<01:02,  3.55it/s]
2022-03-22 03:16:07,061 - INFO - tqdm - f1: 0.8345, accuracy: 0.9239, batch_loss: 0.3936, loss: 0.2026 ||:  98%|#########7| 7028/7204 [26:30<00:44,  3.93it/s]
2022-03-22 03:16:17,148 - INFO - tqdm - f1: 0.8343, accuracy: 0.9238, batch_loss: 0.1945, loss: 0.2028 ||:  98%|#########8| 7072/7204 [26:41<00:29,  4.42it/s]
2022-03-22 03:16:27,200 - INFO - tqdm - f1: 0.8342, accuracy: 0.9237, batch_loss: 0.3871, loss: 0.2032 ||:  99%|#########8| 7118/7204 [26:51<00:15,  5.58it/s]
2022-03-22 03:16:37,370 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.0593, loss: 0.2032 ||:  99%|#########9| 7161/7204 [27:01<00:09,  4.60it/s]
2022-03-22 03:16:39,254 - INFO - tqdm - f1: 0.8341, accuracy: 0.9238, batch_loss: 0.0498, loss: 0.2031 ||: 100%|#########9| 7168/7204 [27:03<00:08,  4.05it/s]
2022-03-22 03:16:39,659 - INFO - tqdm - f1: 0.8341, accuracy: 0.9238, batch_loss: 0.0085, loss: 0.2031 ||: 100%|#########9| 7169/7204 [27:03<00:10,  3.40it/s]
2022-03-22 03:16:39,855 - INFO - tqdm - f1: 0.8341, accuracy: 0.9238, batch_loss: 0.2944, loss: 0.2031 ||: 100%|#########9| 7170/7204 [27:03<00:09,  3.77it/s]
2022-03-22 03:16:40,295 - INFO - tqdm - f1: 0.8341, accuracy: 0.9238, batch_loss: 0.0871, loss: 0.2031 ||: 100%|#########9| 7171/7204 [27:04<00:10,  3.15it/s]
2022-03-22 03:16:40,443 - INFO - tqdm - f1: 0.8341, accuracy: 0.9238, batch_loss: 0.2150, loss: 0.2031 ||: 100%|#########9| 7172/7204 [27:04<00:08,  3.75it/s]
2022-03-22 03:16:40,652 - INFO - tqdm - f1: 0.8341, accuracy: 0.9238, batch_loss: 0.0171, loss: 0.2030 ||: 100%|#########9| 7173/7204 [27:04<00:07,  4.01it/s]
2022-03-22 03:16:40,852 - INFO - tqdm - f1: 0.8341, accuracy: 0.9238, batch_loss: 0.0512, loss: 0.2030 ||: 100%|#########9| 7174/7204 [27:04<00:07,  4.26it/s]
2022-03-22 03:16:40,988 - INFO - tqdm - f1: 0.8341, accuracy: 0.9238, batch_loss: 0.4214, loss: 0.2030 ||: 100%|#########9| 7175/7204 [27:04<00:05,  4.88it/s]
2022-03-22 03:16:41,245 - INFO - tqdm - f1: 0.8341, accuracy: 0.9238, batch_loss: 0.0745, loss: 0.2030 ||: 100%|#########9| 7176/7204 [27:05<00:06,  4.53it/s]
2022-03-22 03:16:41,399 - INFO - tqdm - f1: 0.8341, accuracy: 0.9238, batch_loss: 0.5544, loss: 0.2031 ||: 100%|#########9| 7177/7204 [27:05<00:05,  4.98it/s]
2022-03-22 03:16:41,606 - INFO - tqdm - f1: 0.8341, accuracy: 0.9238, batch_loss: 0.3721, loss: 0.2031 ||: 100%|#########9| 7178/7204 [27:05<00:05,  4.94it/s]
2022-03-22 03:16:41,753 - INFO - tqdm - f1: 0.8341, accuracy: 0.9238, batch_loss: 0.5831, loss: 0.2032 ||: 100%|#########9| 7179/7204 [27:05<00:04,  5.38it/s]
2022-03-22 03:16:41,953 - INFO - tqdm - f1: 0.8341, accuracy: 0.9237, batch_loss: 0.6428, loss: 0.2032 ||: 100%|#########9| 7180/7204 [27:05<00:04,  5.25it/s]
2022-03-22 03:16:42,176 - INFO - tqdm - f1: 0.8341, accuracy: 0.9237, batch_loss: 0.3837, loss: 0.2032 ||: 100%|#########9| 7181/7204 [27:06<00:04,  5.00it/s]
2022-03-22 03:16:42,337 - INFO - tqdm - f1: 0.8341, accuracy: 0.9237, batch_loss: 0.0397, loss: 0.2032 ||: 100%|#########9| 7182/7204 [27:06<00:04,  5.31it/s]
2022-03-22 03:16:42,544 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.1671, loss: 0.2032 ||: 100%|#########9| 7183/7204 [27:06<00:04,  5.16it/s]
2022-03-22 03:16:42,702 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.3386, loss: 0.2032 ||: 100%|#########9| 7184/7204 [27:06<00:03,  5.46it/s]
2022-03-22 03:16:42,874 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.1972, loss: 0.2032 ||: 100%|#########9| 7185/7204 [27:06<00:03,  5.56it/s]
2022-03-22 03:16:42,975 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.0682, loss: 0.2032 ||: 100%|#########9| 7186/7204 [27:06<00:02,  6.40it/s]
2022-03-22 03:16:43,336 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.0549, loss: 0.2032 ||: 100%|#########9| 7187/7204 [27:07<00:03,  4.60it/s]
2022-03-22 03:16:43,563 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.0547, loss: 0.2032 ||: 100%|#########9| 7188/7204 [27:07<00:03,  4.54it/s]
2022-03-22 03:16:43,705 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.1586, loss: 0.2032 ||: 100%|#########9| 7189/7204 [27:07<00:02,  5.08it/s]
2022-03-22 03:16:43,874 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.3632, loss: 0.2032 ||: 100%|#########9| 7190/7204 [27:07<00:02,  5.30it/s]
2022-03-22 03:16:44,124 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.1083, loss: 0.2032 ||: 100%|#########9| 7191/7204 [27:08<00:02,  4.83it/s]
2022-03-22 03:16:44,274 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.1815, loss: 0.2032 ||: 100%|#########9| 7192/7204 [27:08<00:02,  5.27it/s]
2022-03-22 03:16:44,519 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.5257, loss: 0.2032 ||: 100%|#########9| 7193/7204 [27:08<00:02,  4.84it/s]
2022-03-22 03:16:44,924 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.0202, loss: 0.2032 ||: 100%|#########9| 7194/7204 [27:08<00:02,  3.76it/s]
2022-03-22 03:16:45,039 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.2515, loss: 0.2032 ||: 100%|#########9| 7195/7204 [27:08<00:01,  4.53it/s]
2022-03-22 03:16:45,246 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.2063, loss: 0.2032 ||: 100%|#########9| 7196/7204 [27:09<00:01,  4.62it/s]
2022-03-22 03:16:45,463 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.1309, loss: 0.2032 ||: 100%|#########9| 7197/7204 [27:09<00:01,  4.61it/s]
2022-03-22 03:16:45,659 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.0369, loss: 0.2032 ||: 100%|#########9| 7198/7204 [27:09<00:01,  4.75it/s]
2022-03-22 03:16:45,882 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.1017, loss: 0.2031 ||: 100%|#########9| 7199/7204 [27:09<00:01,  4.67it/s]
2022-03-22 03:16:46,163 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.1045, loss: 0.2031 ||: 100%|#########9| 7200/7204 [27:10<00:00,  4.27it/s]
2022-03-22 03:16:46,510 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.0129, loss: 0.2031 ||: 100%|#########9| 7201/7204 [27:10<00:00,  3.73it/s]
2022-03-22 03:16:46,708 - INFO - tqdm - f1: 0.8339, accuracy: 0.9237, batch_loss: 0.2759, loss: 0.2031 ||: 100%|#########9| 7202/7204 [27:10<00:00,  4.05it/s]
2022-03-22 03:16:46,879 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.1464, loss: 0.2031 ||: 100%|#########9| 7203/7204 [27:10<00:00,  4.46it/s]
2022-03-22 03:16:46,989 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.0759, loss: 0.2031 ||: 100%|##########| 7204/7204 [27:10<00:00,  5.26it/s]
2022-03-22 03:16:47,040 - INFO - tqdm - f1: 0.8340, accuracy: 0.9237, batch_loss: 0.0759, loss: 0.2031 ||: 100%|##########| 7204/7204 [27:10<00:00,  4.42it/s]
2022-03-22 03:16:47,077 - INFO - allennlp.training.trainer - Validating
2022-03-22 03:16:47,077 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-22 03:16:57,116 - INFO - tqdm - f1: 0.6312, accuracy: 0.8558, batch_loss: 0.5048, loss: 0.4141 ||:  30%|###       | 95/313 [00:10<00:22,  9.71it/s]
2022-03-22 03:17:07,201 - INFO - tqdm - f1: 0.6432, accuracy: 0.8637, batch_loss: 0.3460, loss: 0.3927 ||:  60%|######    | 189/313 [00:20<00:13,  9.05it/s]
2022-03-22 03:17:17,212 - INFO - tqdm - f1: 0.6492, accuracy: 0.8659, batch_loss: 0.3437, loss: 0.3813 ||:  90%|######### | 282/313 [00:30<00:03,  8.64it/s]
2022-03-22 03:17:20,437 - INFO - tqdm - f1: 0.6506, accuracy: 0.8670, batch_loss: 0.3237, loss: 0.3800 ||: 100%|##########| 313/313 [00:33<00:00,  8.47it/s]
2022-03-22 03:17:20,439 - INFO - tqdm - f1: 0.6506, accuracy: 0.8670, batch_loss: 0.3237, loss: 0.3800 ||: 100%|##########| 313/313 [00:33<00:00,  9.38it/s]
2022-03-22 03:17:20,446 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-22 03:17:20,446 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-22 03:17:22,191 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-22 03:17:22,192 - INFO - allennlp.training.util - Iterating over dataset
2022-03-22 03:17:22,193 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-22 03:17:22,223 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-22 03:17:22,223 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-22 03:17:32,421 - INFO - tqdm - f1: 0.67, accuracy: 0.88, loss: 0.31 ||: : 93it [00:10, 10.25it/s]
2022-03-22 03:17:42,621 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.32 ||: : 193it [00:20,  9.55it/s]
2022-03-22 03:17:52,664 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.31 ||: : 289it [00:30,  8.19it/s]
2022-03-22 03:18:02,684 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.31 ||: : 382it [00:40,  8.20it/s]
2022-03-22 03:18:12,798 - INFO - tqdm - f1: 0.67, accuracy: 0.87, loss: 0.31 ||: : 478it [00:50, 11.15it/s]
2022-03-22 03:18:23,026 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.31 ||: : 573it [01:00,  9.85it/s]
2022-03-22 03:18:33,056 - INFO - tqdm - f1: 0.68, accuracy: 0.88, loss: 0.30 ||: : 667it [01:10,  9.97it/s]
2022-03-22 03:18:43,112 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.30 ||: : 756it [01:20,  7.62it/s]
2022-03-22 03:18:53,223 - INFO - tqdm - f1: 0.69, accuracy: 0.87, loss: 0.31 ||: : 852it [01:31, 10.69it/s]
2022-03-22 03:19:03,244 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.31 ||: : 960it [01:41,  9.66it/s]
2022-03-22 03:19:13,327 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.31 ||: : 1051it [01:51,  8.21it/s]
2022-03-22 03:19:23,533 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.31 ||: : 1146it [02:01,  9.38it/s]
2022-03-22 03:19:33,603 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.31 ||: : 1242it [02:11,  9.39it/s]
2022-03-22 03:19:43,690 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.31 ||: : 1342it [02:21,  9.65it/s]
2022-03-22 03:19:53,887 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.31 ||: : 1444it [02:31,  9.43it/s]
2022-03-22 03:20:03,995 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.31 ||: : 1535it [02:41,  9.32it/s]
2022-03-22 03:20:06,840 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 1,
  "peak_worker_0_memory_MB": 13613.06640625,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "1:54:44.156583",
  "training_start_epoch": 0,
  "training_epochs": 3,
  "epoch": 3,
  "training_f1": 0.7910768687725067,
  "training_accuracy": 0.9071938638276458,
  "training_loss": 0.2358265044366727,
  "training_worker_0_memory_MB": 13613.06640625,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.6740097254514694,
  "validation_accuracy": 0.869,
  "validation_loss": 0.3476174175471496,
  "best_validation_f1": 0.6792206019163132,
  "best_validation_accuracy": 0.8704,
  "best_validation_loss": 0.31591935684464084,
  "test_f1": 0.6800551861524582,
  "test_accuracy": 0.87248,
  "test_loss": 0.31104375710484455
}
2022-03-22 03:20:07,507 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/amazon_base_hyper_small_seed_97/model.tar.gz
