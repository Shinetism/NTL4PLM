2022-03-21 04:13:55,382 - INFO - allennlp.common.params - random_seed = 177
2022-03-21 04:13:55,384 - INFO - allennlp.common.params - numpy_seed = 177
2022-03-21 04:13:55,388 - INFO - allennlp.common.params - pytorch_seed = 177
2022-03-21 04:13:55,395 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-21 04:13:55,397 - INFO - allennlp.common.params - type = default
2022-03-21 04:13:55,399 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-21 04:13:55,401 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 04:13:55,403 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 04:13:55,404 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 04:13:55,405 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 04:13:55,406 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 04:13:55,408 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 04:14:08,114 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 04:14:08,120 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 04:14:08,122 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 04:14:08,123 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-21 04:14:08,124 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-21 04:14:08,126 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 04:14:08,128 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-21 04:14:08,129 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-21 04:14:08,130 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-21 04:14:08,132 - INFO - allennlp.common.params - train_data_path = datasets/rct-20k/train.jsonl
2022-03-21 04:14:08,134 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f810109d290>
2022-03-21 04:14:08,135 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-21 04:14:08,137 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-21 04:14:08,139 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 04:14:08,140 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 04:14:08,141 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 04:14:08,143 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 04:14:08,144 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 04:14:08,148 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 04:14:08,150 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 04:14:08,152 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 04:14:08,153 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 04:14:08,155 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-21 04:14:08,156 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-21 04:14:08,157 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 04:14:08,159 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-21 04:14:08,161 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-21 04:14:08,162 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-21 04:14:08,164 - INFO - allennlp.common.params - validation_data_path = datasets/rct-20k/dev.jsonl
2022-03-21 04:14:08,165 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-21 04:14:08,166 - INFO - allennlp.common.params - test_data_path = datasets/rct-20k/test.jsonl
2022-03-21 04:14:08,167 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-21 04:14:08,169 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-21 04:14:08,170 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 04:14:08,172 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 04:14:08,173 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 04:14:08,174 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 04:14:08,176 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 04:14:08,177 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 04:14:08,178 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 04:14:08,180 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 04:14:08,181 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 04:14:08,182 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 04:14:08,184 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 04:14:08,185 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 04:14:08,187 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 04:14:08,188 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 04:14:08,190 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 04:14:18,286 - INFO - tqdm - loading instances: 36635it [00:10, 4315.94it/s]
2022-03-21 04:14:28,299 - INFO - tqdm - loading instances: 72778it [00:20, 4282.29it/s]
2022-03-21 04:14:38,398 - INFO - tqdm - loading instances: 108269it [00:30, 4148.24it/s]
2022-03-21 04:14:48,472 - INFO - tqdm - loading instances: 145988it [00:40, 4308.76it/s]
2022-03-21 04:14:58,286 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 04:14:58,296 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 04:14:58,298 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 04:14:58,299 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 04:14:58,300 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 04:14:58,302 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 04:14:58,303 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 04:14:58,304 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 04:14:58,305 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 04:14:58,307 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 04:14:58,308 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 04:14:58,309 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 04:14:58,310 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 04:14:58,311 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 04:14:58,313 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 04:15:07,991 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 04:15:07,997 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 04:15:07,998 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 04:15:08,000 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 04:15:08,002 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 04:15:08,003 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 04:15:08,005 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 04:15:08,006 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 04:15:08,007 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 04:15:08,008 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 04:15:08,010 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 04:15:08,011 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 04:15:08,012 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 04:15:08,016 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 04:15:08,017 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 04:15:15,121 - INFO - allennlp.common.params - type = from_instances
2022-03-21 04:15:15,123 - INFO - allennlp.common.params - min_count = None
2022-03-21 04:15:15,124 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-21 04:15:15,126 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-21 04:15:15,127 - INFO - allennlp.common.params - pretrained_files = None
2022-03-21 04:15:15,128 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-21 04:15:15,130 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-21 04:15:15,131 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-21 04:15:15,132 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-21 04:15:15,135 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-21 04:15:15,136 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-21 04:15:15,137 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-21 04:15:16,491 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-21 04:15:16,493 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-21 04:15:16,495 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-21 04:15:16,497 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-21 04:15:16,498 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-21 04:15:16,499 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-21 04:15:16,501 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-21 04:15:16,502 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-21 04:15:16,503 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-21 04:15:16,504 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-21 04:15:16,506 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-21 04:15:16,507 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-21 04:15:16,508 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-21 04:15:22,839 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-21 04:15:22,847 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-21 04:15:22,849 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-21 04:15:22,852 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-21 04:15:22,853 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-21 04:15:22,855 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-21 04:15:22,856 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-21 04:15:22,858 - INFO - allennlp.common.params - type = tanh
2022-03-21 04:15:22,859 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-21 04:15:22,867 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-21 04:15:22,868 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-21 04:15:22,873 - INFO - allennlp.common.params - model.num_labels = None
2022-03-21 04:15:22,875 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-21 04:15:22,877 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f81010b2050>
2022-03-21 04:15:22,878 - INFO - allennlp.common.params - model.regularizer = None
2022-03-21 04:15:22,879 - INFO - allennlp.common.params - model.track_weights = False
2022-03-21 04:15:22,880 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-21 04:15:22,882 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-21 04:15:22,885 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-21 04:15:22,886 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-21 04:15:22,887 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-21 04:15:22,888 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-21 04:15:22,889 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-21 04:15:22,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 04:15:22,891 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 04:15:22,892 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 04:15:22,893 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 04:15:22,894 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 04:15:22,895 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 04:15:22,896 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 04:15:22,898 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 04:15:22,899 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 04:15:22,900 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 04:15:22,901 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 04:15:22,902 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 04:15:22,903 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 04:15:22,907 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 04:15:22,909 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 04:15:22,910 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 04:15:22,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 04:15:22,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 04:15:22,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 04:15:22,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 04:15:22,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 04:15:22,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 04:15:22,918 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 04:15:22,919 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 04:15:22,920 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 04:15:22,922 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 04:15:22,923 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 04:15:22,924 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 04:15:22,925 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 04:15:22,927 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 04:15:22,928 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 04:15:22,929 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 04:15:22,930 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 04:15:22,931 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 04:15:22,933 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 04:15:22,934 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 04:15:22,935 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 04:15:22,936 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 04:15:22,938 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 04:15:22,940 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 04:15:22,941 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 04:15:22,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 04:15:22,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 04:15:22,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 04:15:22,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 04:15:22,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 04:15:22,948 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 04:15:22,949 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 04:15:22,950 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 04:15:22,951 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 04:15:22,952 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 04:15:22,953 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 04:15:22,954 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 04:15:22,955 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 04:15:22,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 04:15:22,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 04:15:22,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 04:15:22,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 04:15:22,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 04:15:22,962 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 04:15:22,963 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 04:15:22,965 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 04:15:22,967 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 04:15:22,972 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 04:15:22,974 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 04:15:22,975 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 04:15:22,976 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 04:15:22,977 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 04:15:22,978 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 04:15:22,979 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 04:15:22,980 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 04:15:22,981 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 04:15:22,983 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 04:15:22,984 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 04:15:22,985 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 04:15:22,986 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 04:15:22,987 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 04:15:22,988 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 04:15:22,989 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 04:15:22,990 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 04:15:22,991 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 04:15:22,993 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 04:15:22,994 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 04:15:22,995 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 04:15:22,996 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 04:15:22,997 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 04:15:22,998 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 04:15:23,000 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 04:15:23,003 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 04:15:23,004 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 04:15:23,005 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 04:15:23,007 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 04:15:23,008 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 04:15:23,009 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 04:15:23,010 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 04:15:23,011 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 04:15:23,013 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 04:15:23,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 04:15:23,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 04:15:23,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 04:15:23,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 04:15:23,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 04:15:23,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 04:15:23,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 04:15:23,023 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 04:15:23,024 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 04:15:23,025 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 04:15:23,026 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 04:15:23,028 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 04:15:23,029 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 04:15:23,030 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 04:15:23,032 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 04:15:23,033 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 04:15:23,035 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 04:15:23,036 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 04:15:23,037 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 04:15:23,038 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 04:15:23,041 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 04:15:23,043 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 04:15:23,044 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 04:15:23,045 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 04:15:23,046 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 04:15:23,047 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 04:15:23,049 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 04:15:23,050 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 04:15:23,051 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 04:15:23,052 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 04:15:23,054 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 04:15:23,055 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 04:15:23,056 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 04:15:23,057 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 04:15:23,058 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 04:15:23,060 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 04:15:23,061 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 04:15:23,062 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 04:15:23,063 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 04:15:23,065 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 04:15:23,067 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 04:15:23,068 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 04:15:23,073 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 04:15:23,075 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 04:15:23,076 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 04:15:23,077 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 04:15:23,078 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 04:15:23,080 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 04:15:23,081 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 04:15:23,082 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 04:15:23,083 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 04:15:23,085 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 04:15:23,086 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 04:15:23,087 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 04:15:23,089 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 04:15:23,090 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 04:15:23,091 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 04:15:23,092 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 04:15:23,093 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 04:15:23,095 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 04:15:23,096 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 04:15:23,097 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 04:15:23,098 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 04:15:23,099 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 04:15:23,103 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 04:15:23,104 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 04:15:23,108 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 04:15:23,109 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 04:15:23,110 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 04:15:23,111 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 04:15:23,113 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 04:15:23,114 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 04:15:23,115 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 04:15:23,116 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 04:15:23,117 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 04:15:23,118 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 04:15:23,119 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 04:15:23,121 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 04:15:23,122 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 04:15:23,123 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 04:15:23,124 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 04:15:23,125 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 04:15:23,126 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 04:15:23,128 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 04:15:23,129 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 04:15:23,130 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 04:15:23,131 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 04:15:23,132 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 04:15:23,133 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 04:15:23,135 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 04:15:23,136 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 04:15:23,137 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 04:15:23,139 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 04:15:23,140 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 04:15:23,141 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 04:15:23,142 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 04:15:23,143 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 04:15:23,144 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 04:15:23,146 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 04:15:23,147 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 04:15:23,148 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 04:15:23,149 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 04:15:32,739 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-21 04:15:32,742 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-21 04:15:32,743 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-21 04:15:32,745 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-21 04:15:32,746 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-21 04:15:32,747 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-21 04:15:32,748 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-21 04:15:32,754 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-21 04:15:32,756 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-21 04:15:32,757 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-21 04:15:32,758 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-21 04:15:32,760 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-21 04:15:32,761 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-21 04:15:32,763 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-21 04:15:32,764 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-21 04:15:32,765 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-21 04:15:32,767 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-21 04:15:38,113 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-21 04:15:38,119 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-21 04:15:38,120 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-21 04:15:38,122 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-21 04:15:38,124 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-21 04:15:38,125 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-21 04:15:38,128 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-21 04:15:38,129 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight'], {'weight_decay': 0}
2022-03-21 04:15:38,132 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight'], {}
2022-03-21 04:15:38,134 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-21 04:15:38,135 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125240069
2022-03-21 04:15:38,137 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-21 04:15:38,139 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-21 04:15:38,141 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 04:15:38,142 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 04:15:38,143 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 04:15:38,144 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 04:15:38,146 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 04:15:38,147 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 04:15:38,148 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 04:15:38,149 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 04:15:38,155 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 04:15:38,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 04:15:38,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 04:15:38,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 04:15:38,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 04:15:38,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 04:15:38,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 04:15:38,164 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 04:15:38,166 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 04:15:38,167 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 04:15:38,168 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 04:15:38,169 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 04:15:38,171 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 04:15:38,172 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 04:15:38,173 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 04:15:38,174 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 04:15:38,175 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 04:15:38,177 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 04:15:38,178 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 04:15:38,179 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 04:15:38,180 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 04:15:38,181 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 04:15:38,183 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 04:15:38,185 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 04:15:38,187 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 04:15:38,190 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 04:15:38,191 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 04:15:38,192 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 04:15:38,194 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 04:15:38,195 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 04:15:38,196 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 04:15:38,197 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 04:15:38,198 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 04:15:38,200 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 04:15:38,201 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 04:15:38,203 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 04:15:38,204 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 04:15:38,207 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 04:15:38,209 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 04:15:38,210 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 04:15:38,211 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 04:15:38,212 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 04:15:38,213 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 04:15:38,214 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 04:15:38,215 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 04:15:38,216 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 04:15:38,217 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 04:15:38,218 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 04:15:38,219 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 04:15:38,221 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 04:15:38,222 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 04:15:38,223 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 04:15:38,224 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 04:15:38,225 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 04:15:38,226 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 04:15:38,227 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 04:15:38,228 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 04:15:38,230 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 04:15:38,231 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 04:15:38,232 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 04:15:38,233 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 04:15:38,235 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 04:15:38,236 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 04:15:38,237 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 04:15:38,238 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 04:15:38,239 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 04:15:38,240 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 04:15:38,241 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 04:15:38,242 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 04:15:38,243 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 04:15:38,244 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 04:15:38,245 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 04:15:38,246 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 04:15:38,248 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 04:15:38,253 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 04:15:38,255 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 04:15:38,256 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 04:15:38,257 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 04:15:38,258 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 04:15:38,259 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 04:15:38,260 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 04:15:38,262 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 04:15:38,263 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 04:15:38,264 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 04:15:38,265 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 04:15:38,268 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 04:15:38,269 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 04:15:38,270 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 04:15:38,271 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 04:15:38,272 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 04:15:38,274 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 04:15:38,275 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 04:15:38,276 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 04:15:38,277 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 04:15:38,278 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 04:15:38,280 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 04:15:38,281 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 04:15:38,282 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 04:15:38,283 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 04:15:38,287 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 04:15:38,288 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 04:15:38,289 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 04:15:38,290 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 04:15:38,291 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 04:15:38,293 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 04:15:38,294 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 04:15:38,295 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 04:15:38,296 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 04:15:38,297 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 04:15:38,299 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 04:15:38,300 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 04:15:38,302 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 04:15:38,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 04:15:38,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 04:15:38,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 04:15:38,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 04:15:38,308 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 04:15:38,309 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 04:15:38,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 04:15:38,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 04:15:38,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 04:15:38,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 04:15:38,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 04:15:38,318 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 04:15:38,319 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 04:15:38,321 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 04:15:38,322 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 04:15:38,323 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 04:15:38,325 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 04:15:38,326 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 04:15:38,327 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 04:15:38,328 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 04:15:38,330 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 04:15:38,331 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 04:15:38,332 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 04:15:38,333 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 04:15:38,335 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 04:15:38,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 04:15:38,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 04:15:38,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 04:15:38,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 04:15:38,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 04:15:38,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 04:15:38,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 04:15:38,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 04:15:38,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 04:15:38,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 04:15:38,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 04:15:38,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 04:15:38,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 04:15:38,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 04:15:38,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 04:15:38,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 04:15:38,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 04:15:38,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 04:15:38,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 04:15:38,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 04:15:38,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 04:15:38,365 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 04:15:38,366 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 04:15:38,367 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 04:15:38,368 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 04:15:38,369 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 04:15:38,371 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 04:15:38,372 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 04:15:38,374 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 04:15:38,375 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 04:15:38,376 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 04:15:38,377 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 04:15:38,379 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 04:15:38,380 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 04:15:38,381 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 04:15:38,382 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 04:15:38,385 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 04:15:38,386 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 04:15:38,388 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 04:15:38,389 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 04:15:38,390 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 04:15:38,391 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 04:15:38,392 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 04:15:38,394 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 04:15:38,395 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 04:15:38,396 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 04:15:38,397 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 04:15:38,398 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 04:15:38,400 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 04:15:38,401 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 04:15:38,402 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 04:15:38,404 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 04:15:38,405 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 04:15:38,406 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 04:15:38,407 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-21 04:15:38,408 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-21 04:15:38,409 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-21 04:15:38,410 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-21 04:15:38,412 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-21 04:15:38,413 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-21 04:15:38,414 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-21 04:15:38,415 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-21 04:15:38,417 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-21 04:15:38,418 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-21 04:15:38,423 - INFO - allennlp.training.trainer - Beginning training.
2022-03-21 04:15:38,424 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-21 04:15:38,425 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.3G
2022-03-21 04:15:38,426 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 04:15:38,428 - INFO - allennlp.training.trainer - Training
2022-03-21 04:15:38,430 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 04:15:38,615 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 04:15:38,617 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 04:15:48,502 - INFO - tqdm - f1: 0.3778, accuracy: 0.5386, batch_loss: 0.6089, loss: 1.1653 ||:   1%|          | 68/11253 [00:10<31:00,  6.01it/s]
2022-03-21 04:15:58,616 - INFO - tqdm - f1: 0.5522, accuracy: 0.6639, batch_loss: 0.5977, loss: 0.8681 ||:   1%|1         | 159/11253 [00:20<22:26,  8.24it/s]
2022-03-21 04:16:08,752 - INFO - tqdm - f1: 0.6204, accuracy: 0.7092, batch_loss: 1.1110, loss: 0.7644 ||:   2%|2         | 253/11253 [00:30<19:24,  9.45it/s]
2022-03-21 04:16:18,801 - INFO - tqdm - f1: 0.6501, accuracy: 0.7365, batch_loss: 0.4990, loss: 0.7015 ||:   3%|2         | 337/11253 [00:40<22:12,  8.19it/s]
2022-03-21 04:16:28,870 - INFO - tqdm - f1: 0.6696, accuracy: 0.7522, batch_loss: 0.4184, loss: 0.6657 ||:   4%|3         | 428/11253 [00:50<18:08,  9.95it/s]
2022-03-21 04:16:38,919 - INFO - tqdm - f1: 0.6879, accuracy: 0.7642, batch_loss: 0.6965, loss: 0.6388 ||:   5%|4         | 512/11253 [01:00<21:09,  8.46it/s]
2022-03-21 04:16:48,954 - INFO - tqdm - f1: 0.6990, accuracy: 0.7727, batch_loss: 0.3823, loss: 0.6160 ||:   5%|5         | 601/11253 [01:10<19:57,  8.90it/s]
2022-03-21 04:16:59,031 - INFO - tqdm - f1: 0.7081, accuracy: 0.7808, batch_loss: 0.1155, loss: 0.5963 ||:   6%|6         | 687/11253 [01:20<21:50,  8.06it/s]
2022-03-21 04:17:09,066 - INFO - tqdm - f1: 0.7132, accuracy: 0.7869, batch_loss: 0.3845, loss: 0.5795 ||:   7%|6         | 777/11253 [01:30<18:37,  9.37it/s]
2022-03-21 04:17:19,067 - INFO - tqdm - f1: 0.7179, accuracy: 0.7909, batch_loss: 0.5374, loss: 0.5685 ||:   8%|7         | 861/11253 [01:40<19:50,  8.73it/s]
2022-03-21 04:17:29,186 - INFO - tqdm - f1: 0.7251, accuracy: 0.7958, batch_loss: 0.5594, loss: 0.5588 ||:   8%|8         | 951/11253 [01:50<19:05,  8.99it/s]
2022-03-21 04:17:39,295 - INFO - tqdm - f1: 0.7297, accuracy: 0.7994, batch_loss: 0.8657, loss: 0.5486 ||:   9%|9         | 1037/11253 [02:00<19:29,  8.74it/s]
2022-03-21 04:17:49,353 - INFO - tqdm - f1: 0.7334, accuracy: 0.8026, batch_loss: 0.3682, loss: 0.5400 ||:  10%|#         | 1126/11253 [02:10<18:04,  9.34it/s]
2022-03-21 04:17:59,382 - INFO - tqdm - f1: 0.7368, accuracy: 0.8052, batch_loss: 0.3731, loss: 0.5340 ||:  11%|#         | 1211/11253 [02:20<19:01,  8.79it/s]
2022-03-21 04:18:09,397 - INFO - tqdm - f1: 0.7410, accuracy: 0.8087, batch_loss: 0.4917, loss: 0.5264 ||:  12%|#1        | 1297/11253 [02:30<20:56,  7.93it/s]
2022-03-21 04:18:19,414 - INFO - tqdm - f1: 0.7444, accuracy: 0.8116, batch_loss: 0.6932, loss: 0.5201 ||:  12%|#2        | 1383/11253 [02:40<26:32,  6.20it/s]
2022-03-21 04:18:29,444 - INFO - tqdm - f1: 0.7454, accuracy: 0.8129, batch_loss: 0.6140, loss: 0.5163 ||:  13%|#3        | 1471/11253 [02:51<17:06,  9.53it/s]
2022-03-21 04:18:39,544 - INFO - tqdm - f1: 0.7473, accuracy: 0.8146, batch_loss: 0.6180, loss: 0.5120 ||:  14%|#3        | 1558/11253 [03:01<18:08,  8.91it/s]
2022-03-21 04:18:49,576 - INFO - tqdm - f1: 0.7497, accuracy: 0.8163, batch_loss: 0.4027, loss: 0.5079 ||:  15%|#4        | 1642/11253 [03:11<16:54,  9.48it/s]
2022-03-21 04:18:59,706 - INFO - tqdm - f1: 0.7523, accuracy: 0.8186, batch_loss: 0.3668, loss: 0.5024 ||:  15%|#5        | 1732/11253 [03:21<21:14,  7.47it/s]
2022-03-21 04:19:09,752 - INFO - tqdm - f1: 0.7535, accuracy: 0.8194, batch_loss: 0.7912, loss: 0.4999 ||:  16%|#6        | 1817/11253 [03:31<17:10,  9.16it/s]
2022-03-21 04:19:19,815 - INFO - tqdm - f1: 0.7568, accuracy: 0.8215, batch_loss: 0.4828, loss: 0.4948 ||:  17%|#6        | 1906/11253 [03:41<18:29,  8.43it/s]
2022-03-21 04:19:29,817 - INFO - tqdm - f1: 0.7577, accuracy: 0.8222, batch_loss: 0.4767, loss: 0.4921 ||:  18%|#7        | 1993/11253 [03:51<15:10, 10.17it/s]
2022-03-21 04:19:39,860 - INFO - tqdm - f1: 0.7584, accuracy: 0.8235, batch_loss: 0.8384, loss: 0.4881 ||:  18%|#8        | 2081/11253 [04:01<16:21,  9.35it/s]
2022-03-21 04:19:50,062 - INFO - tqdm - f1: 0.7595, accuracy: 0.8242, batch_loss: 0.2565, loss: 0.4859 ||:  19%|#9        | 2170/11253 [04:11<16:50,  8.99it/s]
2022-03-21 04:20:00,098 - INFO - tqdm - f1: 0.7610, accuracy: 0.8255, batch_loss: 0.2949, loss: 0.4832 ||:  20%|##        | 2257/11253 [04:21<18:31,  8.10it/s]
2022-03-21 04:20:10,173 - INFO - tqdm - f1: 0.7611, accuracy: 0.8256, batch_loss: 0.2343, loss: 0.4821 ||:  21%|##        | 2339/11253 [04:31<16:56,  8.77it/s]
2022-03-21 04:20:20,210 - INFO - tqdm - f1: 0.7628, accuracy: 0.8272, batch_loss: 0.1442, loss: 0.4776 ||:  22%|##1       | 2427/11253 [04:41<17:06,  8.60it/s]
2022-03-21 04:20:30,282 - INFO - tqdm - f1: 0.7637, accuracy: 0.8281, batch_loss: 0.1087, loss: 0.4749 ||:  22%|##2       | 2511/11253 [04:51<27:27,  5.30it/s]
2022-03-21 04:20:40,318 - INFO - tqdm - f1: 0.7644, accuracy: 0.8288, batch_loss: 0.1077, loss: 0.4725 ||:  23%|##3       | 2599/11253 [05:01<16:49,  8.57it/s]
2022-03-21 04:20:50,327 - INFO - tqdm - f1: 0.7652, accuracy: 0.8293, batch_loss: 0.4440, loss: 0.4714 ||:  24%|##3       | 2687/11253 [05:11<16:43,  8.53it/s]
2022-03-21 04:21:00,393 - INFO - tqdm - f1: 0.7655, accuracy: 0.8299, batch_loss: 0.4465, loss: 0.4700 ||:  25%|##4       | 2774/11253 [05:21<15:15,  9.26it/s]
2022-03-21 04:21:10,468 - INFO - tqdm - f1: 0.7668, accuracy: 0.8306, batch_loss: 0.2913, loss: 0.4678 ||:  25%|##5       | 2865/11253 [05:32<14:52,  9.40it/s]
2022-03-21 04:21:20,531 - INFO - tqdm - f1: 0.7675, accuracy: 0.8313, batch_loss: 0.1123, loss: 0.4659 ||:  26%|##6       | 2948/11253 [05:42<17:44,  7.80it/s]
2022-03-21 04:21:30,710 - INFO - tqdm - f1: 0.7687, accuracy: 0.8321, batch_loss: 0.3260, loss: 0.4641 ||:  27%|##6       | 3036/11253 [05:52<15:02,  9.10it/s]
2022-03-21 04:21:40,741 - INFO - tqdm - f1: 0.7697, accuracy: 0.8331, batch_loss: 0.4612, loss: 0.4609 ||:  28%|##7       | 3122/11253 [06:02<16:33,  8.18it/s]
2022-03-21 04:21:50,819 - INFO - tqdm - f1: 0.7701, accuracy: 0.8338, batch_loss: 0.1632, loss: 0.4596 ||:  29%|##8       | 3208/11253 [06:12<18:30,  7.24it/s]
2022-03-21 04:22:00,901 - INFO - tqdm - f1: 0.7708, accuracy: 0.8343, batch_loss: 0.3297, loss: 0.4577 ||:  29%|##9       | 3290/11253 [06:22<15:26,  8.60it/s]
2022-03-21 04:22:10,987 - INFO - tqdm - f1: 0.7717, accuracy: 0.8350, batch_loss: 0.8375, loss: 0.4555 ||:  30%|###       | 3380/11253 [06:32<14:20,  9.15it/s]
2022-03-21 04:22:21,069 - INFO - tqdm - f1: 0.7729, accuracy: 0.8360, batch_loss: 0.4554, loss: 0.4535 ||:  31%|###       | 3466/11253 [06:42<15:19,  8.47it/s]
2022-03-21 04:22:31,098 - INFO - tqdm - f1: 0.7739, accuracy: 0.8365, batch_loss: 0.9833, loss: 0.4524 ||:  32%|###1      | 3553/11253 [06:52<15:15,  8.41it/s]
2022-03-21 04:22:41,196 - INFO - tqdm - f1: 0.7752, accuracy: 0.8374, batch_loss: 0.1214, loss: 0.4511 ||:  32%|###2      | 3642/11253 [07:02<22:32,  5.63it/s]
2022-03-21 04:22:51,235 - INFO - tqdm - f1: 0.7757, accuracy: 0.8375, batch_loss: 0.5188, loss: 0.4506 ||:  33%|###3      | 3732/11253 [07:12<13:32,  9.26it/s]
2022-03-21 04:23:01,320 - INFO - tqdm - f1: 0.7763, accuracy: 0.8380, batch_loss: 0.1402, loss: 0.4490 ||:  34%|###3      | 3818/11253 [07:22<21:25,  5.78it/s]
2022-03-21 04:23:11,328 - INFO - tqdm - f1: 0.7766, accuracy: 0.8386, batch_loss: 0.6299, loss: 0.4479 ||:  35%|###4      | 3905/11253 [07:32<12:40,  9.66it/s]
2022-03-21 04:23:21,424 - INFO - tqdm - f1: 0.7769, accuracy: 0.8389, batch_loss: 0.5323, loss: 0.4467 ||:  35%|###5      | 3992/11253 [07:42<13:42,  8.83it/s]
2022-03-21 04:23:31,504 - INFO - tqdm - f1: 0.7772, accuracy: 0.8394, batch_loss: 0.4570, loss: 0.4453 ||:  36%|###6      | 4078/11253 [07:53<13:29,  8.87it/s]
2022-03-21 04:23:41,586 - INFO - tqdm - f1: 0.7779, accuracy: 0.8401, batch_loss: 0.2335, loss: 0.4436 ||:  37%|###7      | 4169/11253 [08:03<13:34,  8.70it/s]
2022-03-21 04:23:51,653 - INFO - tqdm - f1: 0.7785, accuracy: 0.8406, batch_loss: 0.3732, loss: 0.4425 ||:  38%|###7      | 4256/11253 [08:13<13:53,  8.39it/s]
2022-03-21 04:24:01,679 - INFO - tqdm - f1: 0.7783, accuracy: 0.8408, batch_loss: 0.5364, loss: 0.4420 ||:  39%|###8      | 4347/11253 [08:23<11:50,  9.71it/s]
2022-03-21 04:24:11,725 - INFO - tqdm - f1: 0.7789, accuracy: 0.8412, batch_loss: 0.2830, loss: 0.4410 ||:  39%|###9      | 4434/11253 [08:33<12:48,  8.88it/s]
2022-03-21 04:24:21,818 - INFO - tqdm - f1: 0.7792, accuracy: 0.8415, batch_loss: 0.4350, loss: 0.4401 ||:  40%|####      | 4525/11253 [08:43<11:48,  9.50it/s]
2022-03-21 04:24:31,914 - INFO - tqdm - f1: 0.7790, accuracy: 0.8416, batch_loss: 0.4094, loss: 0.4399 ||:  41%|####      | 4613/11253 [08:53<13:27,  8.22it/s]
2022-03-21 04:24:42,082 - INFO - tqdm - f1: 0.7793, accuracy: 0.8418, batch_loss: 0.2122, loss: 0.4396 ||:  42%|####1     | 4703/11253 [09:03<11:53,  9.18it/s]
2022-03-21 04:24:52,147 - INFO - tqdm - f1: 0.7797, accuracy: 0.8422, batch_loss: 0.4584, loss: 0.4382 ||:  43%|####2     | 4789/11253 [09:13<17:55,  6.01it/s]
2022-03-21 04:25:02,151 - INFO - tqdm - f1: 0.7799, accuracy: 0.8424, batch_loss: 0.4250, loss: 0.4375 ||:  43%|####3     | 4876/11253 [09:23<12:44,  8.34it/s]
2022-03-21 04:25:12,333 - INFO - tqdm - f1: 0.7803, accuracy: 0.8427, batch_loss: 0.7267, loss: 0.4364 ||:  44%|####4     | 4965/11253 [09:33<11:07,  9.43it/s]
2022-03-21 04:25:22,448 - INFO - tqdm - f1: 0.7801, accuracy: 0.8428, batch_loss: 0.3678, loss: 0.4358 ||:  45%|####4     | 5049/11253 [09:44<12:13,  8.45it/s]
2022-03-21 04:25:32,575 - INFO - tqdm - f1: 0.7804, accuracy: 0.8432, batch_loss: 0.5034, loss: 0.4352 ||:  46%|####5     | 5139/11253 [09:54<12:31,  8.14it/s]
2022-03-21 04:25:42,628 - INFO - tqdm - f1: 0.7808, accuracy: 0.8432, batch_loss: 0.2516, loss: 0.4354 ||:  46%|####6     | 5229/11253 [10:04<10:58,  9.15it/s]
2022-03-21 04:25:52,632 - INFO - tqdm - f1: 0.7806, accuracy: 0.8431, batch_loss: 0.1845, loss: 0.4353 ||:  47%|####7     | 5316/11253 [10:14<12:04,  8.20it/s]
2022-03-21 04:26:02,643 - INFO - tqdm - f1: 0.7810, accuracy: 0.8434, batch_loss: 0.4170, loss: 0.4346 ||:  48%|####7     | 5401/11253 [10:24<11:27,  8.52it/s]
2022-03-21 04:26:12,643 - INFO - tqdm - f1: 0.7816, accuracy: 0.8438, batch_loss: 0.3838, loss: 0.4335 ||:  49%|####8     | 5490/11253 [10:34<11:59,  8.01it/s]
2022-03-21 04:26:22,710 - INFO - tqdm - f1: 0.7816, accuracy: 0.8438, batch_loss: 0.3020, loss: 0.4331 ||:  50%|####9     | 5574/11253 [10:44<10:53,  8.69it/s]
2022-03-21 04:26:32,753 - INFO - tqdm - f1: 0.7814, accuracy: 0.8436, batch_loss: 0.3478, loss: 0.4335 ||:  50%|#####     | 5665/11253 [10:54<09:41,  9.61it/s]
2022-03-21 04:26:42,755 - INFO - tqdm - f1: 0.7817, accuracy: 0.8439, batch_loss: 0.0581, loss: 0.4333 ||:  51%|#####1    | 5752/11253 [11:04<09:42,  9.45it/s]
2022-03-21 04:26:52,845 - INFO - tqdm - f1: 0.7821, accuracy: 0.8442, batch_loss: 0.6600, loss: 0.4325 ||:  52%|#####1    | 5843/11253 [11:14<10:24,  8.66it/s]
2022-03-21 04:27:03,093 - INFO - tqdm - f1: 0.7823, accuracy: 0.8445, batch_loss: 0.3604, loss: 0.4319 ||:  53%|#####2    | 5930/11253 [11:24<10:10,  8.72it/s]
2022-03-21 04:27:13,182 - INFO - tqdm - f1: 0.7826, accuracy: 0.8446, batch_loss: 0.2641, loss: 0.4315 ||:  53%|#####3    | 6018/11253 [11:34<11:10,  7.81it/s]
2022-03-21 04:27:23,228 - INFO - tqdm - f1: 0.7831, accuracy: 0.8449, batch_loss: 0.2643, loss: 0.4309 ||:  54%|#####4    | 6109/11253 [11:44<09:11,  9.32it/s]
2022-03-21 04:27:33,401 - INFO - tqdm - f1: 0.7831, accuracy: 0.8451, batch_loss: 0.3977, loss: 0.4302 ||:  55%|#####5    | 6195/11253 [11:54<08:31,  9.89it/s]
2022-03-21 04:27:43,490 - INFO - tqdm - f1: 0.7836, accuracy: 0.8456, batch_loss: 0.5869, loss: 0.4290 ||:  56%|#####5    | 6283/11253 [12:05<09:03,  9.15it/s]
2022-03-21 04:27:53,654 - INFO - tqdm - f1: 0.7837, accuracy: 0.8458, batch_loss: 0.1921, loss: 0.4283 ||:  57%|#####6    | 6369/11253 [12:15<09:22,  8.68it/s]
2022-03-21 04:28:03,729 - INFO - tqdm - f1: 0.7839, accuracy: 0.8460, batch_loss: 0.2264, loss: 0.4279 ||:  57%|#####7    | 6458/11253 [12:25<08:27,  9.44it/s]
2022-03-21 04:28:13,833 - INFO - tqdm - f1: 0.7840, accuracy: 0.8461, batch_loss: 0.5461, loss: 0.4276 ||:  58%|#####8    | 6543/11253 [12:35<09:29,  8.26it/s]
2022-03-21 04:28:23,952 - INFO - tqdm - f1: 0.7843, accuracy: 0.8463, batch_loss: 0.3735, loss: 0.4272 ||:  59%|#####8    | 6635/11253 [12:45<08:10,  9.42it/s]
2022-03-21 04:28:34,035 - INFO - tqdm - f1: 0.7846, accuracy: 0.8467, batch_loss: 0.1276, loss: 0.4266 ||:  60%|#####9    | 6711/11253 [12:55<12:14,  6.18it/s]
2022-03-21 04:28:44,219 - INFO - tqdm - f1: 0.7847, accuracy: 0.8468, batch_loss: 0.3876, loss: 0.4262 ||:  60%|######    | 6804/11253 [13:05<07:31,  9.85it/s]
2022-03-21 04:28:54,367 - INFO - tqdm - f1: 0.7850, accuracy: 0.8469, batch_loss: 0.1870, loss: 0.4259 ||:  61%|######1   | 6890/11253 [13:15<07:08, 10.17it/s]
2022-03-21 04:29:04,392 - INFO - tqdm - f1: 0.7853, accuracy: 0.8470, batch_loss: 0.3453, loss: 0.4253 ||:  62%|######2   | 6981/11253 [13:25<07:43,  9.21it/s]
2022-03-21 04:29:14,427 - INFO - tqdm - f1: 0.7853, accuracy: 0.8471, batch_loss: 0.5150, loss: 0.4248 ||:  63%|######2   | 7067/11253 [13:35<09:25,  7.40it/s]
2022-03-21 04:29:24,522 - INFO - tqdm - f1: 0.7855, accuracy: 0.8472, batch_loss: 0.4681, loss: 0.4247 ||:  64%|######3   | 7159/11253 [13:46<07:24,  9.21it/s]
2022-03-21 04:29:34,579 - INFO - tqdm - f1: 0.7854, accuracy: 0.8472, batch_loss: 0.3914, loss: 0.4245 ||:  64%|######4   | 7244/11253 [13:56<12:26,  5.37it/s]
2022-03-21 04:29:44,702 - INFO - tqdm - f1: 0.7856, accuracy: 0.8474, batch_loss: 0.1571, loss: 0.4236 ||:  65%|######5   | 7364/11253 [14:06<04:02, 16.03it/s]
2022-03-21 04:29:54,707 - INFO - tqdm - f1: 0.7863, accuracy: 0.8479, batch_loss: 0.8408, loss: 0.4224 ||:  67%|######6   | 7504/11253 [14:16<04:46, 13.06it/s]
2022-03-21 04:30:04,764 - INFO - tqdm - f1: 0.7870, accuracy: 0.8482, batch_loss: 0.3184, loss: 0.4218 ||:  68%|######7   | 7636/11253 [14:26<03:57, 15.25it/s]
2022-03-21 04:30:14,863 - INFO - tqdm - f1: 0.7871, accuracy: 0.8484, batch_loss: 0.3416, loss: 0.4219 ||:  69%|######9   | 7774/11253 [14:36<03:49, 15.19it/s]
2022-03-21 04:30:24,938 - INFO - tqdm - f1: 0.7872, accuracy: 0.8484, batch_loss: 0.5992, loss: 0.4217 ||:  70%|#######   | 7924/11253 [14:46<03:48, 14.56it/s]
2022-03-21 04:30:34,986 - INFO - tqdm - f1: 0.7874, accuracy: 0.8487, batch_loss: 0.2359, loss: 0.4210 ||:  72%|#######1  | 8076/11253 [14:56<03:23, 15.60it/s]
2022-03-21 04:30:45,040 - INFO - tqdm - f1: 0.7876, accuracy: 0.8488, batch_loss: 0.5479, loss: 0.4206 ||:  73%|#######3  | 8226/11253 [15:06<03:18, 15.23it/s]
2022-03-21 04:30:55,133 - INFO - tqdm - f1: 0.7881, accuracy: 0.8491, batch_loss: 0.2101, loss: 0.4197 ||:  74%|#######4  | 8380/11253 [15:16<03:09, 15.13it/s]
2022-03-21 04:31:05,229 - INFO - tqdm - f1: 0.7884, accuracy: 0.8493, batch_loss: 0.1580, loss: 0.4191 ||:  76%|#######5  | 8532/11253 [15:26<02:48, 16.15it/s]
2022-03-21 04:31:15,366 - INFO - tqdm - f1: 0.7887, accuracy: 0.8495, batch_loss: 0.4841, loss: 0.4186 ||:  77%|#######7  | 8674/11253 [15:36<02:59, 14.40it/s]
2022-03-21 04:31:25,413 - INFO - tqdm - f1: 0.7887, accuracy: 0.8498, batch_loss: 0.1851, loss: 0.4180 ||:  78%|#######8  | 8822/11253 [15:46<02:42, 14.93it/s]
2022-03-21 04:31:35,560 - INFO - tqdm - f1: 0.7887, accuracy: 0.8498, batch_loss: 0.4080, loss: 0.4177 ||:  80%|#######9  | 8976/11253 [15:57<02:35, 14.62it/s]
2022-03-21 04:31:45,619 - INFO - tqdm - f1: 0.7889, accuracy: 0.8500, batch_loss: 0.9355, loss: 0.4172 ||:  81%|########1 | 9132/11253 [16:07<02:20, 15.10it/s]
2022-03-21 04:31:55,665 - INFO - tqdm - f1: 0.7894, accuracy: 0.8503, batch_loss: 0.2039, loss: 0.4165 ||:  83%|########2 | 9286/11253 [16:17<02:19, 14.13it/s]
2022-03-21 04:32:05,712 - INFO - tqdm - f1: 0.7898, accuracy: 0.8507, batch_loss: 0.7180, loss: 0.4155 ||:  84%|########3 | 9440/11253 [16:27<02:05, 14.50it/s]
2022-03-21 04:32:15,810 - INFO - tqdm - f1: 0.7897, accuracy: 0.8507, batch_loss: 0.3535, loss: 0.4153 ||:  85%|########5 | 9598/11253 [16:37<01:45, 15.62it/s]
2022-03-21 04:32:25,849 - INFO - tqdm - f1: 0.7898, accuracy: 0.8509, batch_loss: 0.3961, loss: 0.4149 ||:  87%|########6 | 9756/11253 [16:47<01:35, 15.61it/s]
2022-03-21 04:32:35,867 - INFO - tqdm - f1: 0.7897, accuracy: 0.8510, batch_loss: 0.3427, loss: 0.4144 ||:  88%|########7 | 9898/11253 [16:57<01:27, 15.57it/s]
2022-03-21 04:32:45,882 - INFO - tqdm - f1: 0.7900, accuracy: 0.8512, batch_loss: 0.4682, loss: 0.4138 ||:  89%|########9 | 10050/11253 [17:07<01:19, 15.15it/s]
2022-03-21 04:32:56,000 - INFO - tqdm - f1: 0.7902, accuracy: 0.8512, batch_loss: 0.2371, loss: 0.4134 ||:  91%|######### | 10206/11253 [17:17<01:07, 15.56it/s]
2022-03-21 04:33:06,095 - INFO - tqdm - f1: 0.7905, accuracy: 0.8515, batch_loss: 0.2200, loss: 0.4127 ||:  92%|#########2| 10362/11253 [17:27<00:55, 16.06it/s]
2022-03-21 04:33:16,136 - INFO - tqdm - f1: 0.7904, accuracy: 0.8515, batch_loss: 0.3328, loss: 0.4125 ||:  93%|#########3| 10518/11253 [17:37<00:47, 15.40it/s]
2022-03-21 04:33:26,201 - INFO - tqdm - f1: 0.7905, accuracy: 0.8517, batch_loss: 0.4730, loss: 0.4121 ||:  95%|#########4| 10674/11253 [17:47<00:36, 15.87it/s]
2022-03-21 04:33:36,273 - INFO - tqdm - f1: 0.7904, accuracy: 0.8518, batch_loss: 0.3336, loss: 0.4117 ||:  96%|#########6| 10832/11253 [17:57<00:25, 16.81it/s]
2022-03-21 04:33:46,380 - INFO - tqdm - f1: 0.7908, accuracy: 0.8520, batch_loss: 0.4740, loss: 0.4111 ||:  98%|#########7| 10990/11253 [18:07<00:16, 15.70it/s]
2022-03-21 04:33:56,467 - INFO - tqdm - f1: 0.7908, accuracy: 0.8521, batch_loss: 0.7009, loss: 0.4108 ||:  99%|#########9| 11146/11253 [18:18<00:06, 15.82it/s]
2022-03-21 04:33:59,852 - INFO - tqdm - f1: 0.7909, accuracy: 0.8522, batch_loss: 0.4893, loss: 0.4104 ||: 100%|#########9| 11198/11253 [18:21<00:03, 14.72it/s]
2022-03-21 04:33:59,989 - INFO - tqdm - f1: 0.7909, accuracy: 0.8522, batch_loss: 0.6365, loss: 0.4105 ||: 100%|#########9| 11200/11253 [18:21<00:03, 14.67it/s]
2022-03-21 04:34:00,118 - INFO - tqdm - f1: 0.7909, accuracy: 0.8522, batch_loss: 0.2592, loss: 0.4105 ||: 100%|#########9| 11202/11253 [18:21<00:03, 14.92it/s]
2022-03-21 04:34:00,245 - INFO - tqdm - f1: 0.7909, accuracy: 0.8522, batch_loss: 0.3794, loss: 0.4104 ||: 100%|#########9| 11204/11253 [18:21<00:03, 15.15it/s]
2022-03-21 04:34:00,375 - INFO - tqdm - f1: 0.7909, accuracy: 0.8522, batch_loss: 0.1634, loss: 0.4104 ||: 100%|#########9| 11206/11253 [18:21<00:03, 15.24it/s]
2022-03-21 04:34:00,524 - INFO - tqdm - f1: 0.7910, accuracy: 0.8522, batch_loss: 0.2965, loss: 0.4104 ||: 100%|#########9| 11208/11253 [18:22<00:03, 14.64it/s]
2022-03-21 04:34:00,672 - INFO - tqdm - f1: 0.7909, accuracy: 0.8522, batch_loss: 0.6472, loss: 0.4104 ||: 100%|#########9| 11210/11253 [18:22<00:03, 14.27it/s]
2022-03-21 04:34:00,792 - INFO - tqdm - f1: 0.7910, accuracy: 0.8522, batch_loss: 0.9204, loss: 0.4104 ||: 100%|#########9| 11212/11253 [18:22<00:02, 14.91it/s]
2022-03-21 04:34:00,921 - INFO - tqdm - f1: 0.7909, accuracy: 0.8522, batch_loss: 0.7028, loss: 0.4105 ||: 100%|#########9| 11214/11253 [18:22<00:02, 15.09it/s]
2022-03-21 04:34:01,047 - INFO - tqdm - f1: 0.7909, accuracy: 0.8522, batch_loss: 0.1323, loss: 0.4104 ||: 100%|#########9| 11216/11253 [18:22<00:02, 15.33it/s]
2022-03-21 04:34:01,171 - INFO - tqdm - f1: 0.7909, accuracy: 0.8522, batch_loss: 0.8519, loss: 0.4105 ||: 100%|#########9| 11218/11253 [18:22<00:02, 15.55it/s]
2022-03-21 04:34:01,296 - INFO - tqdm - f1: 0.7910, accuracy: 0.8522, batch_loss: 0.1737, loss: 0.4104 ||: 100%|#########9| 11220/11253 [18:22<00:02, 15.69it/s]
2022-03-21 04:34:01,440 - INFO - tqdm - f1: 0.7910, accuracy: 0.8522, batch_loss: 0.5965, loss: 0.4105 ||: 100%|#########9| 11222/11253 [18:23<00:02, 15.10it/s]
2022-03-21 04:34:01,589 - INFO - tqdm - f1: 0.7910, accuracy: 0.8522, batch_loss: 0.4944, loss: 0.4105 ||: 100%|#########9| 11224/11253 [18:23<00:01, 14.55it/s]
2022-03-21 04:34:01,733 - INFO - tqdm - f1: 0.7910, accuracy: 0.8523, batch_loss: 0.2635, loss: 0.4104 ||: 100%|#########9| 11226/11253 [18:23<00:01, 14.35it/s]
2022-03-21 04:34:01,862 - INFO - tqdm - f1: 0.7910, accuracy: 0.8523, batch_loss: 0.6583, loss: 0.4104 ||: 100%|#########9| 11228/11253 [18:23<00:01, 14.66it/s]
2022-03-21 04:34:01,994 - INFO - tqdm - f1: 0.7910, accuracy: 0.8523, batch_loss: 0.5995, loss: 0.4104 ||: 100%|#########9| 11230/11253 [18:23<00:01, 14.82it/s]
2022-03-21 04:34:02,120 - INFO - tqdm - f1: 0.7911, accuracy: 0.8523, batch_loss: 0.2702, loss: 0.4104 ||: 100%|#########9| 11232/11253 [18:23<00:01, 15.11it/s]
2022-03-21 04:34:02,248 - INFO - tqdm - f1: 0.7910, accuracy: 0.8523, batch_loss: 0.8379, loss: 0.4104 ||: 100%|#########9| 11234/11253 [18:23<00:01, 15.29it/s]
2022-03-21 04:34:02,381 - INFO - tqdm - f1: 0.7911, accuracy: 0.8523, batch_loss: 0.5228, loss: 0.4104 ||: 100%|#########9| 11236/11253 [18:23<00:01, 15.20it/s]
2022-03-21 04:34:02,522 - INFO - tqdm - f1: 0.7910, accuracy: 0.8523, batch_loss: 0.2837, loss: 0.4104 ||: 100%|#########9| 11238/11253 [18:24<00:01, 14.87it/s]
2022-03-21 04:34:02,676 - INFO - tqdm - f1: 0.7910, accuracy: 0.8523, batch_loss: 0.7006, loss: 0.4104 ||: 100%|#########9| 11240/11253 [18:24<00:00, 14.26it/s]
2022-03-21 04:34:02,803 - INFO - tqdm - f1: 0.7910, accuracy: 0.8523, batch_loss: 0.4805, loss: 0.4104 ||: 100%|#########9| 11242/11253 [18:24<00:00, 14.68it/s]
2022-03-21 04:34:02,931 - INFO - tqdm - f1: 0.7910, accuracy: 0.8523, batch_loss: 0.6378, loss: 0.4104 ||: 100%|#########9| 11244/11253 [18:24<00:00, 14.93it/s]
2022-03-21 04:34:03,059 - INFO - tqdm - f1: 0.7910, accuracy: 0.8523, batch_loss: 0.2535, loss: 0.4104 ||: 100%|#########9| 11246/11253 [18:24<00:00, 15.13it/s]
2022-03-21 04:34:03,177 - INFO - tqdm - f1: 0.7910, accuracy: 0.8523, batch_loss: 0.2714, loss: 0.4104 ||: 100%|#########9| 11248/11253 [18:24<00:00, 15.65it/s]
2022-03-21 04:34:03,296 - INFO - tqdm - f1: 0.7910, accuracy: 0.8522, batch_loss: 0.8217, loss: 0.4104 ||: 100%|#########9| 11250/11253 [18:24<00:00, 15.98it/s]
2022-03-21 04:34:03,418 - INFO - tqdm - f1: 0.7910, accuracy: 0.8523, batch_loss: 0.1553, loss: 0.4104 ||: 100%|#########9| 11252/11253 [18:24<00:00, 16.09it/s]
2022-03-21 04:34:03,550 - INFO - tqdm - f1: 0.7910, accuracy: 0.8523, batch_loss: 0.6166, loss: 0.4104 ||: 100%|##########| 11253/11253 [18:25<00:00, 10.18it/s]
2022-03-21 04:34:03,556 - INFO - allennlp.training.trainer - Validating
2022-03-21 04:34:03,558 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 04:34:03,588 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 04:34:03,591 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 04:34:13,631 - INFO - tqdm - f1: 0.8214, accuracy: 0.8796, batch_loss: 0.0767, loss: 0.3364 ||:  23%|##3       | 436/1889 [00:10<00:38, 37.39it/s]
2022-03-21 04:34:23,741 - INFO - tqdm - f1: 0.8150, accuracy: 0.8751, batch_loss: 0.0798, loss: 0.3433 ||:  47%|####6     | 885/1889 [00:20<00:25, 39.82it/s]
2022-03-21 04:34:33,835 - INFO - tqdm - f1: 0.8129, accuracy: 0.8737, batch_loss: 0.7624, loss: 0.3491 ||:  71%|#######   | 1335/1889 [00:30<00:12, 42.91it/s]
2022-03-21 04:34:43,885 - INFO - tqdm - f1: 0.8116, accuracy: 0.8718, batch_loss: 0.0078, loss: 0.3519 ||:  94%|#########4| 1783/1889 [00:40<00:02, 45.67it/s]
2022-03-21 04:34:46,148 - INFO - tqdm - f1: 0.8122, accuracy: 0.8721, batch_loss: 0.5538, loss: 0.3526 ||: 100%|#########9| 1884/1889 [00:42<00:00, 48.84it/s]
2022-03-21 04:34:46,247 - INFO - tqdm - f1: 0.8120, accuracy: 0.8719, batch_loss: 0.3892, loss: 0.3528 ||: 100%|##########| 1889/1889 [00:42<00:00, 44.25it/s]
2022-03-21 04:34:46,262 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct-20k_base_hyper_small_seed_177/best.th'.
2022-03-21 04:34:48,600 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 04:34:48,603 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.852  |     0.872
2022-03-21 04:34:48,604 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.791  |     0.812
2022-03-21 04:34:48,606 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 04:34:48,608 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.410  |     0.353
2022-03-21 04:34:48,610 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8465.582  |       N/A
2022-03-21 04:34:48,612 - INFO - allennlp.training.trainer - Epoch duration: 0:19:10.187769
2022-03-21 04:34:48,613 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:52:31
2022-03-21 04:34:48,615 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-21 04:34:48,617 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 04:34:48,618 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 04:34:48,621 - INFO - allennlp.training.trainer - Training
2022-03-21 04:34:48,623 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 04:34:58,668 - INFO - tqdm - f1: 0.8095, accuracy: 0.8719, batch_loss: 0.3877, loss: 0.3451 ||:   1%|1         | 139/11253 [00:10<12:05, 15.32it/s]
2022-03-21 04:35:08,747 - INFO - tqdm - f1: 0.8107, accuracy: 0.8709, batch_loss: 0.5082, loss: 0.3406 ||:   3%|2         | 293/11253 [00:20<12:28, 14.64it/s]
2022-03-21 04:35:18,851 - INFO - tqdm - f1: 0.8072, accuracy: 0.8701, batch_loss: 0.4320, loss: 0.3475 ||:   4%|3         | 447/11253 [00:30<12:01, 14.98it/s]
2022-03-21 04:35:28,912 - INFO - tqdm - f1: 0.8099, accuracy: 0.8719, batch_loss: 0.6070, loss: 0.3468 ||:   5%|5         | 597/11253 [00:40<11:27, 15.51it/s]
2022-03-21 04:35:38,923 - INFO - tqdm - f1: 0.8101, accuracy: 0.8718, batch_loss: 0.4260, loss: 0.3462 ||:   7%|6         | 751/11253 [00:50<11:10, 15.67it/s]
2022-03-21 04:35:49,007 - INFO - tqdm - f1: 0.8110, accuracy: 0.8739, batch_loss: 0.4425, loss: 0.3407 ||:   8%|8         | 905/11253 [01:00<11:00, 15.67it/s]
2022-03-21 04:35:59,134 - INFO - tqdm - f1: 0.8078, accuracy: 0.8725, batch_loss: 0.4419, loss: 0.3427 ||:   9%|9         | 1063/11253 [01:10<10:51, 15.64it/s]
2022-03-21 04:36:09,175 - INFO - tqdm - f1: 0.8092, accuracy: 0.8728, batch_loss: 0.4038, loss: 0.3428 ||:  11%|#         | 1215/11253 [01:20<10:28, 15.97it/s]
2022-03-21 04:36:19,274 - INFO - tqdm - f1: 0.8096, accuracy: 0.8721, batch_loss: 0.6411, loss: 0.3447 ||:  12%|#2        | 1371/11253 [01:30<10:10, 16.20it/s]
2022-03-21 04:36:29,335 - INFO - tqdm - f1: 0.8114, accuracy: 0.8730, batch_loss: 0.5144, loss: 0.3432 ||:  14%|#3        | 1527/11253 [01:40<10:30, 15.42it/s]
2022-03-21 04:36:39,365 - INFO - tqdm - f1: 0.8099, accuracy: 0.8718, batch_loss: 0.4073, loss: 0.3454 ||:  15%|#4        | 1679/11253 [01:50<10:16, 15.53it/s]
2022-03-21 04:36:49,416 - INFO - tqdm - f1: 0.8107, accuracy: 0.8730, batch_loss: 0.0836, loss: 0.3433 ||:  16%|#6        | 1831/11253 [02:00<10:00, 15.69it/s]
2022-03-21 04:36:59,460 - INFO - tqdm - f1: 0.8104, accuracy: 0.8734, batch_loss: 0.2349, loss: 0.3435 ||:  18%|#7        | 1985/11253 [02:10<09:48, 15.75it/s]
2022-03-21 04:37:09,570 - INFO - tqdm - f1: 0.8120, accuracy: 0.8742, batch_loss: 0.0566, loss: 0.3416 ||:  19%|#8        | 2137/11253 [02:20<09:56, 15.27it/s]
2022-03-21 04:37:19,629 - INFO - tqdm - f1: 0.8105, accuracy: 0.8732, batch_loss: 0.1973, loss: 0.3441 ||:  20%|##        | 2291/11253 [02:31<10:11, 14.66it/s]
2022-03-21 04:37:29,698 - INFO - tqdm - f1: 0.8120, accuracy: 0.8734, batch_loss: 0.3182, loss: 0.3451 ||:  22%|##1       | 2445/11253 [02:41<09:32, 15.39it/s]
2022-03-21 04:37:39,835 - INFO - tqdm - f1: 0.8113, accuracy: 0.8728, batch_loss: 0.2496, loss: 0.3471 ||:  23%|##3       | 2595/11253 [02:51<09:53, 14.58it/s]
2022-03-21 04:37:49,899 - INFO - tqdm - f1: 0.8116, accuracy: 0.8730, batch_loss: 0.2485, loss: 0.3474 ||:  24%|##4       | 2747/11253 [03:01<09:19, 15.19it/s]
2022-03-21 04:37:59,902 - INFO - tqdm - f1: 0.8125, accuracy: 0.8731, batch_loss: 0.0654, loss: 0.3478 ||:  26%|##5       | 2897/11253 [03:11<09:22, 14.86it/s]
2022-03-21 04:38:10,053 - INFO - tqdm - f1: 0.8139, accuracy: 0.8737, batch_loss: 0.3926, loss: 0.3469 ||:  27%|##7       | 3045/11253 [03:21<10:29, 13.05it/s]
2022-03-21 04:38:20,139 - INFO - tqdm - f1: 0.8135, accuracy: 0.8737, batch_loss: 0.0810, loss: 0.3461 ||:  28%|##8       | 3199/11253 [03:31<09:06, 14.74it/s]
2022-03-21 04:38:30,171 - INFO - tqdm - f1: 0.8127, accuracy: 0.8731, batch_loss: 0.1602, loss: 0.3467 ||:  30%|##9       | 3349/11253 [03:41<08:46, 15.02it/s]
2022-03-21 04:38:40,271 - INFO - tqdm - f1: 0.8128, accuracy: 0.8730, batch_loss: 0.3760, loss: 0.3471 ||:  31%|###1      | 3495/11253 [03:51<08:54, 14.50it/s]
2022-03-21 04:38:50,358 - INFO - tqdm - f1: 0.8130, accuracy: 0.8731, batch_loss: 0.1554, loss: 0.3473 ||:  32%|###2      | 3649/11253 [04:01<07:53, 16.06it/s]
2022-03-21 04:39:00,461 - INFO - tqdm - f1: 0.8130, accuracy: 0.8729, batch_loss: 0.5598, loss: 0.3472 ||:  34%|###3      | 3803/11253 [04:11<08:02, 15.43it/s]
2022-03-21 04:39:10,515 - INFO - tqdm - f1: 0.8128, accuracy: 0.8730, batch_loss: 0.3863, loss: 0.3470 ||:  35%|###5      | 3953/11253 [04:21<07:44, 15.73it/s]
2022-03-21 04:39:20,554 - INFO - tqdm - f1: 0.8128, accuracy: 0.8733, batch_loss: 0.5423, loss: 0.3463 ||:  36%|###6      | 4107/11253 [04:31<07:34, 15.73it/s]
2022-03-21 04:39:30,563 - INFO - tqdm - f1: 0.8129, accuracy: 0.8734, batch_loss: 0.3150, loss: 0.3458 ||:  38%|###7      | 4257/11253 [04:41<07:25, 15.70it/s]
2022-03-21 04:39:40,671 - INFO - tqdm - f1: 0.8128, accuracy: 0.8731, batch_loss: 0.3337, loss: 0.3464 ||:  39%|###9      | 4409/11253 [04:52<07:32, 15.12it/s]
2022-03-21 04:39:50,754 - INFO - tqdm - f1: 0.8134, accuracy: 0.8734, batch_loss: 0.6012, loss: 0.3454 ||:  41%|####      | 4561/11253 [05:02<07:35, 14.68it/s]
2022-03-21 04:40:00,843 - INFO - tqdm - f1: 0.8129, accuracy: 0.8732, batch_loss: 0.5096, loss: 0.3457 ||:  42%|####1     | 4713/11253 [05:12<07:46, 14.01it/s]
2022-03-21 04:40:10,922 - INFO - tqdm - f1: 0.8132, accuracy: 0.8734, batch_loss: 0.1630, loss: 0.3453 ||:  43%|####3     | 4861/11253 [05:22<07:21, 14.48it/s]
2022-03-21 04:40:21,006 - INFO - tqdm - f1: 0.8136, accuracy: 0.8737, batch_loss: 0.1853, loss: 0.3450 ||:  45%|####4     | 5013/11253 [05:32<07:19, 14.21it/s]
2022-03-21 04:40:31,120 - INFO - tqdm - f1: 0.8138, accuracy: 0.8739, batch_loss: 0.1543, loss: 0.3448 ||:  46%|####5     | 5163/11253 [05:42<06:46, 14.99it/s]
2022-03-21 04:40:41,182 - INFO - tqdm - f1: 0.8143, accuracy: 0.8743, batch_loss: 0.1877, loss: 0.3440 ||:  47%|####7     | 5315/11253 [05:52<06:43, 14.71it/s]
2022-03-21 04:40:51,307 - INFO - tqdm - f1: 0.8147, accuracy: 0.8744, batch_loss: 0.3784, loss: 0.3436 ||:  49%|####8     | 5467/11253 [06:02<06:30, 14.82it/s]
2022-03-21 04:41:01,367 - INFO - tqdm - f1: 0.8150, accuracy: 0.8746, batch_loss: 0.1800, loss: 0.3436 ||:  50%|####9     | 5619/11253 [06:12<06:02, 15.55it/s]
2022-03-21 04:41:11,401 - INFO - tqdm - f1: 0.8150, accuracy: 0.8745, batch_loss: 0.6049, loss: 0.3435 ||:  51%|#####1    | 5769/11253 [06:22<06:09, 14.86it/s]
2022-03-21 04:41:21,474 - INFO - tqdm - f1: 0.8150, accuracy: 0.8745, batch_loss: 0.4039, loss: 0.3437 ||:  53%|#####2    | 5915/11253 [06:32<06:03, 14.69it/s]
2022-03-21 04:41:31,597 - INFO - tqdm - f1: 0.8153, accuracy: 0.8747, batch_loss: 0.2347, loss: 0.3431 ||:  54%|#####3    | 6067/11253 [06:42<05:59, 14.44it/s]
2022-03-21 04:41:41,725 - INFO - tqdm - f1: 0.8151, accuracy: 0.8747, batch_loss: 0.5815, loss: 0.3433 ||:  55%|#####5    | 6219/11253 [06:53<05:25, 15.44it/s]
2022-03-21 04:41:51,830 - INFO - tqdm - f1: 0.8148, accuracy: 0.8746, batch_loss: 0.2427, loss: 0.3432 ||:  57%|#####6    | 6371/11253 [07:03<05:14, 15.55it/s]
2022-03-21 04:42:01,841 - INFO - tqdm - f1: 0.8150, accuracy: 0.8745, batch_loss: 0.2253, loss: 0.3435 ||:  58%|#####7    | 6521/11253 [07:13<05:15, 15.00it/s]
2022-03-21 04:42:11,883 - INFO - tqdm - f1: 0.8146, accuracy: 0.8745, batch_loss: 0.2872, loss: 0.3437 ||:  59%|#####9    | 6671/11253 [07:23<05:11, 14.72it/s]
2022-03-21 04:42:22,003 - INFO - tqdm - f1: 0.8143, accuracy: 0.8741, batch_loss: 0.4129, loss: 0.3443 ||:  61%|######    | 6821/11253 [07:33<05:04, 14.54it/s]
2022-03-21 04:42:32,046 - INFO - tqdm - f1: 0.8143, accuracy: 0.8739, batch_loss: 0.4509, loss: 0.3445 ||:  62%|######1   | 6969/11253 [07:43<04:56, 14.44it/s]
2022-03-21 04:42:42,058 - INFO - tqdm - f1: 0.8146, accuracy: 0.8742, batch_loss: 0.5015, loss: 0.3437 ||:  63%|######3   | 7117/11253 [07:53<04:27, 15.43it/s]
2022-03-21 04:42:52,143 - INFO - tqdm - f1: 0.8147, accuracy: 0.8742, batch_loss: 0.0309, loss: 0.3436 ||:  65%|######4   | 7269/11253 [08:03<04:34, 14.54it/s]
2022-03-21 04:43:02,206 - INFO - tqdm - f1: 0.8147, accuracy: 0.8742, batch_loss: 0.3173, loss: 0.3439 ||:  66%|######5   | 7419/11253 [08:13<04:09, 15.39it/s]
2022-03-21 04:43:12,241 - INFO - tqdm - f1: 0.8146, accuracy: 0.8741, batch_loss: 0.1313, loss: 0.3438 ||:  67%|######7   | 7569/11253 [08:23<04:06, 14.92it/s]
2022-03-21 04:43:22,258 - INFO - tqdm - f1: 0.8144, accuracy: 0.8739, batch_loss: 0.3271, loss: 0.3443 ||:  69%|######8   | 7721/11253 [08:33<03:45, 15.65it/s]
2022-03-21 04:43:32,362 - INFO - tqdm - f1: 0.8140, accuracy: 0.8736, batch_loss: 0.3594, loss: 0.3447 ||:  70%|######9   | 7871/11253 [08:43<04:10, 13.50it/s]
2022-03-21 04:43:42,464 - INFO - tqdm - f1: 0.8142, accuracy: 0.8737, batch_loss: 0.2165, loss: 0.3444 ||:  71%|#######1  | 8017/11253 [08:53<04:00, 13.48it/s]
2022-03-21 04:43:52,521 - INFO - tqdm - f1: 0.8143, accuracy: 0.8737, batch_loss: 0.2238, loss: 0.3449 ||:  73%|#######2  | 8163/11253 [09:03<03:35, 14.34it/s]
2022-03-21 04:44:02,573 - INFO - tqdm - f1: 0.8144, accuracy: 0.8738, batch_loss: 0.2378, loss: 0.3445 ||:  74%|#######3  | 8309/11253 [09:13<03:20, 14.72it/s]
2022-03-21 04:44:12,660 - INFO - tqdm - f1: 0.8146, accuracy: 0.8739, batch_loss: 0.6451, loss: 0.3444 ||:  75%|#######5  | 8455/11253 [09:24<03:07, 14.88it/s]
2022-03-21 04:44:22,666 - INFO - tqdm - f1: 0.8147, accuracy: 0.8740, batch_loss: 0.5494, loss: 0.3445 ||:  76%|#######6  | 8599/11253 [09:34<02:56, 15.02it/s]
2022-03-21 04:44:32,701 - INFO - tqdm - f1: 0.8149, accuracy: 0.8741, batch_loss: 0.4038, loss: 0.3445 ||:  78%|#######7  | 8747/11253 [09:44<02:31, 16.49it/s]
2022-03-21 04:44:42,800 - INFO - tqdm - f1: 0.8146, accuracy: 0.8740, batch_loss: 0.3070, loss: 0.3448 ||:  79%|#######9  | 8903/11253 [09:54<02:26, 16.01it/s]
2022-03-21 04:44:52,903 - INFO - tqdm - f1: 0.8148, accuracy: 0.8741, batch_loss: 0.4598, loss: 0.3448 ||:  80%|########  | 9057/11253 [10:04<02:38, 13.83it/s]
2022-03-21 04:45:02,979 - INFO - tqdm - f1: 0.8149, accuracy: 0.8741, batch_loss: 0.1150, loss: 0.3450 ||:  82%|########1 | 9205/11253 [10:14<02:17, 14.85it/s]
2022-03-21 04:45:13,082 - INFO - tqdm - f1: 0.8149, accuracy: 0.8741, batch_loss: 0.2265, loss: 0.3451 ||:  83%|########3 | 9353/11253 [10:24<02:10, 14.51it/s]
2022-03-21 04:45:23,104 - INFO - tqdm - f1: 0.8150, accuracy: 0.8742, batch_loss: 0.3222, loss: 0.3452 ||:  84%|########4 | 9503/11253 [10:34<01:55, 15.10it/s]
2022-03-21 04:45:33,244 - INFO - tqdm - f1: 0.8149, accuracy: 0.8741, batch_loss: 0.3037, loss: 0.3455 ||:  86%|########5 | 9653/11253 [10:44<01:52, 14.24it/s]
2022-03-21 04:45:43,316 - INFO - tqdm - f1: 0.8151, accuracy: 0.8742, batch_loss: 0.2387, loss: 0.3455 ||:  87%|########7 | 9801/11253 [10:54<01:43, 13.99it/s]
2022-03-21 04:45:53,413 - INFO - tqdm - f1: 0.8150, accuracy: 0.8740, batch_loss: 0.3653, loss: 0.3456 ||:  88%|########8 | 9949/11253 [11:04<01:25, 15.28it/s]
2022-03-21 04:46:03,510 - INFO - tqdm - f1: 0.8150, accuracy: 0.8741, batch_loss: 0.1872, loss: 0.3453 ||:  90%|########9 | 10103/11253 [11:14<01:14, 15.36it/s]
2022-03-21 04:46:13,637 - INFO - tqdm - f1: 0.8151, accuracy: 0.8741, batch_loss: 0.5590, loss: 0.3453 ||:  91%|#########1| 10255/11253 [11:25<01:10, 14.12it/s]
2022-03-21 04:46:23,638 - INFO - tqdm - f1: 0.8149, accuracy: 0.8740, batch_loss: 0.2267, loss: 0.3455 ||:  92%|#########2| 10405/11253 [11:35<00:56, 14.95it/s]
2022-03-21 04:46:33,641 - INFO - tqdm - f1: 0.8149, accuracy: 0.8741, batch_loss: 0.5284, loss: 0.3454 ||:  94%|#########3| 10547/11253 [11:45<00:48, 14.54it/s]
2022-03-21 04:46:43,693 - INFO - tqdm - f1: 0.8150, accuracy: 0.8741, batch_loss: 0.2059, loss: 0.3454 ||:  95%|#########5| 10695/11253 [11:55<00:38, 14.38it/s]
2022-03-21 04:46:53,801 - INFO - tqdm - f1: 0.8151, accuracy: 0.8741, batch_loss: 0.1711, loss: 0.3451 ||:  96%|#########6| 10843/11253 [12:05<00:26, 15.31it/s]
2022-03-21 04:47:03,866 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.2295, loss: 0.3454 ||:  98%|#########7| 10993/11253 [12:15<00:17, 15.27it/s]
2022-03-21 04:47:13,934 - INFO - tqdm - f1: 0.8148, accuracy: 0.8739, batch_loss: 0.9966, loss: 0.3459 ||:  99%|#########9| 11143/11253 [12:25<00:07, 14.25it/s]
2022-03-21 04:47:17,653 - INFO - tqdm - f1: 0.8148, accuracy: 0.8738, batch_loss: 0.3734, loss: 0.3459 ||: 100%|#########9| 11197/11253 [12:29<00:03, 14.51it/s]
2022-03-21 04:47:17,795 - INFO - tqdm - f1: 0.8148, accuracy: 0.8738, batch_loss: 0.0220, loss: 0.3458 ||: 100%|#########9| 11199/11253 [12:29<00:03, 14.37it/s]
2022-03-21 04:47:17,936 - INFO - tqdm - f1: 0.8148, accuracy: 0.8739, batch_loss: 0.4160, loss: 0.3458 ||: 100%|#########9| 11201/11253 [12:29<00:03, 14.32it/s]
2022-03-21 04:47:18,088 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.1856, loss: 0.3458 ||: 100%|#########9| 11203/11253 [12:29<00:03, 13.94it/s]
2022-03-21 04:47:18,241 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.4628, loss: 0.3458 ||: 100%|#########9| 11205/11253 [12:29<00:03, 13.67it/s]
2022-03-21 04:47:18,386 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.3485, loss: 0.3458 ||: 100%|#########9| 11207/11253 [12:29<00:03, 13.71it/s]
2022-03-21 04:47:18,517 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.0446, loss: 0.3458 ||: 100%|#########9| 11209/11253 [12:29<00:03, 14.14it/s]
2022-03-21 04:47:18,644 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.1734, loss: 0.3458 ||: 100%|#########9| 11211/11253 [12:30<00:02, 14.58it/s]
2022-03-21 04:47:18,781 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.0206, loss: 0.3457 ||: 100%|#########9| 11213/11253 [12:30<00:02, 14.60it/s]
2022-03-21 04:47:18,917 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.3360, loss: 0.3457 ||: 100%|#########9| 11215/11253 [12:30<00:02, 14.63it/s]
2022-03-21 04:47:19,050 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.4003, loss: 0.3457 ||: 100%|#########9| 11217/11253 [12:30<00:02, 14.76it/s]
2022-03-21 04:47:19,183 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.5085, loss: 0.3457 ||: 100%|#########9| 11219/11253 [12:30<00:02, 14.85it/s]
2022-03-21 04:47:19,332 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.4933, loss: 0.3457 ||: 100%|#########9| 11221/11253 [12:30<00:02, 14.38it/s]
2022-03-21 04:47:19,453 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.3436, loss: 0.3457 ||: 100%|#########9| 11223/11253 [12:30<00:02, 14.96it/s]
2022-03-21 04:47:19,584 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.2040, loss: 0.3457 ||: 100%|#########9| 11225/11253 [12:30<00:01, 15.04it/s]
2022-03-21 04:47:19,736 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.1543, loss: 0.3457 ||: 100%|#########9| 11227/11253 [12:31<00:01, 14.44it/s]
2022-03-21 04:47:19,861 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.6042, loss: 0.3457 ||: 100%|#########9| 11229/11253 [12:31<00:01, 14.88it/s]
2022-03-21 04:47:19,994 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.5187, loss: 0.3457 ||: 100%|#########9| 11231/11253 [12:31<00:01, 14.91it/s]
2022-03-21 04:47:20,127 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.1354, loss: 0.3456 ||: 100%|#########9| 11233/11253 [12:31<00:01, 14.96it/s]
2022-03-21 04:47:20,281 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.3343, loss: 0.3456 ||: 100%|#########9| 11235/11253 [12:31<00:01, 14.30it/s]
2022-03-21 04:47:20,422 - INFO - tqdm - f1: 0.8150, accuracy: 0.8740, batch_loss: 0.1344, loss: 0.3456 ||: 100%|#########9| 11237/11253 [12:31<00:01, 14.25it/s]
2022-03-21 04:47:20,560 - INFO - tqdm - f1: 0.8149, accuracy: 0.8740, batch_loss: 0.1793, loss: 0.3456 ||: 100%|#########9| 11239/11253 [12:31<00:00, 14.34it/s]
2022-03-21 04:47:20,700 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.2283, loss: 0.3456 ||: 100%|#########9| 11241/11253 [12:32<00:00, 14.32it/s]
2022-03-21 04:47:20,836 - INFO - tqdm - f1: 0.8149, accuracy: 0.8739, batch_loss: 0.1460, loss: 0.3456 ||: 100%|#########9| 11243/11253 [12:32<00:00, 14.45it/s]
2022-03-21 04:47:20,973 - INFO - tqdm - f1: 0.8150, accuracy: 0.8740, batch_loss: 0.1090, loss: 0.3456 ||: 100%|#########9| 11245/11253 [12:32<00:00, 14.49it/s]
2022-03-21 04:47:21,130 - INFO - tqdm - f1: 0.8150, accuracy: 0.8739, batch_loss: 1.2094, loss: 0.3457 ||: 100%|#########9| 11247/11253 [12:32<00:00, 13.91it/s]
2022-03-21 04:47:21,282 - INFO - tqdm - f1: 0.8150, accuracy: 0.8740, batch_loss: 0.2252, loss: 0.3457 ||: 100%|#########9| 11249/11253 [12:32<00:00, 13.68it/s]
2022-03-21 04:47:21,425 - INFO - tqdm - f1: 0.8150, accuracy: 0.8740, batch_loss: 0.0753, loss: 0.3457 ||: 100%|#########9| 11251/11253 [12:32<00:00, 13.76it/s]
2022-03-21 04:47:21,562 - INFO - tqdm - f1: 0.8150, accuracy: 0.8740, batch_loss: 0.3065, loss: 0.3457 ||: 100%|##########| 11253/11253 [12:32<00:00, 14.00it/s]
2022-03-21 04:47:21,626 - INFO - tqdm - f1: 0.8150, accuracy: 0.8740, batch_loss: 0.3065, loss: 0.3457 ||: 100%|##########| 11253/11253 [12:33<00:00, 14.94it/s]
2022-03-21 04:47:21,632 - INFO - allennlp.training.trainer - Validating
2022-03-21 04:47:21,634 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 04:47:31,739 - INFO - tqdm - f1: 0.8201, accuracy: 0.8732, batch_loss: 0.1631, loss: 0.3565 ||:  23%|##3       | 442/1889 [00:10<00:28, 50.87it/s]
2022-03-21 04:47:41,841 - INFO - tqdm - f1: 0.8188, accuracy: 0.8733, batch_loss: 0.7708, loss: 0.3602 ||:  46%|####6     | 870/1889 [00:20<00:22, 46.14it/s]
2022-03-21 04:47:51,886 - INFO - tqdm - f1: 0.8176, accuracy: 0.8726, batch_loss: 0.3122, loss: 0.3611 ||:  69%|######8   | 1296/1889 [00:30<00:14, 41.50it/s]
2022-03-21 04:48:01,978 - INFO - tqdm - f1: 0.8184, accuracy: 0.8721, batch_loss: 0.3752, loss: 0.3614 ||:  92%|#########1| 1733/1889 [00:40<00:03, 46.26it/s]
2022-03-21 04:48:05,496 - INFO - tqdm - f1: 0.8170, accuracy: 0.8711, batch_loss: 0.1377, loss: 0.3628 ||: 100%|#########9| 1881/1889 [00:43<00:00, 42.58it/s]
2022-03-21 04:48:05,607 - INFO - tqdm - f1: 0.8168, accuracy: 0.8710, batch_loss: 0.1595, loss: 0.3630 ||: 100%|#########9| 1887/1889 [00:43<00:00, 45.75it/s]
2022-03-21 04:48:05,654 - INFO - tqdm - f1: 0.8168, accuracy: 0.8710, batch_loss: 0.1841, loss: 0.3629 ||: 100%|##########| 1889/1889 [00:44<00:00, 42.91it/s]
2022-03-21 04:48:05,669 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct-20k_base_hyper_small_seed_177/best.th'.
2022-03-21 04:48:08,254 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 04:48:08,256 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.874  |     0.871
2022-03-21 04:48:08,257 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.815  |     0.817
2022-03-21 04:48:08,259 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 04:48:08,261 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.346  |     0.363
2022-03-21 04:48:08,262 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8641.430  |       N/A
2022-03-21 04:48:08,263 - INFO - allennlp.training.trainer - Epoch duration: 0:13:19.647812
2022-03-21 04:48:08,264 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:09:59
2022-03-21 04:48:08,266 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-21 04:48:08,267 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 04:48:08,269 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 04:48:08,271 - INFO - allennlp.training.trainer - Training
2022-03-21 04:48:08,273 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 04:48:18,318 - INFO - tqdm - f1: 0.8264, accuracy: 0.8776, batch_loss: 0.2572, loss: 0.3331 ||:   1%|          | 73/11253 [00:10<12:31, 14.87it/s]
2022-03-21 04:48:28,349 - INFO - tqdm - f1: 0.8310, accuracy: 0.8834, batch_loss: 0.3922, loss: 0.3198 ||:   2%|1         | 223/11253 [00:20<12:53, 14.25it/s]
2022-03-21 04:48:38,350 - INFO - tqdm - f1: 0.8270, accuracy: 0.8840, batch_loss: 0.2614, loss: 0.3135 ||:   3%|3         | 373/11253 [00:30<12:59, 13.95it/s]
2022-03-21 04:48:48,486 - INFO - tqdm - f1: 0.8251, accuracy: 0.8832, batch_loss: 0.9596, loss: 0.3117 ||:   5%|4         | 521/11253 [00:40<12:29, 14.32it/s]
2022-03-21 04:48:58,526 - INFO - tqdm - f1: 0.8275, accuracy: 0.8852, batch_loss: 0.3473, loss: 0.3071 ||:   6%|5         | 669/11253 [00:50<12:46, 13.81it/s]
2022-03-21 04:49:08,654 - INFO - tqdm - f1: 0.8291, accuracy: 0.8873, batch_loss: 0.1508, loss: 0.3037 ||:   7%|7         | 817/11253 [01:00<11:52, 14.66it/s]
2022-03-21 04:49:18,759 - INFO - tqdm - f1: 0.8280, accuracy: 0.8859, batch_loss: 0.3203, loss: 0.3067 ||:   9%|8         | 971/11253 [01:10<10:39, 16.07it/s]
2022-03-21 04:49:28,849 - INFO - tqdm - f1: 0.8301, accuracy: 0.8871, batch_loss: 0.3964, loss: 0.3065 ||:  10%|9         | 1125/11253 [01:20<11:08, 15.15it/s]
2022-03-21 04:49:38,869 - INFO - tqdm - f1: 0.8312, accuracy: 0.8867, batch_loss: 0.3132, loss: 0.3100 ||:  11%|#1        | 1275/11253 [01:30<10:52, 15.29it/s]
2022-03-21 04:49:48,980 - INFO - tqdm - f1: 0.8316, accuracy: 0.8870, batch_loss: 0.2336, loss: 0.3105 ||:  13%|#2        | 1429/11253 [01:40<10:14, 15.98it/s]
2022-03-21 04:49:59,000 - INFO - tqdm - f1: 0.8318, accuracy: 0.8876, batch_loss: 0.2008, loss: 0.3087 ||:  14%|#4        | 1577/11253 [01:50<10:54, 14.79it/s]
2022-03-21 04:50:09,050 - INFO - tqdm - f1: 0.8333, accuracy: 0.8885, batch_loss: 0.2539, loss: 0.3064 ||:  15%|#5        | 1725/11253 [02:00<10:30, 15.10it/s]
2022-03-21 04:50:19,077 - INFO - tqdm - f1: 0.8333, accuracy: 0.8885, batch_loss: 0.2020, loss: 0.3067 ||:  17%|#6        | 1871/11253 [02:10<10:40, 14.65it/s]
2022-03-21 04:50:29,207 - INFO - tqdm - f1: 0.8343, accuracy: 0.8890, batch_loss: 0.0762, loss: 0.3052 ||:  18%|#7        | 2021/11253 [02:20<10:04, 15.27it/s]
2022-03-21 04:50:39,331 - INFO - tqdm - f1: 0.8352, accuracy: 0.8897, batch_loss: 0.1913, loss: 0.3046 ||:  19%|#9        | 2175/11253 [02:31<10:36, 14.26it/s]
2022-03-21 04:50:49,339 - INFO - tqdm - f1: 0.8349, accuracy: 0.8894, batch_loss: 0.7651, loss: 0.3051 ||:  21%|##        | 2325/11253 [02:41<09:50, 15.11it/s]
2022-03-21 04:50:59,376 - INFO - tqdm - f1: 0.8348, accuracy: 0.8896, batch_loss: 0.3622, loss: 0.3044 ||:  22%|##2       | 2477/11253 [02:51<09:53, 14.78it/s]
2022-03-21 04:51:09,423 - INFO - tqdm - f1: 0.8347, accuracy: 0.8898, batch_loss: 0.1082, loss: 0.3034 ||:  23%|##3       | 2627/11253 [03:01<10:25, 13.78it/s]
2022-03-21 04:51:19,434 - INFO - tqdm - f1: 0.8346, accuracy: 0.8899, batch_loss: 0.0884, loss: 0.3035 ||:  25%|##4       | 2777/11253 [03:11<09:07, 15.48it/s]
2022-03-21 04:51:29,503 - INFO - tqdm - f1: 0.8347, accuracy: 0.8897, batch_loss: 0.3596, loss: 0.3044 ||:  26%|##5       | 2925/11253 [03:21<09:43, 14.28it/s]
2022-03-21 04:51:39,537 - INFO - tqdm - f1: 0.8342, accuracy: 0.8891, batch_loss: 0.0498, loss: 0.3060 ||:  27%|##7       | 3071/11253 [03:31<09:36, 14.20it/s]
2022-03-21 04:51:49,658 - INFO - tqdm - f1: 0.8336, accuracy: 0.8890, batch_loss: 0.6640, loss: 0.3060 ||:  29%|##8       | 3221/11253 [03:41<09:15, 14.46it/s]
2022-03-21 04:51:59,752 - INFO - tqdm - f1: 0.8337, accuracy: 0.8890, batch_loss: 0.2237, loss: 0.3053 ||:  30%|##9       | 3367/11253 [03:51<08:27, 15.53it/s]
2022-03-21 04:52:09,841 - INFO - tqdm - f1: 0.8341, accuracy: 0.8894, batch_loss: 0.1563, loss: 0.3050 ||:  31%|###1      | 3519/11253 [04:01<07:54, 16.29it/s]
2022-03-21 04:52:19,961 - INFO - tqdm - f1: 0.8349, accuracy: 0.8899, batch_loss: 0.4346, loss: 0.3043 ||:  33%|###2      | 3669/11253 [04:11<08:49, 14.33it/s]
2022-03-21 04:52:30,064 - INFO - tqdm - f1: 0.8352, accuracy: 0.8899, batch_loss: 0.3410, loss: 0.3040 ||:  34%|###3      | 3821/11253 [04:21<08:03, 15.36it/s]
2022-03-21 04:52:40,173 - INFO - tqdm - f1: 0.8353, accuracy: 0.8898, batch_loss: 0.6275, loss: 0.3041 ||:  35%|###5      | 3967/11253 [04:31<08:32, 14.22it/s]
2022-03-21 04:52:50,274 - INFO - tqdm - f1: 0.8348, accuracy: 0.8895, batch_loss: 0.2406, loss: 0.3046 ||:  37%|###6      | 4117/11253 [04:41<07:34, 15.69it/s]
2022-03-21 04:53:00,324 - INFO - tqdm - f1: 0.8345, accuracy: 0.8895, batch_loss: 0.0138, loss: 0.3043 ||:  38%|###7      | 4267/11253 [04:52<07:38, 15.22it/s]
2022-03-21 04:53:10,533 - INFO - tqdm - f1: 0.8347, accuracy: 0.8896, batch_loss: 0.4045, loss: 0.3043 ||:  39%|###9      | 4415/11253 [05:02<10:25, 10.93it/s]
2022-03-21 04:53:20,555 - INFO - tqdm - f1: 0.8349, accuracy: 0.8896, batch_loss: 0.3713, loss: 0.3046 ||:  41%|####      | 4563/11253 [05:12<07:54, 14.11it/s]
2022-03-21 04:53:30,579 - INFO - tqdm - f1: 0.8348, accuracy: 0.8895, batch_loss: 0.0698, loss: 0.3045 ||:  42%|####1     | 4709/11253 [05:22<07:28, 14.60it/s]
2022-03-21 04:53:40,684 - INFO - tqdm - f1: 0.8346, accuracy: 0.8895, batch_loss: 0.4884, loss: 0.3043 ||:  43%|####3     | 4863/11253 [05:32<06:58, 15.26it/s]
2022-03-21 04:53:50,792 - INFO - tqdm - f1: 0.8341, accuracy: 0.8890, batch_loss: 0.0129, loss: 0.3053 ||:  45%|####4     | 5013/11253 [05:42<06:58, 14.90it/s]
2022-03-21 04:54:00,860 - INFO - tqdm - f1: 0.8341, accuracy: 0.8891, batch_loss: 0.3904, loss: 0.3047 ||:  46%|####5     | 5159/11253 [05:52<07:01, 14.47it/s]
2022-03-21 04:54:11,004 - INFO - tqdm - f1: 0.8336, accuracy: 0.8887, batch_loss: 0.6808, loss: 0.3057 ||:  47%|####7     | 5307/11253 [06:02<06:54, 14.35it/s]
2022-03-21 04:54:21,104 - INFO - tqdm - f1: 0.8336, accuracy: 0.8886, batch_loss: 0.1953, loss: 0.3059 ||:  48%|####8     | 5457/11253 [06:12<06:13, 15.50it/s]
2022-03-21 04:54:31,225 - INFO - tqdm - f1: 0.8332, accuracy: 0.8881, batch_loss: 0.4604, loss: 0.3070 ||:  50%|####9     | 5609/11253 [06:22<06:08, 15.32it/s]
2022-03-21 04:54:41,270 - INFO - tqdm - f1: 0.8336, accuracy: 0.8883, batch_loss: 0.4626, loss: 0.3064 ||:  51%|#####1    | 5757/11253 [06:32<06:27, 14.18it/s]
2022-03-21 04:54:51,342 - INFO - tqdm - f1: 0.8335, accuracy: 0.8882, batch_loss: 0.3321, loss: 0.3073 ||:  52%|#####2    | 5907/11253 [06:43<05:44, 15.53it/s]
2022-03-21 04:55:01,491 - INFO - tqdm - f1: 0.8338, accuracy: 0.8883, batch_loss: 0.0695, loss: 0.3075 ||:  54%|#####3    | 6055/11253 [06:53<06:10, 14.02it/s]
2022-03-21 04:55:11,507 - INFO - tqdm - f1: 0.8333, accuracy: 0.8880, batch_loss: 0.2468, loss: 0.3083 ||:  55%|#####5    | 6205/11253 [07:03<05:38, 14.90it/s]
2022-03-21 04:55:21,556 - INFO - tqdm - f1: 0.8332, accuracy: 0.8879, batch_loss: 0.3030, loss: 0.3084 ||:  56%|#####6    | 6355/11253 [07:13<05:39, 14.41it/s]
2022-03-21 04:55:31,645 - INFO - tqdm - f1: 0.8332, accuracy: 0.8878, batch_loss: 0.2611, loss: 0.3083 ||:  58%|#####7    | 6503/11253 [07:23<05:53, 13.42it/s]
2022-03-21 04:55:41,667 - INFO - tqdm - f1: 0.8333, accuracy: 0.8877, batch_loss: 0.3255, loss: 0.3083 ||:  59%|#####9    | 6647/11253 [07:33<05:21, 14.34it/s]
2022-03-21 04:55:51,699 - INFO - tqdm - f1: 0.8335, accuracy: 0.8878, batch_loss: 0.4551, loss: 0.3083 ||:  60%|######    | 6797/11253 [07:43<05:05, 14.58it/s]
2022-03-21 04:56:01,772 - INFO - tqdm - f1: 0.8334, accuracy: 0.8878, batch_loss: 0.0794, loss: 0.3082 ||:  62%|######1   | 6947/11253 [07:53<05:01, 14.30it/s]
2022-03-21 04:56:11,807 - INFO - tqdm - f1: 0.8334, accuracy: 0.8878, batch_loss: 0.0177, loss: 0.3083 ||:  63%|######3   | 7095/11253 [08:03<04:37, 14.98it/s]
2022-03-21 04:56:21,844 - INFO - tqdm - f1: 0.8334, accuracy: 0.8879, batch_loss: 0.2473, loss: 0.3081 ||:  64%|######4   | 7241/11253 [08:13<04:32, 14.75it/s]
2022-03-21 04:56:31,885 - INFO - tqdm - f1: 0.8330, accuracy: 0.8878, batch_loss: 0.5226, loss: 0.3085 ||:  66%|######5   | 7383/11253 [08:23<04:25, 14.55it/s]
2022-03-21 04:56:41,886 - INFO - tqdm - f1: 0.8327, accuracy: 0.8875, batch_loss: 0.7980, loss: 0.3088 ||:  67%|######6   | 7531/11253 [08:33<04:21, 14.21it/s]
2022-03-21 04:56:51,939 - INFO - tqdm - f1: 0.8326, accuracy: 0.8875, batch_loss: 0.5540, loss: 0.3084 ||:  68%|######8   | 7681/11253 [08:43<03:56, 15.08it/s]
2022-03-21 04:57:02,004 - INFO - tqdm - f1: 0.8327, accuracy: 0.8876, batch_loss: 0.6535, loss: 0.3084 ||:  70%|######9   | 7833/11253 [08:53<03:43, 15.31it/s]
2022-03-21 04:57:12,028 - INFO - tqdm - f1: 0.8321, accuracy: 0.8872, batch_loss: 0.5342, loss: 0.3091 ||:  71%|#######   | 7981/11253 [09:03<03:42, 14.71it/s]
2022-03-21 04:57:22,059 - INFO - tqdm - f1: 0.8321, accuracy: 0.8873, batch_loss: 0.4195, loss: 0.3090 ||:  72%|#######2  | 8125/11253 [09:13<03:30, 14.89it/s]
2022-03-21 04:57:32,143 - INFO - tqdm - f1: 0.8320, accuracy: 0.8873, batch_loss: 0.1426, loss: 0.3092 ||:  74%|#######3  | 8275/11253 [09:23<03:19, 14.90it/s]
2022-03-21 04:57:42,239 - INFO - tqdm - f1: 0.8318, accuracy: 0.8871, batch_loss: 0.2481, loss: 0.3096 ||:  75%|#######4  | 8429/11253 [09:33<02:56, 15.99it/s]
2022-03-21 04:57:52,361 - INFO - tqdm - f1: 0.8319, accuracy: 0.8873, batch_loss: 0.1171, loss: 0.3094 ||:  76%|#######6  | 8579/11253 [09:44<02:59, 14.88it/s]
2022-03-21 04:58:02,382 - INFO - tqdm - f1: 0.8319, accuracy: 0.8874, batch_loss: 0.1488, loss: 0.3091 ||:  78%|#######7  | 8725/11253 [09:54<02:38, 15.93it/s]
2022-03-21 04:58:12,441 - INFO - tqdm - f1: 0.8318, accuracy: 0.8873, batch_loss: 0.0822, loss: 0.3091 ||:  79%|#######8  | 8875/11253 [10:04<02:37, 15.08it/s]
2022-03-21 04:58:22,575 - INFO - tqdm - f1: 0.8318, accuracy: 0.8874, batch_loss: 0.3483, loss: 0.3091 ||:  80%|########  | 9027/11253 [10:14<02:35, 14.34it/s]
2022-03-21 04:58:32,629 - INFO - tqdm - f1: 0.8320, accuracy: 0.8874, batch_loss: 0.0727, loss: 0.3088 ||:  82%|########1 | 9177/11253 [10:24<02:25, 14.31it/s]
2022-03-21 04:58:42,742 - INFO - tqdm - f1: 0.8318, accuracy: 0.8874, batch_loss: 0.1451, loss: 0.3089 ||:  83%|########2 | 9323/11253 [10:34<02:21, 13.69it/s]
2022-03-21 04:58:52,784 - INFO - tqdm - f1: 0.8317, accuracy: 0.8873, batch_loss: 0.3159, loss: 0.3093 ||:  84%|########4 | 9469/11253 [10:44<02:00, 14.77it/s]
2022-03-21 04:59:02,817 - INFO - tqdm - f1: 0.8317, accuracy: 0.8874, batch_loss: 0.0930, loss: 0.3091 ||:  85%|########5 | 9621/11253 [10:54<01:49, 14.89it/s]
2022-03-21 04:59:12,823 - INFO - tqdm - f1: 0.8317, accuracy: 0.8874, batch_loss: 0.0691, loss: 0.3089 ||:  87%|########6 | 9769/11253 [11:04<01:49, 13.57it/s]
2022-03-21 04:59:22,878 - INFO - tqdm - f1: 0.8315, accuracy: 0.8874, batch_loss: 0.3924, loss: 0.3089 ||:  88%|########8 | 9917/11253 [11:14<01:31, 14.65it/s]
2022-03-21 04:59:32,900 - INFO - tqdm - f1: 0.8316, accuracy: 0.8874, batch_loss: 0.1823, loss: 0.3091 ||:  89%|########9 | 10061/11253 [11:24<01:22, 14.39it/s]
2022-03-21 04:59:42,934 - INFO - tqdm - f1: 0.8315, accuracy: 0.8873, batch_loss: 0.2411, loss: 0.3089 ||:  91%|######### | 10207/11253 [11:34<01:10, 14.77it/s]
2022-03-21 04:59:53,022 - INFO - tqdm - f1: 0.8314, accuracy: 0.8873, batch_loss: 0.1027, loss: 0.3088 ||:  92%|#########2| 10359/11253 [11:44<01:03, 13.98it/s]
2022-03-21 05:00:03,058 - INFO - tqdm - f1: 0.8315, accuracy: 0.8874, batch_loss: 0.1210, loss: 0.3086 ||:  93%|#########3| 10509/11253 [11:54<00:51, 14.32it/s]
2022-03-21 05:00:13,104 - INFO - tqdm - f1: 0.8314, accuracy: 0.8873, batch_loss: 0.0674, loss: 0.3085 ||:  95%|#########4| 10655/11253 [12:04<00:42, 14.15it/s]
2022-03-21 05:00:23,232 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.3015, loss: 0.3083 ||:  96%|#########6| 10803/11253 [12:14<00:31, 14.38it/s]
2022-03-21 05:00:33,300 - INFO - tqdm - f1: 0.8313, accuracy: 0.8872, batch_loss: 0.2600, loss: 0.3088 ||:  97%|#########7| 10955/11253 [12:25<00:18, 15.71it/s]
2022-03-21 05:00:43,352 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.0520, loss: 0.3085 ||:  99%|#########8| 11103/11253 [12:35<00:10, 14.93it/s]
2022-03-21 05:00:49,774 - INFO - tqdm - f1: 0.8313, accuracy: 0.8873, batch_loss: 0.6227, loss: 0.3085 ||: 100%|#########9| 11197/11253 [12:41<00:03, 14.32it/s]
2022-03-21 05:00:49,905 - INFO - tqdm - f1: 0.8313, accuracy: 0.8873, batch_loss: 0.4837, loss: 0.3085 ||: 100%|#########9| 11199/11253 [12:41<00:03, 14.59it/s]
2022-03-21 05:00:50,027 - INFO - tqdm - f1: 0.8313, accuracy: 0.8873, batch_loss: 0.6045, loss: 0.3086 ||: 100%|#########9| 11201/11253 [12:41<00:03, 15.06it/s]
2022-03-21 05:00:50,165 - INFO - tqdm - f1: 0.8313, accuracy: 0.8873, batch_loss: 0.1183, loss: 0.3085 ||: 100%|#########9| 11203/11253 [12:41<00:03, 14.91it/s]
2022-03-21 05:00:50,295 - INFO - tqdm - f1: 0.8313, accuracy: 0.8873, batch_loss: 0.0921, loss: 0.3085 ||: 100%|#########9| 11205/11253 [12:42<00:03, 15.04it/s]
2022-03-21 05:00:50,417 - INFO - tqdm - f1: 0.8313, accuracy: 0.8873, batch_loss: 0.2987, loss: 0.3085 ||: 100%|#########9| 11207/11253 [12:42<00:02, 15.44it/s]
2022-03-21 05:00:50,561 - INFO - tqdm - f1: 0.8314, accuracy: 0.8873, batch_loss: 0.3597, loss: 0.3085 ||: 100%|#########9| 11209/11253 [12:42<00:02, 14.91it/s]
2022-03-21 05:00:50,712 - INFO - tqdm - f1: 0.8313, accuracy: 0.8873, batch_loss: 0.1754, loss: 0.3085 ||: 100%|#########9| 11211/11253 [12:42<00:02, 14.39it/s]
2022-03-21 05:00:50,866 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.1653, loss: 0.3084 ||: 100%|#########9| 11213/11253 [12:42<00:02, 13.93it/s]
2022-03-21 05:00:50,998 - INFO - tqdm - f1: 0.8313, accuracy: 0.8873, batch_loss: 0.3812, loss: 0.3085 ||: 100%|#########9| 11215/11253 [12:42<00:02, 14.28it/s]
2022-03-21 05:00:51,124 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.1367, loss: 0.3084 ||: 100%|#########9| 11217/11253 [12:42<00:02, 14.73it/s]
2022-03-21 05:00:51,254 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.1419, loss: 0.3084 ||: 100%|#########9| 11219/11253 [12:42<00:02, 14.90it/s]
2022-03-21 05:00:51,378 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.5455, loss: 0.3084 ||: 100%|#########9| 11221/11253 [12:43<00:02, 15.27it/s]
2022-03-21 05:00:51,502 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.3938, loss: 0.3084 ||: 100%|#########9| 11223/11253 [12:43<00:01, 15.49it/s]
2022-03-21 05:00:51,640 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.4234, loss: 0.3084 ||: 100%|#########9| 11225/11253 [12:43<00:01, 15.20it/s]
2022-03-21 05:00:51,775 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.1308, loss: 0.3084 ||: 100%|#########9| 11227/11253 [12:43<00:01, 15.05it/s]
2022-03-21 05:00:51,892 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.0653, loss: 0.3084 ||: 100%|#########9| 11229/11253 [12:43<00:01, 15.63it/s]
2022-03-21 05:00:52,022 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.5789, loss: 0.3084 ||: 100%|#########9| 11231/11253 [12:43<00:01, 15.55it/s]
2022-03-21 05:00:52,148 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.0708, loss: 0.3084 ||: 100%|#########9| 11233/11253 [12:43<00:01, 15.66it/s]
2022-03-21 05:00:52,275 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.2559, loss: 0.3084 ||: 100%|#########9| 11235/11253 [12:44<00:01, 15.68it/s]
2022-03-21 05:00:52,396 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.2466, loss: 0.3084 ||: 100%|#########9| 11237/11253 [12:44<00:01, 15.91it/s]
2022-03-21 05:00:52,529 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.3947, loss: 0.3084 ||: 100%|#########9| 11239/11253 [12:44<00:00, 15.65it/s]
2022-03-21 05:00:52,659 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.3575, loss: 0.3084 ||: 100%|#########9| 11241/11253 [12:44<00:00, 15.58it/s]
2022-03-21 05:00:52,818 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.2315, loss: 0.3084 ||: 100%|#########9| 11243/11253 [12:44<00:00, 14.53it/s]
2022-03-21 05:00:52,961 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.2380, loss: 0.3084 ||: 100%|#########9| 11245/11253 [12:44<00:00, 14.36it/s]
2022-03-21 05:00:53,085 - INFO - tqdm - f1: 0.8314, accuracy: 0.8874, batch_loss: 0.1259, loss: 0.3084 ||: 100%|#########9| 11247/11253 [12:44<00:00, 14.84it/s]
2022-03-21 05:00:53,219 - INFO - tqdm - f1: 0.8315, accuracy: 0.8874, batch_loss: 0.1385, loss: 0.3083 ||: 100%|#########9| 11249/11253 [12:44<00:00, 14.86it/s]
2022-03-21 05:00:53,373 - INFO - tqdm - f1: 0.8315, accuracy: 0.8874, batch_loss: 0.2011, loss: 0.3083 ||: 100%|#########9| 11251/11253 [12:45<00:00, 14.26it/s]
2022-03-21 05:00:53,498 - INFO - tqdm - f1: 0.8315, accuracy: 0.8874, batch_loss: 0.3165, loss: 0.3083 ||: 100%|##########| 11253/11253 [12:45<00:00, 14.73it/s]
2022-03-21 05:00:53,563 - INFO - tqdm - f1: 0.8315, accuracy: 0.8874, batch_loss: 0.3165, loss: 0.3083 ||: 100%|##########| 11253/11253 [12:45<00:00, 14.70it/s]
2022-03-21 05:00:53,569 - INFO - allennlp.training.trainer - Validating
2022-03-21 05:00:53,572 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 05:01:03,671 - INFO - tqdm - f1: 0.8229, accuracy: 0.8724, batch_loss: 0.2577, loss: 0.3779 ||:  22%|##2       | 423/1889 [00:10<00:36, 40.26it/s]
2022-03-21 05:01:13,796 - INFO - tqdm - f1: 0.8178, accuracy: 0.8736, batch_loss: 0.4330, loss: 0.3695 ||:  45%|####4     | 848/1889 [00:20<00:27, 37.84it/s]
2022-03-21 05:01:23,842 - INFO - tqdm - f1: 0.8188, accuracy: 0.8734, batch_loss: 0.0522, loss: 0.3755 ||:  69%|######8   | 1295/1889 [00:30<00:14, 41.75it/s]
2022-03-21 05:01:33,885 - INFO - tqdm - f1: 0.8183, accuracy: 0.8738, batch_loss: 0.5442, loss: 0.3746 ||:  92%|#########2| 1747/1889 [00:40<00:03, 39.65it/s]
2022-03-21 05:01:36,814 - INFO - tqdm - f1: 0.8188, accuracy: 0.8742, batch_loss: 0.7485, loss: 0.3746 ||: 100%|#########9| 1881/1889 [00:43<00:00, 40.92it/s]
2022-03-21 05:01:36,966 - INFO - tqdm - f1: 0.8189, accuracy: 0.8743, batch_loss: 0.4292, loss: 0.3745 ||: 100%|#########9| 1886/1889 [00:43<00:00, 38.35it/s]
2022-03-21 05:01:37,042 - INFO - tqdm - f1: 0.8191, accuracy: 0.8744, batch_loss: 0.2144, loss: 0.3741 ||: 100%|##########| 1889/1889 [00:43<00:00, 43.46it/s]
2022-03-21 05:01:37,050 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct-20k_base_hyper_small_seed_177/best.th'.
2022-03-21 05:01:39,423 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 05:01:39,424 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.887  |     0.874
2022-03-21 05:01:39,425 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.831  |     0.819
2022-03-21 05:01:39,427 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 05:01:39,428 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.308  |     0.374
2022-03-21 05:01:39,430 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8641.746  |       N/A
2022-03-21 05:01:39,431 - INFO - allennlp.training.trainer - Epoch duration: 0:13:31.165192
2022-03-21 05:01:39,432 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:47:22
2022-03-21 05:01:39,433 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-21 05:01:39,435 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 05:01:39,436 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 05:01:39,439 - INFO - allennlp.training.trainer - Training
2022-03-21 05:01:39,440 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 05:01:49,503 - INFO - tqdm - f1: 0.8514, accuracy: 0.8993, batch_loss: 0.3307, loss: 0.2884 ||:   1%|1         | 131/11253 [00:10<12:31, 14.80it/s]
2022-03-21 05:01:59,623 - INFO - tqdm - f1: 0.8491, accuracy: 0.9024, batch_loss: 0.1636, loss: 0.2723 ||:   2%|2         | 281/11253 [00:20<12:34, 14.54it/s]
2022-03-21 05:02:09,705 - INFO - tqdm - f1: 0.8465, accuracy: 0.9004, batch_loss: 0.2543, loss: 0.2732 ||:   4%|3         | 431/11253 [00:30<12:17, 14.67it/s]
2022-03-21 05:02:19,796 - INFO - tqdm - f1: 0.8484, accuracy: 0.9014, batch_loss: 0.5026, loss: 0.2706 ||:   5%|5         | 585/11253 [00:40<11:26, 15.54it/s]
2022-03-21 05:02:29,808 - INFO - tqdm - f1: 0.8509, accuracy: 0.9026, batch_loss: 0.1412, loss: 0.2702 ||:   7%|6         | 733/11253 [00:50<12:06, 14.48it/s]
2022-03-21 05:02:39,852 - INFO - tqdm - f1: 0.8534, accuracy: 0.9041, batch_loss: 0.1392, loss: 0.2649 ||:   8%|7         | 877/11253 [01:00<12:14, 14.13it/s]
2022-03-21 05:02:49,854 - INFO - tqdm - f1: 0.8506, accuracy: 0.9025, batch_loss: 0.0595, loss: 0.2675 ||:   9%|9         | 1029/11253 [01:10<11:54, 14.31it/s]
2022-03-21 05:02:59,883 - INFO - tqdm - f1: 0.8495, accuracy: 0.9022, batch_loss: 0.2138, loss: 0.2681 ||:  10%|#         | 1179/11253 [01:20<11:34, 14.51it/s]
2022-03-21 05:03:09,945 - INFO - tqdm - f1: 0.8494, accuracy: 0.9023, batch_loss: 0.1179, loss: 0.2673 ||:  12%|#1        | 1329/11253 [01:30<11:22, 14.55it/s]
2022-03-21 05:03:19,951 - INFO - tqdm - f1: 0.8504, accuracy: 0.9028, batch_loss: 0.5808, loss: 0.2658 ||:  13%|#3        | 1471/11253 [01:40<11:58, 13.62it/s]
2022-03-21 05:03:29,981 - INFO - tqdm - f1: 0.8487, accuracy: 0.9022, batch_loss: 0.2110, loss: 0.2675 ||:  14%|#4        | 1617/11253 [01:50<11:07, 14.44it/s]
2022-03-21 05:03:40,021 - INFO - tqdm - f1: 0.8475, accuracy: 0.9013, batch_loss: 0.2256, loss: 0.2701 ||:  16%|#5        | 1767/11253 [02:00<10:48, 14.62it/s]
2022-03-21 05:03:50,059 - INFO - tqdm - f1: 0.8482, accuracy: 0.9014, batch_loss: 0.1736, loss: 0.2699 ||:  17%|#7        | 1919/11253 [02:10<10:23, 14.96it/s]
2022-03-21 05:04:00,061 - INFO - tqdm - f1: 0.8481, accuracy: 0.9012, batch_loss: 0.0214, loss: 0.2700 ||:  18%|#8        | 2067/11253 [02:20<10:26, 14.67it/s]
2022-03-21 05:04:10,103 - INFO - tqdm - f1: 0.8482, accuracy: 0.9015, batch_loss: 0.7420, loss: 0.2705 ||:  20%|#9        | 2215/11253 [02:30<11:34, 13.02it/s]
2022-03-21 05:04:20,161 - INFO - tqdm - f1: 0.8489, accuracy: 0.9017, batch_loss: 0.2962, loss: 0.2702 ||:  21%|##1       | 2365/11253 [02:40<10:11, 14.55it/s]
2022-03-21 05:04:30,238 - INFO - tqdm - f1: 0.8479, accuracy: 0.9010, batch_loss: 0.0905, loss: 0.2723 ||:  22%|##2       | 2511/11253 [02:50<09:34, 15.21it/s]
2022-03-21 05:04:40,311 - INFO - tqdm - f1: 0.8479, accuracy: 0.9011, batch_loss: 0.4126, loss: 0.2720 ||:  24%|##3       | 2661/11253 [03:00<09:25, 15.18it/s]
2022-03-21 05:04:50,349 - INFO - tqdm - f1: 0.8482, accuracy: 0.9010, batch_loss: 0.2475, loss: 0.2711 ||:  25%|##4       | 2809/11253 [03:10<09:41, 14.52it/s]
2022-03-21 05:05:00,474 - INFO - tqdm - f1: 0.8489, accuracy: 0.9015, batch_loss: 0.1229, loss: 0.2700 ||:  26%|##6       | 2955/11253 [03:21<09:25, 14.67it/s]
2022-03-21 05:05:10,614 - INFO - tqdm - f1: 0.8483, accuracy: 0.9015, batch_loss: 0.9002, loss: 0.2706 ||:  28%|##7       | 3101/11253 [03:31<09:15, 14.68it/s]
2022-03-21 05:05:20,718 - INFO - tqdm - f1: 0.8480, accuracy: 0.9011, batch_loss: 0.1078, loss: 0.2711 ||:  29%|##8       | 3251/11253 [03:41<08:34, 15.56it/s]
2022-03-21 05:05:30,723 - INFO - tqdm - f1: 0.8482, accuracy: 0.9012, batch_loss: 0.0852, loss: 0.2711 ||:  30%|###       | 3399/11253 [03:51<09:03, 14.45it/s]
2022-03-21 05:05:40,864 - INFO - tqdm - f1: 0.8479, accuracy: 0.9010, batch_loss: 0.2142, loss: 0.2719 ||:  32%|###1      | 3547/11253 [04:01<08:32, 15.03it/s]
2022-03-21 05:05:51,016 - INFO - tqdm - f1: 0.8481, accuracy: 0.9009, batch_loss: 0.2707, loss: 0.2722 ||:  33%|###2      | 3693/11253 [04:11<09:04, 13.89it/s]
2022-03-21 05:06:01,140 - INFO - tqdm - f1: 0.8479, accuracy: 0.9012, batch_loss: 0.3624, loss: 0.2718 ||:  34%|###4      | 3841/11253 [04:21<08:56, 13.81it/s]
2022-03-21 05:06:11,189 - INFO - tqdm - f1: 0.8481, accuracy: 0.9009, batch_loss: 0.2595, loss: 0.2721 ||:  35%|###5      | 3989/11253 [04:31<08:29, 14.26it/s]
2022-03-21 05:06:21,305 - INFO - tqdm - f1: 0.8481, accuracy: 0.9009, batch_loss: 0.3261, loss: 0.2723 ||:  37%|###6      | 4139/11253 [04:41<08:08, 14.58it/s]
2022-03-21 05:06:31,450 - INFO - tqdm - f1: 0.8480, accuracy: 0.9007, batch_loss: 0.4670, loss: 0.2725 ||:  38%|###8      | 4289/11253 [04:52<08:10, 14.20it/s]
2022-03-21 05:06:41,571 - INFO - tqdm - f1: 0.8480, accuracy: 0.9007, batch_loss: 0.3953, loss: 0.2723 ||:  39%|###9      | 4439/11253 [05:02<07:22, 15.39it/s]
2022-03-21 05:06:51,676 - INFO - tqdm - f1: 0.8484, accuracy: 0.9006, batch_loss: 0.3107, loss: 0.2727 ||:  41%|####      | 4589/11253 [05:12<07:05, 15.67it/s]
2022-03-21 05:07:01,790 - INFO - tqdm - f1: 0.8482, accuracy: 0.9005, batch_loss: 0.2192, loss: 0.2734 ||:  42%|####2     | 4739/11253 [05:22<07:30, 14.45it/s]
2022-03-21 05:07:11,906 - INFO - tqdm - f1: 0.8480, accuracy: 0.9004, batch_loss: 0.1285, loss: 0.2731 ||:  43%|####3     | 4885/11253 [05:32<07:15, 14.61it/s]
2022-03-21 05:07:22,028 - INFO - tqdm - f1: 0.8480, accuracy: 0.9005, batch_loss: 0.3789, loss: 0.2730 ||:  45%|####4     | 5037/11253 [05:42<07:20, 14.12it/s]
2022-03-21 05:07:32,091 - INFO - tqdm - f1: 0.8480, accuracy: 0.9006, batch_loss: 0.5074, loss: 0.2735 ||:  46%|####6     | 5183/11253 [05:52<06:46, 14.95it/s]
2022-03-21 05:07:42,145 - INFO - tqdm - f1: 0.8481, accuracy: 0.9005, batch_loss: 0.3147, loss: 0.2743 ||:  47%|####7     | 5335/11253 [06:02<06:19, 15.58it/s]
2022-03-21 05:07:52,251 - INFO - tqdm - f1: 0.8482, accuracy: 0.9007, batch_loss: 0.0427, loss: 0.2741 ||:  49%|####8     | 5483/11253 [06:12<06:34, 14.61it/s]
2022-03-21 05:08:02,252 - INFO - tqdm - f1: 0.8481, accuracy: 0.9006, batch_loss: 0.2881, loss: 0.2742 ||:  50%|#####     | 5629/11253 [06:22<06:28, 14.46it/s]
2022-03-21 05:08:12,283 - INFO - tqdm - f1: 0.8478, accuracy: 0.9005, batch_loss: 0.4374, loss: 0.2741 ||:  51%|#####1    | 5777/11253 [06:32<06:11, 14.75it/s]
2022-03-21 05:08:22,375 - INFO - tqdm - f1: 0.8480, accuracy: 0.9007, batch_loss: 0.5298, loss: 0.2737 ||:  53%|#####2    | 5925/11253 [06:42<06:13, 14.27it/s]
2022-03-21 05:08:32,416 - INFO - tqdm - f1: 0.8483, accuracy: 0.9009, batch_loss: 0.1815, loss: 0.2732 ||:  54%|#####4    | 6077/11253 [06:52<05:39, 15.26it/s]
2022-03-21 05:08:42,474 - INFO - tqdm - f1: 0.8484, accuracy: 0.9009, batch_loss: 0.4695, loss: 0.2732 ||:  55%|#####5    | 6225/11253 [07:03<05:33, 15.10it/s]
2022-03-21 05:08:52,532 - INFO - tqdm - f1: 0.8480, accuracy: 0.9006, batch_loss: 0.5210, loss: 0.2742 ||:  57%|#####6    | 6379/11253 [07:13<05:21, 15.14it/s]
2022-03-21 05:09:02,646 - INFO - tqdm - f1: 0.8478, accuracy: 0.9003, batch_loss: 0.0831, loss: 0.2750 ||:  58%|#####8    | 6527/11253 [07:23<05:09, 15.27it/s]
2022-03-21 05:09:12,748 - INFO - tqdm - f1: 0.8480, accuracy: 0.9003, batch_loss: 0.2069, loss: 0.2748 ||:  59%|#####9    | 6677/11253 [07:33<04:45, 16.04it/s]
2022-03-21 05:09:22,753 - INFO - tqdm - f1: 0.8477, accuracy: 0.9001, batch_loss: 0.4596, loss: 0.2750 ||:  61%|######    | 6825/11253 [07:43<04:48, 15.35it/s]
2022-03-21 05:09:32,840 - INFO - tqdm - f1: 0.8477, accuracy: 0.9000, batch_loss: 0.0649, loss: 0.2751 ||:  62%|######1   | 6971/11253 [07:53<04:30, 15.81it/s]
2022-03-21 05:09:42,852 - INFO - tqdm - f1: 0.8479, accuracy: 0.9000, batch_loss: 0.1946, loss: 0.2752 ||:  63%|######3   | 7121/11253 [08:03<04:28, 15.40it/s]
2022-03-21 05:09:52,909 - INFO - tqdm - f1: 0.8480, accuracy: 0.9000, batch_loss: 0.2938, loss: 0.2752 ||:  65%|######4   | 7271/11253 [08:13<04:23, 15.13it/s]
2022-03-21 05:10:03,042 - INFO - tqdm - f1: 0.8481, accuracy: 0.9002, batch_loss: 0.1407, loss: 0.2747 ||:  66%|######5   | 7421/11253 [08:23<04:24, 14.47it/s]
2022-03-21 05:10:13,189 - INFO - tqdm - f1: 0.8479, accuracy: 0.9001, batch_loss: 0.4757, loss: 0.2747 ||:  67%|######7   | 7569/11253 [08:33<04:36, 13.30it/s]
2022-03-21 05:10:23,305 - INFO - tqdm - f1: 0.8479, accuracy: 0.9002, batch_loss: 0.0765, loss: 0.2745 ||:  69%|######8   | 7719/11253 [08:43<04:08, 14.22it/s]
2022-03-21 05:10:33,373 - INFO - tqdm - f1: 0.8479, accuracy: 0.9001, batch_loss: 0.2735, loss: 0.2747 ||:  70%|######9   | 7867/11253 [08:53<03:54, 14.44it/s]
2022-03-21 05:10:43,392 - INFO - tqdm - f1: 0.8480, accuracy: 0.9002, batch_loss: 0.2618, loss: 0.2746 ||:  71%|#######1  | 8015/11253 [09:03<03:39, 14.77it/s]
2022-03-21 05:10:53,406 - INFO - tqdm - f1: 0.8479, accuracy: 0.9002, batch_loss: 0.0538, loss: 0.2748 ||:  73%|#######2  | 8161/11253 [09:13<03:37, 14.23it/s]
2022-03-21 05:11:03,526 - INFO - tqdm - f1: 0.8479, accuracy: 0.9001, batch_loss: 0.2640, loss: 0.2750 ||:  74%|#######3  | 8307/11253 [09:24<03:17, 14.90it/s]
2022-03-21 05:11:13,562 - INFO - tqdm - f1: 0.8478, accuracy: 0.9001, batch_loss: 0.4762, loss: 0.2750 ||:  75%|#######5  | 8457/11253 [09:34<03:08, 14.87it/s]
2022-03-21 05:11:23,688 - INFO - tqdm - f1: 0.8479, accuracy: 0.9000, batch_loss: 0.0737, loss: 0.2754 ||:  76%|#######6  | 8605/11253 [09:44<03:03, 14.40it/s]
2022-03-21 05:11:33,809 - INFO - tqdm - f1: 0.8478, accuracy: 0.9000, batch_loss: 0.0625, loss: 0.2752 ||:  78%|#######7  | 8757/11253 [09:54<02:41, 15.48it/s]
2022-03-21 05:11:43,911 - INFO - tqdm - f1: 0.8478, accuracy: 0.8999, batch_loss: 0.2089, loss: 0.2754 ||:  79%|#######9  | 8903/11253 [10:04<02:38, 14.81it/s]
2022-03-21 05:11:54,003 - INFO - tqdm - f1: 0.8479, accuracy: 0.8998, batch_loss: 0.4213, loss: 0.2754 ||:  80%|########  | 9053/11253 [10:14<02:20, 15.65it/s]
2022-03-21 05:12:04,014 - INFO - tqdm - f1: 0.8477, accuracy: 0.8997, batch_loss: 0.2456, loss: 0.2757 ||:  82%|########1 | 9203/11253 [10:24<02:18, 14.80it/s]
2022-03-21 05:12:14,060 - INFO - tqdm - f1: 0.8475, accuracy: 0.8996, batch_loss: 0.2538, loss: 0.2757 ||:  83%|########3 | 9351/11253 [10:34<02:03, 15.45it/s]
2022-03-21 05:12:24,064 - INFO - tqdm - f1: 0.8474, accuracy: 0.8995, batch_loss: 0.2957, loss: 0.2760 ||:  84%|########4 | 9501/11253 [10:44<01:57, 14.86it/s]
2022-03-21 05:12:34,140 - INFO - tqdm - f1: 0.8474, accuracy: 0.8995, batch_loss: 0.2297, loss: 0.2759 ||:  86%|########5 | 9649/11253 [10:54<01:48, 14.79it/s]
2022-03-21 05:12:44,218 - INFO - tqdm - f1: 0.8474, accuracy: 0.8996, batch_loss: 0.3858, loss: 0.2759 ||:  87%|########7 | 9799/11253 [11:04<01:32, 15.75it/s]
2022-03-21 05:12:54,237 - INFO - tqdm - f1: 0.8472, accuracy: 0.8996, batch_loss: 0.1337, loss: 0.2758 ||:  88%|########8 | 9949/11253 [11:14<01:29, 14.52it/s]
2022-03-21 05:13:04,355 - INFO - tqdm - f1: 0.8471, accuracy: 0.8996, batch_loss: 0.1463, loss: 0.2758 ||:  90%|########9 | 10099/11253 [11:24<01:14, 15.42it/s]
2022-03-21 05:13:14,371 - INFO - tqdm - f1: 0.8470, accuracy: 0.8995, batch_loss: 0.0776, loss: 0.2757 ||:  91%|#########1| 10249/11253 [11:34<01:09, 14.35it/s]
2022-03-21 05:13:24,477 - INFO - tqdm - f1: 0.8468, accuracy: 0.8995, batch_loss: 0.1614, loss: 0.2759 ||:  92%|#########2| 10395/11253 [11:45<01:01, 13.90it/s]
2022-03-21 05:13:34,491 - INFO - tqdm - f1: 0.8469, accuracy: 0.8995, batch_loss: 0.1264, loss: 0.2760 ||:  94%|#########3| 10541/11253 [11:55<00:52, 13.57it/s]
2022-03-21 05:13:44,514 - INFO - tqdm - f1: 0.8465, accuracy: 0.8993, batch_loss: 0.1302, loss: 0.2762 ||:  95%|#########5| 10691/11253 [12:05<00:37, 15.11it/s]
2022-03-21 05:13:54,526 - INFO - tqdm - f1: 0.8465, accuracy: 0.8993, batch_loss: 0.2525, loss: 0.2764 ||:  96%|#########6| 10837/11253 [12:15<00:30, 13.65it/s]
2022-03-21 05:14:04,537 - INFO - tqdm - f1: 0.8466, accuracy: 0.8994, batch_loss: 0.3234, loss: 0.2763 ||:  98%|#########7| 10983/11253 [12:25<00:19, 13.94it/s]
2022-03-21 05:14:14,619 - INFO - tqdm - f1: 0.8465, accuracy: 0.8993, batch_loss: 0.5804, loss: 0.2766 ||:  99%|#########8| 11131/11253 [12:35<00:08, 14.82it/s]
2022-03-21 05:14:19,109 - INFO - tqdm - f1: 0.8465, accuracy: 0.8993, batch_loss: 0.1603, loss: 0.2764 ||: 100%|#########9| 11197/11253 [12:39<00:03, 15.28it/s]
2022-03-21 05:14:19,256 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.1057, loss: 0.2764 ||: 100%|#########9| 11199/11253 [12:39<00:03, 14.76it/s]
2022-03-21 05:14:19,399 - INFO - tqdm - f1: 0.8465, accuracy: 0.8993, batch_loss: 0.2676, loss: 0.2764 ||: 100%|#########9| 11201/11253 [12:39<00:03, 14.50it/s]
2022-03-21 05:14:19,541 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.1279, loss: 0.2763 ||: 100%|#########9| 11203/11253 [12:40<00:03, 14.36it/s]
2022-03-21 05:14:19,680 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.1916, loss: 0.2763 ||: 100%|#########9| 11205/11253 [12:40<00:03, 14.40it/s]
2022-03-21 05:14:19,810 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.2602, loss: 0.2763 ||: 100%|#########9| 11207/11253 [12:40<00:03, 14.65it/s]
2022-03-21 05:14:19,947 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.2650, loss: 0.2763 ||: 100%|#########9| 11209/11253 [12:40<00:03, 14.66it/s]
2022-03-21 05:14:20,087 - INFO - tqdm - f1: 0.8465, accuracy: 0.8993, batch_loss: 0.3597, loss: 0.2764 ||: 100%|#########9| 11211/11253 [12:40<00:02, 14.53it/s]
2022-03-21 05:14:20,244 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.2467, loss: 0.2764 ||: 100%|#########9| 11213/11253 [12:40<00:02, 13.95it/s]
2022-03-21 05:14:20,406 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.5201, loss: 0.2764 ||: 100%|#########9| 11215/11253 [12:40<00:02, 13.41it/s]
2022-03-21 05:14:20,544 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.0828, loss: 0.2764 ||: 100%|#########9| 11217/11253 [12:41<00:02, 13.74it/s]
2022-03-21 05:14:20,698 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.3996, loss: 0.2765 ||: 100%|#########9| 11219/11253 [12:41<00:02, 13.51it/s]
2022-03-21 05:14:20,824 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.1299, loss: 0.2765 ||: 100%|#########9| 11221/11253 [12:41<00:02, 14.14it/s]
2022-03-21 05:14:20,948 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.1198, loss: 0.2764 ||: 100%|#########9| 11223/11253 [12:41<00:02, 14.67it/s]
2022-03-21 05:14:21,074 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.4033, loss: 0.2764 ||: 100%|#########9| 11225/11253 [12:41<00:01, 15.00it/s]
2022-03-21 05:14:21,218 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.5602, loss: 0.2765 ||: 100%|#########9| 11227/11253 [12:41<00:01, 14.67it/s]
2022-03-21 05:14:21,375 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.3597, loss: 0.2765 ||: 100%|#########9| 11229/11253 [12:41<00:01, 14.01it/s]
2022-03-21 05:14:21,502 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.0359, loss: 0.2764 ||: 100%|#########9| 11231/11253 [12:42<00:01, 14.49it/s]
2022-03-21 05:14:21,634 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.2884, loss: 0.2764 ||: 100%|#########9| 11233/11253 [12:42<00:01, 14.68it/s]
2022-03-21 05:14:21,778 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.1895, loss: 0.2764 ||: 100%|#########9| 11235/11253 [12:42<00:01, 14.44it/s]
2022-03-21 05:14:21,915 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.3805, loss: 0.2764 ||: 100%|#########9| 11237/11253 [12:42<00:01, 14.50it/s]
2022-03-21 05:14:22,046 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.1362, loss: 0.2764 ||: 100%|#########9| 11239/11253 [12:42<00:00, 14.71it/s]
2022-03-21 05:14:22,190 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.2492, loss: 0.2764 ||: 100%|#########9| 11241/11253 [12:42<00:00, 14.46it/s]
2022-03-21 05:14:22,351 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.1507, loss: 0.2764 ||: 100%|#########9| 11243/11253 [12:42<00:00, 13.78it/s]
2022-03-21 05:14:22,520 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.0809, loss: 0.2764 ||: 100%|#########9| 11245/11253 [12:43<00:00, 13.12it/s]
2022-03-21 05:14:22,650 - INFO - tqdm - f1: 0.8467, accuracy: 0.8993, batch_loss: 0.1255, loss: 0.2764 ||: 100%|#########9| 11247/11253 [12:43<00:00, 13.74it/s]
2022-03-21 05:14:22,788 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.4860, loss: 0.2764 ||: 100%|#########9| 11249/11253 [12:43<00:00, 13.95it/s]
2022-03-21 05:14:22,915 - INFO - tqdm - f1: 0.8466, accuracy: 0.8993, batch_loss: 0.6095, loss: 0.2764 ||: 100%|#########9| 11251/11253 [12:43<00:00, 14.45it/s]
2022-03-21 05:14:23,046 - INFO - tqdm - f1: 0.8467, accuracy: 0.8993, batch_loss: 0.1471, loss: 0.2764 ||: 100%|##########| 11253/11253 [12:43<00:00, 14.68it/s]
2022-03-21 05:14:23,110 - INFO - tqdm - f1: 0.8467, accuracy: 0.8993, batch_loss: 0.1471, loss: 0.2764 ||: 100%|##########| 11253/11253 [12:43<00:00, 14.74it/s]
2022-03-21 05:14:23,118 - INFO - allennlp.training.trainer - Validating
2022-03-21 05:14:23,120 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 05:14:33,208 - INFO - tqdm - f1: 0.8053, accuracy: 0.8679, batch_loss: 0.9047, loss: 0.3804 ||:  23%|##3       | 437/1889 [00:10<00:36, 39.81it/s]
2022-03-21 05:14:43,313 - INFO - tqdm - f1: 0.8110, accuracy: 0.8700, batch_loss: 0.3696, loss: 0.3742 ||:  46%|####5     | 863/1889 [00:20<00:28, 36.61it/s]
2022-03-21 05:14:53,418 - INFO - tqdm - f1: 0.8088, accuracy: 0.8672, batch_loss: 0.2742, loss: 0.3835 ||:  68%|######7   | 1278/1889 [00:30<00:15, 39.62it/s]
2022-03-21 05:15:03,479 - INFO - tqdm - f1: 0.8082, accuracy: 0.8662, batch_loss: 1.1522, loss: 0.3864 ||:  91%|######### | 1717/1889 [00:40<00:03, 43.63it/s]
2022-03-21 05:15:07,175 - INFO - tqdm - f1: 0.8071, accuracy: 0.8655, batch_loss: 0.3474, loss: 0.3886 ||: 100%|#########9| 1884/1889 [00:44<00:00, 47.03it/s]
2022-03-21 05:15:07,344 - INFO - tqdm - f1: 0.8073, accuracy: 0.8657, batch_loss: 0.0555, loss: 0.3881 ||: 100%|##########| 1889/1889 [00:44<00:00, 40.59it/s]
2022-03-21 05:15:07,354 - INFO - tqdm - f1: 0.8073, accuracy: 0.8657, batch_loss: 0.0555, loss: 0.3881 ||: 100%|##########| 1889/1889 [00:44<00:00, 42.71it/s]
2022-03-21 05:15:07,363 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 05:15:07,365 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.899  |     0.866
2022-03-21 05:15:07,366 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.847  |     0.807
2022-03-21 05:15:07,367 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 05:15:07,368 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.276  |     0.388
2022-03-21 05:15:07,369 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8642.188  |       N/A
2022-03-21 05:15:07,371 - INFO - allennlp.training.trainer - Epoch duration: 0:13:27.937310
2022-03-21 05:15:07,372 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:29:13
2022-03-21 05:15:07,373 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-21 05:15:07,375 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 05:15:07,376 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 05:15:07,379 - INFO - allennlp.training.trainer - Training
2022-03-21 05:15:07,380 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 05:15:17,437 - INFO - tqdm - f1: 0.8784, accuracy: 0.9227, batch_loss: 0.0297, loss: 0.2276 ||:   1%|1         | 135/11253 [00:10<12:47, 14.48it/s]
2022-03-21 05:15:27,507 - INFO - tqdm - f1: 0.8651, accuracy: 0.9149, batch_loss: 0.6828, loss: 0.2425 ||:   3%|2         | 285/11253 [00:20<12:17, 14.88it/s]
2022-03-21 05:15:37,630 - INFO - tqdm - f1: 0.8654, accuracy: 0.9166, batch_loss: 0.1846, loss: 0.2339 ||:   4%|3         | 433/11253 [00:30<12:43, 14.17it/s]
2022-03-21 05:15:47,663 - INFO - tqdm - f1: 0.8643, accuracy: 0.9180, batch_loss: 0.3846, loss: 0.2290 ||:   5%|5         | 583/11253 [00:40<12:26, 14.29it/s]
2022-03-21 05:15:57,736 - INFO - tqdm - f1: 0.8616, accuracy: 0.9151, batch_loss: 0.1732, loss: 0.2362 ||:   6%|6         | 731/11253 [00:50<11:42, 14.99it/s]
2022-03-21 05:16:07,838 - INFO - tqdm - f1: 0.8619, accuracy: 0.9156, batch_loss: 0.2034, loss: 0.2374 ||:   8%|7         | 881/11253 [01:00<11:27, 15.09it/s]
2022-03-21 05:16:17,844 - INFO - tqdm - f1: 0.8604, accuracy: 0.9146, batch_loss: 0.2687, loss: 0.2381 ||:   9%|9         | 1027/11253 [01:10<11:57, 14.26it/s]
2022-03-21 05:16:27,884 - INFO - tqdm - f1: 0.8611, accuracy: 0.9150, batch_loss: 0.3674, loss: 0.2365 ||:  10%|#         | 1175/11253 [01:20<10:58, 15.31it/s]
2022-03-21 05:16:37,932 - INFO - tqdm - f1: 0.8639, accuracy: 0.9161, batch_loss: 0.0587, loss: 0.2367 ||:  12%|#1        | 1327/11253 [01:30<10:19, 16.02it/s]
2022-03-21 05:16:48,028 - INFO - tqdm - f1: 0.8653, accuracy: 0.9164, batch_loss: 0.3189, loss: 0.2363 ||:  13%|#3        | 1481/11253 [01:40<10:31, 15.46it/s]
2022-03-21 05:16:58,101 - INFO - tqdm - f1: 0.8633, accuracy: 0.9157, batch_loss: 0.5731, loss: 0.2373 ||:  14%|#4        | 1631/11253 [01:50<10:38, 15.08it/s]
2022-03-21 05:17:08,187 - INFO - tqdm - f1: 0.8637, accuracy: 0.9158, batch_loss: 0.3588, loss: 0.2362 ||:  16%|#5        | 1779/11253 [02:00<10:35, 14.90it/s]
2022-03-21 05:17:18,267 - INFO - tqdm - f1: 0.8643, accuracy: 0.9164, batch_loss: 0.1848, loss: 0.2336 ||:  17%|#7        | 1931/11253 [02:10<10:25, 14.89it/s]
2022-03-21 05:17:28,270 - INFO - tqdm - f1: 0.8647, accuracy: 0.9167, batch_loss: 0.1527, loss: 0.2328 ||:  18%|#8        | 2077/11253 [02:20<09:53, 15.46it/s]
2022-03-21 05:17:38,354 - INFO - tqdm - f1: 0.8654, accuracy: 0.9166, batch_loss: 0.2396, loss: 0.2334 ||:  20%|#9        | 2227/11253 [02:30<10:01, 15.00it/s]
2022-03-21 05:17:48,374 - INFO - tqdm - f1: 0.8654, accuracy: 0.9163, batch_loss: 0.0783, loss: 0.2344 ||:  21%|##1       | 2371/11253 [02:40<10:46, 13.75it/s]
2022-03-21 05:17:58,494 - INFO - tqdm - f1: 0.8647, accuracy: 0.9159, batch_loss: 0.3302, loss: 0.2353 ||:  22%|##2       | 2517/11253 [02:51<09:44, 14.95it/s]
2022-03-21 05:18:08,546 - INFO - tqdm - f1: 0.8646, accuracy: 0.9158, batch_loss: 0.3014, loss: 0.2360 ||:  24%|##3       | 2667/11253 [03:01<10:00, 14.29it/s]
2022-03-21 05:18:18,575 - INFO - tqdm - f1: 0.8644, accuracy: 0.9154, batch_loss: 0.2365, loss: 0.2365 ||:  25%|##5       | 2817/11253 [03:11<10:13, 13.75it/s]
2022-03-21 05:18:28,649 - INFO - tqdm - f1: 0.8649, accuracy: 0.9153, batch_loss: 0.6838, loss: 0.2371 ||:  26%|##6       | 2967/11253 [03:21<09:34, 14.42it/s]
2022-03-21 05:18:38,740 - INFO - tqdm - f1: 0.8652, accuracy: 0.9155, batch_loss: 0.1107, loss: 0.2360 ||:  28%|##7       | 3111/11253 [03:31<09:32, 14.22it/s]
2022-03-21 05:18:48,812 - INFO - tqdm - f1: 0.8653, accuracy: 0.9151, batch_loss: 0.0972, loss: 0.2372 ||:  29%|##8       | 3257/11253 [03:41<08:53, 14.99it/s]
2022-03-21 05:18:58,884 - INFO - tqdm - f1: 0.8653, accuracy: 0.9153, batch_loss: 0.1442, loss: 0.2362 ||:  30%|###       | 3405/11253 [03:51<08:26, 15.50it/s]
2022-03-21 05:19:08,894 - INFO - tqdm - f1: 0.8651, accuracy: 0.9153, batch_loss: 0.0734, loss: 0.2361 ||:  32%|###1      | 3553/11253 [04:01<08:18, 15.44it/s]
2022-03-21 05:19:18,969 - INFO - tqdm - f1: 0.8651, accuracy: 0.9153, batch_loss: 0.3005, loss: 0.2358 ||:  33%|###2      | 3699/11253 [04:11<08:46, 14.35it/s]
2022-03-21 05:19:29,095 - INFO - tqdm - f1: 0.8642, accuracy: 0.9147, batch_loss: 0.7426, loss: 0.2372 ||:  34%|###4      | 3843/11253 [04:21<08:48, 14.02it/s]
2022-03-21 05:19:39,096 - INFO - tqdm - f1: 0.8643, accuracy: 0.9146, batch_loss: 0.0072, loss: 0.2376 ||:  35%|###5      | 3991/11253 [04:31<07:54, 15.30it/s]
2022-03-21 05:19:49,125 - INFO - tqdm - f1: 0.8646, accuracy: 0.9145, batch_loss: 0.2255, loss: 0.2377 ||:  37%|###6      | 4137/11253 [04:41<07:49, 15.15it/s]
2022-03-21 05:19:59,177 - INFO - tqdm - f1: 0.8645, accuracy: 0.9143, batch_loss: 0.5145, loss: 0.2380 ||:  38%|###8      | 4287/11253 [04:51<07:31, 15.41it/s]
2022-03-21 05:20:09,222 - INFO - tqdm - f1: 0.8642, accuracy: 0.9142, batch_loss: 0.1562, loss: 0.2381 ||:  39%|###9      | 4431/11253 [05:01<07:59, 14.23it/s]
2022-03-21 05:20:19,261 - INFO - tqdm - f1: 0.8643, accuracy: 0.9142, batch_loss: 0.0077, loss: 0.2379 ||:  41%|####      | 4579/11253 [05:11<07:13, 15.38it/s]
2022-03-21 05:20:29,387 - INFO - tqdm - f1: 0.8643, accuracy: 0.9141, batch_loss: 0.5227, loss: 0.2380 ||:  42%|####2     | 4731/11253 [05:22<06:57, 15.62it/s]
2022-03-21 05:20:39,422 - INFO - tqdm - f1: 0.8642, accuracy: 0.9140, batch_loss: 0.4979, loss: 0.2380 ||:  43%|####3     | 4881/11253 [05:32<07:00, 15.14it/s]
2022-03-21 05:20:49,519 - INFO - tqdm - f1: 0.8641, accuracy: 0.9138, batch_loss: 0.5969, loss: 0.2385 ||:  45%|####4     | 5027/11253 [05:42<07:21, 14.10it/s]
2022-03-21 05:20:59,596 - INFO - tqdm - f1: 0.8644, accuracy: 0.9139, batch_loss: 0.1842, loss: 0.2385 ||:  46%|####5     | 5173/11253 [05:52<07:13, 14.02it/s]
2022-03-21 05:21:09,684 - INFO - tqdm - f1: 0.8644, accuracy: 0.9140, batch_loss: 0.3224, loss: 0.2381 ||:  47%|####7     | 5321/11253 [06:02<07:00, 14.12it/s]
2022-03-21 05:21:19,799 - INFO - tqdm - f1: 0.8646, accuracy: 0.9140, batch_loss: 0.5980, loss: 0.2386 ||:  49%|####8     | 5471/11253 [06:12<06:27, 14.92it/s]
2022-03-21 05:21:29,859 - INFO - tqdm - f1: 0.8647, accuracy: 0.9141, batch_loss: 0.2169, loss: 0.2384 ||:  50%|####9     | 5623/11253 [06:22<06:11, 15.17it/s]
2022-03-21 05:21:39,989 - INFO - tqdm - f1: 0.8640, accuracy: 0.9136, batch_loss: 0.1599, loss: 0.2391 ||:  51%|#####1    | 5769/11253 [06:32<07:02, 12.97it/s]
2022-03-21 05:21:50,113 - INFO - tqdm - f1: 0.8637, accuracy: 0.9134, batch_loss: 0.1180, loss: 0.2395 ||:  53%|#####2    | 5915/11253 [06:42<06:18, 14.09it/s]
2022-03-21 05:22:00,128 - INFO - tqdm - f1: 0.8633, accuracy: 0.9131, batch_loss: 0.1994, loss: 0.2403 ||:  54%|#####3    | 6067/11253 [06:52<05:31, 15.66it/s]
2022-03-21 05:22:10,134 - INFO - tqdm - f1: 0.8631, accuracy: 0.9129, batch_loss: 0.3991, loss: 0.2408 ||:  55%|#####5    | 6217/11253 [07:02<05:32, 15.14it/s]
2022-03-21 05:22:20,268 - INFO - tqdm - f1: 0.8629, accuracy: 0.9127, batch_loss: 0.0604, loss: 0.2413 ||:  57%|#####6    | 6369/11253 [07:12<05:37, 14.45it/s]
2022-03-21 05:22:30,326 - INFO - tqdm - f1: 0.8631, accuracy: 0.9126, batch_loss: 0.1867, loss: 0.2415 ||:  58%|#####7    | 6513/11253 [07:22<05:33, 14.22it/s]
2022-03-21 05:22:40,417 - INFO - tqdm - f1: 0.8628, accuracy: 0.9125, batch_loss: 0.1023, loss: 0.2417 ||:  59%|#####9    | 6665/11253 [07:33<04:34, 16.72it/s]
2022-03-21 05:22:50,518 - INFO - tqdm - f1: 0.8628, accuracy: 0.9125, batch_loss: 0.5070, loss: 0.2415 ||:  61%|######    | 6813/11253 [07:43<04:51, 15.24it/s]
2022-03-21 05:23:00,564 - INFO - tqdm - f1: 0.8624, accuracy: 0.9123, batch_loss: 0.1490, loss: 0.2416 ||:  62%|######1   | 6961/11253 [07:53<04:33, 15.67it/s]
2022-03-21 05:23:10,623 - INFO - tqdm - f1: 0.8623, accuracy: 0.9123, batch_loss: 0.0629, loss: 0.2415 ||:  63%|######3   | 7109/11253 [08:03<05:06, 13.52it/s]
2022-03-21 05:23:20,672 - INFO - tqdm - f1: 0.8623, accuracy: 0.9122, batch_loss: 0.4893, loss: 0.2415 ||:  64%|######4   | 7251/11253 [08:13<04:35, 14.50it/s]
2022-03-21 05:23:30,778 - INFO - tqdm - f1: 0.8620, accuracy: 0.9122, batch_loss: 0.4163, loss: 0.2418 ||:  66%|######5   | 7401/11253 [08:23<04:36, 13.93it/s]
2022-03-21 05:23:40,783 - INFO - tqdm - f1: 0.8621, accuracy: 0.9121, batch_loss: 0.1585, loss: 0.2418 ||:  67%|######7   | 7549/11253 [08:33<04:12, 14.69it/s]
2022-03-21 05:23:50,860 - INFO - tqdm - f1: 0.8618, accuracy: 0.9119, batch_loss: 0.4122, loss: 0.2420 ||:  68%|######8   | 7699/11253 [08:43<04:27, 13.28it/s]
2022-03-21 05:24:00,949 - INFO - tqdm - f1: 0.8620, accuracy: 0.9119, batch_loss: 0.2553, loss: 0.2423 ||:  70%|######9   | 7843/11253 [08:53<04:00, 14.17it/s]
2022-03-21 05:24:11,012 - INFO - tqdm - f1: 0.8617, accuracy: 0.9117, batch_loss: 0.2241, loss: 0.2426 ||:  71%|#######1  | 7991/11253 [09:03<03:56, 13.81it/s]
2022-03-21 05:24:21,021 - INFO - tqdm - f1: 0.8616, accuracy: 0.9116, batch_loss: 0.1037, loss: 0.2425 ||:  72%|#######2  | 8139/11253 [09:13<03:26, 15.05it/s]
2022-03-21 05:24:31,113 - INFO - tqdm - f1: 0.8614, accuracy: 0.9115, batch_loss: 0.5784, loss: 0.2428 ||:  74%|#######3  | 8291/11253 [09:23<03:15, 15.14it/s]
2022-03-21 05:24:41,177 - INFO - tqdm - f1: 0.8611, accuracy: 0.9113, batch_loss: 0.7123, loss: 0.2431 ||:  75%|#######4  | 8437/11253 [09:33<03:16, 14.30it/s]
2022-03-21 05:24:51,186 - INFO - tqdm - f1: 0.8613, accuracy: 0.9115, batch_loss: 0.1158, loss: 0.2429 ||:  76%|#######6  | 8581/11253 [09:43<02:57, 15.02it/s]
2022-03-21 05:25:01,244 - INFO - tqdm - f1: 0.8614, accuracy: 0.9114, batch_loss: 1.0441, loss: 0.2429 ||:  78%|#######7  | 8725/11253 [09:53<02:44, 15.34it/s]
2022-03-21 05:25:11,359 - INFO - tqdm - f1: 0.8617, accuracy: 0.9115, batch_loss: 0.2771, loss: 0.2429 ||:  79%|#######8  | 8877/11253 [10:03<02:28, 15.95it/s]
2022-03-21 05:25:21,376 - INFO - tqdm - f1: 0.8617, accuracy: 0.9114, batch_loss: 0.3365, loss: 0.2431 ||:  80%|########  | 9029/11253 [10:13<02:26, 15.20it/s]
2022-03-21 05:25:31,395 - INFO - tqdm - f1: 0.8616, accuracy: 0.9114, batch_loss: 0.2357, loss: 0.2432 ||:  82%|########1 | 9179/11253 [10:24<02:10, 15.88it/s]
2022-03-21 05:25:41,506 - INFO - tqdm - f1: 0.8615, accuracy: 0.9113, batch_loss: 0.2896, loss: 0.2433 ||:  83%|########2 | 9331/11253 [10:34<02:05, 15.35it/s]
2022-03-21 05:25:51,661 - INFO - tqdm - f1: 0.8615, accuracy: 0.9113, batch_loss: 0.4571, loss: 0.2439 ||:  84%|########4 | 9481/11253 [10:44<02:05, 14.08it/s]
2022-03-21 05:26:01,715 - INFO - tqdm - f1: 0.8614, accuracy: 0.9112, batch_loss: 0.9349, loss: 0.2442 ||:  86%|########5 | 9631/11253 [10:54<01:46, 15.28it/s]
2022-03-21 05:26:11,810 - INFO - tqdm - f1: 0.8616, accuracy: 0.9112, batch_loss: 0.1483, loss: 0.2442 ||:  87%|########6 | 9779/11253 [11:04<01:43, 14.20it/s]
2022-03-21 05:26:21,901 - INFO - tqdm - f1: 0.8615, accuracy: 0.9112, batch_loss: 0.0566, loss: 0.2444 ||:  88%|########8 | 9929/11253 [11:14<01:32, 14.24it/s]
2022-03-21 05:26:31,914 - INFO - tqdm - f1: 0.8611, accuracy: 0.9109, batch_loss: 0.5306, loss: 0.2448 ||:  90%|########9 | 10077/11253 [11:24<01:25, 13.81it/s]
2022-03-21 05:26:42,014 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.4811, loss: 0.2449 ||:  91%|######### | 10229/11253 [11:34<01:08, 14.89it/s]
2022-03-21 05:26:52,053 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.1441, loss: 0.2451 ||:  92%|#########2| 10383/11253 [11:44<00:59, 14.67it/s]
2022-03-21 05:27:02,176 - INFO - tqdm - f1: 0.8611, accuracy: 0.9108, batch_loss: 0.4331, loss: 0.2454 ||:  94%|#########3| 10531/11253 [11:54<00:48, 14.92it/s]
2022-03-21 05:27:12,202 - INFO - tqdm - f1: 0.8611, accuracy: 0.9108, batch_loss: 0.3829, loss: 0.2455 ||:  95%|#########4| 10679/11253 [12:04<00:37, 15.48it/s]
2022-03-21 05:27:22,218 - INFO - tqdm - f1: 0.8613, accuracy: 0.9109, batch_loss: 0.4014, loss: 0.2454 ||:  96%|#########6| 10829/11253 [12:14<00:29, 14.49it/s]
2022-03-21 05:27:32,270 - INFO - tqdm - f1: 0.8612, accuracy: 0.9109, batch_loss: 0.2912, loss: 0.2457 ||:  98%|#########7| 10981/11253 [12:24<00:17, 15.27it/s]
2022-03-21 05:27:42,337 - INFO - tqdm - f1: 0.8611, accuracy: 0.9108, batch_loss: 0.2258, loss: 0.2457 ||:  99%|#########8| 11129/11253 [12:34<00:08, 14.40it/s]
2022-03-21 05:27:46,909 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.0860, loss: 0.2458 ||: 100%|#########9| 11197/11253 [12:39<00:03, 14.16it/s]
2022-03-21 05:27:47,056 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.1741, loss: 0.2458 ||: 100%|#########9| 11199/11253 [12:39<00:03, 13.99it/s]
2022-03-21 05:27:47,207 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.1269, loss: 0.2457 ||: 100%|#########9| 11201/11253 [12:39<00:03, 13.77it/s]
2022-03-21 05:27:47,338 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.1125, loss: 0.2457 ||: 100%|#########9| 11203/11253 [12:39<00:03, 14.17it/s]
2022-03-21 05:27:47,470 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.1989, loss: 0.2457 ||: 100%|#########9| 11205/11253 [12:40<00:03, 14.45it/s]
2022-03-21 05:27:47,599 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.3675, loss: 0.2457 ||: 100%|#########9| 11207/11253 [12:40<00:03, 14.74it/s]
2022-03-21 05:27:47,754 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.1057, loss: 0.2457 ||: 100%|#########9| 11209/11253 [12:40<00:03, 14.15it/s]
2022-03-21 05:27:47,890 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.6699, loss: 0.2457 ||: 100%|#########9| 11211/11253 [12:40<00:02, 14.32it/s]
2022-03-21 05:27:48,007 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.3537, loss: 0.2457 ||: 100%|#########9| 11213/11253 [12:40<00:02, 15.05it/s]
2022-03-21 05:27:48,135 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.2292, loss: 0.2457 ||: 100%|#########9| 11215/11253 [12:40<00:02, 15.20it/s]
2022-03-21 05:27:48,268 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.0619, loss: 0.2457 ||: 100%|#########9| 11217/11253 [12:40<00:02, 15.17it/s]
2022-03-21 05:27:48,398 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.1940, loss: 0.2457 ||: 100%|#########9| 11219/11253 [12:41<00:02, 15.22it/s]
2022-03-21 05:27:48,526 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.3695, loss: 0.2457 ||: 100%|#########9| 11221/11253 [12:41<00:02, 15.34it/s]
2022-03-21 05:27:48,649 - INFO - tqdm - f1: 0.8611, accuracy: 0.9108, batch_loss: 0.2236, loss: 0.2457 ||: 100%|#########9| 11223/11253 [12:41<00:01, 15.60it/s]
2022-03-21 05:27:48,782 - INFO - tqdm - f1: 0.8611, accuracy: 0.9108, batch_loss: 0.1014, loss: 0.2457 ||: 100%|#########9| 11225/11253 [12:41<00:01, 15.44it/s]
2022-03-21 05:27:48,934 - INFO - tqdm - f1: 0.8611, accuracy: 0.9108, batch_loss: 0.0908, loss: 0.2457 ||: 100%|#########9| 11227/11253 [12:41<00:01, 14.68it/s]
2022-03-21 05:27:49,070 - INFO - tqdm - f1: 0.8611, accuracy: 0.9108, batch_loss: 0.6515, loss: 0.2457 ||: 100%|#########9| 11229/11253 [12:41<00:01, 14.67it/s]
2022-03-21 05:27:49,202 - INFO - tqdm - f1: 0.8611, accuracy: 0.9108, batch_loss: 0.0834, loss: 0.2457 ||: 100%|#########9| 11231/11253 [12:41<00:01, 14.83it/s]
2022-03-21 05:27:49,334 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.5385, loss: 0.2457 ||: 100%|#########9| 11233/11253 [12:41<00:01, 14.91it/s]
2022-03-21 05:27:49,471 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.4914, loss: 0.2458 ||: 100%|#########9| 11235/11253 [12:42<00:01, 14.83it/s]
2022-03-21 05:27:49,600 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.2159, loss: 0.2458 ||: 100%|#########9| 11237/11253 [12:42<00:01, 15.03it/s]
2022-03-21 05:27:49,748 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.0186, loss: 0.2458 ||: 100%|#########9| 11239/11253 [12:42<00:00, 14.53it/s]
2022-03-21 05:27:49,901 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.1132, loss: 0.2457 ||: 100%|#########9| 11241/11253 [12:42<00:00, 14.07it/s]
2022-03-21 05:27:50,043 - INFO - tqdm - f1: 0.8611, accuracy: 0.9108, batch_loss: 0.1555, loss: 0.2458 ||: 100%|#########9| 11243/11253 [12:42<00:00, 14.06it/s]
2022-03-21 05:27:50,198 - INFO - tqdm - f1: 0.8610, accuracy: 0.9108, batch_loss: 0.2231, loss: 0.2458 ||: 100%|#########9| 11245/11253 [12:42<00:00, 13.70it/s]
2022-03-21 05:27:50,341 - INFO - tqdm - f1: 0.8610, accuracy: 0.9107, batch_loss: 0.4336, loss: 0.2458 ||: 100%|#########9| 11247/11253 [12:42<00:00, 13.78it/s]
2022-03-21 05:27:50,473 - INFO - tqdm - f1: 0.8610, accuracy: 0.9107, batch_loss: 0.1722, loss: 0.2458 ||: 100%|#########9| 11249/11253 [12:43<00:00, 14.16it/s]
2022-03-21 05:27:50,603 - INFO - tqdm - f1: 0.8610, accuracy: 0.9107, batch_loss: 0.2239, loss: 0.2458 ||: 100%|#########9| 11251/11253 [12:43<00:00, 14.50it/s]
2022-03-21 05:27:50,743 - INFO - tqdm - f1: 0.8610, accuracy: 0.9107, batch_loss: 0.3314, loss: 0.2458 ||: 100%|##########| 11253/11253 [12:43<00:00, 14.44it/s]
2022-03-21 05:27:50,807 - INFO - tqdm - f1: 0.8610, accuracy: 0.9107, batch_loss: 0.3314, loss: 0.2458 ||: 100%|##########| 11253/11253 [12:43<00:00, 14.74it/s]
2022-03-21 05:27:50,814 - INFO - allennlp.training.trainer - Validating
2022-03-21 05:27:50,816 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 05:28:00,888 - INFO - tqdm - f1: 0.8166, accuracy: 0.8765, batch_loss: 0.2934, loss: 0.3677 ||:  23%|##2       | 431/1889 [00:10<00:35, 41.30it/s]
2022-03-21 05:28:10,931 - INFO - tqdm - f1: 0.8132, accuracy: 0.8740, batch_loss: 0.4967, loss: 0.3787 ||:  46%|####5     | 868/1889 [00:20<00:24, 41.18it/s]
2022-03-21 05:28:20,967 - INFO - tqdm - f1: 0.8124, accuracy: 0.8727, batch_loss: 0.6135, loss: 0.3869 ||:  69%|######9   | 1304/1889 [00:30<00:15, 36.68it/s]
2022-03-21 05:28:30,967 - INFO - tqdm - f1: 0.8114, accuracy: 0.8729, batch_loss: 0.2924, loss: 0.3869 ||:  92%|#########1| 1732/1889 [00:40<00:04, 34.11it/s]
2022-03-21 05:28:34,572 - INFO - tqdm - f1: 0.8097, accuracy: 0.8709, batch_loss: 0.2429, loss: 0.3910 ||: 100%|#########9| 1882/1889 [00:43<00:00, 41.52it/s]
2022-03-21 05:28:34,697 - INFO - tqdm - f1: 0.8098, accuracy: 0.8709, batch_loss: 0.4965, loss: 0.3909 ||: 100%|#########9| 1887/1889 [00:43<00:00, 41.07it/s]
2022-03-21 05:28:34,764 - INFO - tqdm - f1: 0.8098, accuracy: 0.8709, batch_loss: 0.2700, loss: 0.3910 ||: 100%|##########| 1889/1889 [00:43<00:00, 42.98it/s]
2022-03-21 05:28:34,779 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 05:28:34,780 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.911  |     0.871
2022-03-21 05:28:34,781 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.861  |     0.810
2022-03-21 05:28:34,782 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 05:28:34,784 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.246  |     0.391
2022-03-21 05:28:34,785 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8642.188  |       N/A
2022-03-21 05:28:34,786 - INFO - allennlp.training.trainer - Epoch duration: 0:13:27.412657
2022-03-21 05:28:34,787 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:12:56
2022-03-21 05:28:34,788 - INFO - allennlp.training.trainer - Epoch 5/9
2022-03-21 05:28:34,789 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-21 05:28:34,790 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 05:28:34,792 - INFO - allennlp.training.trainer - Training
2022-03-21 05:28:34,793 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-21 05:28:44,881 - INFO - tqdm - f1: 0.8904, accuracy: 0.9279, batch_loss: 0.1525, loss: 0.1874 ||:   1%|          | 65/11253 [00:10<12:28, 14.95it/s]
2022-03-21 05:28:54,967 - INFO - tqdm - f1: 0.8759, accuracy: 0.9231, batch_loss: 0.2158, loss: 0.2015 ||:   2%|1         | 213/11253 [00:20<12:23, 14.84it/s]
2022-03-21 05:29:05,066 - INFO - tqdm - f1: 0.8759, accuracy: 0.9229, batch_loss: 0.1237, loss: 0.2068 ||:   3%|3         | 365/11253 [00:30<12:18, 14.74it/s]
2022-03-21 05:29:15,173 - INFO - tqdm - f1: 0.8821, accuracy: 0.9270, batch_loss: 0.3700, loss: 0.2005 ||:   5%|4         | 517/11253 [00:40<12:10, 14.70it/s]
2022-03-21 05:29:25,277 - INFO - tqdm - f1: 0.8834, accuracy: 0.9280, batch_loss: 0.2090, loss: 0.2006 ||:   6%|5         | 667/11253 [00:50<11:58, 14.73it/s]
2022-03-21 05:29:35,369 - INFO - tqdm - f1: 0.8812, accuracy: 0.9263, batch_loss: 0.2655, loss: 0.2045 ||:   7%|7         | 817/11253 [01:00<11:40, 14.89it/s]
2022-03-21 05:29:45,479 - INFO - tqdm - f1: 0.8801, accuracy: 0.9256, batch_loss: 0.0691, loss: 0.2055 ||:   9%|8         | 965/11253 [01:10<11:28, 14.94it/s]
2022-03-21 05:29:55,568 - INFO - tqdm - f1: 0.8794, accuracy: 0.9253, batch_loss: 0.1753, loss: 0.2054 ||:  10%|9         | 1117/11253 [01:20<11:18, 14.93it/s]
2022-03-21 05:30:05,589 - INFO - tqdm - f1: 0.8796, accuracy: 0.9253, batch_loss: 0.0582, loss: 0.2058 ||:  11%|#1        | 1265/11253 [01:30<11:41, 14.24it/s]
2022-03-21 05:30:15,598 - INFO - tqdm - f1: 0.8786, accuracy: 0.9251, batch_loss: 0.1114, loss: 0.2063 ||:  13%|#2        | 1413/11253 [01:40<10:23, 15.79it/s]
2022-03-21 05:30:25,736 - INFO - tqdm - f1: 0.8793, accuracy: 0.9256, batch_loss: 0.0646, loss: 0.2046 ||:  14%|#3        | 1559/11253 [01:50<11:07, 14.51it/s]
2022-03-21 05:30:35,808 - INFO - tqdm - f1: 0.8795, accuracy: 0.9253, batch_loss: 0.2101, loss: 0.2054 ||:  15%|#5        | 1705/11253 [02:01<10:47, 14.74it/s]
2022-03-21 05:30:45,917 - INFO - tqdm - f1: 0.8781, accuracy: 0.9248, batch_loss: 0.0768, loss: 0.2052 ||:  16%|#6        | 1853/11253 [02:11<10:18, 15.20it/s]
2022-03-21 05:30:55,943 - INFO - tqdm - f1: 0.8770, accuracy: 0.9238, batch_loss: 0.0746, loss: 0.2078 ||:  18%|#7        | 2005/11253 [02:21<10:13, 15.07it/s]
2022-03-21 05:31:05,957 - INFO - tqdm - f1: 0.8771, accuracy: 0.9239, batch_loss: 0.1439, loss: 0.2076 ||:  19%|#9        | 2157/11253 [02:31<10:13, 14.82it/s]
2022-03-21 05:31:16,034 - INFO - tqdm - f1: 0.8775, accuracy: 0.9238, batch_loss: 0.1295, loss: 0.2071 ||:  21%|##        | 2309/11253 [02:41<09:43, 15.33it/s]
2022-03-21 05:31:26,123 - INFO - tqdm - f1: 0.8774, accuracy: 0.9237, batch_loss: 0.1273, loss: 0.2083 ||:  22%|##1       | 2465/11253 [02:51<09:46, 14.98it/s]
2022-03-21 05:31:36,204 - INFO - tqdm - f1: 0.8774, accuracy: 0.9238, batch_loss: 0.2283, loss: 0.2073 ||:  23%|##3       | 2615/11253 [03:01<09:56, 14.47it/s]
2022-03-21 05:31:46,303 - INFO - tqdm - f1: 0.8773, accuracy: 0.9238, batch_loss: 0.0263, loss: 0.2076 ||:  25%|##4       | 2763/11253 [03:11<09:27, 14.97it/s]
2022-03-21 05:31:56,409 - INFO - tqdm - f1: 0.8769, accuracy: 0.9235, batch_loss: 0.1921, loss: 0.2077 ||:  26%|##5       | 2915/11253 [03:21<09:31, 14.60it/s]
2022-03-21 05:32:06,481 - INFO - tqdm - f1: 0.8769, accuracy: 0.9235, batch_loss: 0.2460, loss: 0.2081 ||:  27%|##7       | 3067/11253 [03:31<08:39, 15.77it/s]
2022-03-21 05:32:16,495 - INFO - tqdm - f1: 0.8771, accuracy: 0.9235, batch_loss: 0.2084, loss: 0.2081 ||:  29%|##8       | 3215/11253 [03:41<09:06, 14.71it/s]
2022-03-21 05:32:26,572 - INFO - tqdm - f1: 0.8763, accuracy: 0.9230, batch_loss: 0.2070, loss: 0.2089 ||:  30%|##9       | 3359/11253 [03:51<08:53, 14.79it/s]
2022-03-21 05:32:36,662 - INFO - tqdm - f1: 0.8765, accuracy: 0.9229, batch_loss: 0.0648, loss: 0.2087 ||:  31%|###1      | 3509/11253 [04:01<08:37, 14.98it/s]
2022-03-21 05:32:46,719 - INFO - tqdm - f1: 0.8769, accuracy: 0.9232, batch_loss: 0.1666, loss: 0.2083 ||:  32%|###2      | 3657/11253 [04:11<08:24, 15.06it/s]
2022-03-21 05:32:56,742 - INFO - tqdm - f1: 0.8772, accuracy: 0.9233, batch_loss: 0.3820, loss: 0.2082 ||:  34%|###3      | 3805/11253 [04:21<08:18, 14.95it/s]
2022-03-21 05:33:06,874 - INFO - tqdm - f1: 0.8771, accuracy: 0.9231, batch_loss: 0.1430, loss: 0.2086 ||:  35%|###5      | 3953/11253 [04:32<08:29, 14.33it/s]
2022-03-21 05:33:16,930 - INFO - tqdm - f1: 0.8767, accuracy: 0.9230, batch_loss: 0.0349, loss: 0.2090 ||:  36%|###6      | 4101/11253 [04:42<08:08, 14.64it/s]
2022-03-21 05:33:27,036 - INFO - tqdm - f1: 0.8763, accuracy: 0.9227, batch_loss: 0.3136, loss: 0.2097 ||:  38%|###7      | 4251/11253 [04:52<07:58, 14.65it/s]
2022-03-21 05:33:37,158 - INFO - tqdm - f1: 0.8759, accuracy: 0.9224, batch_loss: 0.0373, loss: 0.2101 ||:  39%|###9      | 4401/11253 [05:02<07:36, 14.99it/s]
2022-03-21 05:33:47,220 - INFO - tqdm - f1: 0.8761, accuracy: 0.9225, batch_loss: 0.5515, loss: 0.2102 ||:  40%|####      | 4551/11253 [05:12<07:26, 15.01it/s]
2022-03-21 05:33:57,311 - INFO - tqdm - f1: 0.8761, accuracy: 0.9225, batch_loss: 0.2141, loss: 0.2102 ||:  42%|####1     | 4693/11253 [05:22<08:02, 13.60it/s]
2022-03-21 05:34:07,330 - INFO - tqdm - f1: 0.8763, accuracy: 0.9227, batch_loss: 0.1443, loss: 0.2100 ||:  43%|####3     | 4843/11253 [05:32<06:54, 15.48it/s]
2022-03-21 05:34:17,436 - INFO - tqdm - f1: 0.8765, accuracy: 0.9227, batch_loss: 0.1207, loss: 0.2102 ||:  44%|####4     | 4997/11253 [05:42<06:49, 15.27it/s]
2022-03-21 05:34:27,553 - INFO - tqdm - f1: 0.8765, accuracy: 0.9228, batch_loss: 0.0760, loss: 0.2106 ||:  46%|####5     | 5149/11253 [05:52<06:40, 15.24it/s]
2022-03-21 05:34:37,628 - INFO - tqdm - f1: 0.8761, accuracy: 0.9224, batch_loss: 0.2411, loss: 0.2112 ||:  47%|####7     | 5297/11253 [06:02<06:42, 14.80it/s]
2022-03-21 05:34:47,741 - INFO - tqdm - f1: 0.8755, accuracy: 0.9221, batch_loss: 0.3964, loss: 0.2120 ||:  48%|####8     | 5447/11253 [06:12<06:26, 15.00it/s]
2022-03-21 05:34:57,819 - INFO - tqdm - f1: 0.8753, accuracy: 0.9218, batch_loss: 0.2871, loss: 0.2131 ||:  50%|####9     | 5599/11253 [06:23<06:10, 15.25it/s]
2022-03-21 05:35:07,859 - INFO - tqdm - f1: 0.8750, accuracy: 0.9218, batch_loss: 0.1280, loss: 0.2133 ||:  51%|#####1    | 5747/11253 [06:33<05:54, 15.52it/s]
2022-03-21 05:35:17,893 - INFO - tqdm - f1: 0.8751, accuracy: 0.9217, batch_loss: 0.0413, loss: 0.2133 ||:  52%|#####2    | 5897/11253 [06:43<05:33, 16.08it/s]
2022-03-21 05:35:28,030 - INFO - tqdm - f1: 0.8749, accuracy: 0.9215, batch_loss: 0.1013, loss: 0.2137 ||:  54%|#####3    | 6041/11253 [06:53<05:51, 14.83it/s]
2022-03-21 05:35:38,093 - INFO - tqdm - f1: 0.8747, accuracy: 0.9214, batch_loss: 0.2519, loss: 0.2139 ||:  55%|#####5    | 6193/11253 [07:03<05:36, 15.04it/s]
2022-03-21 05:35:48,123 - INFO - tqdm - f1: 0.8748, accuracy: 0.9214, batch_loss: 0.0721, loss: 0.2136 ||:  56%|#####6    | 6343/11253 [07:13<05:33, 14.71it/s]
2022-03-21 05:35:58,220 - INFO - tqdm - f1: 0.8747, accuracy: 0.9212, batch_loss: 0.1088, loss: 0.2143 ||:  58%|#####7    | 6495/11253 [07:23<05:20, 14.86it/s]
2022-03-21 05:36:08,304 - INFO - tqdm - f1: 0.8745, accuracy: 0.9211, batch_loss: 0.0757, loss: 0.2146 ||:  59%|#####9    | 6643/11253 [07:33<05:02, 15.23it/s]
2022-03-21 05:36:18,422 - INFO - tqdm - f1: 0.8743, accuracy: 0.9210, batch_loss: 0.2745, loss: 0.2148 ||:  60%|######    | 6795/11253 [07:43<04:42, 15.75it/s]
2022-03-21 05:36:28,512 - INFO - tqdm - f1: 0.8743, accuracy: 0.9210, batch_loss: 0.0520, loss: 0.2144 ||:  62%|######1   | 6949/11253 [07:53<04:30, 15.93it/s]
2022-03-21 05:36:38,589 - INFO - tqdm - f1: 0.8740, accuracy: 0.9209, batch_loss: 0.0670, loss: 0.2147 ||:  63%|######3   | 7103/11253 [08:03<04:40, 14.81it/s]
2022-03-21 05:36:48,636 - INFO - tqdm - f1: 0.8738, accuracy: 0.9207, batch_loss: 0.1501, loss: 0.2151 ||:  64%|######4   | 7253/11253 [08:13<04:37, 14.39it/s]
2022-03-21 05:36:58,719 - INFO - tqdm - f1: 0.8739, accuracy: 0.9206, batch_loss: 0.0828, loss: 0.2155 ||:  66%|######5   | 7403/11253 [08:23<04:10, 15.36it/s]
2022-03-21 05:37:08,824 - INFO - tqdm - f1: 0.8741, accuracy: 0.9208, batch_loss: 0.3023, loss: 0.2156 ||:  67%|######7   | 7555/11253 [08:34<04:06, 14.98it/s]
2022-03-21 05:37:18,955 - INFO - tqdm - f1: 0.8740, accuracy: 0.9208, batch_loss: 0.1203, loss: 0.2158 ||:  69%|######8   | 7709/11253 [08:44<03:47, 15.61it/s]
2022-03-21 05:37:29,071 - INFO - tqdm - f1: 0.8738, accuracy: 0.9206, batch_loss: 0.1290, loss: 0.2160 ||:  70%|######9   | 7861/11253 [08:54<03:50, 14.69it/s]
2022-03-21 05:37:39,079 - INFO - tqdm - f1: 0.8740, accuracy: 0.9206, batch_loss: 0.0150, loss: 0.2165 ||:  71%|#######1  | 8007/11253 [09:04<03:33, 15.17it/s]
2022-03-21 05:37:49,189 - INFO - tqdm - f1: 0.8738, accuracy: 0.9206, batch_loss: 0.0339, loss: 0.2167 ||:  72%|#######2  | 8155/11253 [09:14<03:28, 14.83it/s]
2022-03-21 05:37:59,262 - INFO - tqdm - f1: 0.8738, accuracy: 0.9206, batch_loss: 0.0856, loss: 0.2168 ||:  74%|#######3  | 8305/11253 [09:24<03:15, 15.09it/s]
2022-03-21 05:38:09,391 - INFO - tqdm - f1: 0.8737, accuracy: 0.9204, batch_loss: 0.3388, loss: 0.2173 ||:  75%|#######5  | 8459/11253 [09:34<03:15, 14.26it/s]
2022-03-21 05:38:19,501 - INFO - tqdm - f1: 0.8739, accuracy: 0.9205, batch_loss: 0.5251, loss: 0.2174 ||:  77%|#######6  | 8615/11253 [09:44<02:53, 15.19it/s]
2022-03-21 05:38:29,543 - INFO - tqdm - f1: 0.8738, accuracy: 0.9203, batch_loss: 0.6259, loss: 0.2177 ||:  78%|#######7  | 8757/11253 [09:54<02:59, 13.93it/s]
2022-03-21 05:38:39,576 - INFO - tqdm - f1: 0.8737, accuracy: 0.9203, batch_loss: 0.1260, loss: 0.2177 ||:  79%|#######9  | 8899/11253 [10:04<02:44, 14.28it/s]
2022-03-21 05:38:49,580 - INFO - tqdm - f1: 0.8737, accuracy: 0.9203, batch_loss: 0.1285, loss: 0.2180 ||:  80%|########  | 9049/11253 [10:14<02:24, 15.20it/s]
2022-03-21 05:38:59,702 - INFO - tqdm - f1: 0.8735, accuracy: 0.9202, batch_loss: 0.4914, loss: 0.2178 ||:  82%|########1 | 9201/11253 [10:24<02:24, 14.23it/s]
2022-03-21 05:39:09,830 - INFO - tqdm - f1: 0.8738, accuracy: 0.9203, batch_loss: 0.2147, loss: 0.2179 ||:  83%|########3 | 9353/11253 [10:35<02:09, 14.64it/s]
2022-03-21 05:39:19,875 - INFO - tqdm - f1: 0.8735, accuracy: 0.9201, batch_loss: 0.5101, loss: 0.2181 ||:  84%|########4 | 9497/11253 [10:45<01:52, 15.61it/s]
2022-03-21 05:39:29,995 - INFO - tqdm - f1: 0.8734, accuracy: 0.9200, batch_loss: 0.0649, loss: 0.2184 ||:  86%|########5 | 9653/11253 [10:55<01:41, 15.83it/s]
2022-03-21 05:39:40,020 - INFO - tqdm - f1: 0.8735, accuracy: 0.9200, batch_loss: 0.1734, loss: 0.2185 ||:  87%|########7 | 9809/11253 [11:05<01:32, 15.69it/s]
2022-03-21 05:39:50,098 - INFO - tqdm - f1: 0.8734, accuracy: 0.9200, batch_loss: 0.1024, loss: 0.2184 ||:  89%|########8 | 9959/11253 [11:15<01:28, 14.63it/s]
2022-03-21 05:40:00,134 - INFO - tqdm - f1: 0.8731, accuracy: 0.9198, batch_loss: 0.2718, loss: 0.2190 ||:  90%|########9 | 10097/11253 [11:25<01:26, 13.35it/s]
2022-03-21 05:40:10,253 - INFO - tqdm - f1: 0.8734, accuracy: 0.9199, batch_loss: 0.0821, loss: 0.2187 ||:  91%|######### | 10233/11253 [11:35<01:08, 14.87it/s]
2022-03-21 05:40:20,290 - INFO - tqdm - f1: 0.8732, accuracy: 0.9198, batch_loss: 0.1277, loss: 0.2189 ||:  92%|#########2| 10381/11253 [11:45<00:59, 14.72it/s]
2022-03-21 05:40:30,330 - INFO - tqdm - f1: 0.8731, accuracy: 0.9197, batch_loss: 0.2631, loss: 0.2194 ||:  94%|#########3| 10531/11253 [11:55<00:49, 14.48it/s]
2022-03-21 05:40:40,377 - INFO - tqdm - f1: 0.8730, accuracy: 0.9198, batch_loss: 0.1905, loss: 0.2195 ||:  95%|#########4| 10681/11253 [12:05<00:39, 14.61it/s]
2022-03-21 05:40:50,430 - INFO - tqdm - f1: 0.8731, accuracy: 0.9198, batch_loss: 0.0369, loss: 0.2195 ||:  96%|#########6| 10829/11253 [12:15<00:29, 14.61it/s]
2022-03-21 05:41:00,507 - INFO - tqdm - f1: 0.8732, accuracy: 0.9199, batch_loss: 0.2594, loss: 0.2193 ||:  98%|#########7| 10981/11253 [12:25<00:18, 14.49it/s]
2022-03-21 05:41:10,512 - INFO - tqdm - f1: 0.8730, accuracy: 0.9198, batch_loss: 0.0366, loss: 0.2193 ||:  99%|#########8| 11135/11253 [12:35<00:08, 14.29it/s]
2022-03-21 05:41:14,719 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.2239, loss: 0.2195 ||: 100%|#########9| 11197/11253 [12:39<00:03, 14.78it/s]
2022-03-21 05:41:14,854 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.4212, loss: 0.2196 ||: 100%|#########9| 11199/11253 [12:40<00:03, 14.79it/s]
2022-03-21 05:41:14,988 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.2067, loss: 0.2195 ||: 100%|#########9| 11201/11253 [12:40<00:03, 14.83it/s]
2022-03-21 05:41:15,111 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.2137, loss: 0.2195 ||: 100%|#########9| 11203/11253 [12:40<00:03, 15.21it/s]
2022-03-21 05:41:15,254 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.4232, loss: 0.2196 ||: 100%|#########9| 11205/11253 [12:40<00:03, 14.85it/s]
2022-03-21 05:41:15,397 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.2224, loss: 0.2195 ||: 100%|#########9| 11207/11253 [12:40<00:03, 14.57it/s]
2022-03-21 05:41:15,550 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.2044, loss: 0.2196 ||: 100%|#########9| 11209/11253 [12:40<00:03, 14.10it/s]
2022-03-21 05:41:15,702 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.1503, loss: 0.2195 ||: 100%|#########9| 11211/11253 [12:40<00:03, 13.79it/s]
2022-03-21 05:41:15,826 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.3271, loss: 0.2195 ||: 100%|#########9| 11213/11253 [12:41<00:02, 14.42it/s]
2022-03-21 05:41:15,967 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.1522, loss: 0.2195 ||: 100%|#########9| 11215/11253 [12:41<00:02, 14.36it/s]
2022-03-21 05:41:16,089 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.4154, loss: 0.2195 ||: 100%|#########9| 11217/11253 [12:41<00:02, 14.89it/s]
2022-03-21 05:41:16,238 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.8777, loss: 0.2196 ||: 100%|#########9| 11219/11253 [12:41<00:02, 14.41it/s]
2022-03-21 05:41:16,375 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.1359, loss: 0.2196 ||: 100%|#########9| 11221/11253 [12:41<00:02, 14.48it/s]
2022-03-21 05:41:16,508 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.1039, loss: 0.2196 ||: 100%|#########9| 11223/11253 [12:41<00:02, 14.66it/s]
2022-03-21 05:41:16,636 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.2524, loss: 0.2196 ||: 100%|#########9| 11225/11253 [12:41<00:01, 14.91it/s]
2022-03-21 05:41:16,761 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.1149, loss: 0.2196 ||: 100%|#########9| 11227/11253 [12:41<00:01, 15.23it/s]
2022-03-21 05:41:16,891 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.3881, loss: 0.2196 ||: 100%|#########9| 11229/11253 [12:42<00:01, 15.28it/s]
2022-03-21 05:41:17,016 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.1962, loss: 0.2196 ||: 100%|#########9| 11231/11253 [12:42<00:01, 15.49it/s]
2022-03-21 05:41:17,142 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.0856, loss: 0.2196 ||: 100%|#########9| 11233/11253 [12:42<00:01, 15.59it/s]
2022-03-21 05:41:17,284 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.2942, loss: 0.2196 ||: 100%|#########9| 11235/11253 [12:42<00:01, 15.12it/s]
2022-03-21 05:41:17,420 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.1330, loss: 0.2196 ||: 100%|#########9| 11237/11253 [12:42<00:01, 15.00it/s]
2022-03-21 05:41:17,552 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.0168, loss: 0.2196 ||: 100%|#########9| 11239/11253 [12:42<00:00, 15.05it/s]
2022-03-21 05:41:17,679 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.1683, loss: 0.2196 ||: 100%|#########9| 11241/11253 [12:42<00:00, 15.24it/s]
2022-03-21 05:41:17,807 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.1669, loss: 0.2195 ||: 100%|#########9| 11243/11253 [12:43<00:00, 15.33it/s]
2022-03-21 05:41:17,931 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.1367, loss: 0.2195 ||: 100%|#########9| 11245/11253 [12:43<00:00, 15.57it/s]
2022-03-21 05:41:18,063 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.0577, loss: 0.2195 ||: 100%|#########9| 11247/11253 [12:43<00:00, 15.44it/s]
2022-03-21 05:41:18,185 - INFO - tqdm - f1: 0.8728, accuracy: 0.9197, batch_loss: 0.2967, loss: 0.2195 ||: 100%|#########9| 11249/11253 [12:43<00:00, 15.74it/s]
2022-03-21 05:41:18,323 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.5000, loss: 0.2196 ||: 100%|#########9| 11251/11253 [12:43<00:00, 15.34it/s]
2022-03-21 05:41:18,460 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.4616, loss: 0.2196 ||: 100%|##########| 11253/11253 [12:43<00:00, 15.11it/s]
2022-03-21 05:41:18,527 - INFO - tqdm - f1: 0.8728, accuracy: 0.9196, batch_loss: 0.4616, loss: 0.2196 ||: 100%|##########| 11253/11253 [12:43<00:00, 14.73it/s]
2022-03-21 05:41:18,535 - INFO - allennlp.training.trainer - Validating
2022-03-21 05:41:18,537 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-21 05:41:28,554 - INFO - tqdm - f1: 0.8108, accuracy: 0.8702, batch_loss: 0.2372, loss: 0.4121 ||:  19%|#8        | 355/1889 [00:10<01:08, 22.50it/s]
2022-03-21 05:41:38,654 - INFO - tqdm - f1: 0.8138, accuracy: 0.8722, batch_loss: 0.2313, loss: 0.4050 ||:  37%|###6      | 695/1889 [00:20<00:28, 41.92it/s]
2022-03-21 05:41:48,675 - INFO - tqdm - f1: 0.8163, accuracy: 0.8737, batch_loss: 0.6653, loss: 0.3990 ||:  61%|######    | 1151/1889 [00:30<00:17, 43.38it/s]
2022-03-21 05:41:58,753 - INFO - tqdm - f1: 0.8179, accuracy: 0.8739, batch_loss: 0.0949, loss: 0.3999 ||:  84%|########4 | 1594/1889 [00:40<00:06, 46.17it/s]
2022-03-21 05:42:05,183 - INFO - tqdm - f1: 0.8178, accuracy: 0.8729, batch_loss: 0.6407, loss: 0.4054 ||: 100%|#########9| 1883/1889 [00:46<00:00, 50.84it/s]
2022-03-21 05:42:05,361 - INFO - tqdm - f1: 0.8177, accuracy: 0.8728, batch_loss: 0.3429, loss: 0.4059 ||: 100%|##########| 1889/1889 [00:46<00:00, 44.05it/s]
2022-03-21 05:42:05,374 - INFO - tqdm - f1: 0.8177, accuracy: 0.8728, batch_loss: 0.3429, loss: 0.4059 ||: 100%|##########| 1889/1889 [00:46<00:00, 40.33it/s]
2022-03-21 05:42:05,378 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-21 05:42:05,380 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-21 05:42:06,879 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-21 05:42:06,882 - INFO - allennlp.training.util - Iterating over dataset
2022-03-21 05:42:06,883 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-21 05:42:06,928 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 05:42:06,930 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 05:42:16,940 - INFO - tqdm - f1: 0.82, accuracy: 0.87, loss: 0.38 ||: : 419it [00:10, 42.70it/s]
2022-03-21 05:42:26,986 - INFO - tqdm - f1: 0.82, accuracy: 0.87, loss: 0.38 ||: : 862it [00:20, 47.07it/s]
2022-03-21 05:42:37,006 - INFO - tqdm - f1: 0.82, accuracy: 0.87, loss: 0.39 ||: : 1304it [00:30, 45.53it/s]
2022-03-21 05:42:47,070 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.40 ||: : 1754it [00:40, 50.11it/s]
2022-03-21 05:42:50,084 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 2,
  "peak_worker_0_memory_MB": 8642.1875,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "1:12:56.344822",
  "training_start_epoch": 0,
  "training_epochs": 4,
  "epoch": 4,
  "training_f1": 0.8609906077384949,
  "training_accuracy": 0.9107420573205954,
  "training_loss": 0.2458031200218688,
  "training_worker_0_memory_MB": 8642.1875,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.8097896218299866,
  "validation_accuracy": 0.8709453197405005,
  "validation_loss": 0.3909633515775894,
  "best_validation_f1": 0.8190619945526123,
  "best_validation_accuracy": 0.8744207599629287,
  "best_validation_loss": 0.374073999710805,
  "test_f1": 0.8114978194236755,
  "test_accuracy": 0.8674298987887838,
  "test_loss": 0.39991715891907614
}
2022-03-21 05:42:50,274 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/rct-20k_base_hyper_small_seed_177/model.tar.gz
