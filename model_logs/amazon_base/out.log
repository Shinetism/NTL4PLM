2022-03-19 20:18:56,453 - INFO - allennlp.common.params - random_seed = 1475232695
2022-03-19 20:18:56,456 - INFO - allennlp.common.params - numpy_seed = 1475232695
2022-03-19 20:18:56,458 - INFO - allennlp.common.params - pytorch_seed = 1475232695
2022-03-19 20:18:56,464 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-19 20:18:56,466 - INFO - allennlp.common.params - type = default
2022-03-19 20:18:56,469 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-19 20:18:56,471 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-19 20:18:56,472 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-19 20:18:56,474 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-19 20:18:56,476 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-19 20:18:56,477 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-19 20:18:56,479 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-19 20:19:09,056 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-19 20:19:09,062 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-19 20:19:09,063 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-19 20:19:09,065 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-19 20:19:09,073 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-19 20:19:09,074 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-19 20:19:09,076 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-19 20:19:09,078 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-19 20:19:09,079 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-19 20:19:09,081 - INFO - allennlp.common.params - train_data_path = datasets/amazon/train.jsonl
2022-03-19 20:19:09,083 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f9fccaad310>
2022-03-19 20:19:09,084 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-19 20:19:09,085 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-19 20:19:09,087 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-19 20:19:09,088 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-19 20:19:09,090 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-19 20:19:09,092 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-19 20:19:09,093 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-19 20:19:09,094 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-19 20:19:09,096 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-19 20:19:09,098 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-19 20:19:09,099 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-19 20:19:09,100 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-19 20:19:09,102 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-19 20:19:09,103 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-19 20:19:09,105 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-19 20:19:09,107 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-19 20:19:09,108 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-19 20:19:09,110 - INFO - allennlp.common.params - validation_data_path = datasets/amazon/dev.jsonl
2022-03-19 20:19:09,111 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-19 20:19:09,112 - INFO - allennlp.common.params - test_data_path = datasets/amazon/test.jsonl
2022-03-19 20:19:09,114 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-19 20:19:09,115 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-19 20:19:09,116 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-19 20:19:09,118 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-19 20:19:09,120 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-19 20:19:09,121 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-19 20:19:09,122 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-19 20:19:09,124 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-19 20:19:09,125 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-19 20:19:09,126 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-19 20:19:09,128 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-19 20:19:09,129 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-19 20:19:09,131 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-19 20:19:09,132 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-19 20:19:09,133 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-19 20:19:09,135 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-19 20:19:09,137 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-19 20:19:19,169 - INFO - tqdm - loading instances: 7472it [00:10, 734.14it/s]
2022-03-19 20:19:29,214 - INFO - tqdm - loading instances: 15675it [00:20, 771.69it/s]
2022-03-19 20:19:39,541 - INFO - tqdm - loading instances: 23671it [00:30, 208.27it/s]
2022-03-19 20:19:49,620 - INFO - tqdm - loading instances: 32029it [00:40, 1069.87it/s]
2022-03-19 20:19:59,658 - INFO - tqdm - loading instances: 40234it [00:50, 922.56it/s]
2022-03-19 20:20:09,692 - INFO - tqdm - loading instances: 47948it [01:00, 411.28it/s]
2022-03-19 20:20:19,749 - INFO - tqdm - loading instances: 57450it [01:10, 1010.15it/s]
2022-03-19 20:20:29,846 - INFO - tqdm - loading instances: 64257it [01:20, 1047.58it/s]
2022-03-19 20:20:39,938 - INFO - tqdm - loading instances: 73365it [01:30, 896.35it/s]
2022-03-19 20:20:50,013 - INFO - tqdm - loading instances: 80025it [01:40, 885.77it/s]
2022-03-19 20:21:00,103 - INFO - tqdm - loading instances: 89630it [01:50, 995.70it/s]
2022-03-19 20:21:10,181 - INFO - tqdm - loading instances: 95299it [02:01, 730.37it/s]
2022-03-19 20:21:20,197 - INFO - tqdm - loading instances: 104942it [02:11, 974.89it/s]
2022-03-19 20:21:30,210 - INFO - tqdm - loading instances: 114467it [02:21, 1051.02it/s]
2022-03-19 20:21:31,125 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-19 20:21:31,131 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-19 20:21:31,133 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-19 20:21:31,134 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-19 20:21:31,136 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-19 20:21:31,142 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-19 20:21:31,144 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-19 20:21:31,146 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-19 20:21:31,148 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-19 20:21:31,150 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-19 20:21:31,152 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-19 20:21:31,154 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-19 20:21:31,155 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-19 20:21:31,157 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-19 20:21:31,159 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-19 20:21:41,211 - INFO - tqdm - loading instances: 3658it [00:10, 297.75it/s]
2022-03-19 20:21:42,775 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-19 20:21:42,782 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-19 20:21:42,784 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-19 20:21:42,786 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-19 20:21:42,787 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-19 20:21:42,789 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-19 20:21:42,791 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-19 20:21:42,793 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-19 20:21:42,799 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-19 20:21:42,801 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-19 20:21:42,802 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-19 20:21:42,804 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-19 20:21:42,805 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-19 20:21:42,807 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-19 20:21:42,809 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-19 20:21:52,863 - INFO - tqdm - loading instances: 9015it [00:10, 916.07it/s]
2022-03-19 20:22:02,921 - INFO - tqdm - loading instances: 18818it [00:20, 1026.66it/s]
2022-03-19 20:22:09,731 - INFO - allennlp.common.params - type = from_instances
2022-03-19 20:22:09,737 - INFO - allennlp.common.params - min_count = None
2022-03-19 20:22:09,739 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-19 20:22:09,740 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-19 20:22:09,742 - INFO - allennlp.common.params - pretrained_files = None
2022-03-19 20:22:09,748 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-19 20:22:09,753 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-19 20:22:09,758 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-19 20:22:09,764 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-19 20:22:09,771 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-19 20:22:09,776 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-19 20:22:09,782 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-19 20:22:13,185 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-19 20:22:13,191 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-19 20:22:13,193 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-19 20:22:13,195 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-19 20:22:13,196 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-19 20:22:13,198 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-19 20:22:13,199 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-19 20:22:13,202 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-19 20:22:13,204 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-19 20:22:13,205 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-19 20:22:13,207 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-19 20:22:13,209 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-19 20:22:13,210 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-19 20:22:21,543 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-19 20:22:21,550 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-19 20:22:21,552 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-19 20:22:21,553 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-19 20:22:21,556 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-19 20:22:21,558 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-19 20:22:21,560 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-19 20:22:21,561 - INFO - allennlp.common.params - type = tanh
2022-03-19 20:22:21,563 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-19 20:22:21,568 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-19 20:22:21,570 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-19 20:22:21,571 - INFO - allennlp.common.params - model.num_labels = None
2022-03-19 20:22:21,573 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-19 20:22:21,574 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f9fccac2dd0>
2022-03-19 20:22:21,576 - INFO - allennlp.common.params - model.regularizer = None
2022-03-19 20:22:21,577 - INFO - allennlp.common.params - model.track_weights = False
2022-03-19 20:22:21,579 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-19 20:22:21,580 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-19 20:22:21,583 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-19 20:22:21,588 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-19 20:22:21,590 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-19 20:22:21,591 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-19 20:22:21,593 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-19 20:22:21,594 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-19 20:22:21,596 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-19 20:22:21,597 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-19 20:22:21,599 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-19 20:22:21,600 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-19 20:22:21,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-19 20:22:21,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-19 20:22:21,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-19 20:22:21,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-19 20:22:21,608 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-19 20:22:21,609 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-19 20:22:21,611 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-19 20:22:21,613 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-19 20:22:21,614 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-19 20:22:21,615 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-19 20:22:21,617 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-19 20:22:21,618 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-19 20:22:21,620 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-19 20:22:21,621 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-19 20:22:21,623 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-19 20:22:21,624 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-19 20:22:21,625 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-19 20:22:21,627 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-19 20:22:21,628 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-19 20:22:21,630 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-19 20:22:21,631 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-19 20:22:21,633 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-19 20:22:21,634 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-19 20:22:21,636 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-19 20:22:21,637 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-19 20:22:21,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-19 20:22:21,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-19 20:22:21,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-19 20:22:21,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-19 20:22:21,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-19 20:22:21,647 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-19 20:22:21,648 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-19 20:22:21,649 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-19 20:22:21,650 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-19 20:22:21,652 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-19 20:22:21,653 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-19 20:22:21,655 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-19 20:22:21,656 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-19 20:22:21,657 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-19 20:22:21,662 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-19 20:22:21,663 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-19 20:22:21,665 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-19 20:22:21,666 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-19 20:22:21,668 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-19 20:22:21,669 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-19 20:22:21,671 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-19 20:22:21,673 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-19 20:22:21,674 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-19 20:22:21,676 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-19 20:22:21,677 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-19 20:22:21,680 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-19 20:22:21,681 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-19 20:22:21,682 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-19 20:22:21,684 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-19 20:22:21,685 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-19 20:22:21,687 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-19 20:22:21,690 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-19 20:22:21,691 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-19 20:22:21,692 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-19 20:22:21,694 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-19 20:22:21,695 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-19 20:22:21,697 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-19 20:22:21,698 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-19 20:22:21,699 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-19 20:22:21,701 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-19 20:22:21,702 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-19 20:22:21,704 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-19 20:22:21,705 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-19 20:22:21,706 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-19 20:22:21,708 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-19 20:22:21,709 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-19 20:22:21,710 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-19 20:22:21,712 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-19 20:22:21,713 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-19 20:22:21,715 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-19 20:22:21,717 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-19 20:22:21,718 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-19 20:22:21,719 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-19 20:22:21,721 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-19 20:22:21,722 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-19 20:22:21,723 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-19 20:22:21,724 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-19 20:22:21,726 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-19 20:22:21,730 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-19 20:22:21,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-19 20:22:21,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-19 20:22:21,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-19 20:22:21,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-19 20:22:21,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-19 20:22:21,740 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-19 20:22:21,742 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-19 20:22:21,743 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-19 20:22:21,744 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-19 20:22:21,746 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-19 20:22:21,747 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-19 20:22:21,748 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-19 20:22:21,750 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-19 20:22:21,751 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-19 20:22:21,752 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-19 20:22:21,754 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-19 20:22:21,756 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-19 20:22:21,757 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-19 20:22:21,758 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-19 20:22:21,760 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-19 20:22:21,761 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-19 20:22:21,762 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-19 20:22:21,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-19 20:22:21,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-19 20:22:21,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-19 20:22:21,770 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-19 20:22:21,771 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-19 20:22:21,772 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-19 20:22:21,774 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-19 20:22:21,775 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-19 20:22:21,776 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-19 20:22:21,778 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-19 20:22:21,779 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-19 20:22:21,780 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-19 20:22:21,785 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-19 20:22:21,790 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-19 20:22:21,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-19 20:22:21,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-19 20:22:21,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-19 20:22:21,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-19 20:22:21,798 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-19 20:22:21,799 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-19 20:22:21,801 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-19 20:22:21,802 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-19 20:22:21,803 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-19 20:22:21,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-19 20:22:21,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-19 20:22:21,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-19 20:22:21,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-19 20:22:21,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-19 20:22:21,812 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-19 20:22:21,813 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-19 20:22:21,815 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-19 20:22:21,816 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-19 20:22:21,817 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-19 20:22:21,818 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-19 20:22:21,820 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-19 20:22:21,825 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-19 20:22:21,826 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-19 20:22:21,828 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-19 20:22:21,829 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-19 20:22:21,831 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-19 20:22:21,832 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-19 20:22:21,833 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-19 20:22:21,834 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-19 20:22:21,836 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-19 20:22:21,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-19 20:22:21,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-19 20:22:21,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-19 20:22:21,841 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-19 20:22:21,843 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-19 20:22:21,844 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-19 20:22:21,847 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-19 20:22:21,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-19 20:22:21,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-19 20:22:21,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-19 20:22:21,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-19 20:22:21,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-19 20:22:21,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-19 20:22:21,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-19 20:22:21,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-19 20:22:21,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-19 20:22:21,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-19 20:22:21,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-19 20:22:21,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-19 20:22:21,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-19 20:22:21,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-19 20:22:21,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-19 20:22:21,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-19 20:22:21,874 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-19 20:22:21,876 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-19 20:22:21,878 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-19 20:22:21,879 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-19 20:22:21,880 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-19 20:22:21,881 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-19 20:22:21,883 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-19 20:22:21,884 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-19 20:22:21,885 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-19 20:22:21,886 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-19 20:22:21,888 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-19 20:22:21,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-19 20:22:21,891 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-19 20:22:21,892 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-19 20:22:21,893 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-19 20:22:21,895 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-19 20:22:21,897 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-19 20:22:21,898 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-19 20:22:21,900 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-19 20:22:21,901 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-19 20:22:21,903 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-19 20:22:41,148 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-19 20:22:41,154 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-19 20:22:41,156 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-19 20:22:41,158 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-19 20:22:41,159 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-19 20:22:41,161 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-19 20:22:41,163 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-19 20:22:41,164 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-19 20:22:41,166 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-19 20:22:41,168 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-19 20:22:41,169 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-19 20:22:41,171 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-19 20:22:41,172 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-19 20:22:41,173 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-19 20:22:41,178 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-19 20:22:41,180 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-19 20:22:41,181 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-19 20:22:50,289 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-19 20:22:50,296 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-19 20:22:50,298 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-19 20:22:50,299 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-19 20:22:50,301 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-19 20:22:50,303 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-19 20:22:50,305 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-19 20:22:50,307 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias'], {'weight_decay': 0}
2022-03-19 20:22:50,309 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight'], {}
2022-03-19 20:22:50,312 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-19 20:22:50,313 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125237762
2022-03-19 20:22:50,317 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-19 20:22:50,319 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-19 20:22:50,320 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-19 20:22:50,321 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-19 20:22:50,323 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-19 20:22:50,324 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-19 20:22:50,326 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-19 20:22:50,327 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-19 20:22:50,329 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-19 20:22:50,330 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-19 20:22:50,332 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-19 20:22:50,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-19 20:22:50,335 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-19 20:22:50,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-19 20:22:50,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-19 20:22:50,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-19 20:22:50,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-19 20:22:50,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-19 20:22:50,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-19 20:22:50,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-19 20:22:50,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-19 20:22:50,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-19 20:22:50,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-19 20:22:50,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-19 20:22:50,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-19 20:22:50,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-19 20:22:50,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-19 20:22:50,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-19 20:22:50,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-19 20:22:50,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-19 20:22:50,365 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-19 20:22:50,366 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-19 20:22:50,368 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-19 20:22:50,369 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-19 20:22:50,372 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-19 20:22:50,373 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-19 20:22:50,375 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-19 20:22:50,377 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-19 20:22:50,378 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-19 20:22:50,379 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-19 20:22:50,381 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-19 20:22:50,382 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-19 20:22:50,383 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-19 20:22:50,385 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-19 20:22:50,386 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-19 20:22:50,387 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-19 20:22:50,388 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-19 20:22:50,390 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-19 20:22:50,391 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-19 20:22:50,392 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-19 20:22:50,394 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-19 20:22:50,395 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-19 20:22:50,396 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-19 20:22:50,400 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-19 20:22:50,402 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-19 20:22:50,404 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-19 20:22:50,405 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-19 20:22:50,406 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-19 20:22:50,407 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-19 20:22:50,409 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-19 20:22:50,410 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-19 20:22:50,411 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-19 20:22:50,413 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-19 20:22:50,414 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-19 20:22:50,416 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-19 20:22:50,417 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-19 20:22:50,419 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-19 20:22:50,420 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-19 20:22:50,421 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-19 20:22:50,422 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-19 20:22:50,424 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-19 20:22:50,425 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-19 20:22:50,427 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-19 20:22:50,428 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-19 20:22:50,432 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-19 20:22:50,433 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-19 20:22:50,434 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-19 20:22:50,435 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-19 20:22:50,437 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-19 20:22:50,438 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-19 20:22:50,439 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-19 20:22:50,441 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-19 20:22:50,442 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-19 20:22:50,443 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-19 20:22:50,444 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-19 20:22:50,448 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-19 20:22:50,449 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-19 20:22:50,450 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-19 20:22:50,452 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-19 20:22:50,454 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-19 20:22:50,455 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-19 20:22:50,456 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-19 20:22:50,457 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-19 20:22:50,459 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-19 20:22:50,460 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-19 20:22:50,461 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-19 20:22:50,463 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-19 20:22:50,464 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-19 20:22:50,465 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-19 20:22:50,466 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-19 20:22:50,468 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-19 20:22:50,469 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-19 20:22:50,470 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-19 20:22:50,472 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-19 20:22:50,473 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-19 20:22:50,474 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-19 20:22:50,475 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-19 20:22:50,480 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-19 20:22:50,482 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-19 20:22:50,484 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-19 20:22:50,485 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-19 20:22:50,486 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-19 20:22:50,488 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-19 20:22:50,489 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-19 20:22:50,491 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-19 20:22:50,492 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-19 20:22:50,494 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-19 20:22:50,495 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-19 20:22:50,496 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-19 20:22:50,497 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-19 20:22:50,499 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-19 20:22:50,500 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-19 20:22:50,501 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-19 20:22:50,502 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-19 20:22:50,504 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-19 20:22:50,505 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-19 20:22:50,506 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-19 20:22:50,508 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-19 20:22:50,509 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-19 20:22:50,511 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-19 20:22:50,512 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-19 20:22:50,513 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-19 20:22:50,515 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-19 20:22:50,516 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-19 20:22:50,519 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-19 20:22:50,520 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-19 20:22:50,522 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-19 20:22:50,523 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-19 20:22:50,524 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-19 20:22:50,526 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-19 20:22:50,528 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-19 20:22:50,529 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-19 20:22:50,530 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-19 20:22:50,532 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-19 20:22:50,533 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-19 20:22:50,535 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-19 20:22:50,536 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-19 20:22:50,538 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-19 20:22:50,542 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-19 20:22:50,544 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-19 20:22:50,546 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-19 20:22:50,547 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-19 20:22:50,548 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-19 20:22:50,550 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-19 20:22:50,551 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-19 20:22:50,552 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-19 20:22:50,554 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-19 20:22:50,555 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-19 20:22:50,557 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-19 20:22:50,558 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-19 20:22:50,560 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-19 20:22:50,561 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-19 20:22:50,563 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-19 20:22:50,564 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-19 20:22:50,565 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-19 20:22:50,568 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-19 20:22:50,569 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-19 20:22:50,570 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-19 20:22:50,572 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-19 20:22:50,573 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-19 20:22:50,575 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-19 20:22:50,576 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-19 20:22:50,577 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-19 20:22:50,579 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-19 20:22:50,580 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-19 20:22:50,582 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-19 20:22:50,583 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-19 20:22:50,584 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-19 20:22:50,586 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-19 20:22:50,587 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-19 20:22:50,589 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-19 20:22:50,592 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-19 20:22:50,594 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-19 20:22:50,595 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-19 20:22:50,596 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-19 20:22:50,598 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-19 20:22:50,599 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-19 20:22:50,601 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-19 20:22:50,602 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-19 20:22:50,603 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-19 20:22:50,605 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-19 20:22:50,607 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-19 20:22:50,608 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-19 20:22:50,610 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-19 20:22:50,611 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-19 20:22:50,612 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-19 20:22:50,614 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-19 20:22:50,618 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-19 20:22:50,621 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-19 20:22:50,622 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-19 20:22:50,624 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-19 20:22:50,625 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-19 20:22:50,626 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-19 20:22:50,628 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-19 20:22:50,629 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-19 20:22:50,631 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-19 20:22:50,633 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-19 20:22:50,634 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-19 20:22:50,636 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-19 20:22:50,637 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-19 20:22:50,639 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-19 20:22:50,644 - INFO - allennlp.training.trainer - Beginning training.
2022-03-19 20:22:50,645 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-19 20:22:50,647 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-19 20:22:50,649 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-19 20:22:50,651 - INFO - allennlp.training.trainer - Training
2022-03-19 20:22:50,653 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-19 20:22:50,816 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-19 20:22:50,818 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-19 20:23:01,020 - INFO - tqdm - f1: 0.4780, accuracy: 0.8562, batch_loss: 1.1382, loss: 0.4190 ||:   1%|          | 50/7204 [00:10<28:05,  4.24it/s]
2022-03-19 20:23:11,216 - INFO - tqdm - f1: 0.4863, accuracy: 0.8460, batch_loss: 0.3866, loss: 0.4183 ||:   2%|1         | 136/7204 [00:20<10:45, 10.95it/s]
2022-03-19 20:23:21,254 - INFO - tqdm - f1: 0.4773, accuracy: 0.8410, batch_loss: 0.2878, loss: 0.4111 ||:   3%|3         | 219/7204 [00:30<09:23, 12.39it/s]
2022-03-19 20:23:31,292 - INFO - tqdm - f1: 0.4751, accuracy: 0.8394, batch_loss: 0.4689, loss: 0.4075 ||:   4%|4         | 297/7204 [00:40<15:29,  7.43it/s]
2022-03-19 20:23:41,356 - INFO - tqdm - f1: 0.4726, accuracy: 0.8425, batch_loss: 0.5969, loss: 0.3965 ||:   5%|5         | 373/7204 [00:50<30:48,  3.70it/s]
2022-03-19 20:23:51,421 - INFO - tqdm - f1: 0.4709, accuracy: 0.8457, batch_loss: 0.3339, loss: 0.3879 ||:   6%|6         | 463/7204 [01:00<08:44, 12.85it/s]
2022-03-19 20:24:01,443 - INFO - tqdm - f1: 0.4706, accuracy: 0.8477, batch_loss: 0.4934, loss: 0.3811 ||:   7%|7         | 540/7204 [01:10<09:55, 11.19it/s]
2022-03-19 20:24:11,611 - INFO - tqdm - f1: 0.4807, accuracy: 0.8474, batch_loss: 0.4722, loss: 0.3792 ||:   9%|8         | 618/7204 [01:20<17:52,  6.14it/s]
2022-03-19 20:24:21,913 - INFO - tqdm - f1: 0.4897, accuracy: 0.8480, batch_loss: 0.3412, loss: 0.3765 ||:  10%|9         | 696/7204 [01:31<29:54,  3.63it/s]
2022-03-19 20:24:32,005 - INFO - tqdm - f1: 0.5011, accuracy: 0.8491, batch_loss: 0.1285, loss: 0.3719 ||:  11%|#         | 782/7204 [01:41<10:19, 10.37it/s]
2022-03-19 20:24:42,113 - INFO - tqdm - f1: 0.5046, accuracy: 0.8499, batch_loss: 0.4135, loss: 0.3664 ||:  12%|#2        | 865/7204 [01:51<08:56, 11.81it/s]
2022-03-19 20:24:52,238 - INFO - tqdm - f1: 0.5048, accuracy: 0.8498, batch_loss: 0.1986, loss: 0.3651 ||:  13%|#3        | 941/7204 [02:01<17:05,  6.11it/s]
2022-03-19 20:25:02,659 - INFO - tqdm - f1: 0.5116, accuracy: 0.8506, batch_loss: 0.0471, loss: 0.3620 ||:  14%|#4        | 1024/7204 [02:12<20:47,  4.95it/s]
2022-03-19 20:25:13,890 - INFO - tqdm - f1: 0.5147, accuracy: 0.8515, batch_loss: 0.3037, loss: 0.3592 ||:  15%|#5        | 1114/7204 [02:23<24:14,  4.19it/s]
2022-03-19 20:25:24,693 - INFO - tqdm - f1: 0.5159, accuracy: 0.8512, batch_loss: 0.3136, loss: 0.3591 ||:  17%|#6        | 1206/7204 [02:34<22:58,  4.35it/s]
2022-03-19 20:25:35,475 - INFO - tqdm - f1: 0.5172, accuracy: 0.8510, batch_loss: 0.2983, loss: 0.3574 ||:  18%|#7        | 1296/7204 [02:44<25:29,  3.86it/s]
2022-03-19 20:25:46,185 - INFO - tqdm - f1: 0.5233, accuracy: 0.8507, batch_loss: 0.3200, loss: 0.3573 ||:  19%|#9        | 1383/7204 [02:55<23:54,  4.06it/s]
2022-03-19 20:25:57,011 - INFO - tqdm - f1: 0.5297, accuracy: 0.8500, batch_loss: 0.4703, loss: 0.3583 ||:  21%|##        | 1477/7204 [03:06<22:37,  4.22it/s]
2022-03-19 20:26:07,106 - INFO - tqdm - f1: 0.5360, accuracy: 0.8504, batch_loss: 0.4164, loss: 0.3576 ||:  22%|##1       | 1561/7204 [03:16<19:05,  4.93it/s]
2022-03-19 20:26:17,517 - INFO - tqdm - f1: 0.5411, accuracy: 0.8510, batch_loss: 0.2933, loss: 0.3552 ||:  23%|##2       | 1644/7204 [03:26<19:57,  4.64it/s]
2022-03-19 20:26:27,628 - INFO - tqdm - f1: 0.5441, accuracy: 0.8522, batch_loss: 0.3944, loss: 0.3527 ||:  24%|##4       | 1734/7204 [03:36<08:26, 10.80it/s]
2022-03-19 20:26:37,706 - INFO - tqdm - f1: 0.5451, accuracy: 0.8532, batch_loss: 0.4552, loss: 0.3513 ||:  25%|##5       | 1819/7204 [03:47<07:52, 11.40it/s]
2022-03-19 20:26:47,817 - INFO - tqdm - f1: 0.5453, accuracy: 0.8529, batch_loss: 0.5410, loss: 0.3520 ||:  26%|##6       | 1904/7204 [03:57<08:16, 10.67it/s]
2022-03-19 20:26:57,838 - INFO - tqdm - f1: 0.5493, accuracy: 0.8535, batch_loss: 0.1853, loss: 0.3511 ||:  28%|##7       | 1983/7204 [04:07<12:55,  6.73it/s]
2022-03-19 20:27:08,028 - INFO - tqdm - f1: 0.5515, accuracy: 0.8539, batch_loss: 0.0296, loss: 0.3498 ||:  29%|##8       | 2063/7204 [04:17<17:40,  4.85it/s]
2022-03-19 20:27:18,284 - INFO - tqdm - f1: 0.5575, accuracy: 0.8549, batch_loss: 0.2740, loss: 0.3484 ||:  30%|##9       | 2149/7204 [04:27<20:31,  4.10it/s]
2022-03-19 20:27:28,531 - INFO - tqdm - f1: 0.5599, accuracy: 0.8556, batch_loss: 0.4987, loss: 0.3470 ||:  31%|###       | 2233/7204 [04:37<17:11,  4.82it/s]
2022-03-19 20:27:39,493 - INFO - tqdm - f1: 0.5628, accuracy: 0.8563, batch_loss: 0.0655, loss: 0.3460 ||:  32%|###2      | 2320/7204 [04:48<18:58,  4.29it/s]
2022-03-19 20:27:49,851 - INFO - tqdm - f1: 0.5640, accuracy: 0.8566, batch_loss: 0.1209, loss: 0.3451 ||:  33%|###3      | 2410/7204 [04:59<16:47,  4.76it/s]
2022-03-19 20:28:00,057 - INFO - tqdm - f1: 0.5635, accuracy: 0.8564, batch_loss: 0.1527, loss: 0.3447 ||:  35%|###4      | 2509/7204 [05:09<06:30, 12.02it/s]
2022-03-19 20:28:10,146 - INFO - tqdm - f1: 0.5663, accuracy: 0.8559, batch_loss: 0.6521, loss: 0.3456 ||:  36%|###6      | 2599/7204 [05:19<06:13, 12.33it/s]
2022-03-19 20:28:20,337 - INFO - tqdm - f1: 0.5699, accuracy: 0.8560, batch_loss: 0.4513, loss: 0.3449 ||:  37%|###7      | 2684/7204 [05:29<06:27, 11.67it/s]
2022-03-19 20:28:30,414 - INFO - tqdm - f1: 0.5704, accuracy: 0.8565, batch_loss: 0.1212, loss: 0.3440 ||:  38%|###8      | 2763/7204 [05:39<07:28,  9.91it/s]
2022-03-19 20:28:40,512 - INFO - tqdm - f1: 0.5719, accuracy: 0.8564, batch_loss: 0.0671, loss: 0.3442 ||:  40%|###9      | 2846/7204 [05:49<09:24,  7.72it/s]
2022-03-19 20:28:50,802 - INFO - tqdm - f1: 0.5752, accuracy: 0.8567, batch_loss: 0.0975, loss: 0.3434 ||:  41%|####      | 2936/7204 [06:00<16:56,  4.20it/s]
2022-03-19 20:29:00,890 - INFO - tqdm - f1: 0.5763, accuracy: 0.8566, batch_loss: 0.3557, loss: 0.3435 ||:  42%|####1     | 3023/7204 [06:10<12:01,  5.80it/s]
2022-03-19 20:29:11,622 - INFO - tqdm - f1: 0.5779, accuracy: 0.8566, batch_loss: 0.3693, loss: 0.3436 ||:  43%|####3     | 3115/7204 [06:20<14:28,  4.71it/s]
2022-03-19 20:29:22,424 - INFO - tqdm - f1: 0.5793, accuracy: 0.8570, batch_loss: 0.5051, loss: 0.3423 ||:  44%|####4     | 3204/7204 [06:31<16:52,  3.95it/s]
2022-03-19 20:29:32,840 - INFO - tqdm - f1: 0.5805, accuracy: 0.8572, batch_loss: 0.2540, loss: 0.3417 ||:  46%|####5     | 3297/7204 [06:42<14:00,  4.65it/s]
2022-03-19 20:29:43,327 - INFO - tqdm - f1: 0.5816, accuracy: 0.8575, batch_loss: 0.0609, loss: 0.3413 ||:  47%|####6     | 3385/7204 [06:52<11:55,  5.34it/s]
2022-03-19 20:29:53,608 - INFO - tqdm - f1: 0.5830, accuracy: 0.8580, batch_loss: 0.3429, loss: 0.3407 ||:  48%|####8     | 3469/7204 [07:02<12:43,  4.89it/s]
2022-03-19 20:30:04,127 - INFO - tqdm - f1: 0.5846, accuracy: 0.8579, batch_loss: 0.3709, loss: 0.3400 ||:  49%|####9     | 3556/7204 [07:13<11:35,  5.25it/s]
2022-03-19 20:30:14,536 - INFO - tqdm - f1: 0.5850, accuracy: 0.8579, batch_loss: 0.4552, loss: 0.3394 ||:  51%|#####     | 3645/7204 [07:23<11:57,  4.96it/s]
2022-03-19 20:30:25,235 - INFO - tqdm - f1: 0.5865, accuracy: 0.8577, batch_loss: 0.1447, loss: 0.3393 ||:  52%|#####1    | 3735/7204 [07:34<13:12,  4.38it/s]
2022-03-19 20:30:35,243 - INFO - tqdm - f1: 0.5871, accuracy: 0.8582, batch_loss: 0.2741, loss: 0.3388 ||:  53%|#####2    | 3818/7204 [07:44<11:28,  4.92it/s]
2022-03-19 20:30:45,558 - INFO - tqdm - f1: 0.5882, accuracy: 0.8585, batch_loss: 0.2657, loss: 0.3383 ||:  54%|#####4    | 3909/7204 [07:54<11:12,  4.90it/s]
2022-03-19 20:30:56,125 - INFO - tqdm - f1: 0.5888, accuracy: 0.8592, batch_loss: 0.4796, loss: 0.3372 ||:  55%|#####5    | 3997/7204 [08:05<11:51,  4.51it/s]
2022-03-19 20:31:06,342 - INFO - tqdm - f1: 0.5886, accuracy: 0.8591, batch_loss: 0.1418, loss: 0.3371 ||:  57%|#####6    | 4081/7204 [08:15<11:05,  4.69it/s]
2022-03-19 20:31:16,659 - INFO - tqdm - f1: 0.5893, accuracy: 0.8592, batch_loss: 0.1579, loss: 0.3367 ||:  58%|#####7    | 4166/7204 [08:26<09:15,  5.47it/s]
2022-03-19 20:31:26,714 - INFO - tqdm - f1: 0.5886, accuracy: 0.8594, batch_loss: 0.4667, loss: 0.3360 ||:  59%|#####8    | 4245/7204 [08:36<10:49,  4.56it/s]
2022-03-19 20:31:37,158 - INFO - tqdm - f1: 0.5896, accuracy: 0.8594, batch_loss: 0.0999, loss: 0.3356 ||:  60%|######    | 4335/7204 [08:46<11:10,  4.28it/s]
2022-03-19 20:31:47,249 - INFO - tqdm - f1: 0.5897, accuracy: 0.8593, batch_loss: 0.2699, loss: 0.3361 ||:  61%|######1   | 4421/7204 [08:56<10:30,  4.41it/s]
2022-03-19 20:31:57,744 - INFO - tqdm - f1: 0.5918, accuracy: 0.8593, batch_loss: 0.1352, loss: 0.3357 ||:  63%|######2   | 4509/7204 [09:07<09:14,  4.86it/s]
2022-03-19 20:32:08,153 - INFO - tqdm - f1: 0.5930, accuracy: 0.8593, batch_loss: 0.3160, loss: 0.3355 ||:  64%|######3   | 4596/7204 [09:17<08:53,  4.89it/s]
2022-03-19 20:32:18,609 - INFO - tqdm - f1: 0.5931, accuracy: 0.8592, batch_loss: 0.0802, loss: 0.3355 ||:  65%|######5   | 4684/7204 [09:27<08:58,  4.68it/s]
2022-03-19 20:32:29,185 - INFO - tqdm - f1: 0.5940, accuracy: 0.8594, batch_loss: 0.3119, loss: 0.3353 ||:  66%|######6   | 4778/7204 [09:38<08:45,  4.62it/s]
2022-03-19 20:32:39,676 - INFO - tqdm - f1: 0.5949, accuracy: 0.8595, batch_loss: 0.2932, loss: 0.3350 ||:  68%|######7   | 4864/7204 [09:49<10:04,  3.87it/s]
2022-03-19 20:32:49,957 - INFO - tqdm - f1: 0.5964, accuracy: 0.8595, batch_loss: 0.4628, loss: 0.3348 ||:  69%|######8   | 4951/7204 [09:59<08:56,  4.20it/s]
2022-03-19 20:33:00,030 - INFO - tqdm - f1: 0.5970, accuracy: 0.8594, batch_loss: 0.6631, loss: 0.3350 ||:  70%|######9   | 5036/7204 [10:09<07:39,  4.72it/s]
2022-03-19 20:33:10,550 - INFO - tqdm - f1: 0.5973, accuracy: 0.8598, batch_loss: 0.5265, loss: 0.3344 ||:  71%|#######1  | 5122/7204 [10:19<07:38,  4.54it/s]
2022-03-19 20:33:20,889 - INFO - tqdm - f1: 0.5970, accuracy: 0.8597, batch_loss: 0.3774, loss: 0.3345 ||:  72%|#######2  | 5207/7204 [10:30<06:42,  4.96it/s]
2022-03-19 20:33:31,839 - INFO - tqdm - f1: 0.5970, accuracy: 0.8598, batch_loss: 0.2266, loss: 0.3341 ||:  73%|#######3  | 5293/7204 [10:41<07:47,  4.08it/s]
2022-03-19 20:33:42,706 - INFO - tqdm - f1: 0.5982, accuracy: 0.8600, batch_loss: 0.5260, loss: 0.3338 ||:  75%|#######4  | 5387/7204 [10:52<06:43,  4.50it/s]
2022-03-19 20:33:52,715 - INFO - tqdm - f1: 0.5986, accuracy: 0.8602, batch_loss: 0.3724, loss: 0.3337 ||:  76%|#######6  | 5483/7204 [11:02<02:23, 11.97it/s]
2022-03-19 20:34:02,941 - INFO - tqdm - f1: 0.5990, accuracy: 0.8605, batch_loss: 0.2004, loss: 0.3331 ||:  77%|#######7  | 5563/7204 [11:12<02:23, 11.47it/s]
2022-03-19 20:34:12,944 - INFO - tqdm - f1: 0.5982, accuracy: 0.8605, batch_loss: 0.1155, loss: 0.3328 ||:  78%|#######8  | 5640/7204 [11:22<02:50,  9.16it/s]
2022-03-19 20:34:23,043 - INFO - tqdm - f1: 0.5990, accuracy: 0.8605, batch_loss: 0.2846, loss: 0.3328 ||:  79%|#######9  | 5716/7204 [11:32<04:06,  6.03it/s]
2022-03-19 20:34:33,161 - INFO - tqdm - f1: 0.5996, accuracy: 0.8605, batch_loss: 0.1105, loss: 0.3325 ||:  81%|########  | 5803/7204 [11:42<04:29,  5.19it/s]
2022-03-19 20:34:43,619 - INFO - tqdm - f1: 0.5996, accuracy: 0.8605, batch_loss: 0.2084, loss: 0.3322 ||:  82%|########1 | 5880/7204 [11:52<04:40,  4.72it/s]
2022-03-19 20:34:53,792 - INFO - tqdm - f1: 0.6008, accuracy: 0.8609, batch_loss: 0.3454, loss: 0.3316 ||:  83%|########2 | 5964/7204 [12:03<01:53, 10.93it/s]
2022-03-19 20:35:03,892 - INFO - tqdm - f1: 0.6017, accuracy: 0.8608, batch_loss: 0.4134, loss: 0.3317 ||:  84%|########3 | 6042/7204 [12:13<01:54, 10.12it/s]
2022-03-19 20:35:13,911 - INFO - tqdm - f1: 0.6016, accuracy: 0.8609, batch_loss: 0.1321, loss: 0.3315 ||:  85%|########4 | 6104/7204 [12:23<04:49,  3.80it/s]
2022-03-19 20:35:24,089 - INFO - tqdm - f1: 0.6022, accuracy: 0.8611, batch_loss: 0.1020, loss: 0.3312 ||:  86%|########5 | 6187/7204 [12:33<01:45,  9.61it/s]
2022-03-19 20:35:34,260 - INFO - tqdm - f1: 0.6027, accuracy: 0.8612, batch_loss: 0.5108, loss: 0.3307 ||:  87%|########6 | 6257/7204 [12:43<01:39,  9.49it/s]
2022-03-19 20:35:44,389 - INFO - tqdm - f1: 0.6028, accuracy: 0.8614, batch_loss: 0.2409, loss: 0.3302 ||:  88%|########7 | 6337/7204 [12:53<01:55,  7.48it/s]
2022-03-19 20:35:54,500 - INFO - tqdm - f1: 0.6030, accuracy: 0.8615, batch_loss: 0.1785, loss: 0.3301 ||:  89%|########9 | 6418/7204 [13:03<02:12,  5.92it/s]
2022-03-19 20:36:04,518 - INFO - tqdm - f1: 0.6036, accuracy: 0.8615, batch_loss: 0.4127, loss: 0.3298 ||:  90%|######### | 6498/7204 [13:13<02:58,  3.96it/s]
2022-03-19 20:36:14,981 - INFO - tqdm - f1: 0.6032, accuracy: 0.8616, batch_loss: 0.1276, loss: 0.3298 ||:  91%|#########1| 6581/7204 [13:24<02:15,  4.61it/s]
2022-03-19 20:36:25,903 - INFO - tqdm - f1: 0.6038, accuracy: 0.8616, batch_loss: 0.3203, loss: 0.3296 ||:  93%|#########2| 6666/7204 [13:35<02:18,  3.90it/s]
2022-03-19 20:36:36,323 - INFO - tqdm - f1: 0.6043, accuracy: 0.8618, batch_loss: 0.3183, loss: 0.3293 ||:  94%|#########3| 6743/7204 [13:45<01:38,  4.67it/s]
2022-03-19 20:36:47,176 - INFO - tqdm - f1: 0.6039, accuracy: 0.8619, batch_loss: 0.2262, loss: 0.3290 ||:  95%|#########4| 6819/7204 [13:56<01:25,  4.51it/s]
2022-03-19 20:36:57,536 - INFO - tqdm - f1: 0.6045, accuracy: 0.8621, batch_loss: 0.3230, loss: 0.3286 ||:  96%|#########5| 6893/7204 [14:06<00:38,  8.08it/s]
2022-03-19 20:37:07,670 - INFO - tqdm - f1: 0.6058, accuracy: 0.8624, batch_loss: 0.0883, loss: 0.3283 ||:  97%|#########6| 6962/7204 [14:17<00:31,  7.56it/s]
2022-03-19 20:37:17,893 - INFO - tqdm - f1: 0.6059, accuracy: 0.8625, batch_loss: 0.1559, loss: 0.3281 ||:  98%|#########7| 7036/7204 [14:27<00:19,  8.56it/s]
2022-03-19 20:37:28,121 - INFO - tqdm - f1: 0.6068, accuracy: 0.8625, batch_loss: 0.4123, loss: 0.3280 ||:  99%|#########8| 7109/7204 [14:37<00:10,  8.67it/s]
2022-03-19 20:37:35,596 - INFO - tqdm - f1: 0.6071, accuracy: 0.8625, batch_loss: 0.5641, loss: 0.3281 ||: 100%|#########9| 7168/7204 [14:44<00:03, 11.88it/s]
2022-03-19 20:37:35,802 - INFO - tqdm - f1: 0.6072, accuracy: 0.8625, batch_loss: 0.2250, loss: 0.3281 ||: 100%|#########9| 7170/7204 [14:45<00:03, 11.13it/s]
2022-03-19 20:37:36,008 - INFO - tqdm - f1: 0.6072, accuracy: 0.8625, batch_loss: 0.4197, loss: 0.3280 ||: 100%|#########9| 7172/7204 [14:45<00:03, 10.66it/s]
2022-03-19 20:37:36,191 - INFO - tqdm - f1: 0.6072, accuracy: 0.8625, batch_loss: 0.2417, loss: 0.3280 ||: 100%|#########9| 7174/7204 [14:45<00:02, 10.74it/s]
2022-03-19 20:37:36,362 - INFO - tqdm - f1: 0.6072, accuracy: 0.8625, batch_loss: 0.3777, loss: 0.3280 ||: 100%|#########9| 7176/7204 [14:45<00:02, 11.05it/s]
2022-03-19 20:37:36,535 - INFO - tqdm - f1: 0.6071, accuracy: 0.8625, batch_loss: 0.4628, loss: 0.3280 ||: 100%|#########9| 7178/7204 [14:45<00:02, 11.17it/s]
2022-03-19 20:37:36,687 - INFO - tqdm - f1: 0.6072, accuracy: 0.8625, batch_loss: 0.3606, loss: 0.3280 ||: 100%|#########9| 7180/7204 [14:46<00:02, 11.70it/s]
2022-03-19 20:37:36,820 - INFO - tqdm - f1: 0.6071, accuracy: 0.8625, batch_loss: 0.8838, loss: 0.3281 ||: 100%|#########9| 7182/7204 [14:46<00:01, 12.53it/s]
2022-03-19 20:37:38,134 - INFO - tqdm - f1: 0.6071, accuracy: 0.8625, batch_loss: 0.2636, loss: 0.3281 ||: 100%|#########9| 7184/7204 [14:47<00:05,  3.95it/s]
2022-03-19 20:37:38,279 - INFO - tqdm - f1: 0.6072, accuracy: 0.8626, batch_loss: 0.2559, loss: 0.3281 ||: 100%|#########9| 7186/7204 [14:47<00:03,  5.03it/s]
2022-03-19 20:37:38,435 - INFO - tqdm - f1: 0.6072, accuracy: 0.8626, batch_loss: 0.3334, loss: 0.3281 ||: 100%|#########9| 7188/7204 [14:47<00:02,  6.15it/s]
2022-03-19 20:37:38,655 - INFO - tqdm - f1: 0.6072, accuracy: 0.8626, batch_loss: 0.3228, loss: 0.3280 ||: 100%|#########9| 7190/7204 [14:48<00:02,  6.81it/s]
2022-03-19 20:37:38,807 - INFO - tqdm - f1: 0.6073, accuracy: 0.8626, batch_loss: 0.2568, loss: 0.3280 ||: 100%|#########9| 7192/7204 [14:48<00:01,  7.97it/s]
2022-03-19 20:37:38,926 - INFO - tqdm - f1: 0.6072, accuracy: 0.8626, batch_loss: 0.0749, loss: 0.3280 ||: 100%|#########9| 7194/7204 [14:48<00:01,  9.46it/s]
2022-03-19 20:37:39,062 - INFO - tqdm - f1: 0.6072, accuracy: 0.8626, batch_loss: 0.2700, loss: 0.3280 ||: 100%|#########9| 7196/7204 [14:48<00:00, 10.59it/s]
2022-03-19 20:37:39,192 - INFO - tqdm - f1: 0.6073, accuracy: 0.8626, batch_loss: 0.7028, loss: 0.3280 ||: 100%|#########9| 7198/7204 [14:48<00:00, 11.67it/s]
2022-03-19 20:37:39,405 - INFO - tqdm - f1: 0.6073, accuracy: 0.8626, batch_loss: 0.4590, loss: 0.3280 ||: 100%|#########9| 7200/7204 [14:48<00:00, 10.89it/s]
2022-03-19 20:37:39,529 - INFO - tqdm - f1: 0.6074, accuracy: 0.8625, batch_loss: 0.5719, loss: 0.3281 ||: 100%|#########9| 7202/7204 [14:48<00:00, 12.05it/s]
2022-03-19 20:37:39,806 - INFO - tqdm - f1: 0.6074, accuracy: 0.8625, batch_loss: 0.3483, loss: 0.3281 ||: 100%|##########| 7204/7204 [14:49<00:00, 10.04it/s]
2022-03-19 20:37:39,909 - INFO - tqdm - f1: 0.6074, accuracy: 0.8625, batch_loss: 0.3483, loss: 0.3281 ||: 100%|##########| 7204/7204 [14:49<00:00,  8.10it/s]
2022-03-19 20:37:39,916 - INFO - allennlp.training.trainer - Validating
2022-03-19 20:37:39,919 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-19 20:37:39,929 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-19 20:37:39,933 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-19 20:37:49,930 - INFO - tqdm - f1: 0.6054, accuracy: 0.8760, batch_loss: 0.3430, loss: 0.2975 ||:  62%|######1   | 193/313 [00:10<00:05, 20.03it/s]
2022-03-19 20:37:54,397 - INFO - tqdm - f1: 0.6074, accuracy: 0.8674, batch_loss: 0.3888, loss: 0.3181 ||: 100%|##########| 313/313 [00:14<00:00, 21.62it/s]
2022-03-19 20:37:54,414 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/amazon_base/best.th'.
2022-03-19 20:37:56,457 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-19 20:37:56,463 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.863  |     0.867
2022-03-19 20:37:56,464 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.607  |     0.607
2022-03-19 20:37:56,466 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-19 20:37:56,467 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.328  |     0.318
2022-03-19 20:37:56,468 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13507.848  |       N/A
2022-03-19 20:37:56,470 - INFO - allennlp.training.trainer - Epoch duration: 0:15:05.824547
2022-03-19 20:37:56,472 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:15:52
2022-03-19 20:37:56,473 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-19 20:37:56,475 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-19 20:37:56,476 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-19 20:37:56,478 - INFO - allennlp.training.trainer - Training
2022-03-19 20:37:56,480 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-19 20:38:06,623 - INFO - tqdm - f1: 0.7325, accuracy: 0.8884, batch_loss: 0.3134, loss: 0.2904 ||:   1%|          | 70/7204 [00:10<29:34,  4.02it/s]
2022-03-19 20:38:17,587 - INFO - tqdm - f1: 0.6964, accuracy: 0.8815, batch_loss: 0.5072, loss: 0.2938 ||:   2%|2         | 154/7204 [00:21<25:29,  4.61it/s]
2022-03-19 20:38:27,830 - INFO - tqdm - f1: 0.7016, accuracy: 0.8829, batch_loss: 0.0220, loss: 0.2918 ||:   3%|3         | 237/7204 [00:31<12:41,  9.14it/s]
2022-03-19 20:38:38,047 - INFO - tqdm - f1: 0.6921, accuracy: 0.8827, batch_loss: 0.1123, loss: 0.2913 ||:   4%|4         | 310/7204 [00:41<15:05,  7.62it/s]
2022-03-19 20:38:48,164 - INFO - tqdm - f1: 0.6921, accuracy: 0.8781, batch_loss: 0.0569, loss: 0.2947 ||:   6%|5         | 398/7204 [00:51<14:33,  7.79it/s]
2022-03-19 20:38:58,232 - INFO - tqdm - f1: 0.6873, accuracy: 0.8775, batch_loss: 0.6590, loss: 0.2950 ||:   7%|6         | 470/7204 [01:01<13:47,  8.14it/s]
2022-03-19 20:39:08,422 - INFO - tqdm - f1: 0.6908, accuracy: 0.8782, batch_loss: 0.1338, loss: 0.2938 ||:   8%|7         | 543/7204 [01:11<31:28,  3.53it/s]
2022-03-19 20:39:18,594 - INFO - tqdm - f1: 0.6976, accuracy: 0.8799, batch_loss: 0.1897, loss: 0.2910 ||:   9%|8         | 618/7204 [01:22<10:53, 10.08it/s]
2022-03-19 20:39:29,520 - INFO - tqdm - f1: 0.6965, accuracy: 0.8783, batch_loss: 0.2047, loss: 0.2933 ||:   9%|9         | 684/7204 [01:33<21:51,  4.97it/s]
2022-03-19 20:39:39,588 - INFO - tqdm - f1: 0.6959, accuracy: 0.8771, batch_loss: 0.3585, loss: 0.2968 ||:  11%|#         | 758/7204 [01:43<14:30,  7.40it/s]
2022-03-19 20:39:49,784 - INFO - tqdm - f1: 0.6971, accuracy: 0.8787, batch_loss: 0.2327, loss: 0.2940 ||:  11%|#1        | 815/7204 [01:53<38:22,  2.77it/s]
2022-03-19 20:39:59,921 - INFO - tqdm - f1: 0.6942, accuracy: 0.8784, batch_loss: 0.1567, loss: 0.2928 ||:  12%|#2        | 887/7204 [02:03<10:23, 10.13it/s]
2022-03-19 20:40:10,132 - INFO - tqdm - f1: 0.6933, accuracy: 0.8784, batch_loss: 0.4847, loss: 0.2928 ||:  13%|#3        | 954/7204 [02:13<20:25,  5.10it/s]
2022-03-19 20:40:20,227 - INFO - tqdm - f1: 0.6918, accuracy: 0.8782, batch_loss: 0.2246, loss: 0.2924 ||:  14%|#4        | 1029/7204 [02:23<09:04, 11.33it/s]
2022-03-19 20:40:30,258 - INFO - tqdm - f1: 0.6893, accuracy: 0.8774, batch_loss: 0.0504, loss: 0.2939 ||:  15%|#5        | 1105/7204 [02:33<09:55, 10.24it/s]
2022-03-19 20:40:40,650 - INFO - tqdm - f1: 0.6907, accuracy: 0.8770, batch_loss: 0.6532, loss: 0.2939 ||:  16%|#6        | 1182/7204 [02:44<21:27,  4.68it/s]
2022-03-19 20:40:50,676 - INFO - tqdm - f1: 0.6907, accuracy: 0.8760, batch_loss: 0.4974, loss: 0.2955 ||:  18%|#7        | 1263/7204 [02:54<09:39, 10.24it/s]
2022-03-19 20:41:01,589 - INFO - tqdm - f1: 0.6919, accuracy: 0.8763, batch_loss: 0.1557, loss: 0.2942 ||:  19%|#8        | 1347/7204 [03:05<23:11,  4.21it/s]
2022-03-19 20:41:11,784 - INFO - tqdm - f1: 0.6933, accuracy: 0.8763, batch_loss: 0.2821, loss: 0.2933 ||:  20%|#9        | 1430/7204 [03:15<08:28, 11.35it/s]
2022-03-19 20:41:21,832 - INFO - tqdm - f1: 0.6901, accuracy: 0.8759, batch_loss: 0.0257, loss: 0.2934 ||:  21%|##1       | 1519/7204 [03:25<09:49,  9.64it/s]
2022-03-19 20:41:31,890 - INFO - tqdm - f1: 0.6918, accuracy: 0.8765, batch_loss: 0.3851, loss: 0.2927 ||:  22%|##2       | 1592/7204 [03:35<11:47,  7.93it/s]
2022-03-19 20:41:42,170 - INFO - tqdm - f1: 0.6907, accuracy: 0.8763, batch_loss: 0.2312, loss: 0.2917 ||:  23%|##3       | 1668/7204 [03:45<22:07,  4.17it/s]
2022-03-19 20:41:52,178 - INFO - tqdm - f1: 0.6917, accuracy: 0.8771, batch_loss: 0.2458, loss: 0.2906 ||:  24%|##4       | 1758/7204 [03:55<08:32, 10.63it/s]
2022-03-19 20:42:02,275 - INFO - tqdm - f1: 0.6920, accuracy: 0.8768, batch_loss: 0.2054, loss: 0.2910 ||:  25%|##5       | 1836/7204 [04:05<08:43, 10.25it/s]
2022-03-19 20:42:12,383 - INFO - tqdm - f1: 0.6906, accuracy: 0.8767, batch_loss: 0.5799, loss: 0.2909 ||:  27%|##6       | 1910/7204 [04:15<15:26,  5.71it/s]
2022-03-19 20:42:22,564 - INFO - tqdm - f1: 0.6898, accuracy: 0.8778, batch_loss: 0.2840, loss: 0.2894 ||:  28%|##8       | 2019/7204 [04:26<08:19, 10.38it/s]
2022-03-19 20:42:32,567 - INFO - tqdm - f1: 0.6877, accuracy: 0.8770, batch_loss: 0.1465, loss: 0.2903 ||:  29%|##9       | 2105/7204 [04:36<16:18,  5.21it/s]
2022-03-19 20:42:42,984 - INFO - tqdm - f1: 0.6866, accuracy: 0.8771, batch_loss: 0.2254, loss: 0.2900 ||:  30%|###       | 2190/7204 [04:46<20:39,  4.04it/s]
2022-03-19 20:42:53,004 - INFO - tqdm - f1: 0.6836, accuracy: 0.8769, batch_loss: 0.3245, loss: 0.2907 ||:  32%|###1      | 2276/7204 [04:56<06:53, 11.93it/s]
2022-03-19 20:43:03,168 - INFO - tqdm - f1: 0.6839, accuracy: 0.8771, batch_loss: 0.0217, loss: 0.2904 ||:  33%|###2      | 2358/7204 [05:06<09:22,  8.62it/s]
2022-03-19 20:43:13,262 - INFO - tqdm - f1: 0.6849, accuracy: 0.8767, batch_loss: 0.3053, loss: 0.2909 ||:  34%|###4      | 2460/7204 [05:16<07:34, 10.45it/s]
2022-03-19 20:43:23,291 - INFO - tqdm - f1: 0.6865, accuracy: 0.8768, batch_loss: 0.1815, loss: 0.2908 ||:  35%|###5      | 2539/7204 [05:26<13:07,  5.92it/s]
2022-03-19 20:43:34,241 - INFO - tqdm - f1: 0.6867, accuracy: 0.8762, batch_loss: 0.1220, loss: 0.2914 ||:  37%|###6      | 2635/7204 [05:37<15:31,  4.91it/s]
2022-03-19 20:43:44,348 - INFO - tqdm - f1: 0.6858, accuracy: 0.8760, batch_loss: 0.5713, loss: 0.2920 ||:  38%|###7      | 2734/7204 [05:47<06:40, 11.15it/s]
2022-03-19 20:43:54,368 - INFO - tqdm - f1: 0.6849, accuracy: 0.8756, batch_loss: 0.1074, loss: 0.2922 ||:  39%|###9      | 2836/7204 [05:57<06:31, 11.16it/s]
2022-03-19 20:44:05,134 - INFO - tqdm - f1: 0.6843, accuracy: 0.8755, batch_loss: 0.2538, loss: 0.2930 ||:  41%|####      | 2934/7204 [06:08<18:39,  3.81it/s]
2022-03-19 20:44:15,788 - INFO - tqdm - f1: 0.6851, accuracy: 0.8759, batch_loss: 0.0928, loss: 0.2928 ||:  42%|####1     | 3016/7204 [06:19<14:50,  4.70it/s]
2022-03-19 20:44:25,864 - INFO - tqdm - f1: 0.6847, accuracy: 0.8758, batch_loss: 0.6212, loss: 0.2928 ||:  43%|####3     | 3099/7204 [06:29<05:24, 12.65it/s]
2022-03-19 20:44:36,002 - INFO - tqdm - f1: 0.6858, accuracy: 0.8759, batch_loss: 0.1350, loss: 0.2931 ||:  44%|####4     | 3187/7204 [06:39<06:18, 10.60it/s]
2022-03-19 20:44:46,202 - INFO - tqdm - f1: 0.6844, accuracy: 0.8759, batch_loss: 0.2369, loss: 0.2937 ||:  46%|####5     | 3281/7204 [06:49<06:48,  9.60it/s]
2022-03-19 20:44:56,206 - INFO - tqdm - f1: 0.6848, accuracy: 0.8762, batch_loss: 0.4363, loss: 0.2934 ||:  47%|####6     | 3380/7204 [06:59<06:25,  9.93it/s]
2022-03-19 20:45:06,213 - INFO - tqdm - f1: 0.6844, accuracy: 0.8761, batch_loss: 0.0359, loss: 0.2933 ||:  48%|####8     | 3470/7204 [07:09<06:08, 10.12it/s]
2022-03-19 20:45:16,395 - INFO - tqdm - f1: 0.6846, accuracy: 0.8763, batch_loss: 0.3423, loss: 0.2932 ||:  49%|####9     | 3539/7204 [07:19<16:33,  3.69it/s]
2022-03-19 20:45:26,530 - INFO - tqdm - f1: 0.6852, accuracy: 0.8766, batch_loss: 0.4039, loss: 0.2933 ||:  50%|#####     | 3632/7204 [07:30<05:18, 11.21it/s]
2022-03-19 20:45:36,552 - INFO - tqdm - f1: 0.6847, accuracy: 0.8767, batch_loss: 0.1372, loss: 0.2929 ||:  51%|#####1    | 3701/7204 [07:40<11:50,  4.93it/s]
2022-03-19 20:45:46,649 - INFO - tqdm - f1: 0.6856, accuracy: 0.8770, batch_loss: 0.1083, loss: 0.2927 ||:  53%|#####2    | 3791/7204 [07:50<05:08, 11.08it/s]
2022-03-19 20:45:56,800 - INFO - tqdm - f1: 0.6854, accuracy: 0.8771, batch_loss: 0.1789, loss: 0.2926 ||:  54%|#####3    | 3870/7204 [08:00<10:57,  5.07it/s]
2022-03-19 20:46:06,845 - INFO - tqdm - f1: 0.6841, accuracy: 0.8769, batch_loss: 0.4648, loss: 0.2931 ||:  55%|#####4    | 3955/7204 [08:10<05:50,  9.26it/s]
2022-03-19 20:46:17,454 - INFO - tqdm - f1: 0.6846, accuracy: 0.8771, batch_loss: 0.3135, loss: 0.2929 ||:  56%|#####5    | 4034/7204 [08:20<11:04,  4.77it/s]
2022-03-19 20:46:27,501 - INFO - tqdm - f1: 0.6844, accuracy: 0.8771, batch_loss: 0.2071, loss: 0.2929 ||:  57%|#####7    | 4114/7204 [08:31<04:40, 11.03it/s]
2022-03-19 20:46:37,724 - INFO - tqdm - f1: 0.6839, accuracy: 0.8769, batch_loss: 0.5275, loss: 0.2932 ||:  58%|#####8    | 4194/7204 [08:41<11:37,  4.31it/s]
2022-03-19 20:46:48,527 - INFO - tqdm - f1: 0.6856, accuracy: 0.8772, batch_loss: 0.0567, loss: 0.2928 ||:  59%|#####9    | 4279/7204 [08:52<10:36,  4.59it/s]
2022-03-19 20:46:58,679 - INFO - tqdm - f1: 0.6855, accuracy: 0.8768, batch_loss: 0.2133, loss: 0.2936 ||:  61%|######    | 4375/7204 [09:02<04:54,  9.60it/s]
2022-03-19 20:47:08,867 - INFO - tqdm - f1: 0.6866, accuracy: 0.8769, batch_loss: 0.0799, loss: 0.2936 ||:  62%|######1   | 4457/7204 [09:12<05:10,  8.86it/s]
2022-03-19 20:47:19,148 - INFO - tqdm - f1: 0.6872, accuracy: 0.8772, batch_loss: 0.4860, loss: 0.2932 ||:  63%|######2   | 4534/7204 [09:22<11:37,  3.83it/s]
2022-03-19 20:47:30,154 - INFO - tqdm - f1: 0.6863, accuracy: 0.8771, batch_loss: 0.3920, loss: 0.2939 ||:  64%|######4   | 4623/7204 [09:33<10:19,  4.17it/s]
2022-03-19 20:47:40,618 - INFO - tqdm - f1: 0.6854, accuracy: 0.8772, batch_loss: 0.2178, loss: 0.2938 ||:  65%|######5   | 4714/7204 [09:44<08:19,  4.98it/s]
2022-03-19 20:47:50,729 - INFO - tqdm - f1: 0.6849, accuracy: 0.8772, batch_loss: 0.1218, loss: 0.2937 ||:  67%|######6   | 4807/7204 [09:54<03:07, 12.81it/s]
2022-03-19 20:48:00,834 - INFO - tqdm - f1: 0.6843, accuracy: 0.8773, batch_loss: 0.2677, loss: 0.2938 ||:  68%|######7   | 4887/7204 [10:04<03:32, 10.92it/s]
2022-03-19 20:48:10,919 - INFO - tqdm - f1: 0.6846, accuracy: 0.8776, batch_loss: 0.3175, loss: 0.2934 ||:  69%|######8   | 4960/7204 [10:14<06:49,  5.48it/s]
2022-03-19 20:48:21,225 - INFO - tqdm - f1: 0.6851, accuracy: 0.8775, batch_loss: 0.2956, loss: 0.2931 ||:  70%|#######   | 5047/7204 [10:24<08:03,  4.46it/s]
2022-03-19 20:48:31,392 - INFO - tqdm - f1: 0.6846, accuracy: 0.8774, batch_loss: 0.0440, loss: 0.2932 ||:  71%|#######1  | 5143/7204 [10:34<02:56, 11.69it/s]
2022-03-19 20:48:41,459 - INFO - tqdm - f1: 0.6851, accuracy: 0.8773, batch_loss: 0.4572, loss: 0.2931 ||:  73%|#######2  | 5224/7204 [10:44<02:27, 13.38it/s]
2022-03-19 20:48:51,628 - INFO - tqdm - f1: 0.6852, accuracy: 0.8771, batch_loss: 0.1138, loss: 0.2933 ||:  74%|#######3  | 5304/7204 [10:55<05:06,  6.20it/s]
2022-03-19 20:49:02,443 - INFO - tqdm - f1: 0.6844, accuracy: 0.8770, batch_loss: 0.3704, loss: 0.2933 ||:  75%|#######4  | 5389/7204 [11:05<07:12,  4.20it/s]
2022-03-19 20:49:13,252 - INFO - tqdm - f1: 0.6840, accuracy: 0.8770, batch_loss: 0.2343, loss: 0.2933 ||:  76%|#######6  | 5484/7204 [11:16<07:07,  4.02it/s]
2022-03-19 20:49:24,069 - INFO - tqdm - f1: 0.6843, accuracy: 0.8770, batch_loss: 0.2446, loss: 0.2931 ||:  77%|#######7  | 5570/7204 [11:27<05:57,  4.57it/s]
2022-03-19 20:49:35,088 - INFO - tqdm - f1: 0.6836, accuracy: 0.8771, batch_loss: 0.1901, loss: 0.2930 ||:  79%|#######8  | 5659/7204 [11:38<06:55,  3.72it/s]
2022-03-19 20:49:46,146 - INFO - tqdm - f1: 0.6834, accuracy: 0.8771, batch_loss: 0.2883, loss: 0.2930 ||:  80%|#######9  | 5746/7204 [11:49<05:11,  4.68it/s]
2022-03-19 20:49:56,262 - INFO - tqdm - f1: 0.6839, accuracy: 0.8770, batch_loss: 0.2398, loss: 0.2931 ||:  81%|########1 | 5844/7204 [11:59<01:33, 14.49it/s]
2022-03-19 20:50:06,400 - INFO - tqdm - f1: 0.6841, accuracy: 0.8768, batch_loss: 0.4797, loss: 0.2934 ||:  82%|########2 | 5924/7204 [12:09<02:02, 10.46it/s]
2022-03-19 20:50:16,498 - INFO - tqdm - f1: 0.6846, accuracy: 0.8768, batch_loss: 0.0308, loss: 0.2938 ||:  83%|########3 | 6008/7204 [12:20<03:13,  6.19it/s]
2022-03-19 20:50:26,842 - INFO - tqdm - f1: 0.6850, accuracy: 0.8769, batch_loss: 0.1455, loss: 0.2936 ||:  85%|########4 | 6095/7204 [12:30<03:47,  4.88it/s]
2022-03-19 20:50:36,865 - INFO - tqdm - f1: 0.6850, accuracy: 0.8770, batch_loss: 0.3172, loss: 0.2939 ||:  86%|########5 | 6182/7204 [12:40<01:34, 10.81it/s]
2022-03-19 20:50:46,910 - INFO - tqdm - f1: 0.6851, accuracy: 0.8771, batch_loss: 0.2847, loss: 0.2937 ||:  87%|########6 | 6262/7204 [12:50<01:49,  8.60it/s]
2022-03-19 20:50:56,923 - INFO - tqdm - f1: 0.6849, accuracy: 0.8772, batch_loss: 0.2002, loss: 0.2936 ||:  88%|########8 | 6351/7204 [13:00<01:27,  9.80it/s]
2022-03-19 20:51:06,965 - INFO - tqdm - f1: 0.6853, accuracy: 0.8772, batch_loss: 0.3716, loss: 0.2936 ||:  89%|########9 | 6432/7204 [13:10<02:53,  4.45it/s]
2022-03-19 20:51:17,486 - INFO - tqdm - f1: 0.6854, accuracy: 0.8771, batch_loss: 0.0884, loss: 0.2939 ||:  91%|######### | 6525/7204 [13:21<02:35,  4.36it/s]
2022-03-19 20:51:27,712 - INFO - tqdm - f1: 0.6857, accuracy: 0.8771, batch_loss: 0.5771, loss: 0.2940 ||:  92%|#########1| 6617/7204 [13:31<01:56,  5.05it/s]
2022-03-19 20:51:38,829 - INFO - tqdm - f1: 0.6852, accuracy: 0.8771, batch_loss: 0.6267, loss: 0.2942 ||:  93%|#########3| 6710/7204 [13:42<02:04,  3.97it/s]
2022-03-19 20:51:49,624 - INFO - tqdm - f1: 0.6853, accuracy: 0.8771, batch_loss: 0.0965, loss: 0.2940 ||:  94%|#########4| 6804/7204 [13:53<01:31,  4.39it/s]
2022-03-19 20:52:00,331 - INFO - tqdm - f1: 0.6858, accuracy: 0.8773, batch_loss: 0.2964, loss: 0.2937 ||:  96%|#########5| 6895/7204 [14:03<01:13,  4.22it/s]
2022-03-19 20:52:11,066 - INFO - tqdm - f1: 0.6857, accuracy: 0.8773, batch_loss: 0.3006, loss: 0.2936 ||:  97%|#########6| 6986/7204 [14:14<00:53,  4.08it/s]
2022-03-19 20:52:21,820 - INFO - tqdm - f1: 0.6859, accuracy: 0.8774, batch_loss: 0.3960, loss: 0.2934 ||:  98%|#########8| 7076/7204 [14:25<00:30,  4.19it/s]
2022-03-19 20:52:32,197 - INFO - tqdm - f1: 0.6865, accuracy: 0.8773, batch_loss: 0.4132, loss: 0.2938 ||:  99%|#########9| 7164/7204 [14:35<00:08,  4.70it/s]
2022-03-19 20:52:32,817 - INFO - tqdm - f1: 0.6864, accuracy: 0.8773, batch_loss: 0.5527, loss: 0.2938 ||: 100%|#########9| 7169/7204 [14:36<00:05,  6.77it/s]
2022-03-19 20:52:32,982 - INFO - tqdm - f1: 0.6864, accuracy: 0.8773, batch_loss: 0.0226, loss: 0.2938 ||: 100%|#########9| 7170/7204 [14:36<00:05,  6.62it/s]
2022-03-19 20:52:33,236 - INFO - tqdm - f1: 0.6865, accuracy: 0.8773, batch_loss: 0.0319, loss: 0.2937 ||: 100%|#########9| 7172/7204 [14:36<00:04,  7.01it/s]
2022-03-19 20:52:33,382 - INFO - tqdm - f1: 0.6864, accuracy: 0.8773, batch_loss: 0.2448, loss: 0.2937 ||: 100%|#########9| 7174/7204 [14:36<00:03,  8.38it/s]
2022-03-19 20:52:33,532 - INFO - tqdm - f1: 0.6864, accuracy: 0.8773, batch_loss: 0.3098, loss: 0.2937 ||: 100%|#########9| 7176/7204 [14:37<00:02,  9.51it/s]
2022-03-19 20:52:33,667 - INFO - tqdm - f1: 0.6865, accuracy: 0.8773, batch_loss: 0.1287, loss: 0.2937 ||: 100%|#########9| 7178/7204 [14:37<00:02, 10.72it/s]
2022-03-19 20:52:33,799 - INFO - tqdm - f1: 0.6866, accuracy: 0.8773, batch_loss: 0.2165, loss: 0.2937 ||: 100%|#########9| 7180/7204 [14:37<00:02, 11.81it/s]
2022-03-19 20:52:33,936 - INFO - tqdm - f1: 0.6866, accuracy: 0.8773, batch_loss: 0.3117, loss: 0.2937 ||: 100%|#########9| 7182/7204 [14:37<00:01, 12.54it/s]
2022-03-19 20:52:34,072 - INFO - tqdm - f1: 0.6866, accuracy: 0.8773, batch_loss: 0.4045, loss: 0.2937 ||: 100%|#########9| 7184/7204 [14:37<00:01, 13.12it/s]
2022-03-19 20:52:34,392 - INFO - tqdm - f1: 0.6866, accuracy: 0.8773, batch_loss: 0.0379, loss: 0.2937 ||: 100%|#########9| 7186/7204 [14:37<00:01,  9.84it/s]
2022-03-19 20:52:34,576 - INFO - tqdm - f1: 0.6866, accuracy: 0.8774, batch_loss: 0.1470, loss: 0.2936 ||: 100%|#########9| 7188/7204 [14:38<00:01, 10.14it/s]
2022-03-19 20:52:34,717 - INFO - tqdm - f1: 0.6866, accuracy: 0.8773, batch_loss: 0.2712, loss: 0.2936 ||: 100%|#########9| 7190/7204 [14:38<00:01, 11.09it/s]
2022-03-19 20:52:35,766 - INFO - tqdm - f1: 0.6866, accuracy: 0.8773, batch_loss: 0.2113, loss: 0.2936 ||: 100%|#########9| 7192/7204 [14:39<00:02,  4.52it/s]
2022-03-19 20:52:35,996 - INFO - tqdm - f1: 0.6866, accuracy: 0.8773, batch_loss: 0.2674, loss: 0.2936 ||: 100%|#########9| 7193/7204 [14:39<00:02,  4.49it/s]
2022-03-19 20:52:36,143 - INFO - tqdm - f1: 0.6866, accuracy: 0.8773, batch_loss: 0.2613, loss: 0.2936 ||: 100%|#########9| 7195/7204 [14:39<00:01,  5.80it/s]
2022-03-19 20:52:36,292 - INFO - tqdm - f1: 0.6865, accuracy: 0.8773, batch_loss: 0.4117, loss: 0.2937 ||: 100%|#########9| 7197/7204 [14:39<00:00,  7.11it/s]
2022-03-19 20:52:36,435 - INFO - tqdm - f1: 0.6865, accuracy: 0.8773, batch_loss: 0.1678, loss: 0.2937 ||: 100%|#########9| 7199/7204 [14:39<00:00,  8.41it/s]
2022-03-19 20:52:36,658 - INFO - tqdm - f1: 0.6865, accuracy: 0.8773, batch_loss: 0.6110, loss: 0.2937 ||: 100%|#########9| 7201/7204 [14:40<00:00,  8.58it/s]
2022-03-19 20:52:36,806 - INFO - tqdm - f1: 0.6865, accuracy: 0.8774, batch_loss: 0.1081, loss: 0.2936 ||: 100%|#########9| 7203/7204 [14:40<00:00,  9.67it/s]
2022-03-19 20:52:36,926 - INFO - tqdm - f1: 0.6865, accuracy: 0.8774, batch_loss: 0.3492, loss: 0.2936 ||: 100%|##########| 7204/7204 [14:40<00:00,  8.18it/s]
2022-03-19 20:52:36,937 - INFO - allennlp.training.trainer - Validating
2022-03-19 20:52:36,942 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-19 20:52:46,948 - INFO - tqdm - f1: 0.6552, accuracy: 0.8711, batch_loss: 0.4213, loss: 0.3271 ||:  92%|#########1| 287/313 [00:10<00:01, 16.28it/s]
2022-03-19 20:52:47,638 - INFO - tqdm - f1: 0.6532, accuracy: 0.8716, batch_loss: 0.0980, loss: 0.3264 ||: 100%|##########| 313/313 [00:10<00:00, 31.38it/s]
2022-03-19 20:52:47,645 - INFO - tqdm - f1: 0.6532, accuracy: 0.8716, batch_loss: 0.0980, loss: 0.3264 ||: 100%|##########| 313/313 [00:10<00:00, 29.25it/s]
2022-03-19 20:52:47,661 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/amazon_base/best.th'.
2022-03-19 20:52:50,270 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-19 20:52:50,273 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.877  |     0.872
2022-03-19 20:52:50,275 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.687  |     0.653
2022-03-19 20:52:50,277 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-19 20:52:50,279 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.294  |     0.326
2022-03-19 20:52:50,280 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13602.652  |       N/A
2022-03-19 20:52:50,282 - INFO - allennlp.training.trainer - Epoch duration: 0:14:53.809133
2022-03-19 20:52:50,284 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:59:58
2022-03-19 20:52:50,286 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-19 20:52:50,288 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-19 20:52:50,291 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-19 20:52:50,295 - INFO - allennlp.training.trainer - Training
2022-03-19 20:52:50,303 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-19 20:53:01,240 - INFO - tqdm - f1: 0.7409, accuracy: 0.9062, batch_loss: 0.1299, loss: 0.2346 ||:   1%|1         | 78/7204 [00:10<29:37,  4.01it/s]
2022-03-19 20:53:11,542 - INFO - tqdm - f1: 0.7592, accuracy: 0.8981, batch_loss: 0.0115, loss: 0.2440 ||:   2%|2         | 165/7204 [00:21<26:49,  4.37it/s]
2022-03-19 20:53:21,742 - INFO - tqdm - f1: 0.7616, accuracy: 0.8942, batch_loss: 0.1330, loss: 0.2529 ||:   3%|3         | 251/7204 [00:31<25:19,  4.58it/s]
2022-03-19 20:53:32,540 - INFO - tqdm - f1: 0.7477, accuracy: 0.8898, batch_loss: 0.4939, loss: 0.2618 ||:   5%|4         | 341/7204 [00:42<27:46,  4.12it/s]
2022-03-19 20:53:43,010 - INFO - tqdm - f1: 0.7477, accuracy: 0.8906, batch_loss: 0.1970, loss: 0.2604 ||:   6%|5         | 430/7204 [00:52<22:01,  5.13it/s]
2022-03-19 20:53:53,781 - INFO - tqdm - f1: 0.7496, accuracy: 0.8925, batch_loss: 0.6121, loss: 0.2559 ||:   7%|7         | 521/7204 [01:03<22:14,  5.01it/s]
2022-03-19 20:54:04,661 - INFO - tqdm - f1: 0.7507, accuracy: 0.8919, batch_loss: 0.1876, loss: 0.2558 ||:   9%|8         | 618/7204 [01:14<25:46,  4.26it/s]
2022-03-19 20:54:15,099 - INFO - tqdm - f1: 0.7500, accuracy: 0.8934, batch_loss: 0.0138, loss: 0.2545 ||:  10%|9         | 703/7204 [01:24<24:45,  4.38it/s]
2022-03-19 20:54:25,816 - INFO - tqdm - f1: 0.7477, accuracy: 0.8928, batch_loss: 0.1275, loss: 0.2536 ||:  11%|#1        | 793/7204 [01:35<24:40,  4.33it/s]
2022-03-19 20:54:36,524 - INFO - tqdm - f1: 0.7474, accuracy: 0.8936, batch_loss: 0.3761, loss: 0.2532 ||:  12%|#2        | 875/7204 [01:46<26:01,  4.05it/s]
2022-03-19 20:54:47,093 - INFO - tqdm - f1: 0.7472, accuracy: 0.8932, batch_loss: 0.2641, loss: 0.2541 ||:  13%|#3        | 966/7204 [01:56<22:36,  4.60it/s]
2022-03-19 20:54:57,648 - INFO - tqdm - f1: 0.7463, accuracy: 0.8924, batch_loss: 0.2596, loss: 0.2562 ||:  15%|#4        | 1059/7204 [02:07<23:25,  4.37it/s]
2022-03-19 20:55:08,478 - INFO - tqdm - f1: 0.7475, accuracy: 0.8918, batch_loss: 0.2204, loss: 0.2578 ||:  16%|#6        | 1158/7204 [02:18<20:51,  4.83it/s]
2022-03-19 20:55:18,721 - INFO - tqdm - f1: 0.7477, accuracy: 0.8924, batch_loss: 0.0736, loss: 0.2568 ||:  17%|#7        | 1239/7204 [02:28<10:47,  9.21it/s]
2022-03-19 20:55:28,884 - INFO - tqdm - f1: 0.7460, accuracy: 0.8918, batch_loss: 0.3878, loss: 0.2580 ||:  18%|#8        | 1322/7204 [02:38<12:27,  7.86it/s]
2022-03-19 20:55:39,039 - INFO - tqdm - f1: 0.7478, accuracy: 0.8923, batch_loss: 0.2581, loss: 0.2574 ||:  20%|#9        | 1408/7204 [02:48<23:28,  4.12it/s]
2022-03-19 20:55:49,428 - INFO - tqdm - f1: 0.7511, accuracy: 0.8932, batch_loss: 0.3447, loss: 0.2559 ||:  21%|##        | 1498/7204 [02:59<21:52,  4.35it/s]
2022-03-19 20:55:59,550 - INFO - tqdm - f1: 0.7525, accuracy: 0.8936, batch_loss: 0.2251, loss: 0.2558 ||:  22%|##2       | 1589/7204 [03:09<17:38,  5.30it/s]
2022-03-19 20:56:10,011 - INFO - tqdm - f1: 0.7523, accuracy: 0.8938, batch_loss: 0.0302, loss: 0.2553 ||:  23%|##3       | 1678/7204 [03:19<20:44,  4.44it/s]
2022-03-19 20:56:20,924 - INFO - tqdm - f1: 0.7513, accuracy: 0.8939, batch_loss: 0.2749, loss: 0.2553 ||:  25%|##4       | 1769/7204 [03:30<22:18,  4.06it/s]
2022-03-19 20:56:31,497 - INFO - tqdm - f1: 0.7510, accuracy: 0.8937, batch_loss: 0.3144, loss: 0.2562 ||:  26%|##5       | 1857/7204 [03:41<20:35,  4.33it/s]
2022-03-19 20:56:41,577 - INFO - tqdm - f1: 0.7516, accuracy: 0.8939, batch_loss: 0.2767, loss: 0.2558 ||:  27%|##6       | 1936/7204 [03:51<21:06,  4.16it/s]
2022-03-19 20:56:51,614 - INFO - tqdm - f1: 0.7523, accuracy: 0.8940, batch_loss: 0.3406, loss: 0.2565 ||:  28%|##8       | 2019/7204 [04:01<08:37, 10.02it/s]
2022-03-19 20:57:01,735 - INFO - tqdm - f1: 0.7524, accuracy: 0.8940, batch_loss: 0.3484, loss: 0.2568 ||:  29%|##9       | 2102/7204 [04:11<12:17,  6.91it/s]
2022-03-19 20:57:11,899 - INFO - tqdm - f1: 0.7525, accuracy: 0.8944, batch_loss: 0.2242, loss: 0.2562 ||:  30%|###       | 2188/7204 [04:21<17:16,  4.84it/s]
2022-03-19 20:57:22,476 - INFO - tqdm - f1: 0.7527, accuracy: 0.8941, batch_loss: 0.2116, loss: 0.2575 ||:  32%|###1      | 2282/7204 [04:32<17:44,  4.63it/s]
2022-03-19 20:57:32,538 - INFO - tqdm - f1: 0.7524, accuracy: 0.8934, batch_loss: 0.5101, loss: 0.2591 ||:  33%|###3      | 2381/7204 [04:42<05:29, 14.66it/s]
2022-03-19 20:57:42,553 - INFO - tqdm - f1: 0.7510, accuracy: 0.8934, batch_loss: 0.1756, loss: 0.2588 ||:  34%|###4      | 2463/7204 [04:52<06:07, 12.89it/s]
2022-03-19 20:57:52,554 - INFO - tqdm - f1: 0.7519, accuracy: 0.8935, batch_loss: 0.1565, loss: 0.2584 ||:  35%|###5      | 2546/7204 [05:02<08:58,  8.66it/s]
2022-03-19 20:58:02,555 - INFO - tqdm - f1: 0.7531, accuracy: 0.8939, batch_loss: 0.4691, loss: 0.2584 ||:  37%|###6      | 2631/7204 [05:12<15:47,  4.83it/s]
2022-03-19 20:58:12,669 - INFO - tqdm - f1: 0.7533, accuracy: 0.8937, batch_loss: 0.2243, loss: 0.2585 ||:  38%|###7      | 2723/7204 [05:22<05:10, 14.45it/s]
2022-03-19 20:58:22,737 - INFO - tqdm - f1: 0.7528, accuracy: 0.8940, batch_loss: 0.2640, loss: 0.2577 ||:  39%|###8      | 2806/7204 [05:32<07:13, 10.16it/s]
2022-03-19 20:58:32,897 - INFO - tqdm - f1: 0.7531, accuracy: 0.8944, batch_loss: 0.4937, loss: 0.2574 ||:  40%|####      | 2889/7204 [05:42<07:16,  9.89it/s]
2022-03-19 20:58:43,057 - INFO - tqdm - f1: 0.7540, accuracy: 0.8947, batch_loss: 0.0254, loss: 0.2564 ||:  41%|####1     | 2972/7204 [05:52<08:13,  8.58it/s]
2022-03-19 20:58:53,247 - INFO - tqdm - f1: 0.7542, accuracy: 0.8954, batch_loss: 0.0044, loss: 0.2551 ||:  42%|####2     | 3050/7204 [06:02<10:33,  6.56it/s]
2022-03-19 20:59:03,316 - INFO - tqdm - f1: 0.7543, accuracy: 0.8956, batch_loss: 0.4108, loss: 0.2554 ||:  43%|####3     | 3127/7204 [06:13<15:56,  4.26it/s]
2022-03-19 20:59:13,718 - INFO - tqdm - f1: 0.7536, accuracy: 0.8949, batch_loss: 0.1058, loss: 0.2561 ||:  45%|####4     | 3220/7204 [06:23<13:46,  4.82it/s]
2022-03-19 20:59:23,874 - INFO - tqdm - f1: 0.7539, accuracy: 0.8950, batch_loss: 0.2352, loss: 0.2559 ||:  46%|####5     | 3308/7204 [06:33<14:15,  4.55it/s]
2022-03-19 20:59:34,893 - INFO - tqdm - f1: 0.7540, accuracy: 0.8949, batch_loss: 0.3463, loss: 0.2557 ||:  47%|####7     | 3395/7204 [06:44<15:08,  4.19it/s]
2022-03-19 20:59:45,440 - INFO - tqdm - f1: 0.7527, accuracy: 0.8942, batch_loss: 0.3020, loss: 0.2573 ||:  49%|####8     | 3496/7204 [06:55<12:44,  4.85it/s]
2022-03-19 20:59:56,120 - INFO - tqdm - f1: 0.7528, accuracy: 0.8943, batch_loss: 0.1410, loss: 0.2573 ||:  50%|####9     | 3593/7204 [07:05<11:35,  5.19it/s]
2022-03-19 21:00:06,402 - INFO - tqdm - f1: 0.7518, accuracy: 0.8938, batch_loss: 0.0996, loss: 0.2581 ||:  51%|#####1    | 3687/7204 [07:16<10:39,  5.50it/s]
2022-03-19 21:00:17,500 - INFO - tqdm - f1: 0.7523, accuracy: 0.8936, batch_loss: 0.0589, loss: 0.2583 ||:  52%|#####2    | 3779/7204 [07:27<14:48,  3.85it/s]
2022-03-19 21:00:28,355 - INFO - tqdm - f1: 0.7522, accuracy: 0.8936, batch_loss: 0.1554, loss: 0.2584 ||:  54%|#####3    | 3875/7204 [07:38<11:52,  4.67it/s]
2022-03-19 21:00:38,584 - INFO - tqdm - f1: 0.7523, accuracy: 0.8938, batch_loss: 0.2205, loss: 0.2581 ||:  55%|#####5    | 3967/7204 [07:48<10:50,  4.98it/s]
2022-03-19 21:00:49,523 - INFO - tqdm - f1: 0.7521, accuracy: 0.8935, batch_loss: 0.4369, loss: 0.2592 ||:  56%|#####6    | 4058/7204 [07:59<12:27,  4.21it/s]
2022-03-19 21:00:59,752 - INFO - tqdm - f1: 0.7517, accuracy: 0.8933, batch_loss: 0.6934, loss: 0.2593 ||:  58%|#####7    | 4144/7204 [08:09<10:42,  4.76it/s]
2022-03-19 21:01:10,141 - INFO - tqdm - f1: 0.7523, accuracy: 0.8936, batch_loss: 0.2414, loss: 0.2590 ||:  59%|#####8    | 4229/7204 [08:19<11:07,  4.46it/s]
2022-03-19 21:01:20,812 - INFO - tqdm - f1: 0.7521, accuracy: 0.8937, batch_loss: 0.1140, loss: 0.2587 ||:  60%|#####9    | 4312/7204 [08:30<10:42,  4.50it/s]
2022-03-19 21:01:31,284 - INFO - tqdm - f1: 0.7527, accuracy: 0.8940, batch_loss: 0.4300, loss: 0.2586 ||:  61%|######1   | 4404/7204 [08:40<09:31,  4.90it/s]
2022-03-19 21:01:42,266 - INFO - tqdm - f1: 0.7533, accuracy: 0.8941, batch_loss: 0.0252, loss: 0.2586 ||:  62%|######2   | 4499/7204 [08:51<11:16,  4.00it/s]
2022-03-19 21:01:52,732 - INFO - tqdm - f1: 0.7535, accuracy: 0.8940, batch_loss: 0.3423, loss: 0.2585 ||:  64%|######3   | 4598/7204 [09:02<09:28,  4.58it/s]
2022-03-19 21:02:03,398 - INFO - tqdm - f1: 0.7539, accuracy: 0.8939, batch_loss: 0.3045, loss: 0.2587 ||:  65%|######5   | 4695/7204 [09:13<09:28,  4.41it/s]
2022-03-19 21:02:13,598 - INFO - tqdm - f1: 0.7539, accuracy: 0.8942, batch_loss: 0.0524, loss: 0.2583 ||:  66%|######6   | 4780/7204 [09:23<08:11,  4.94it/s]
2022-03-19 21:02:24,446 - INFO - tqdm - f1: 0.7542, accuracy: 0.8945, batch_loss: 0.3033, loss: 0.2580 ||:  68%|######7   | 4869/7204 [09:34<09:19,  4.17it/s]
2022-03-19 21:02:34,924 - INFO - tqdm - f1: 0.7535, accuracy: 0.8943, batch_loss: 0.2339, loss: 0.2582 ||:  69%|######8   | 4960/7204 [09:44<08:40,  4.31it/s]
2022-03-19 21:02:46,024 - INFO - tqdm - f1: 0.7530, accuracy: 0.8941, batch_loss: 0.3873, loss: 0.2586 ||:  70%|#######   | 5061/7204 [09:55<08:23,  4.26it/s]
2022-03-19 21:02:56,843 - INFO - tqdm - f1: 0.7524, accuracy: 0.8938, batch_loss: 0.2735, loss: 0.2590 ||:  72%|#######1  | 5153/7204 [10:06<08:05,  4.22it/s]
2022-03-19 21:03:07,334 - INFO - tqdm - f1: 0.7522, accuracy: 0.8939, batch_loss: 0.6530, loss: 0.2591 ||:  73%|#######2  | 5242/7204 [10:17<07:07,  4.59it/s]
2022-03-19 21:03:18,049 - INFO - tqdm - f1: 0.7516, accuracy: 0.8939, batch_loss: 0.3255, loss: 0.2595 ||:  74%|#######4  | 5335/7204 [10:27<05:52,  5.30it/s]
2022-03-19 21:03:28,669 - INFO - tqdm - f1: 0.7518, accuracy: 0.8938, batch_loss: 0.3810, loss: 0.2597 ||:  75%|#######5  | 5427/7204 [10:38<05:36,  5.27it/s]
2022-03-19 21:03:39,180 - INFO - tqdm - f1: 0.7512, accuracy: 0.8935, batch_loss: 0.3535, loss: 0.2602 ||:  77%|#######6  | 5519/7204 [10:48<05:32,  5.06it/s]
2022-03-19 21:03:50,028 - INFO - tqdm - f1: 0.7508, accuracy: 0.8934, batch_loss: 0.3395, loss: 0.2603 ||:  78%|#######7  | 5610/7204 [10:59<06:16,  4.24it/s]
2022-03-19 21:04:00,283 - INFO - tqdm - f1: 0.7509, accuracy: 0.8934, batch_loss: 0.4881, loss: 0.2608 ||:  79%|#######9  | 5699/7204 [11:09<05:40,  4.42it/s]
2022-03-19 21:04:10,498 - INFO - tqdm - f1: 0.7507, accuracy: 0.8933, batch_loss: 0.3065, loss: 0.2611 ||:  80%|########  | 5790/7204 [11:20<04:21,  5.40it/s]
2022-03-19 21:04:21,171 - INFO - tqdm - f1: 0.7509, accuracy: 0.8934, batch_loss: 0.3294, loss: 0.2608 ||:  82%|########1 | 5884/7204 [11:30<04:39,  4.72it/s]
2022-03-19 21:04:31,948 - INFO - tqdm - f1: 0.7506, accuracy: 0.8933, batch_loss: 0.3502, loss: 0.2609 ||:  83%|########2 | 5979/7204 [11:41<03:50,  5.32it/s]
2022-03-19 21:04:42,662 - INFO - tqdm - f1: 0.7503, accuracy: 0.8930, batch_loss: 0.3410, loss: 0.2614 ||:  84%|########4 | 6075/7204 [11:52<03:46,  4.99it/s]
2022-03-19 21:04:53,681 - INFO - tqdm - f1: 0.7506, accuracy: 0.8932, batch_loss: 0.4184, loss: 0.2611 ||:  86%|########5 | 6166/7204 [12:03<03:56,  4.39it/s]
2022-03-19 21:05:03,973 - INFO - tqdm - f1: 0.7499, accuracy: 0.8931, batch_loss: 0.3903, loss: 0.2611 ||:  87%|########6 | 6251/7204 [12:13<03:26,  4.63it/s]
2022-03-19 21:05:14,878 - INFO - tqdm - f1: 0.7497, accuracy: 0.8932, batch_loss: 0.3354, loss: 0.2611 ||:  88%|########8 | 6345/7204 [12:24<03:28,  4.11it/s]
2022-03-19 21:05:25,503 - INFO - tqdm - f1: 0.7499, accuracy: 0.8932, batch_loss: 0.3304, loss: 0.2614 ||:  89%|########9 | 6433/7204 [12:35<03:06,  4.13it/s]
2022-03-19 21:05:35,697 - INFO - tqdm - f1: 0.7499, accuracy: 0.8933, batch_loss: 0.0134, loss: 0.2611 ||:  90%|######### | 6513/7204 [12:45<01:09,  9.98it/s]
2022-03-19 21:05:45,761 - INFO - tqdm - f1: 0.7497, accuracy: 0.8933, batch_loss: 0.3392, loss: 0.2612 ||:  92%|#########1| 6596/7204 [12:55<01:08,  8.83it/s]
2022-03-19 21:05:56,159 - INFO - tqdm - f1: 0.7499, accuracy: 0.8933, batch_loss: 0.3346, loss: 0.2613 ||:  93%|#########2| 6690/7204 [13:05<01:51,  4.63it/s]
2022-03-19 21:06:06,381 - INFO - tqdm - f1: 0.7500, accuracy: 0.8934, batch_loss: 0.1854, loss: 0.2610 ||:  94%|#########3| 6770/7204 [13:16<00:45,  9.44it/s]
2022-03-19 21:06:16,406 - INFO - tqdm - f1: 0.7501, accuracy: 0.8935, batch_loss: 0.1938, loss: 0.2609 ||:  95%|#########5| 6850/7204 [13:26<00:55,  6.42it/s]
2022-03-19 21:06:27,018 - INFO - tqdm - f1: 0.7499, accuracy: 0.8934, batch_loss: 0.2382, loss: 0.2613 ||:  96%|#########6| 6941/7204 [13:36<00:59,  4.44it/s]
2022-03-19 21:06:37,799 - INFO - tqdm - f1: 0.7496, accuracy: 0.8933, batch_loss: 0.2446, loss: 0.2613 ||:  98%|#########7| 7034/7204 [13:47<00:33,  5.09it/s]
2022-03-19 21:06:48,626 - INFO - tqdm - f1: 0.7489, accuracy: 0.8933, batch_loss: 0.1848, loss: 0.2615 ||:  99%|#########8| 7125/7204 [13:58<00:16,  4.70it/s]
2022-03-19 21:06:53,314 - INFO - tqdm - f1: 0.7492, accuracy: 0.8934, batch_loss: 0.1188, loss: 0.2614 ||: 100%|#########9| 7169/7204 [14:03<00:03,  8.92it/s]
2022-03-19 21:06:53,540 - INFO - tqdm - f1: 0.7492, accuracy: 0.8934, batch_loss: 0.2192, loss: 0.2614 ||: 100%|#########9| 7171/7204 [14:03<00:03,  8.90it/s]
2022-03-19 21:06:53,773 - INFO - tqdm - f1: 0.7492, accuracy: 0.8934, batch_loss: 0.2489, loss: 0.2613 ||: 100%|#########9| 7173/7204 [14:03<00:03,  8.79it/s]
2022-03-19 21:06:53,912 - INFO - tqdm - f1: 0.7492, accuracy: 0.8934, batch_loss: 0.4725, loss: 0.2614 ||: 100%|#########9| 7175/7204 [14:03<00:02,  9.96it/s]
2022-03-19 21:06:54,060 - INFO - tqdm - f1: 0.7492, accuracy: 0.8934, batch_loss: 0.3247, loss: 0.2614 ||: 100%|#########9| 7177/7204 [14:03<00:02, 10.81it/s]
2022-03-19 21:06:54,201 - INFO - tqdm - f1: 0.7491, accuracy: 0.8933, batch_loss: 0.2940, loss: 0.2614 ||: 100%|#########9| 7179/7204 [14:03<00:02, 11.64it/s]
2022-03-19 21:06:54,410 - INFO - tqdm - f1: 0.7491, accuracy: 0.8933, batch_loss: 0.3459, loss: 0.2614 ||: 100%|#########9| 7181/7204 [14:04<00:02, 10.94it/s]
2022-03-19 21:06:54,731 - INFO - tqdm - f1: 0.7491, accuracy: 0.8933, batch_loss: 0.0339, loss: 0.2614 ||: 100%|#########9| 7183/7204 [14:04<00:02,  8.92it/s]
2022-03-19 21:06:54,891 - INFO - tqdm - f1: 0.7490, accuracy: 0.8933, batch_loss: 0.4019, loss: 0.2614 ||: 100%|#########9| 7185/7204 [14:04<00:01,  9.75it/s]
2022-03-19 21:06:55,063 - INFO - tqdm - f1: 0.7490, accuracy: 0.8933, batch_loss: 0.0216, loss: 0.2614 ||: 100%|#########9| 7187/7204 [14:04<00:01, 10.25it/s]
2022-03-19 21:06:55,205 - INFO - tqdm - f1: 0.7490, accuracy: 0.8933, batch_loss: 0.3803, loss: 0.2613 ||: 100%|#########9| 7189/7204 [14:04<00:01, 11.17it/s]
2022-03-19 21:06:55,392 - INFO - tqdm - f1: 0.7490, accuracy: 0.8934, batch_loss: 0.0519, loss: 0.2613 ||: 100%|#########9| 7191/7204 [14:05<00:01, 11.02it/s]
2022-03-19 21:06:56,513 - INFO - tqdm - f1: 0.7490, accuracy: 0.8934, batch_loss: 0.2436, loss: 0.2613 ||: 100%|#########9| 7193/7204 [14:06<00:02,  4.32it/s]
2022-03-19 21:06:56,651 - INFO - tqdm - f1: 0.7490, accuracy: 0.8934, batch_loss: 0.3206, loss: 0.2613 ||: 100%|#########9| 7195/7204 [14:06<00:01,  5.47it/s]
2022-03-19 21:06:56,934 - INFO - tqdm - f1: 0.7490, accuracy: 0.8934, batch_loss: 0.0558, loss: 0.2612 ||: 100%|#########9| 7197/7204 [14:06<00:01,  5.86it/s]
2022-03-19 21:06:57,133 - INFO - tqdm - f1: 0.7490, accuracy: 0.8934, batch_loss: 0.0557, loss: 0.2612 ||: 100%|#########9| 7199/7204 [14:06<00:00,  6.70it/s]
2022-03-19 21:06:57,255 - INFO - tqdm - f1: 0.7490, accuracy: 0.8934, batch_loss: 0.1338, loss: 0.2612 ||: 100%|#########9| 7200/7204 [14:06<00:00,  6.93it/s]
2022-03-19 21:06:57,387 - INFO - tqdm - f1: 0.7490, accuracy: 0.8934, batch_loss: 0.3258, loss: 0.2612 ||: 100%|#########9| 7202/7204 [14:07<00:00,  8.46it/s]
2022-03-19 21:06:57,580 - INFO - tqdm - f1: 0.7491, accuracy: 0.8934, batch_loss: 0.1708, loss: 0.2612 ||: 100%|##########| 7204/7204 [14:07<00:00,  9.01it/s]
2022-03-19 21:06:57,637 - INFO - tqdm - f1: 0.7491, accuracy: 0.8934, batch_loss: 0.1708, loss: 0.2612 ||: 100%|##########| 7204/7204 [14:07<00:00,  8.50it/s]
2022-03-19 21:06:57,643 - INFO - allennlp.training.trainer - Validating
2022-03-19 21:06:57,646 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-19 21:07:07,659 - INFO - tqdm - f1: 0.6893, accuracy: 0.8708, batch_loss: 0.0152, loss: 0.3420 ||:  90%|########9 | 281/313 [00:10<00:00, 38.36it/s]
2022-03-19 21:07:08,320 - INFO - tqdm - f1: 0.6915, accuracy: 0.8698, batch_loss: 0.3069, loss: 0.3465 ||: 100%|##########| 313/313 [00:10<00:00, 29.33it/s]
2022-03-19 21:07:08,339 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/amazon_base/best.th'.
2022-03-19 21:07:10,965 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-19 21:07:10,969 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.893  |     0.870
2022-03-19 21:07:10,972 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.749  |     0.692
2022-03-19 21:07:10,975 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-19 21:07:10,978 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.261  |     0.346
2022-03-19 21:07:10,981 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13603.656  |       N/A
2022-03-19 21:07:10,984 - INFO - allennlp.training.trainer - Epoch duration: 0:14:20.697890
2022-03-19 21:07:10,987 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:43:27
2022-03-19 21:07:10,990 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-19 21:07:10,993 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-19 21:07:10,996 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-19 21:07:11,000 - INFO - allennlp.training.trainer - Training
2022-03-19 21:07:11,004 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-19 21:07:21,093 - INFO - tqdm - f1: 0.8317, accuracy: 0.9267, batch_loss: 0.1756, loss: 0.2081 ||:   1%|1         | 87/7204 [00:10<08:33, 13.86it/s]
2022-03-19 21:07:31,196 - INFO - tqdm - f1: 0.8064, accuracy: 0.9127, batch_loss: 0.1499, loss: 0.2266 ||:   2%|2         | 169/7204 [00:20<13:20,  8.79it/s]
2022-03-19 21:07:41,504 - INFO - tqdm - f1: 0.8082, accuracy: 0.9154, batch_loss: 0.0411, loss: 0.2184 ||:   3%|3         | 252/7204 [00:30<11:57,  9.69it/s]
2022-03-19 21:07:51,572 - INFO - tqdm - f1: 0.8069, accuracy: 0.9139, batch_loss: 0.2110, loss: 0.2180 ||:   5%|4         | 336/7204 [00:40<09:16, 12.34it/s]
2022-03-19 21:08:01,677 - INFO - tqdm - f1: 0.8000, accuracy: 0.9128, batch_loss: 0.0598, loss: 0.2187 ||:   6%|5         | 418/7204 [00:50<16:31,  6.84it/s]
2022-03-19 21:08:11,855 - INFO - tqdm - f1: 0.8022, accuracy: 0.9138, batch_loss: 0.2205, loss: 0.2161 ||:   7%|7         | 510/7204 [01:00<20:30,  5.44it/s]
2022-03-19 21:08:22,683 - INFO - tqdm - f1: 0.8028, accuracy: 0.9146, batch_loss: 0.5263, loss: 0.2146 ||:   8%|8         | 603/7204 [01:11<23:56,  4.59it/s]
2022-03-19 21:08:33,495 - INFO - tqdm - f1: 0.8055, accuracy: 0.9162, batch_loss: 0.1434, loss: 0.2126 ||:  10%|9         | 693/7204 [01:22<23:55,  4.54it/s]
2022-03-19 21:08:43,561 - INFO - tqdm - f1: 0.8070, accuracy: 0.9179, batch_loss: 0.3134, loss: 0.2104 ||:  11%|#         | 783/7204 [01:32<08:34, 12.49it/s]
2022-03-19 21:08:53,725 - INFO - tqdm - f1: 0.8056, accuracy: 0.9162, batch_loss: 0.4400, loss: 0.2129 ||:  12%|#2        | 870/7204 [01:42<09:30, 11.09it/s]
2022-03-19 21:09:03,881 - INFO - tqdm - f1: 0.8072, accuracy: 0.9169, batch_loss: 0.1136, loss: 0.2108 ||:  13%|#3        | 953/7204 [01:52<10:35,  9.84it/s]
2022-03-19 21:09:14,110 - INFO - tqdm - f1: 0.8076, accuracy: 0.9159, batch_loss: 0.3585, loss: 0.2115 ||:  14%|#4        | 1040/7204 [02:03<23:15,  4.42it/s]
2022-03-19 21:09:24,603 - INFO - tqdm - f1: 0.8066, accuracy: 0.9147, batch_loss: 0.1011, loss: 0.2148 ||:  16%|#5        | 1133/7204 [02:13<20:25,  4.95it/s]
2022-03-19 21:09:35,462 - INFO - tqdm - f1: 0.8070, accuracy: 0.9141, batch_loss: 0.4143, loss: 0.2165 ||:  17%|#7        | 1227/7204 [02:24<21:48,  4.57it/s]
2022-03-19 21:09:45,598 - INFO - tqdm - f1: 0.8085, accuracy: 0.9140, batch_loss: 0.3113, loss: 0.2171 ||:  18%|#8        | 1324/7204 [02:34<09:35, 10.22it/s]
2022-03-19 21:09:55,734 - INFO - tqdm - f1: 0.8082, accuracy: 0.9139, batch_loss: 0.0549, loss: 0.2175 ||:  19%|#9        | 1402/7204 [02:44<09:42,  9.95it/s]
2022-03-19 21:10:05,846 - INFO - tqdm - f1: 0.8095, accuracy: 0.9144, batch_loss: 0.1761, loss: 0.2171 ||:  21%|##        | 1484/7204 [02:54<13:22,  7.12it/s]
2022-03-19 21:10:16,130 - INFO - tqdm - f1: 0.8094, accuracy: 0.9141, batch_loss: 0.7266, loss: 0.2180 ||:  22%|##1       | 1575/7204 [03:05<17:44,  5.29it/s]
2022-03-19 21:10:26,574 - INFO - tqdm - f1: 0.8081, accuracy: 0.9147, batch_loss: 0.0918, loss: 0.2167 ||:  23%|##3       | 1662/7204 [03:15<19:16,  4.79it/s]
2022-03-19 21:10:36,610 - INFO - tqdm - f1: 0.8073, accuracy: 0.9140, batch_loss: 0.1875, loss: 0.2173 ||:  24%|##4       | 1757/7204 [03:25<06:33, 13.85it/s]
2022-03-19 21:10:46,849 - INFO - tqdm - f1: 0.8090, accuracy: 0.9142, batch_loss: 0.0928, loss: 0.2170 ||:  26%|##5       | 1842/7204 [03:35<13:51,  6.45it/s]
2022-03-19 21:10:57,038 - INFO - tqdm - f1: 0.8085, accuracy: 0.9139, batch_loss: 0.2380, loss: 0.2178 ||:  27%|##6       | 1926/7204 [03:46<18:18,  4.80it/s]
2022-03-19 21:11:07,844 - INFO - tqdm - f1: 0.8090, accuracy: 0.9143, batch_loss: 0.1704, loss: 0.2179 ||:  28%|##7       | 2014/7204 [03:56<19:11,  4.51it/s]
2022-03-19 21:11:18,464 - INFO - tqdm - f1: 0.8082, accuracy: 0.9143, batch_loss: 0.2195, loss: 0.2172 ||:  29%|##9       | 2100/7204 [04:07<17:22,  4.90it/s]
2022-03-19 21:11:29,351 - INFO - tqdm - f1: 0.8089, accuracy: 0.9146, batch_loss: 0.0257, loss: 0.2173 ||:  30%|###       | 2190/7204 [04:18<19:16,  4.34it/s]
2022-03-19 21:11:40,241 - INFO - tqdm - f1: 0.8097, accuracy: 0.9144, batch_loss: 0.0409, loss: 0.2173 ||:  32%|###1      | 2286/7204 [04:29<18:34,  4.41it/s]
2022-03-19 21:11:50,852 - INFO - tqdm - f1: 0.8106, accuracy: 0.9144, batch_loss: 0.2742, loss: 0.2179 ||:  33%|###3      | 2387/7204 [04:39<15:09,  5.30it/s]
2022-03-19 21:12:01,684 - INFO - tqdm - f1: 0.8104, accuracy: 0.9146, batch_loss: 0.2816, loss: 0.2175 ||:  34%|###4      | 2476/7204 [04:50<15:30,  5.08it/s]
2022-03-19 21:12:12,320 - INFO - tqdm - f1: 0.8103, accuracy: 0.9148, batch_loss: 0.2834, loss: 0.2173 ||:  36%|###5      | 2566/7204 [05:01<15:05,  5.12it/s]
2022-03-19 21:12:22,393 - INFO - tqdm - f1: 0.8108, accuracy: 0.9147, batch_loss: 0.3286, loss: 0.2179 ||:  37%|###6      | 2657/7204 [05:11<07:40,  9.87it/s]
2022-03-19 21:12:32,468 - INFO - tqdm - f1: 0.8111, accuracy: 0.9144, batch_loss: 0.2012, loss: 0.2187 ||:  38%|###8      | 2743/7204 [05:21<06:22, 11.67it/s]
2022-03-19 21:12:42,585 - INFO - tqdm - f1: 0.8106, accuracy: 0.9139, batch_loss: 0.1591, loss: 0.2197 ||:  39%|###9      | 2828/7204 [05:31<08:00,  9.10it/s]
2022-03-19 21:12:52,666 - INFO - tqdm - f1: 0.8105, accuracy: 0.9136, batch_loss: 0.3271, loss: 0.2207 ||:  41%|####      | 2918/7204 [05:41<15:19,  4.66it/s]
2022-03-19 21:13:03,170 - INFO - tqdm - f1: 0.8104, accuracy: 0.9136, batch_loss: 0.1345, loss: 0.2201 ||:  42%|####1     | 3011/7204 [05:52<13:16,  5.26it/s]
2022-03-19 21:13:14,022 - INFO - tqdm - f1: 0.8098, accuracy: 0.9132, batch_loss: 0.2231, loss: 0.2208 ||:  43%|####3     | 3107/7204 [06:03<14:30,  4.71it/s]
2022-03-19 21:13:24,028 - INFO - tqdm - f1: 0.8093, accuracy: 0.9129, batch_loss: 0.4871, loss: 0.2220 ||:  44%|####4     | 3198/7204 [06:13<05:46, 11.58it/s]
2022-03-19 21:13:34,189 - INFO - tqdm - f1: 0.8089, accuracy: 0.9125, batch_loss: 0.1595, loss: 0.2229 ||:  46%|####5     | 3284/7204 [06:23<06:27, 10.11it/s]
2022-03-19 21:13:44,339 - INFO - tqdm - f1: 0.8088, accuracy: 0.9127, batch_loss: 0.0226, loss: 0.2225 ||:  47%|####6     | 3360/7204 [06:33<08:27,  7.57it/s]
2022-03-19 21:13:54,381 - INFO - tqdm - f1: 0.8086, accuracy: 0.9127, batch_loss: 0.1394, loss: 0.2228 ||:  48%|####7     | 3448/7204 [06:43<06:52,  9.11it/s]
2022-03-19 21:14:04,936 - INFO - tqdm - f1: 0.8081, accuracy: 0.9125, batch_loss: 0.2655, loss: 0.2228 ||:  49%|####9     | 3542/7204 [06:53<13:37,  4.48it/s]
2022-03-19 21:14:15,793 - INFO - tqdm - f1: 0.8083, accuracy: 0.9125, batch_loss: 0.4261, loss: 0.2230 ||:  50%|#####     | 3638/7204 [07:04<12:51,  4.62it/s]
2022-03-19 21:14:25,808 - INFO - tqdm - f1: 0.8084, accuracy: 0.9128, batch_loss: 0.1648, loss: 0.2226 ||:  52%|#####1    | 3734/7204 [07:14<04:30, 12.81it/s]
2022-03-19 21:14:35,851 - INFO - tqdm - f1: 0.8085, accuracy: 0.9130, batch_loss: 0.2025, loss: 0.2223 ||:  53%|#####2    | 3818/7204 [07:24<05:08, 10.97it/s]
2022-03-19 21:14:46,054 - INFO - tqdm - f1: 0.8088, accuracy: 0.9131, batch_loss: 0.2023, loss: 0.2220 ||:  54%|#####4    | 3902/7204 [07:35<06:01,  9.13it/s]
2022-03-19 21:14:56,088 - INFO - tqdm - f1: 0.8088, accuracy: 0.9131, batch_loss: 0.0632, loss: 0.2218 ||:  55%|#####5    | 3982/7204 [07:45<12:33,  4.28it/s]
2022-03-19 21:15:06,592 - INFO - tqdm - f1: 0.8087, accuracy: 0.9132, batch_loss: 0.4724, loss: 0.2219 ||:  57%|#####6    | 4075/7204 [07:55<10:03,  5.18it/s]
2022-03-19 21:15:17,539 - INFO - tqdm - f1: 0.8088, accuracy: 0.9133, batch_loss: 0.1157, loss: 0.2216 ||:  58%|#####7    | 4170/7204 [08:06<12:49,  3.94it/s]
2022-03-19 21:15:28,542 - INFO - tqdm - f1: 0.8081, accuracy: 0.9130, batch_loss: 0.0732, loss: 0.2218 ||:  59%|#####9    | 4272/7204 [08:17<11:15,  4.34it/s]
2022-03-19 21:15:39,041 - INFO - tqdm - f1: 0.8082, accuracy: 0.9131, batch_loss: 0.0774, loss: 0.2215 ||:  61%|######    | 4366/7204 [08:28<08:46,  5.39it/s]
2022-03-19 21:15:49,168 - INFO - tqdm - f1: 0.8084, accuracy: 0.9134, batch_loss: 0.0724, loss: 0.2209 ||:  62%|######1   | 4454/7204 [08:38<04:18, 10.65it/s]
2022-03-19 21:15:59,377 - INFO - tqdm - f1: 0.8078, accuracy: 0.9133, batch_loss: 0.1403, loss: 0.2209 ||:  63%|######3   | 4539/7204 [08:48<04:02, 10.98it/s]
2022-03-19 21:16:09,407 - INFO - tqdm - f1: 0.8076, accuracy: 0.9132, batch_loss: 0.3297, loss: 0.2209 ||:  64%|######4   | 4620/7204 [08:58<04:28,  9.62it/s]
2022-03-19 21:16:19,448 - INFO - tqdm - f1: 0.8071, accuracy: 0.9130, batch_loss: 0.4650, loss: 0.2212 ||:  65%|######5   | 4707/7204 [09:08<04:31,  9.19it/s]
2022-03-19 21:16:29,671 - INFO - tqdm - f1: 0.8070, accuracy: 0.9131, batch_loss: 0.1545, loss: 0.2209 ||:  66%|######6   | 4789/7204 [09:18<08:53,  4.53it/s]
2022-03-19 21:16:40,226 - INFO - tqdm - f1: 0.8073, accuracy: 0.9133, batch_loss: 0.2511, loss: 0.2207 ||:  68%|######7   | 4881/7204 [09:29<08:47,  4.40it/s]
2022-03-19 21:16:50,558 - INFO - tqdm - f1: 0.8076, accuracy: 0.9134, batch_loss: 0.2239, loss: 0.2206 ||:  69%|######9   | 4973/7204 [09:39<08:10,  4.55it/s]
2022-03-19 21:17:00,961 - INFO - tqdm - f1: 0.8072, accuracy: 0.9135, batch_loss: 0.4065, loss: 0.2206 ||:  70%|#######   | 5062/7204 [09:49<06:35,  5.42it/s]
2022-03-19 21:17:11,875 - INFO - tqdm - f1: 0.8075, accuracy: 0.9135, batch_loss: 1.0017, loss: 0.2205 ||:  72%|#######1  | 5165/7204 [10:00<07:37,  4.46it/s]
2022-03-19 21:17:22,635 - INFO - tqdm - f1: 0.8078, accuracy: 0.9135, batch_loss: 0.3108, loss: 0.2204 ||:  73%|#######2  | 5258/7204 [10:11<07:46,  4.18it/s]
2022-03-19 21:17:32,683 - INFO - tqdm - f1: 0.8074, accuracy: 0.9134, batch_loss: 0.1355, loss: 0.2207 ||:  74%|#######4  | 5348/7204 [10:21<02:48, 11.01it/s]
2022-03-19 21:17:42,896 - INFO - tqdm - f1: 0.8079, accuracy: 0.9135, batch_loss: 0.0197, loss: 0.2208 ||:  75%|#######5  | 5433/7204 [10:31<02:41, 10.98it/s]
2022-03-19 21:17:53,047 - INFO - tqdm - f1: 0.8085, accuracy: 0.9138, batch_loss: 0.1211, loss: 0.2204 ||:  77%|#######6  | 5519/7204 [10:42<02:28, 11.35it/s]
2022-03-19 21:18:03,059 - INFO - tqdm - f1: 0.8082, accuracy: 0.9136, batch_loss: 0.0884, loss: 0.2209 ||:  78%|#######7  | 5607/7204 [10:52<03:02,  8.74it/s]
2022-03-19 21:18:13,148 - INFO - tqdm - f1: 0.8079, accuracy: 0.9134, batch_loss: 0.2303, loss: 0.2215 ||:  79%|#######9  | 5695/7204 [11:02<02:38,  9.53it/s]
2022-03-19 21:18:23,290 - INFO - tqdm - f1: 0.8078, accuracy: 0.9132, batch_loss: 0.1823, loss: 0.2217 ||:  80%|########  | 5781/7204 [11:12<04:43,  5.02it/s]
2022-03-19 21:18:33,770 - INFO - tqdm - f1: 0.8077, accuracy: 0.9133, batch_loss: 0.2564, loss: 0.2217 ||:  82%|########1 | 5874/7204 [11:22<04:14,  5.22it/s]
2022-03-19 21:18:44,569 - INFO - tqdm - f1: 0.8073, accuracy: 0.9131, batch_loss: 0.1617, loss: 0.2221 ||:  83%|########2 | 5964/7204 [11:33<04:55,  4.20it/s]
2022-03-19 21:18:55,162 - INFO - tqdm - f1: 0.8065, accuracy: 0.9129, batch_loss: 0.4490, loss: 0.2226 ||:  84%|########4 | 6056/7204 [11:44<04:33,  4.19it/s]
2022-03-19 21:19:06,059 - INFO - tqdm - f1: 0.8059, accuracy: 0.9128, batch_loss: 0.3554, loss: 0.2227 ||:  85%|########5 | 6151/7204 [11:55<04:29,  3.90it/s]
2022-03-19 21:19:16,372 - INFO - tqdm - f1: 0.8060, accuracy: 0.9129, batch_loss: 0.1364, loss: 0.2228 ||:  87%|########6 | 6238/7204 [12:05<03:25,  4.70it/s]
2022-03-19 21:19:26,908 - INFO - tqdm - f1: 0.8061, accuracy: 0.9126, batch_loss: 0.0650, loss: 0.2232 ||:  88%|########7 | 6332/7204 [12:15<02:42,  5.37it/s]
2022-03-19 21:19:37,741 - INFO - tqdm - f1: 0.8059, accuracy: 0.9126, batch_loss: 0.1507, loss: 0.2234 ||:  89%|########9 | 6427/7204 [12:26<02:56,  4.41it/s]
2022-03-19 21:19:48,738 - INFO - tqdm - f1: 0.8056, accuracy: 0.9125, batch_loss: 0.1235, loss: 0.2236 ||:  91%|######### | 6520/7204 [12:37<02:41,  4.23it/s]
2022-03-19 21:19:59,534 - INFO - tqdm - f1: 0.8056, accuracy: 0.9126, batch_loss: 0.0254, loss: 0.2233 ||:  92%|#########1| 6609/7204 [12:48<02:27,  4.03it/s]
2022-03-19 21:20:09,788 - INFO - tqdm - f1: 0.8055, accuracy: 0.9125, batch_loss: 0.3447, loss: 0.2235 ||:  93%|#########3| 6702/7204 [12:58<01:40,  4.99it/s]
2022-03-19 21:20:20,387 - INFO - tqdm - f1: 0.8055, accuracy: 0.9125, batch_loss: 0.5581, loss: 0.2239 ||:  94%|#########4| 6792/7204 [13:09<01:17,  5.32it/s]
2022-03-19 21:20:30,947 - INFO - tqdm - f1: 0.8057, accuracy: 0.9127, batch_loss: 0.1242, loss: 0.2235 ||:  96%|#########5| 6885/7204 [13:19<01:01,  5.20it/s]
2022-03-19 21:20:40,965 - INFO - tqdm - f1: 0.8057, accuracy: 0.9128, batch_loss: 0.2412, loss: 0.2233 ||:  97%|#########6| 6979/7204 [13:29<00:17, 12.77it/s]
2022-03-19 21:20:51,009 - INFO - tqdm - f1: 0.8057, accuracy: 0.9128, batch_loss: 0.1713, loss: 0.2236 ||:  98%|#########8| 7060/7204 [13:40<00:13, 10.35it/s]
2022-03-19 21:21:01,117 - INFO - tqdm - f1: 0.8058, accuracy: 0.9128, batch_loss: 0.1746, loss: 0.2239 ||:  99%|#########9| 7144/7204 [13:50<00:06,  9.48it/s]
2022-03-19 21:21:04,108 - INFO - tqdm - f1: 0.8059, accuracy: 0.9128, batch_loss: 0.2831, loss: 0.2238 ||: 100%|#########9| 7169/7204 [13:53<00:05,  6.21it/s]
2022-03-19 21:21:04,266 - INFO - tqdm - f1: 0.8059, accuracy: 0.9128, batch_loss: 0.0493, loss: 0.2237 ||: 100%|#########9| 7171/7204 [13:53<00:04,  7.43it/s]
2022-03-19 21:21:04,470 - INFO - tqdm - f1: 0.8059, accuracy: 0.9128, batch_loss: 0.0992, loss: 0.2237 ||: 100%|#########9| 7173/7204 [13:53<00:03,  8.05it/s]
2022-03-19 21:21:04,616 - INFO - tqdm - f1: 0.8059, accuracy: 0.9128, batch_loss: 0.2485, loss: 0.2238 ||: 100%|#########9| 7175/7204 [13:53<00:03,  9.24it/s]
2022-03-19 21:21:04,795 - INFO - tqdm - f1: 0.8059, accuracy: 0.9128, batch_loss: 0.3143, loss: 0.2237 ||: 100%|#########9| 7177/7204 [13:53<00:02,  9.75it/s]
2022-03-19 21:21:05,033 - INFO - tqdm - f1: 0.8059, accuracy: 0.9128, batch_loss: 0.2520, loss: 0.2237 ||: 100%|#########9| 7179/7204 [13:54<00:02,  9.30it/s]
2022-03-19 21:21:05,273 - INFO - tqdm - f1: 0.8059, accuracy: 0.9128, batch_loss: 0.0322, loss: 0.2237 ||: 100%|#########9| 7181/7204 [13:54<00:02,  8.99it/s]
2022-03-19 21:21:05,422 - INFO - tqdm - f1: 0.8058, accuracy: 0.9128, batch_loss: 0.3519, loss: 0.2237 ||: 100%|#########9| 7183/7204 [13:54<00:02,  9.98it/s]
2022-03-19 21:21:05,601 - INFO - tqdm - f1: 0.8058, accuracy: 0.9128, batch_loss: 0.0475, loss: 0.2237 ||: 100%|#########9| 7185/7204 [13:54<00:01, 10.32it/s]
2022-03-19 21:21:05,870 - INFO - tqdm - f1: 0.8058, accuracy: 0.9128, batch_loss: 0.2559, loss: 0.2237 ||: 100%|#########9| 7187/7204 [13:54<00:01,  9.23it/s]
2022-03-19 21:21:06,044 - INFO - tqdm - f1: 0.8058, accuracy: 0.9128, batch_loss: 0.1944, loss: 0.2237 ||: 100%|#########9| 7188/7204 [13:55<00:01,  8.35it/s]
2022-03-19 21:21:06,180 - INFO - tqdm - f1: 0.8058, accuracy: 0.9128, batch_loss: 0.1466, loss: 0.2237 ||: 100%|#########9| 7190/7204 [13:55<00:01,  9.75it/s]
2022-03-19 21:21:06,335 - INFO - tqdm - f1: 0.8058, accuracy: 0.9128, batch_loss: 0.2412, loss: 0.2237 ||: 100%|#########9| 7192/7204 [13:55<00:01, 10.60it/s]
2022-03-19 21:21:06,533 - INFO - tqdm - f1: 0.8059, accuracy: 0.9128, batch_loss: 0.1040, loss: 0.2237 ||: 100%|#########9| 7194/7204 [13:55<00:00, 10.43it/s]
2022-03-19 21:21:07,608 - INFO - tqdm - f1: 0.8059, accuracy: 0.9128, batch_loss: 0.0350, loss: 0.2236 ||: 100%|#########9| 7196/7204 [13:56<00:01,  4.29it/s]
2022-03-19 21:21:07,814 - INFO - tqdm - f1: 0.8059, accuracy: 0.9128, batch_loss: 0.7267, loss: 0.2237 ||: 100%|#########9| 7197/7204 [13:56<00:01,  4.38it/s]
2022-03-19 21:21:07,961 - INFO - tqdm - f1: 0.8059, accuracy: 0.9129, batch_loss: 0.2088, loss: 0.2237 ||: 100%|#########9| 7199/7204 [13:56<00:00,  5.70it/s]
2022-03-19 21:21:08,103 - INFO - tqdm - f1: 0.8060, accuracy: 0.9129, batch_loss: 0.2105, loss: 0.2237 ||: 100%|#########9| 7201/7204 [13:57<00:00,  7.09it/s]
2022-03-19 21:21:08,237 - INFO - tqdm - f1: 0.8060, accuracy: 0.9129, batch_loss: 0.1146, loss: 0.2236 ||: 100%|#########9| 7203/7204 [13:57<00:00,  8.51it/s]
2022-03-19 21:21:08,368 - INFO - tqdm - f1: 0.8060, accuracy: 0.9129, batch_loss: 0.1623, loss: 0.2236 ||: 100%|##########| 7204/7204 [13:57<00:00,  8.60it/s]
2022-03-19 21:21:08,375 - INFO - allennlp.training.trainer - Validating
2022-03-19 21:21:08,378 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-19 21:21:18,762 - INFO - tqdm - f1: 0.6683, accuracy: 0.8684, batch_loss: 0.4561, loss: 0.3666 ||:  94%|#########4| 295/313 [00:10<00:01, 10.30it/s]
2022-03-19 21:21:19,254 - INFO - tqdm - f1: 0.6658, accuracy: 0.8692, batch_loss: 0.1636, loss: 0.3641 ||: 100%|#########9| 312/313 [00:10<00:00, 20.94it/s]
2022-03-19 21:21:19,283 - INFO - tqdm - f1: 0.6652, accuracy: 0.8690, batch_loss: 0.6921, loss: 0.3652 ||: 100%|##########| 313/313 [00:10<00:00, 28.71it/s]
2022-03-19 21:21:19,292 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-19 21:21:19,296 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.913  |     0.869
2022-03-19 21:21:19,298 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.806  |     0.665
2022-03-19 21:21:19,299 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-19 21:21:19,301 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.224  |     0.365
2022-03-19 21:21:19,303 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13603.656  |       N/A
2022-03-19 21:21:19,305 - INFO - allennlp.training.trainer - Epoch duration: 0:14:08.314660
2022-03-19 21:21:19,306 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:27:42
2022-03-19 21:21:19,308 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-19 21:21:19,310 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-19 21:21:19,312 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-19 21:21:19,315 - INFO - allennlp.training.trainer - Training
2022-03-19 21:21:19,317 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-19 21:21:29,425 - INFO - tqdm - f1: 0.8534, accuracy: 0.9391, batch_loss: 0.3299, loss: 0.1689 ||:   1%|1         | 76/7204 [00:10<23:00,  5.16it/s]
2022-03-19 21:21:40,649 - INFO - tqdm - f1: 0.8509, accuracy: 0.9364, batch_loss: 0.1249, loss: 0.1727 ||:   2%|2         | 166/7204 [00:21<27:59,  4.19it/s]
2022-03-19 21:21:51,422 - INFO - tqdm - f1: 0.8524, accuracy: 0.9349, batch_loss: 0.0453, loss: 0.1712 ||:   4%|3         | 260/7204 [00:32<24:59,  4.63it/s]
2022-03-19 21:22:01,468 - INFO - tqdm - f1: 0.8600, accuracy: 0.9354, batch_loss: 0.3340, loss: 0.1738 ||:   5%|4         | 356/7204 [00:42<10:48, 10.56it/s]
2022-03-19 21:22:11,531 - INFO - tqdm - f1: 0.8619, accuracy: 0.9369, batch_loss: 0.0109, loss: 0.1694 ||:   6%|6         | 436/7204 [00:52<11:22,  9.92it/s]
2022-03-19 21:22:21,766 - INFO - tqdm - f1: 0.8645, accuracy: 0.9385, batch_loss: 0.0118, loss: 0.1658 ||:   7%|7         | 520/7204 [01:02<16:22,  6.80it/s]
2022-03-19 21:22:31,856 - INFO - tqdm - f1: 0.8606, accuracy: 0.9367, batch_loss: 0.2196, loss: 0.1697 ||:   8%|8         | 611/7204 [01:12<21:53,  5.02it/s]
2022-03-19 21:22:42,965 - INFO - tqdm - f1: 0.8622, accuracy: 0.9367, batch_loss: 0.2475, loss: 0.1705 ||:  10%|9         | 706/7204 [01:23<26:16,  4.12it/s]
2022-03-19 21:22:53,670 - INFO - tqdm - f1: 0.8636, accuracy: 0.9367, batch_loss: 0.2117, loss: 0.1706 ||:  11%|#1        | 802/7204 [01:34<23:22,  4.56it/s]
2022-03-19 21:23:04,098 - INFO - tqdm - f1: 0.8627, accuracy: 0.9376, batch_loss: 0.1312, loss: 0.1688 ||:  12%|#2        | 890/7204 [01:44<21:17,  4.94it/s]
2022-03-19 21:23:14,836 - INFO - tqdm - f1: 0.8629, accuracy: 0.9376, batch_loss: 0.3178, loss: 0.1711 ||:  14%|#3        | 981/7204 [01:55<22:02,  4.71it/s]
2022-03-19 21:23:26,010 - INFO - tqdm - f1: 0.8620, accuracy: 0.9370, batch_loss: 0.0568, loss: 0.1722 ||:  15%|#4        | 1076/7204 [02:06<26:08,  3.91it/s]
2022-03-19 21:23:37,076 - INFO - tqdm - f1: 0.8626, accuracy: 0.9373, batch_loss: 0.1224, loss: 0.1725 ||:  16%|#6        | 1172/7204 [02:17<22:02,  4.56it/s]
2022-03-19 21:23:48,018 - INFO - tqdm - f1: 0.8628, accuracy: 0.9373, batch_loss: 0.1832, loss: 0.1724 ||:  18%|#7        | 1267/7204 [02:28<23:37,  4.19it/s]
2022-03-19 21:23:58,879 - INFO - tqdm - f1: 0.8624, accuracy: 0.9371, batch_loss: 0.1299, loss: 0.1738 ||:  19%|#8        | 1355/7204 [02:39<23:42,  4.11it/s]
2022-03-19 21:24:09,709 - INFO - tqdm - f1: 0.8619, accuracy: 0.9369, batch_loss: 0.1352, loss: 0.1738 ||:  20%|##        | 1454/7204 [02:50<18:28,  5.19it/s]
2022-03-19 21:24:19,949 - INFO - tqdm - f1: 0.8608, accuracy: 0.9365, batch_loss: 0.0742, loss: 0.1745 ||:  21%|##1       | 1545/7204 [03:00<09:48,  9.62it/s]
2022-03-19 21:24:30,081 - INFO - tqdm - f1: 0.8619, accuracy: 0.9368, batch_loss: 0.2368, loss: 0.1743 ||:  22%|##2       | 1619/7204 [03:10<21:42,  4.29it/s]
2022-03-19 21:24:41,137 - INFO - tqdm - f1: 0.8624, accuracy: 0.9370, batch_loss: 0.3207, loss: 0.1734 ||:  24%|##3       | 1704/7204 [03:21<22:23,  4.09it/s]
2022-03-19 21:24:51,169 - INFO - tqdm - f1: 0.8625, accuracy: 0.9366, batch_loss: 0.0251, loss: 0.1748 ||:  25%|##4       | 1795/7204 [03:31<07:03, 12.77it/s]
2022-03-19 21:25:01,225 - INFO - tqdm - f1: 0.8616, accuracy: 0.9362, batch_loss: 0.1090, loss: 0.1756 ||:  26%|##6       | 1878/7204 [03:41<07:33, 11.75it/s]
2022-03-19 21:25:11,254 - INFO - tqdm - f1: 0.8622, accuracy: 0.9362, batch_loss: 0.0512, loss: 0.1752 ||:  27%|##7       | 1954/7204 [03:51<09:42,  9.02it/s]
2022-03-19 21:25:21,972 - INFO - tqdm - f1: 0.8628, accuracy: 0.9364, batch_loss: 0.1751, loss: 0.1745 ||:  28%|##8       | 2030/7204 [04:02<19:36,  4.40it/s]
2022-03-19 21:25:32,156 - INFO - tqdm - f1: 0.8638, accuracy: 0.9368, batch_loss: 0.0221, loss: 0.1736 ||:  29%|##9       | 2109/7204 [04:12<10:03,  8.44it/s]
2022-03-19 21:25:42,448 - INFO - tqdm - f1: 0.8630, accuracy: 0.9366, batch_loss: 0.1245, loss: 0.1744 ||:  30%|###       | 2187/7204 [04:23<20:13,  4.13it/s]
2022-03-19 21:25:52,629 - INFO - tqdm - f1: 0.8626, accuracy: 0.9362, batch_loss: 0.0757, loss: 0.1750 ||:  32%|###1      | 2272/7204 [04:33<08:49,  9.31it/s]
2022-03-19 21:26:02,728 - INFO - tqdm - f1: 0.8620, accuracy: 0.9363, batch_loss: 0.0331, loss: 0.1752 ||:  33%|###2      | 2371/7204 [04:43<09:58,  8.07it/s]
2022-03-19 21:26:13,688 - INFO - tqdm - f1: 0.8619, accuracy: 0.9362, batch_loss: 0.1661, loss: 0.1755 ||:  34%|###3      | 2447/7204 [04:54<19:02,  4.17it/s]
2022-03-19 21:26:24,244 - INFO - tqdm - f1: 0.8615, accuracy: 0.9362, batch_loss: 0.0694, loss: 0.1754 ||:  35%|###5      | 2540/7204 [05:04<20:16,  3.83it/s]
2022-03-19 21:26:34,333 - INFO - tqdm - f1: 0.8621, accuracy: 0.9366, batch_loss: 0.0201, loss: 0.1748 ||:  36%|###6      | 2622/7204 [05:15<08:58,  8.51it/s]
2022-03-19 21:26:44,363 - INFO - tqdm - f1: 0.8618, accuracy: 0.9366, batch_loss: 0.0074, loss: 0.1752 ||:  38%|###7      | 2726/7204 [05:25<07:52,  9.47it/s]
2022-03-19 21:26:54,444 - INFO - tqdm - f1: 0.8617, accuracy: 0.9365, batch_loss: 0.1354, loss: 0.1752 ||:  39%|###9      | 2836/7204 [05:35<07:57,  9.15it/s]
2022-03-19 21:27:04,589 - INFO - tqdm - f1: 0.8605, accuracy: 0.9361, batch_loss: 0.4579, loss: 0.1759 ||:  41%|####      | 2926/7204 [05:45<20:59,  3.40it/s]
2022-03-19 21:27:14,696 - INFO - tqdm - f1: 0.8592, accuracy: 0.9357, batch_loss: 0.1874, loss: 0.1768 ||:  42%|####1     | 3008/7204 [05:55<05:17, 13.23it/s]
2022-03-19 21:27:24,813 - INFO - tqdm - f1: 0.8586, accuracy: 0.9354, batch_loss: 0.4768, loss: 0.1777 ||:  43%|####2     | 3088/7204 [06:05<09:43,  7.06it/s]
2022-03-19 21:27:34,911 - INFO - tqdm - f1: 0.8583, accuracy: 0.9354, batch_loss: 0.0546, loss: 0.1773 ||:  44%|####4     | 3173/7204 [06:15<15:57,  4.21it/s]
2022-03-19 21:27:44,966 - INFO - tqdm - f1: 0.8579, accuracy: 0.9352, batch_loss: 0.3062, loss: 0.1779 ||:  45%|####5     | 3250/7204 [06:25<06:36,  9.98it/s]
2022-03-19 21:27:55,030 - INFO - tqdm - f1: 0.8576, accuracy: 0.9350, batch_loss: 0.1820, loss: 0.1785 ||:  46%|####6     | 3332/7204 [06:35<05:40, 11.39it/s]
2022-03-19 21:28:05,092 - INFO - tqdm - f1: 0.8577, accuracy: 0.9351, batch_loss: 0.0799, loss: 0.1789 ||:  47%|####7     | 3407/7204 [06:45<16:44,  3.78it/s]
2022-03-19 21:28:15,117 - INFO - tqdm - f1: 0.8574, accuracy: 0.9350, batch_loss: 0.0910, loss: 0.1789 ||:  49%|####8     | 3512/7204 [06:55<05:40, 10.85it/s]
2022-03-19 21:28:25,201 - INFO - tqdm - f1: 0.8571, accuracy: 0.9348, batch_loss: 0.1737, loss: 0.1792 ||:  50%|####9     | 3598/7204 [07:05<10:54,  5.51it/s]
2022-03-19 21:28:35,268 - INFO - tqdm - f1: 0.8567, accuracy: 0.9345, batch_loss: 0.2447, loss: 0.1801 ||:  51%|#####1    | 3689/7204 [07:15<05:32, 10.56it/s]
2022-03-19 21:28:45,327 - INFO - tqdm - f1: 0.8561, accuracy: 0.9342, batch_loss: 0.3896, loss: 0.1805 ||:  52%|#####2    | 3779/7204 [07:26<05:01, 11.37it/s]
2022-03-19 21:28:55,559 - INFO - tqdm - f1: 0.8561, accuracy: 0.9342, batch_loss: 0.2584, loss: 0.1804 ||:  54%|#####3    | 3886/7204 [07:36<10:36,  5.21it/s]
2022-03-19 21:29:05,601 - INFO - tqdm - f1: 0.8561, accuracy: 0.9343, batch_loss: 0.2395, loss: 0.1803 ||:  55%|#####5    | 3974/7204 [07:46<03:57, 13.61it/s]
2022-03-19 21:29:15,685 - INFO - tqdm - f1: 0.8557, accuracy: 0.9339, batch_loss: 0.1096, loss: 0.1812 ||:  56%|#####6    | 4066/7204 [07:56<04:43, 11.05it/s]
2022-03-19 21:29:25,741 - INFO - tqdm - f1: 0.8556, accuracy: 0.9338, batch_loss: 0.0696, loss: 0.1817 ||:  58%|#####7    | 4150/7204 [08:06<05:57,  8.54it/s]
2022-03-19 21:29:35,857 - INFO - tqdm - f1: 0.8556, accuracy: 0.9338, batch_loss: 0.1170, loss: 0.1819 ||:  59%|#####8    | 4234/7204 [08:16<05:50,  8.47it/s]
2022-03-19 21:29:46,186 - INFO - tqdm - f1: 0.8556, accuracy: 0.9338, batch_loss: 0.0805, loss: 0.1820 ||:  60%|#####9    | 4319/7204 [08:26<13:54,  3.46it/s]
2022-03-19 21:29:56,273 - INFO - tqdm - f1: 0.8556, accuracy: 0.9338, batch_loss: 0.3473, loss: 0.1818 ||:  61%|######1   | 4421/7204 [08:36<03:14, 14.28it/s]
2022-03-19 21:30:06,312 - INFO - tqdm - f1: 0.8559, accuracy: 0.9340, batch_loss: 0.2749, loss: 0.1814 ||:  63%|######2   | 4506/7204 [08:46<11:46,  3.82it/s]
2022-03-19 21:30:17,165 - INFO - tqdm - f1: 0.8558, accuracy: 0.9339, batch_loss: 0.2108, loss: 0.1814 ||:  64%|######3   | 4590/7204 [08:57<08:55,  4.88it/s]
2022-03-19 21:30:27,168 - INFO - tqdm - f1: 0.8555, accuracy: 0.9338, batch_loss: 0.0840, loss: 0.1813 ||:  65%|######5   | 4689/7204 [09:07<03:17, 12.72it/s]
2022-03-19 21:30:37,315 - INFO - tqdm - f1: 0.8552, accuracy: 0.9339, batch_loss: 0.3069, loss: 0.1812 ||:  66%|######6   | 4761/7204 [09:17<04:32,  8.96it/s]
2022-03-19 21:30:47,470 - INFO - tqdm - f1: 0.8552, accuracy: 0.9337, batch_loss: 0.2743, loss: 0.1815 ||:  67%|######7   | 4857/7204 [09:28<03:50, 10.18it/s]
2022-03-19 21:30:57,942 - INFO - tqdm - f1: 0.8551, accuracy: 0.9337, batch_loss: 0.0093, loss: 0.1816 ||:  69%|######8   | 4943/7204 [09:38<09:56,  3.79it/s]
2022-03-19 21:31:08,252 - INFO - tqdm - f1: 0.8550, accuracy: 0.9337, batch_loss: 0.0628, loss: 0.1817 ||:  70%|######9   | 5041/7204 [09:48<07:28,  4.83it/s]
2022-03-19 21:31:18,320 - INFO - tqdm - f1: 0.8551, accuracy: 0.9337, batch_loss: 0.0349, loss: 0.1819 ||:  71%|#######1  | 5131/7204 [09:59<03:20, 10.34it/s]
2022-03-19 21:31:28,322 - INFO - tqdm - f1: 0.8545, accuracy: 0.9333, batch_loss: 0.4177, loss: 0.1826 ||:  73%|#######2  | 5226/7204 [10:09<02:28, 13.28it/s]
2022-03-19 21:31:38,480 - INFO - tqdm - f1: 0.8544, accuracy: 0.9332, batch_loss: 0.3123, loss: 0.1829 ||:  74%|#######4  | 5331/7204 [10:19<03:37,  8.62it/s]
2022-03-19 21:31:48,622 - INFO - tqdm - f1: 0.8537, accuracy: 0.9329, batch_loss: 0.1106, loss: 0.1832 ||:  75%|#######5  | 5426/7204 [10:29<03:25,  8.66it/s]
2022-03-19 21:31:59,048 - INFO - tqdm - f1: 0.8534, accuracy: 0.9328, batch_loss: 0.5893, loss: 0.1836 ||:  77%|#######6  | 5512/7204 [10:39<07:54,  3.57it/s]
2022-03-19 21:32:09,110 - INFO - tqdm - f1: 0.8528, accuracy: 0.9326, batch_loss: 0.2497, loss: 0.1840 ||:  78%|#######7  | 5601/7204 [10:49<02:10, 12.26it/s]
2022-03-19 21:32:19,210 - INFO - tqdm - f1: 0.8523, accuracy: 0.9322, batch_loss: 0.3990, loss: 0.1849 ||:  79%|#######9  | 5714/7204 [10:59<01:53, 13.12it/s]
2022-03-19 21:32:29,780 - INFO - tqdm - f1: 0.8527, accuracy: 0.9323, batch_loss: 0.1895, loss: 0.1847 ||:  80%|########  | 5797/7204 [11:10<05:42,  4.11it/s]
2022-03-19 21:32:39,862 - INFO - tqdm - f1: 0.8524, accuracy: 0.9322, batch_loss: 0.2015, loss: 0.1848 ||:  82%|########1 | 5889/7204 [11:20<01:59, 11.04it/s]
2022-03-19 21:32:49,924 - INFO - tqdm - f1: 0.8519, accuracy: 0.9318, batch_loss: 0.0852, loss: 0.1855 ||:  83%|########3 | 5982/7204 [11:30<01:48, 11.24it/s]
2022-03-19 21:33:01,049 - INFO - tqdm - f1: 0.8518, accuracy: 0.9317, batch_loss: 0.0466, loss: 0.1856 ||:  84%|########4 | 6061/7204 [11:41<05:39,  3.36it/s]
2022-03-19 21:33:11,065 - INFO - tqdm - f1: 0.8520, accuracy: 0.9317, batch_loss: 0.3021, loss: 0.1858 ||:  85%|########5 | 6144/7204 [11:51<01:34, 11.25it/s]
2022-03-19 21:33:21,085 - INFO - tqdm - f1: 0.8524, accuracy: 0.9318, batch_loss: 0.0564, loss: 0.1857 ||:  86%|########6 | 6228/7204 [12:01<01:34, 10.28it/s]
2022-03-19 21:33:31,289 - INFO - tqdm - f1: 0.8522, accuracy: 0.9317, batch_loss: 0.0898, loss: 0.1858 ||:  88%|########7 | 6306/7204 [12:11<03:23,  4.41it/s]
2022-03-19 21:33:41,320 - INFO - tqdm - f1: 0.8521, accuracy: 0.9317, batch_loss: 0.0713, loss: 0.1861 ||:  89%|########8 | 6389/7204 [12:22<01:26,  9.48it/s]
2022-03-19 21:33:52,198 - INFO - tqdm - f1: 0.8524, accuracy: 0.9318, batch_loss: 0.3209, loss: 0.1859 ||:  90%|########9 | 6470/7204 [12:32<02:52,  4.25it/s]
2022-03-19 21:34:02,302 - INFO - tqdm - f1: 0.8523, accuracy: 0.9318, batch_loss: 0.1424, loss: 0.1860 ||:  91%|######### | 6554/7204 [12:42<01:09,  9.36it/s]
2022-03-19 21:34:12,423 - INFO - tqdm - f1: 0.8519, accuracy: 0.9316, batch_loss: 0.2762, loss: 0.1864 ||:  92%|#########2| 6648/7204 [12:53<01:30,  6.13it/s]
2022-03-19 21:34:22,492 - INFO - tqdm - f1: 0.8517, accuracy: 0.9316, batch_loss: 0.0935, loss: 0.1864 ||:  93%|#########3| 6707/7204 [13:03<01:40,  4.97it/s]
2022-03-19 21:34:32,507 - INFO - tqdm - f1: 0.8518, accuracy: 0.9315, batch_loss: 0.1340, loss: 0.1866 ||:  94%|#########3| 6771/7204 [13:13<01:06,  6.53it/s]
2022-03-19 21:34:42,534 - INFO - tqdm - f1: 0.8517, accuracy: 0.9315, batch_loss: 0.0345, loss: 0.1865 ||:  95%|#########4| 6825/7204 [13:23<01:03,  5.99it/s]
2022-03-19 21:34:52,641 - INFO - tqdm - f1: 0.8518, accuracy: 0.9315, batch_loss: 0.0631, loss: 0.1865 ||:  96%|#########5| 6895/7204 [13:33<00:38,  7.99it/s]
2022-03-19 21:35:02,667 - INFO - tqdm - f1: 0.8518, accuracy: 0.9315, batch_loss: 0.2427, loss: 0.1864 ||:  96%|#########6| 6949/7204 [13:43<00:53,  4.75it/s]
2022-03-19 21:35:12,684 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.0156, loss: 0.1866 ||:  97%|#########7| 7014/7204 [13:53<00:26,  7.10it/s]
2022-03-19 21:35:22,738 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.2944, loss: 0.1867 ||:  98%|#########8| 7073/7204 [14:03<00:26,  5.01it/s]
2022-03-19 21:35:32,978 - INFO - tqdm - f1: 0.8514, accuracy: 0.9314, batch_loss: 0.0937, loss: 0.1869 ||:  99%|#########9| 7133/7204 [14:13<00:15,  4.55it/s]
2022-03-19 21:35:38,757 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.1317, loss: 0.1868 ||: 100%|#########9| 7168/7204 [14:19<00:06,  5.96it/s]
2022-03-19 21:35:38,902 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.1433, loss: 0.1868 ||: 100%|#########9| 7169/7204 [14:19<00:05,  6.22it/s]
2022-03-19 21:35:39,068 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.0686, loss: 0.1868 ||: 100%|#########9| 7170/7204 [14:19<00:05,  6.15it/s]
2022-03-19 21:35:39,176 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.4081, loss: 0.1868 ||: 100%|#########9| 7171/7204 [14:19<00:04,  6.85it/s]
2022-03-19 21:35:39,326 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.1589, loss: 0.1868 ||: 100%|#########9| 7172/7204 [14:20<00:04,  6.80it/s]
2022-03-19 21:35:39,667 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.3406, loss: 0.1868 ||: 100%|#########9| 7173/7204 [14:20<00:06,  4.87it/s]
2022-03-19 21:35:39,839 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.1592, loss: 0.1868 ||: 100%|#########9| 7174/7204 [14:20<00:05,  5.12it/s]
2022-03-19 21:35:40,131 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.1320, loss: 0.1868 ||: 100%|#########9| 7175/7204 [14:20<00:06,  4.46it/s]
2022-03-19 21:35:40,329 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.0843, loss: 0.1868 ||: 100%|#########9| 7176/7204 [14:21<00:06,  4.62it/s]
2022-03-19 21:35:40,468 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.7181, loss: 0.1869 ||: 100%|#########9| 7177/7204 [14:21<00:05,  5.17it/s]
2022-03-19 21:35:40,679 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.1151, loss: 0.1869 ||: 100%|#########9| 7178/7204 [14:21<00:05,  5.04it/s]
2022-03-19 21:35:40,823 - INFO - tqdm - f1: 0.8514, accuracy: 0.9314, batch_loss: 0.3728, loss: 0.1869 ||: 100%|#########9| 7179/7204 [14:21<00:04,  5.49it/s]
2022-03-19 21:35:40,970 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.1347, loss: 0.1869 ||: 100%|#########9| 7180/7204 [14:21<00:04,  5.83it/s]
2022-03-19 21:35:41,205 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.0160, loss: 0.1869 ||: 100%|#########9| 7181/7204 [14:21<00:04,  5.25it/s]
2022-03-19 21:35:41,431 - INFO - tqdm - f1: 0.8515, accuracy: 0.9314, batch_loss: 0.1224, loss: 0.1869 ||: 100%|#########9| 7182/7204 [14:22<00:04,  4.97it/s]
2022-03-19 21:35:41,575 - INFO - tqdm - f1: 0.8514, accuracy: 0.9314, batch_loss: 0.3126, loss: 0.1869 ||: 100%|#########9| 7183/7204 [14:22<00:03,  5.43it/s]
2022-03-19 21:35:41,829 - INFO - tqdm - f1: 0.8514, accuracy: 0.9314, batch_loss: 0.1827, loss: 0.1869 ||: 100%|#########9| 7184/7204 [14:22<00:04,  4.87it/s]
2022-03-19 21:35:42,014 - INFO - tqdm - f1: 0.8514, accuracy: 0.9314, batch_loss: 0.0258, loss: 0.1869 ||: 100%|#########9| 7185/7204 [14:22<00:03,  5.03it/s]
2022-03-19 21:35:42,154 - INFO - tqdm - f1: 0.8514, accuracy: 0.9314, batch_loss: 0.1042, loss: 0.1868 ||: 100%|#########9| 7186/7204 [14:22<00:03,  5.52it/s]
2022-03-19 21:35:42,324 - INFO - tqdm - f1: 0.8514, accuracy: 0.9314, batch_loss: 0.1874, loss: 0.1868 ||: 100%|#########9| 7187/7204 [14:23<00:03,  5.62it/s]
2022-03-19 21:35:42,667 - INFO - tqdm - f1: 0.8514, accuracy: 0.9314, batch_loss: 0.2106, loss: 0.1868 ||: 100%|#########9| 7188/7204 [14:23<00:03,  4.40it/s]
2022-03-19 21:35:43,077 - INFO - tqdm - f1: 0.8514, accuracy: 0.9313, batch_loss: 0.1678, loss: 0.1869 ||: 100%|#########9| 7190/7204 [14:23<00:03,  4.61it/s]
2022-03-19 21:35:43,390 - INFO - tqdm - f1: 0.8514, accuracy: 0.9314, batch_loss: 0.0131, loss: 0.1868 ||: 100%|#########9| 7191/7204 [14:24<00:03,  4.15it/s]
2022-03-19 21:35:43,613 - INFO - tqdm - f1: 0.8513, accuracy: 0.9313, batch_loss: 0.5674, loss: 0.1869 ||: 100%|#########9| 7192/7204 [14:24<00:02,  4.24it/s]
2022-03-19 21:35:43,965 - INFO - tqdm - f1: 0.8513, accuracy: 0.9313, batch_loss: 0.0222, loss: 0.1869 ||: 100%|#########9| 7194/7204 [14:24<00:02,  4.75it/s]
2022-03-19 21:35:44,074 - INFO - tqdm - f1: 0.8513, accuracy: 0.9313, batch_loss: 0.2262, loss: 0.1869 ||: 100%|#########9| 7195/7204 [14:24<00:01,  5.35it/s]
2022-03-19 21:35:44,239 - INFO - tqdm - f1: 0.8513, accuracy: 0.9313, batch_loss: 0.1703, loss: 0.1869 ||: 100%|#########9| 7196/7204 [14:24<00:01,  5.52it/s]
2022-03-19 21:35:44,375 - INFO - tqdm - f1: 0.8512, accuracy: 0.9313, batch_loss: 0.3189, loss: 0.1869 ||: 100%|#########9| 7197/7204 [14:25<00:01,  5.90it/s]
2022-03-19 21:35:44,714 - INFO - tqdm - f1: 0.8512, accuracy: 0.9313, batch_loss: 0.1597, loss: 0.1869 ||: 100%|#########9| 7198/7204 [14:25<00:01,  4.64it/s]
2022-03-19 21:35:44,980 - INFO - tqdm - f1: 0.8513, accuracy: 0.9313, batch_loss: 0.1837, loss: 0.1869 ||: 100%|#########9| 7199/7204 [14:25<00:01,  4.35it/s]
2022-03-19 21:35:45,087 - INFO - tqdm - f1: 0.8512, accuracy: 0.9313, batch_loss: 0.3490, loss: 0.1870 ||: 100%|#########9| 7200/7204 [14:25<00:00,  5.14it/s]
2022-03-19 21:35:45,270 - INFO - tqdm - f1: 0.8512, accuracy: 0.9313, batch_loss: 0.1666, loss: 0.1870 ||: 100%|#########9| 7201/7204 [14:25<00:00,  5.22it/s]
2022-03-19 21:35:45,441 - INFO - tqdm - f1: 0.8512, accuracy: 0.9313, batch_loss: 0.0808, loss: 0.1869 ||: 100%|#########9| 7202/7204 [14:26<00:00,  5.40it/s]
2022-03-19 21:35:45,841 - INFO - tqdm - f1: 0.8512, accuracy: 0.9313, batch_loss: 0.0635, loss: 0.1870 ||: 100%|##########| 7204/7204 [14:26<00:00,  5.21it/s]
2022-03-19 21:35:45,906 - INFO - tqdm - f1: 0.8512, accuracy: 0.9313, batch_loss: 0.0635, loss: 0.1870 ||: 100%|##########| 7204/7204 [14:26<00:00,  8.31it/s]
2022-03-19 21:35:45,913 - INFO - allennlp.training.trainer - Validating
2022-03-19 21:35:45,916 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-19 21:35:56,976 - INFO - tqdm - f1: 0.6207, accuracy: 0.8635, batch_loss: 0.1806, loss: 0.3740 ||:  43%|####3     | 136/313 [00:11<00:32,  5.53it/s]
2022-03-19 21:36:07,003 - INFO - tqdm - f1: 0.6390, accuracy: 0.8679, batch_loss: 0.7070, loss: 0.3690 ||:  84%|########4 | 264/313 [00:21<00:03, 16.14it/s]
2022-03-19 21:36:10,918 - INFO - tqdm - f1: 0.6362, accuracy: 0.8682, batch_loss: 0.2708, loss: 0.3652 ||: 100%|##########| 313/313 [00:24<00:00, 15.23it/s]
2022-03-19 21:36:10,922 - INFO - tqdm - f1: 0.6362, accuracy: 0.8682, batch_loss: 0.2708, loss: 0.3652 ||: 100%|##########| 313/313 [00:25<00:00, 12.52it/s]
2022-03-19 21:36:10,952 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-19 21:36:10,954 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.931  |     0.868
2022-03-19 21:36:10,957 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.851  |     0.636
2022-03-19 21:36:10,959 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-19 21:36:10,962 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.187  |     0.365
2022-03-19 21:36:10,964 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13603.656  |       N/A
2022-03-19 21:36:10,966 - INFO - allennlp.training.trainer - Epoch duration: 0:14:51.658121
2022-03-19 21:36:10,969 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:13:20
2022-03-19 21:36:10,971 - INFO - allennlp.training.trainer - Epoch 5/9
2022-03-19 21:36:10,974 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-19 21:36:10,977 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-19 21:36:10,981 - INFO - allennlp.training.trainer - Training
2022-03-19 21:36:10,983 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-19 21:36:20,995 - INFO - tqdm - f1: 0.9006, accuracy: 0.9557, batch_loss: 0.0630, loss: 0.1446 ||:   1%|          | 48/7204 [00:10<20:01,  5.96it/s]
2022-03-19 21:36:31,116 - INFO - tqdm - f1: 0.9094, accuracy: 0.9571, batch_loss: 0.1338, loss: 0.1339 ||:   1%|1         | 102/7204 [00:20<17:49,  6.64it/s]
2022-03-19 21:36:41,251 - INFO - tqdm - f1: 0.8970, accuracy: 0.9489, batch_loss: 0.0369, loss: 0.1479 ||:   2%|2         | 159/7204 [00:30<17:33,  6.69it/s]
2022-03-19 21:36:51,348 - INFO - tqdm - f1: 0.8866, accuracy: 0.9435, batch_loss: 0.4124, loss: 0.1508 ||:   3%|3         | 219/7204 [00:40<19:05,  6.10it/s]
2022-03-19 21:37:01,368 - INFO - tqdm - f1: 0.8918, accuracy: 0.9463, batch_loss: 0.2787, loss: 0.1443 ||:   4%|3         | 269/7204 [00:50<23:11,  4.99it/s]
2022-03-19 21:37:11,379 - INFO - tqdm - f1: 0.8917, accuracy: 0.9463, batch_loss: 0.0092, loss: 0.1432 ||:   4%|4         | 320/7204 [01:00<23:06,  4.97it/s]
2022-03-19 21:37:21,430 - INFO - tqdm - f1: 0.8918, accuracy: 0.9464, batch_loss: 0.0322, loss: 0.1450 ||:   5%|5         | 365/7204 [01:10<29:19,  3.89it/s]
2022-03-19 21:37:31,692 - INFO - tqdm - f1: 0.8928, accuracy: 0.9474, batch_loss: 0.0853, loss: 0.1419 ||:   6%|5         | 424/7204 [01:20<16:41,  6.77it/s]
2022-03-19 21:37:41,879 - INFO - tqdm - f1: 0.8948, accuracy: 0.9489, batch_loss: 0.3068, loss: 0.1370 ||:   7%|6         | 470/7204 [01:30<32:19,  3.47it/s]
2022-03-19 21:37:51,890 - INFO - tqdm - f1: 0.8951, accuracy: 0.9488, batch_loss: 0.0198, loss: 0.1386 ||:   7%|7         | 531/7204 [01:40<11:22,  9.78it/s]
2022-03-19 21:38:02,674 - INFO - tqdm - f1: 0.8953, accuracy: 0.9492, batch_loss: 0.0772, loss: 0.1380 ||:   8%|8         | 584/7204 [01:51<41:21,  2.67it/s]
2022-03-19 21:38:12,761 - INFO - tqdm - f1: 0.8939, accuracy: 0.9489, batch_loss: 0.2000, loss: 0.1394 ||:   9%|8         | 646/7204 [02:01<15:59,  6.84it/s]
2022-03-19 21:38:23,498 - INFO - tqdm - f1: 0.8926, accuracy: 0.9483, batch_loss: 0.2028, loss: 0.1412 ||:  10%|9         | 709/7204 [02:12<30:47,  3.52it/s]
2022-03-19 21:38:33,710 - INFO - tqdm - f1: 0.8931, accuracy: 0.9488, batch_loss: 0.0978, loss: 0.1398 ||:  11%|#         | 766/7204 [02:22<33:42,  3.18it/s]
2022-03-19 21:38:43,857 - INFO - tqdm - f1: 0.8929, accuracy: 0.9488, batch_loss: 0.0161, loss: 0.1403 ||:  11%|#1        | 826/7204 [02:32<17:05,  6.22it/s]
2022-03-19 21:38:53,991 - INFO - tqdm - f1: 0.8900, accuracy: 0.9482, batch_loss: 0.0949, loss: 0.1413 ||:  12%|#2        | 884/7204 [02:43<27:03,  3.89it/s]
2022-03-19 21:39:04,131 - INFO - tqdm - f1: 0.8877, accuracy: 0.9467, batch_loss: 0.2568, loss: 0.1432 ||:  13%|#2        | 934/7204 [02:53<19:47,  5.28it/s]
2022-03-19 21:39:14,191 - INFO - tqdm - f1: 0.8878, accuracy: 0.9470, batch_loss: 0.0205, loss: 0.1435 ||:  14%|#3        | 992/7204 [03:03<21:01,  4.92it/s]
2022-03-19 21:39:24,542 - INFO - tqdm - f1: 0.8887, accuracy: 0.9474, batch_loss: 0.0851, loss: 0.1431 ||:  14%|#4        | 1043/7204 [03:13<45:34,  2.25it/s]
2022-03-19 21:39:34,607 - INFO - tqdm - f1: 0.8899, accuracy: 0.9478, batch_loss: 0.0525, loss: 0.1418 ||:  15%|#5        | 1089/7204 [03:23<24:02,  4.24it/s]
2022-03-19 21:39:44,771 - INFO - tqdm - f1: 0.8905, accuracy: 0.9483, batch_loss: 0.0932, loss: 0.1413 ||:  16%|#5        | 1131/7204 [03:33<16:45,  6.04it/s]
2022-03-19 21:39:55,010 - INFO - tqdm - f1: 0.8925, accuracy: 0.9493, batch_loss: 0.0182, loss: 0.1395 ||:  16%|#6        | 1174/7204 [03:44<24:48,  4.05it/s]
2022-03-19 21:40:05,331 - INFO - tqdm - f1: 0.8924, accuracy: 0.9493, batch_loss: 0.2165, loss: 0.1407 ||:  17%|#6        | 1216/7204 [03:54<23:12,  4.30it/s]
2022-03-19 21:40:15,420 - INFO - tqdm - f1: 0.8924, accuracy: 0.9494, batch_loss: 0.3073, loss: 0.1408 ||:  17%|#7        | 1259/7204 [04:04<21:34,  4.59it/s]
2022-03-19 21:40:25,547 - INFO - tqdm - f1: 0.8922, accuracy: 0.9493, batch_loss: 0.0397, loss: 0.1415 ||:  19%|#8        | 1346/7204 [04:14<08:41, 11.24it/s]
2022-03-19 21:40:35,556 - INFO - tqdm - f1: 0.8911, accuracy: 0.9488, batch_loss: 0.0480, loss: 0.1430 ||:  20%|#9        | 1425/7204 [04:24<11:29,  8.38it/s]
2022-03-19 21:40:45,623 - INFO - tqdm - f1: 0.8927, accuracy: 0.9494, batch_loss: 0.0167, loss: 0.1413 ||:  21%|##1       | 1517/7204 [04:34<09:20, 10.14it/s]
2022-03-19 21:40:55,647 - INFO - tqdm - f1: 0.8925, accuracy: 0.9493, batch_loss: 0.0089, loss: 0.1422 ||:  23%|##2       | 1623/7204 [04:44<08:58, 10.36it/s]
2022-03-19 21:41:05,750 - INFO - tqdm - f1: 0.8919, accuracy: 0.9492, batch_loss: 0.4242, loss: 0.1424 ||:  24%|##3       | 1706/7204 [04:54<12:08,  7.55it/s]
2022-03-19 21:41:15,887 - INFO - tqdm - f1: 0.8928, accuracy: 0.9497, batch_loss: 0.0085, loss: 0.1417 ||:  25%|##5       | 1803/7204 [05:04<08:00, 11.24it/s]
2022-03-19 21:41:25,986 - INFO - tqdm - f1: 0.8919, accuracy: 0.9491, batch_loss: 0.1367, loss: 0.1432 ||:  26%|##6       | 1890/7204 [05:15<07:57, 11.13it/s]
2022-03-19 21:41:36,285 - INFO - tqdm - f1: 0.8913, accuracy: 0.9489, batch_loss: 0.0172, loss: 0.1443 ||:  27%|##7       | 1973/7204 [05:25<21:16,  4.10it/s]
2022-03-19 21:41:46,329 - INFO - tqdm - f1: 0.8909, accuracy: 0.9488, batch_loss: 0.2392, loss: 0.1449 ||:  29%|##8       | 2069/7204 [05:35<07:06, 12.04it/s]
2022-03-19 21:41:56,422 - INFO - tqdm - f1: 0.8911, accuracy: 0.9488, batch_loss: 0.0310, loss: 0.1445 ||:  30%|##9       | 2148/7204 [05:45<09:03,  9.31it/s]
2022-03-19 21:42:06,549 - INFO - tqdm - f1: 0.8918, accuracy: 0.9491, batch_loss: 0.0334, loss: 0.1440 ||:  31%|###       | 2230/7204 [05:55<10:28,  7.92it/s]
2022-03-19 21:42:16,580 - INFO - tqdm - f1: 0.8913, accuracy: 0.9487, batch_loss: 0.0859, loss: 0.1447 ||:  32%|###2      | 2315/7204 [06:05<17:08,  4.75it/s]
2022-03-19 21:42:26,607 - INFO - tqdm - f1: 0.8912, accuracy: 0.9487, batch_loss: 0.2946, loss: 0.1445 ||:  33%|###3      | 2397/7204 [06:15<07:44, 10.34it/s]
2022-03-19 21:42:36,631 - INFO - tqdm - f1: 0.8906, accuracy: 0.9483, batch_loss: 0.1039, loss: 0.1454 ||:  34%|###4      | 2476/7204 [06:25<07:07, 11.05it/s]
2022-03-19 21:42:46,684 - INFO - tqdm - f1: 0.8906, accuracy: 0.9483, batch_loss: 0.0315, loss: 0.1453 ||:  36%|###5      | 2561/7204 [06:35<14:14,  5.43it/s]
2022-03-19 21:42:57,229 - INFO - tqdm - f1: 0.8908, accuracy: 0.9483, batch_loss: 0.1047, loss: 0.1448 ||:  37%|###6      | 2651/7204 [06:46<15:57,  4.75it/s]
2022-03-19 21:43:08,221 - INFO - tqdm - f1: 0.8910, accuracy: 0.9483, batch_loss: 0.0967, loss: 0.1450 ||:  38%|###8      | 2742/7204 [06:57<16:02,  4.63it/s]
2022-03-19 21:43:18,290 - INFO - tqdm - f1: 0.8904, accuracy: 0.9483, batch_loss: 0.2221, loss: 0.1451 ||:  39%|###9      | 2828/7204 [07:07<05:54, 12.35it/s]
2022-03-19 21:43:28,463 - INFO - tqdm - f1: 0.8910, accuracy: 0.9483, batch_loss: 0.0334, loss: 0.1458 ||:  41%|####      | 2918/7204 [07:17<07:22,  9.68it/s]
2022-03-19 21:43:38,546 - INFO - tqdm - f1: 0.8902, accuracy: 0.9479, batch_loss: 0.4529, loss: 0.1470 ||:  42%|####1     | 3004/7204 [07:27<14:14,  4.92it/s]
2022-03-19 21:43:48,642 - INFO - tqdm - f1: 0.8903, accuracy: 0.9480, batch_loss: 0.0307, loss: 0.1466 ||:  43%|####2     | 3089/7204 [07:37<06:30, 10.54it/s]
2022-03-19 21:43:58,708 - INFO - tqdm - f1: 0.8901, accuracy: 0.9476, batch_loss: 0.2941, loss: 0.1475 ||:  44%|####4     | 3174/7204 [07:47<06:59,  9.60it/s]
2022-03-19 21:44:08,889 - INFO - tqdm - f1: 0.8898, accuracy: 0.9477, batch_loss: 0.1301, loss: 0.1471 ||:  45%|####5     | 3268/7204 [07:57<06:40,  9.83it/s]
2022-03-19 21:44:19,472 - INFO - tqdm - f1: 0.8902, accuracy: 0.9478, batch_loss: 0.0160, loss: 0.1470 ||:  47%|####6     | 3351/7204 [08:08<17:26,  3.68it/s]
2022-03-19 21:44:30,587 - INFO - tqdm - f1: 0.8900, accuracy: 0.9478, batch_loss: 0.3408, loss: 0.1473 ||:  48%|####7     | 3445/7204 [08:19<14:48,  4.23it/s]
2022-03-19 21:44:40,753 - INFO - tqdm - f1: 0.8898, accuracy: 0.9479, batch_loss: 0.0466, loss: 0.1468 ||:  49%|####9     | 3531/7204 [08:29<06:42,  9.13it/s]
2022-03-19 21:44:50,796 - INFO - tqdm - f1: 0.8891, accuracy: 0.9477, batch_loss: 0.0969, loss: 0.1472 ||:  50%|#####     | 3603/7204 [08:39<14:42,  4.08it/s]
2022-03-19 21:45:01,044 - INFO - tqdm - f1: 0.8893, accuracy: 0.9476, batch_loss: 0.1289, loss: 0.1471 ||:  51%|#####1    | 3698/7204 [08:50<07:19,  7.98it/s]
2022-03-19 21:45:11,168 - INFO - tqdm - f1: 0.8895, accuracy: 0.9476, batch_loss: 0.1404, loss: 0.1473 ||:  52%|#####2    | 3767/7204 [09:00<14:22,  3.99it/s]
2022-03-19 21:45:21,174 - INFO - tqdm - f1: 0.8895, accuracy: 0.9476, batch_loss: 0.0374, loss: 0.1475 ||:  54%|#####3    | 3855/7204 [09:10<05:49,  9.59it/s]
2022-03-19 21:45:31,742 - INFO - tqdm - f1: 0.8891, accuracy: 0.9475, batch_loss: 0.3355, loss: 0.1473 ||:  55%|#####4    | 3934/7204 [09:20<14:14,  3.83it/s]
2022-03-19 21:45:41,925 - INFO - tqdm - f1: 0.8893, accuracy: 0.9476, batch_loss: 0.0274, loss: 0.1473 ||:  56%|#####5    | 4020/7204 [09:30<05:50,  9.08it/s]
2022-03-19 21:45:53,148 - INFO - tqdm - f1: 0.8889, accuracy: 0.9474, batch_loss: 0.0529, loss: 0.1477 ||:  57%|#####6    | 4102/7204 [09:42<14:08,  3.66it/s]
2022-03-19 21:46:03,279 - INFO - tqdm - f1: 0.8888, accuracy: 0.9474, batch_loss: 0.1317, loss: 0.1479 ||:  58%|#####8    | 4188/7204 [09:52<04:35, 10.93it/s]
2022-03-19 21:46:13,372 - INFO - tqdm - f1: 0.8888, accuracy: 0.9474, batch_loss: 0.0506, loss: 0.1480 ||:  59%|#####9    | 4258/7204 [10:02<12:06,  4.06it/s]
2022-03-19 21:46:23,477 - INFO - tqdm - f1: 0.8888, accuracy: 0.9473, batch_loss: 0.0111, loss: 0.1482 ||:  60%|######    | 4337/7204 [10:12<05:41,  8.40it/s]
2022-03-19 21:46:33,818 - INFO - tqdm - f1: 0.8882, accuracy: 0.9471, batch_loss: 0.0245, loss: 0.1487 ||:  61%|######1   | 4414/7204 [10:22<11:38,  3.99it/s]
2022-03-19 21:46:43,866 - INFO - tqdm - f1: 0.8883, accuracy: 0.9472, batch_loss: 0.0919, loss: 0.1484 ||:  62%|######2   | 4496/7204 [10:32<04:11, 10.79it/s]
2022-03-19 21:46:53,985 - INFO - tqdm - f1: 0.8883, accuracy: 0.9472, batch_loss: 0.4240, loss: 0.1484 ||:  64%|######3   | 4576/7204 [10:42<10:18,  4.25it/s]
2022-03-19 21:47:03,998 - INFO - tqdm - f1: 0.8885, accuracy: 0.9473, batch_loss: 0.2016, loss: 0.1484 ||:  65%|######4   | 4660/7204 [10:53<03:38, 11.63it/s]
2022-03-19 21:47:14,164 - INFO - tqdm - f1: 0.8881, accuracy: 0.9471, batch_loss: 0.0830, loss: 0.1489 ||:  66%|######5   | 4737/7204 [11:03<08:53,  4.62it/s]
2022-03-19 21:47:24,190 - INFO - tqdm - f1: 0.8881, accuracy: 0.9472, batch_loss: 0.1579, loss: 0.1491 ||:  67%|######6   | 4824/7204 [11:13<03:43, 10.67it/s]
2022-03-19 21:47:34,564 - INFO - tqdm - f1: 0.8878, accuracy: 0.9470, batch_loss: 0.4210, loss: 0.1496 ||:  68%|######8   | 4907/7204 [11:23<09:03,  4.23it/s]
2022-03-19 21:47:44,648 - INFO - tqdm - f1: 0.8882, accuracy: 0.9471, batch_loss: 0.0511, loss: 0.1498 ||:  69%|######9   | 4993/7204 [11:33<02:52, 12.80it/s]
2022-03-19 21:47:55,615 - INFO - tqdm - f1: 0.8886, accuracy: 0.9471, batch_loss: 0.0125, loss: 0.1497 ||:  70%|#######   | 5077/7204 [11:44<09:13,  3.84it/s]
2022-03-19 21:48:05,664 - INFO - tqdm - f1: 0.8880, accuracy: 0.9469, batch_loss: 0.1376, loss: 0.1502 ||:  72%|#######1  | 5163/7204 [11:54<03:08, 10.80it/s]
2022-03-19 21:48:15,880 - INFO - tqdm - f1: 0.8884, accuracy: 0.9470, batch_loss: 0.1313, loss: 0.1498 ||:  73%|#######2  | 5239/7204 [12:04<08:34,  3.82it/s]
2022-03-19 21:48:26,027 - INFO - tqdm - f1: 0.8880, accuracy: 0.9469, batch_loss: 0.2584, loss: 0.1499 ||:  74%|#######4  | 5332/7204 [12:15<03:02, 10.26it/s]
2022-03-19 21:48:36,126 - INFO - tqdm - f1: 0.8880, accuracy: 0.9469, batch_loss: 0.1098, loss: 0.1500 ||:  75%|#######5  | 5415/7204 [12:25<05:49,  5.12it/s]
2022-03-19 21:48:46,250 - INFO - tqdm - f1: 0.8879, accuracy: 0.9468, batch_loss: 0.2351, loss: 0.1501 ||:  76%|#######6  | 5495/7204 [12:35<02:24, 11.85it/s]
2022-03-19 21:48:56,889 - INFO - tqdm - f1: 0.8878, accuracy: 0.9467, batch_loss: 0.3176, loss: 0.1504 ||:  77%|#######7  | 5583/7204 [12:45<05:34,  4.85it/s]
2022-03-19 21:49:06,994 - INFO - tqdm - f1: 0.8874, accuracy: 0.9466, batch_loss: 0.3447, loss: 0.1506 ||:  79%|#######8  | 5663/7204 [12:56<03:04,  8.36it/s]
2022-03-19 21:49:17,507 - INFO - tqdm - f1: 0.8875, accuracy: 0.9465, batch_loss: 0.1618, loss: 0.1507 ||:  80%|#######9  | 5742/7204 [13:06<06:22,  3.82it/s]
2022-03-19 21:49:27,509 - INFO - tqdm - f1: 0.8875, accuracy: 0.9466, batch_loss: 0.0781, loss: 0.1506 ||:  81%|########  | 5828/7204 [13:16<02:34,  8.93it/s]
2022-03-19 21:49:37,835 - INFO - tqdm - f1: 0.8873, accuracy: 0.9465, batch_loss: 0.2313, loss: 0.1508 ||:  82%|########1 | 5903/7204 [13:26<04:55,  4.41it/s]
2022-03-19 21:49:47,942 - INFO - tqdm - f1: 0.8871, accuracy: 0.9464, batch_loss: 0.2914, loss: 0.1511 ||:  83%|########3 | 5987/7204 [13:36<02:15,  9.00it/s]
2022-03-19 21:49:58,643 - INFO - tqdm - f1: 0.8866, accuracy: 0.9463, batch_loss: 0.2354, loss: 0.1515 ||:  84%|########4 | 6067/7204 [13:47<04:14,  4.47it/s]
2022-03-19 21:50:08,742 - INFO - tqdm - f1: 0.8868, accuracy: 0.9462, batch_loss: 0.1089, loss: 0.1518 ||:  85%|########5 | 6151/7204 [13:57<01:48,  9.68it/s]
2022-03-19 21:50:18,870 - INFO - tqdm - f1: 0.8868, accuracy: 0.9462, batch_loss: 0.0335, loss: 0.1519 ||:  87%|########6 | 6237/7204 [14:07<01:40,  9.61it/s]
2022-03-19 21:50:28,971 - INFO - tqdm - f1: 0.8867, accuracy: 0.9463, batch_loss: 0.0477, loss: 0.1519 ||:  88%|########7 | 6309/7204 [14:17<03:03,  4.88it/s]
2022-03-19 21:50:39,141 - INFO - tqdm - f1: 0.8866, accuracy: 0.9463, batch_loss: 0.3142, loss: 0.1519 ||:  89%|########8 | 6389/7204 [14:28<01:31,  8.86it/s]
2022-03-19 21:50:49,367 - INFO - tqdm - f1: 0.8866, accuracy: 0.9462, batch_loss: 0.0351, loss: 0.1521 ||:  90%|########9 | 6460/7204 [14:38<03:09,  3.93it/s]
2022-03-19 21:50:59,503 - INFO - tqdm - f1: 0.8867, accuracy: 0.9462, batch_loss: 0.0392, loss: 0.1523 ||:  91%|######### | 6535/7204 [14:48<01:17,  8.64it/s]
2022-03-19 21:51:09,640 - INFO - tqdm - f1: 0.8867, accuracy: 0.9462, batch_loss: 0.1874, loss: 0.1524 ||:  92%|#########1| 6617/7204 [14:58<01:04,  9.15it/s]
2022-03-19 21:51:19,743 - INFO - tqdm - f1: 0.8865, accuracy: 0.9462, batch_loss: 0.0325, loss: 0.1523 ||:  93%|#########3| 6707/7204 [15:08<00:59,  8.40it/s]
2022-03-19 21:51:29,887 - INFO - tqdm - f1: 0.8867, accuracy: 0.9462, batch_loss: 0.2625, loss: 0.1522 ||:  94%|#########4| 6794/7204 [15:18<01:09,  5.90it/s]
2022-03-19 21:51:39,956 - INFO - tqdm - f1: 0.8867, accuracy: 0.9461, batch_loss: 0.3287, loss: 0.1523 ||:  96%|#########5| 6902/7204 [15:28<00:32,  9.36it/s]
2022-03-19 21:51:50,055 - INFO - tqdm - f1: 0.8869, accuracy: 0.9461, batch_loss: 0.2472, loss: 0.1524 ||:  97%|#########7| 7003/7204 [15:39<00:27,  7.29it/s]
2022-03-19 21:52:00,425 - INFO - tqdm - f1: 0.8868, accuracy: 0.9462, batch_loss: 0.0312, loss: 0.1524 ||:  98%|#########8| 7082/7204 [15:49<00:29,  4.19it/s]
2022-03-19 21:52:10,089 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.0335, loss: 0.1522 ||: 100%|#########9| 7168/7204 [15:59<00:02, 13.22it/s]
2022-03-19 21:52:10,228 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.0460, loss: 0.1522 ||: 100%|#########9| 7170/7204 [15:59<00:02, 13.57it/s]
2022-03-19 21:52:10,421 - INFO - tqdm - f1: 0.8869, accuracy: 0.9463, batch_loss: 0.0391, loss: 0.1522 ||: 100%|#########9| 7172/7204 [15:59<00:02, 12.37it/s]
2022-03-19 21:52:10,627 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.2952, loss: 0.1522 ||: 100%|#########9| 7174/7204 [15:59<00:02, 11.40it/s]
2022-03-19 21:52:10,754 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.1484, loss: 0.1522 ||: 100%|#########9| 7176/7204 [15:59<00:02, 12.46it/s]
2022-03-19 21:52:10,881 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.1661, loss: 0.1522 ||: 100%|#########9| 7178/7204 [15:59<00:01, 13.32it/s]
2022-03-19 21:52:11,878 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.0819, loss: 0.1522 ||: 100%|#########9| 7180/7204 [16:00<00:04,  4.91it/s]
2022-03-19 21:52:12,216 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.1822, loss: 0.1522 ||: 100%|#########9| 7182/7204 [16:01<00:04,  5.18it/s]
2022-03-19 21:52:12,344 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.0284, loss: 0.1522 ||: 100%|#########9| 7183/7204 [16:01<00:03,  5.51it/s]
2022-03-19 21:52:12,578 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.1986, loss: 0.1522 ||: 100%|#########9| 7185/7204 [16:01<00:03,  6.26it/s]
2022-03-19 21:52:12,748 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.1989, loss: 0.1522 ||: 100%|#########9| 7187/7204 [16:01<00:02,  7.38it/s]
2022-03-19 21:52:12,883 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.0809, loss: 0.1522 ||: 100%|#########9| 7189/7204 [16:01<00:01,  8.78it/s]
2022-03-19 21:52:13,088 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.1121, loss: 0.1522 ||: 100%|#########9| 7191/7204 [16:02<00:01,  9.06it/s]
2022-03-19 21:52:13,253 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.1751, loss: 0.1522 ||: 100%|#########9| 7193/7204 [16:02<00:01,  9.83it/s]
2022-03-19 21:52:13,415 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.3922, loss: 0.1522 ||: 100%|#########9| 7195/7204 [16:02<00:00, 10.48it/s]
2022-03-19 21:52:13,661 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.2130, loss: 0.1522 ||: 100%|#########9| 7197/7204 [16:02<00:00,  9.65it/s]
2022-03-19 21:52:13,892 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.0423, loss: 0.1522 ||: 100%|#########9| 7199/7204 [16:02<00:00,  9.31it/s]
2022-03-19 21:52:14,024 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.0390, loss: 0.1522 ||: 100%|#########9| 7201/7204 [16:03<00:00, 10.54it/s]
2022-03-19 21:52:14,148 - INFO - tqdm - f1: 0.8869, accuracy: 0.9462, batch_loss: 0.0639, loss: 0.1522 ||: 100%|#########9| 7203/7204 [16:03<00:00, 11.77it/s]
2022-03-19 21:52:14,375 - INFO - tqdm - f1: 0.8870, accuracy: 0.9462, batch_loss: 0.0452, loss: 0.1522 ||: 100%|##########| 7204/7204 [16:03<00:00,  7.48it/s]
2022-03-19 21:52:14,383 - INFO - allennlp.training.trainer - Validating
2022-03-19 21:52:14,386 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-19 21:52:24,398 - INFO - tqdm - f1: 0.6833, accuracy: 0.8646, batch_loss: 0.0074, loss: 0.4432 ||:  79%|#######8  | 247/313 [00:10<00:02, 26.83it/s]
2022-03-19 21:52:25,987 - INFO - tqdm - f1: 0.6831, accuracy: 0.8604, batch_loss: 0.3793, loss: 0.4528 ||: 100%|##########| 313/313 [00:11<00:00, 26.98it/s]
2022-03-19 21:52:25,995 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-19 21:52:25,996 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-19 21:52:26,343 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-19 21:52:26,350 - INFO - allennlp.training.util - Iterating over dataset
2022-03-19 21:52:26,352 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-19 21:52:26,387 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-19 21:52:26,389 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-19 21:52:36,358 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.34 ||: : 256it [00:10, 39.64it/s]
2022-03-19 21:52:46,579 - INFO - tqdm - f1: 0.69, accuracy: 0.88, loss: 0.34 ||: : 522it [00:20, 11.52it/s]
2022-03-19 21:52:56,651 - INFO - tqdm - f1: 0.70, accuracy: 0.88, loss: 0.33 ||: : 827it [00:30, 41.42it/s]
2022-03-19 21:53:06,696 - INFO - tqdm - f1: 0.69, accuracy: 0.88, loss: 0.34 ||: : 1074it [00:40, 21.98it/s]
2022-03-19 21:53:16,768 - INFO - tqdm - f1: 0.69, accuracy: 0.87, loss: 0.34 ||: : 1369it [00:50, 39.58it/s]
2022-03-19 21:53:24,533 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 2,
  "peak_worker_0_memory_MB": 13603.65625,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "1:13:20.295738",
  "training_start_epoch": 0,
  "training_epochs": 4,
  "epoch": 4,
  "training_f1": 0.8511935770511627,
  "training_accuracy": 0.9312630693009172,
  "training_loss": 0.18697345290508335,
  "training_worker_0_memory_MB": 13603.65625,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.6361508518457413,
  "validation_accuracy": 0.8682,
  "validation_loss": 0.36523651717284233,
  "best_validation_f1": 0.6915393471717834,
  "best_validation_accuracy": 0.8698,
  "best_validation_loss": 0.3464769286790881,
  "test_f1": 0.6880792379379272,
  "test_accuracy": 0.87344,
  "test_loss": 0.34044426736038746
}
2022-03-19 21:53:25,209 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/amazon_base/model.tar.gz
