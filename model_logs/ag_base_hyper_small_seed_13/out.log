2022-03-21 08:01:06,729 - INFO - allennlp.common.params - random_seed = 13
2022-03-21 08:01:06,733 - INFO - allennlp.common.params - numpy_seed = 13
2022-03-21 08:01:06,749 - INFO - allennlp.common.params - pytorch_seed = 13
2022-03-21 08:01:06,759 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-21 08:01:06,767 - INFO - allennlp.common.params - type = default
2022-03-21 08:01:06,778 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-21 08:01:06,780 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 08:01:06,810 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 08:01:06,822 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 08:01:06,834 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 08:01:06,835 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 08:01:06,837 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 08:01:19,484 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 08:01:19,491 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 08:01:19,502 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 08:01:19,513 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-21 08:01:19,524 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-21 08:01:19,536 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 08:01:19,562 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-21 08:01:19,573 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-21 08:01:19,597 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-21 08:01:19,617 - INFO - allennlp.common.params - train_data_path = datasets/ag/train.jsonl
2022-03-21 08:01:19,629 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7fdf67042190>
2022-03-21 08:01:19,641 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-21 08:01:19,653 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-21 08:01:19,665 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 08:01:19,675 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 08:01:19,686 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 08:01:19,697 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 08:01:19,708 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 08:01:19,719 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 08:01:19,731 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 08:01:19,742 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 08:01:19,753 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 08:01:19,764 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-21 08:01:19,776 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-21 08:01:19,787 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 08:01:19,798 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-21 08:01:19,811 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-21 08:01:19,821 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-21 08:01:19,822 - INFO - allennlp.common.params - validation_data_path = datasets/ag/dev.jsonl
2022-03-21 08:01:19,833 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-21 08:01:19,844 - INFO - allennlp.common.params - test_data_path = datasets/ag/test.jsonl
2022-03-21 08:01:19,874 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-21 08:01:19,900 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-21 08:01:19,937 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 08:01:19,946 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 08:01:19,971 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 08:01:19,972 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 08:01:19,975 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 08:01:19,977 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 08:01:19,990 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 08:01:19,992 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 08:01:19,994 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 08:01:20,008 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 08:01:20,011 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 08:01:20,023 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 08:01:20,035 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 08:01:20,037 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 08:01:20,049 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 08:01:30,099 - INFO - tqdm - loading instances: 30173it [00:10, 3623.57it/s]
2022-03-21 08:01:40,186 - INFO - tqdm - loading instances: 60130it [00:20, 3571.52it/s]
2022-03-21 08:01:50,238 - INFO - tqdm - loading instances: 89870it [00:30, 899.01it/s]
2022-03-21 08:01:58,635 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 08:01:58,640 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 08:01:58,651 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 08:01:58,652 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 08:01:58,653 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 08:01:58,666 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 08:01:58,676 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 08:01:58,688 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 08:01:58,689 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 08:01:58,701 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 08:01:58,712 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 08:01:58,723 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 08:01:58,735 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 08:01:58,753 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 08:01:58,761 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 08:02:00,284 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 08:02:00,294 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 08:02:00,305 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 08:02:00,316 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 08:02:00,328 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 08:02:00,339 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 08:02:00,350 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 08:02:00,362 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 08:02:00,389 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 08:02:00,421 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 08:02:00,432 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 08:02:00,434 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 08:02:00,457 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 08:02:00,469 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 08:02:00,498 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 08:02:02,679 - INFO - allennlp.common.params - type = from_instances
2022-03-21 08:02:02,687 - INFO - allennlp.common.params - min_count = None
2022-03-21 08:02:02,697 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-21 08:02:02,709 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-21 08:02:02,720 - INFO - allennlp.common.params - pretrained_files = None
2022-03-21 08:02:02,757 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-21 08:02:02,760 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-21 08:02:02,762 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-21 08:02:02,764 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-21 08:02:02,766 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-21 08:02:02,777 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-21 08:02:02,789 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-21 08:02:03,468 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-21 08:02:03,489 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-21 08:02:03,521 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-21 08:02:03,523 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-21 08:02:03,526 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-21 08:02:03,528 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-21 08:02:03,530 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-21 08:02:03,532 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-21 08:02:03,534 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-21 08:02:03,536 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-21 08:02:03,538 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-21 08:02:03,540 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-21 08:02:03,541 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-21 08:02:10,999 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-21 08:02:11,009 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-21 08:02:11,041 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-21 08:02:11,044 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-21 08:02:11,077 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-21 08:02:11,078 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-21 08:02:11,091 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-21 08:02:11,103 - INFO - allennlp.common.params - type = tanh
2022-03-21 08:02:11,115 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-21 08:02:11,129 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-21 08:02:11,161 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-21 08:02:11,207 - INFO - allennlp.common.params - model.num_labels = None
2022-03-21 08:02:11,226 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-21 08:02:11,243 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fdf67060ed0>
2022-03-21 08:02:11,253 - INFO - allennlp.common.params - model.regularizer = None
2022-03-21 08:02:11,264 - INFO - allennlp.common.params - model.track_weights = False
2022-03-21 08:02:11,276 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-21 08:02:11,288 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-21 08:02:11,302 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-21 08:02:11,311 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-21 08:02:11,322 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-21 08:02:11,323 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-21 08:02:11,325 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-21 08:02:11,326 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 08:02:11,339 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 08:02:11,351 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 08:02:11,369 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 08:02:11,373 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 08:02:11,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 08:02:11,428 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 08:02:11,431 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 08:02:11,432 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 08:02:11,433 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 08:02:11,436 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 08:02:11,437 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 08:02:11,438 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 08:02:11,439 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 08:02:11,464 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 08:02:11,465 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 08:02:11,506 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 08:02:11,517 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 08:02:11,529 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 08:02:11,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 08:02:11,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 08:02:11,542 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 08:02:11,569 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 08:02:11,577 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 08:02:11,583 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 08:02:11,595 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 08:02:11,597 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 08:02:11,598 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 08:02:11,599 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 08:02:11,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 08:02:11,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 08:02:11,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 08:02:11,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 08:02:11,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 08:02:11,608 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 08:02:11,609 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 08:02:11,611 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 08:02:11,613 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 08:02:11,615 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 08:02:11,616 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 08:02:11,617 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 08:02:11,619 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 08:02:11,621 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 08:02:11,623 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 08:02:11,625 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 08:02:11,629 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 08:02:11,630 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 08:02:11,633 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 08:02:11,634 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 08:02:11,636 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 08:02:11,637 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 08:02:11,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 08:02:11,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 08:02:11,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 08:02:11,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 08:02:11,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 08:02:11,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 08:02:11,661 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 08:02:11,665 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 08:02:11,669 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 08:02:11,670 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 08:02:11,672 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 08:02:11,673 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 08:02:11,675 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 08:02:11,676 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 08:02:11,677 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 08:02:11,678 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 08:02:11,680 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 08:02:11,681 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 08:02:11,682 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 08:02:11,683 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 08:02:11,684 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 08:02:11,685 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 08:02:11,686 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 08:02:11,688 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 08:02:11,689 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 08:02:11,690 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 08:02:11,691 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 08:02:11,692 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 08:02:11,693 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 08:02:11,695 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 08:02:11,696 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 08:02:11,697 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 08:02:11,698 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 08:02:11,699 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 08:02:11,700 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 08:02:11,701 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 08:02:11,703 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 08:02:11,705 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 08:02:11,706 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 08:02:11,707 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 08:02:11,708 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 08:02:11,709 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 08:02:11,711 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 08:02:11,712 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 08:02:11,713 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 08:02:11,714 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 08:02:11,715 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 08:02:11,717 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 08:02:11,718 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 08:02:11,719 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 08:02:11,720 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 08:02:11,721 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 08:02:11,723 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 08:02:11,724 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 08:02:11,725 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 08:02:11,726 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 08:02:11,727 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 08:02:11,729 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 08:02:11,731 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 08:02:11,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 08:02:11,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 08:02:11,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 08:02:11,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 08:02:11,741 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 08:02:11,742 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 08:02:11,743 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 08:02:11,744 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 08:02:11,745 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 08:02:11,747 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 08:02:11,749 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 08:02:11,751 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 08:02:11,753 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 08:02:11,755 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 08:02:11,756 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 08:02:11,758 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 08:02:11,759 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 08:02:11,760 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 08:02:11,762 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 08:02:11,763 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 08:02:11,765 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 08:02:11,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 08:02:11,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 08:02:11,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 08:02:11,770 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 08:02:11,772 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 08:02:11,775 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 08:02:11,777 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 08:02:11,778 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 08:02:11,783 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 08:02:11,784 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 08:02:11,785 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 08:02:11,786 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 08:02:11,788 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 08:02:11,789 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 08:02:11,790 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 08:02:11,791 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 08:02:11,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 08:02:11,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 08:02:11,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 08:02:11,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 08:02:11,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 08:02:11,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 08:02:11,798 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 08:02:11,799 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 08:02:11,800 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 08:02:11,801 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 08:02:11,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 08:02:11,812 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 08:02:11,813 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 08:02:11,814 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 08:02:11,815 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 08:02:11,817 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 08:02:11,817 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 08:02:11,818 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 08:02:11,819 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 08:02:11,820 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 08:02:11,822 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 08:02:11,823 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 08:02:11,824 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 08:02:11,825 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 08:02:11,826 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 08:02:11,827 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 08:02:11,828 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 08:02:11,829 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 08:02:11,830 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 08:02:11,831 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 08:02:11,832 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 08:02:11,833 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 08:02:11,834 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 08:02:11,835 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 08:02:11,836 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 08:02:11,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 08:02:11,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 08:02:11,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 08:02:11,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 08:02:11,842 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 08:02:11,843 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 08:02:11,844 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 08:02:11,845 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 08:02:11,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 08:02:11,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 08:02:11,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 08:02:11,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 08:02:11,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 08:02:11,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 08:02:11,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 08:02:11,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 08:02:11,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 08:02:19,153 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-21 08:02:19,158 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-21 08:02:19,169 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-21 08:02:19,181 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-21 08:02:19,192 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-21 08:02:19,203 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-21 08:02:19,221 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-21 08:02:19,229 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-21 08:02:19,239 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-21 08:02:19,251 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-21 08:02:19,263 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-21 08:02:19,266 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-21 08:02:19,269 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-21 08:02:19,280 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-21 08:02:19,303 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-21 08:02:19,341 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-21 08:02:19,342 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-21 08:02:29,247 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-21 08:02:29,280 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-21 08:02:29,291 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-21 08:02:29,292 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-21 08:02:29,293 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-21 08:02:29,307 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-21 08:02:29,320 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-21 08:02:29,321 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight'], {'weight_decay': 0}
2022-03-21 08:02:29,323 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight'], {}
2022-03-21 08:02:29,325 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-21 08:02:29,340 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125239300
2022-03-21 08:02:29,348 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-21 08:02:29,361 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-21 08:02:29,372 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 08:02:29,384 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 08:02:29,396 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 08:02:29,407 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 08:02:29,408 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 08:02:29,410 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 08:02:29,411 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 08:02:29,412 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 08:02:29,414 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 08:02:29,415 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 08:02:29,416 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 08:02:29,429 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 08:02:29,434 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 08:02:29,436 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 08:02:29,437 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 08:02:29,438 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 08:02:29,439 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 08:02:29,441 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 08:02:29,442 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 08:02:29,443 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 08:02:29,444 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 08:02:29,445 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 08:02:29,446 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 08:02:29,448 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 08:02:29,449 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 08:02:29,450 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 08:02:29,451 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 08:02:29,453 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 08:02:29,454 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 08:02:29,455 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 08:02:29,456 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 08:02:29,457 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 08:02:29,459 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 08:02:29,460 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 08:02:29,473 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 08:02:29,484 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 08:02:29,495 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 08:02:29,507 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 08:02:29,519 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 08:02:29,520 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 08:02:29,522 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 08:02:29,523 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 08:02:29,554 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 08:02:29,565 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 08:02:29,576 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 08:02:29,588 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 08:02:29,599 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 08:02:29,611 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 08:02:29,622 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 08:02:29,624 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 08:02:29,625 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 08:02:29,626 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 08:02:29,627 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 08:02:29,629 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 08:02:29,630 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 08:02:29,631 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 08:02:29,645 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 08:02:29,660 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 08:02:29,669 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 08:02:29,680 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 08:02:29,692 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 08:02:29,704 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 08:02:29,716 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 08:02:29,728 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 08:02:29,739 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 08:02:29,789 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 08:02:29,810 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 08:02:29,821 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 08:02:29,833 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 08:02:29,835 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 08:02:29,836 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 08:02:29,847 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 08:02:29,859 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 08:02:29,870 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 08:02:29,872 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 08:02:29,873 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 08:02:29,885 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 08:02:29,897 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 08:02:29,908 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 08:02:29,920 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 08:02:29,931 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 08:02:29,945 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 08:02:29,954 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 08:02:29,955 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 08:02:29,956 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 08:02:29,957 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 08:02:29,972 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 08:02:29,984 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 08:02:29,996 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 08:02:30,008 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 08:02:30,032 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 08:02:30,038 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 08:02:30,074 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 08:02:30,086 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 08:02:30,099 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 08:02:30,100 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 08:02:30,102 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 08:02:30,113 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 08:02:30,128 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 08:02:30,137 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 08:02:30,148 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 08:02:30,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 08:02:30,196 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 08:02:30,197 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 08:02:30,198 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 08:02:30,200 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 08:02:30,201 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 08:02:30,202 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 08:02:30,203 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 08:02:30,205 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 08:02:30,206 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 08:02:30,207 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 08:02:30,209 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 08:02:30,210 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 08:02:30,211 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 08:02:30,212 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 08:02:30,214 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 08:02:30,215 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 08:02:30,216 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 08:02:30,217 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 08:02:30,219 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 08:02:30,221 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 08:02:30,222 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 08:02:30,223 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 08:02:30,224 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 08:02:30,225 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 08:02:30,227 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 08:02:30,228 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 08:02:30,229 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 08:02:30,230 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 08:02:30,231 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 08:02:30,232 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 08:02:30,233 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 08:02:30,235 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 08:02:30,236 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 08:02:30,237 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 08:02:30,238 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 08:02:30,239 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 08:02:30,240 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 08:02:30,241 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 08:02:30,242 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 08:02:30,243 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 08:02:30,245 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 08:02:30,246 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 08:02:30,248 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 08:02:30,249 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 08:02:30,251 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 08:02:30,252 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 08:02:30,253 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 08:02:30,255 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 08:02:30,256 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 08:02:30,258 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 08:02:30,259 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 08:02:30,260 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 08:02:30,261 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 08:02:30,262 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 08:02:30,263 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 08:02:30,264 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 08:02:30,266 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 08:02:30,267 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 08:02:30,268 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 08:02:30,269 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 08:02:30,270 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 08:02:30,271 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 08:02:30,272 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 08:02:30,273 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 08:02:30,274 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 08:02:30,275 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 08:02:30,277 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 08:02:30,278 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 08:02:30,279 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 08:02:30,281 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 08:02:30,293 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 08:02:30,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 08:02:30,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 08:02:30,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 08:02:30,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 08:02:30,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 08:02:30,393 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 08:02:30,405 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 08:02:30,406 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 08:02:30,409 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 08:02:30,428 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 08:02:30,432 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 08:02:30,433 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 08:02:30,434 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 08:02:30,435 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 08:02:30,437 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 08:02:30,449 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 08:02:30,461 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 08:02:30,473 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 08:02:30,484 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 08:02:30,521 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 08:02:30,531 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 08:02:30,537 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 08:02:30,562 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 08:02:30,575 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 08:02:30,591 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 08:02:30,592 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 08:02:30,607 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-21 08:02:30,615 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-21 08:02:30,626 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-21 08:02:30,637 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-21 08:02:30,649 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-21 08:02:30,661 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-21 08:02:30,662 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-21 08:02:30,663 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-21 08:02:30,710 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-21 08:02:30,721 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-21 08:02:30,781 - INFO - allennlp.training.trainer - Beginning training.
2022-03-21 08:02:30,806 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-21 08:02:30,817 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.2G
2022-03-21 08:02:30,856 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 08:02:30,868 - INFO - allennlp.training.trainer - Training
2022-03-21 08:02:30,879 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 08:02:30,981 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 08:02:30,992 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 08:02:41,028 - INFO - tqdm - f1: 0.4180, accuracy: 0.4464, batch_loss: 0.8788, loss: 1.2486 ||:   0%|          | 28/7188 [00:10<33:23,  3.57it/s]
2022-03-21 08:02:51,275 - INFO - tqdm - f1: 0.7012, accuracy: 0.6976, batch_loss: 0.4915, loss: 0.7762 ||:   1%|          | 68/7188 [00:20<33:46,  3.51it/s]
2022-03-21 08:03:01,403 - INFO - tqdm - f1: 0.7611, accuracy: 0.7595, batch_loss: 0.7122, loss: 0.6271 ||:   1%|1         | 105/7188 [00:30<30:19,  3.89it/s]
2022-03-21 08:03:11,585 - INFO - tqdm - f1: 0.7906, accuracy: 0.7895, batch_loss: 0.0932, loss: 0.5586 ||:   2%|2         | 144/7188 [00:40<33:02,  3.55it/s]
2022-03-21 08:03:21,634 - INFO - tqdm - f1: 0.8156, accuracy: 0.8149, batch_loss: 0.6374, loss: 0.4987 ||:   3%|2         | 184/7188 [00:50<27:56,  4.18it/s]
2022-03-21 08:03:31,641 - INFO - tqdm - f1: 0.8262, accuracy: 0.8260, batch_loss: 0.3560, loss: 0.4764 ||:   3%|3         | 223/7188 [01:00<28:47,  4.03it/s]
2022-03-21 08:03:41,742 - INFO - tqdm - f1: 0.8338, accuracy: 0.8340, batch_loss: 0.0953, loss: 0.4600 ||:   4%|3         | 264/7188 [01:10<31:26,  3.67it/s]
2022-03-21 08:03:51,853 - INFO - tqdm - f1: 0.8405, accuracy: 0.8408, batch_loss: 0.9783, loss: 0.4457 ||:   4%|4         | 303/7188 [01:20<28:57,  3.96it/s]
2022-03-21 08:04:01,940 - INFO - tqdm - f1: 0.8475, accuracy: 0.8481, batch_loss: 0.4770, loss: 0.4283 ||:   5%|4         | 346/7188 [01:31<27:17,  4.18it/s]
2022-03-21 08:04:12,097 - INFO - tqdm - f1: 0.8506, accuracy: 0.8514, batch_loss: 0.2828, loss: 0.4186 ||:   5%|5         | 389/7188 [01:41<25:57,  4.37it/s]
2022-03-21 08:04:22,153 - INFO - tqdm - f1: 0.8552, accuracy: 0.8559, batch_loss: 0.3424, loss: 0.4089 ||:   6%|6         | 433/7188 [01:51<26:21,  4.27it/s]
2022-03-21 08:04:32,170 - INFO - tqdm - f1: 0.8602, accuracy: 0.8609, batch_loss: 0.0311, loss: 0.3964 ||:   7%|6         | 478/7188 [02:01<23:19,  4.79it/s]
2022-03-21 08:04:42,394 - INFO - tqdm - f1: 0.8631, accuracy: 0.8638, batch_loss: 0.5514, loss: 0.3900 ||:   7%|7         | 526/7188 [02:11<24:02,  4.62it/s]
2022-03-21 08:04:52,467 - INFO - tqdm - f1: 0.8659, accuracy: 0.8665, batch_loss: 0.2977, loss: 0.3841 ||:   8%|7         | 575/7188 [02:21<23:26,  4.70it/s]
2022-03-21 08:05:02,566 - INFO - tqdm - f1: 0.8698, accuracy: 0.8706, batch_loss: 0.2000, loss: 0.3748 ||:   9%|8         | 625/7188 [02:31<23:54,  4.57it/s]
2022-03-21 08:05:12,721 - INFO - tqdm - f1: 0.8726, accuracy: 0.8732, batch_loss: 0.2489, loss: 0.3692 ||:   9%|9         | 672/7188 [02:41<23:33,  4.61it/s]
2022-03-21 08:05:22,854 - INFO - tqdm - f1: 0.8749, accuracy: 0.8755, batch_loss: 0.8051, loss: 0.3642 ||:  10%|#         | 720/7188 [02:51<23:25,  4.60it/s]
2022-03-21 08:05:32,946 - INFO - tqdm - f1: 0.8753, accuracy: 0.8759, batch_loss: 0.2491, loss: 0.3615 ||:  11%|#         | 768/7188 [03:02<23:38,  4.53it/s]
2022-03-21 08:05:43,167 - INFO - tqdm - f1: 0.8758, accuracy: 0.8763, batch_loss: 0.4071, loss: 0.3601 ||:  11%|#1        | 816/7188 [03:12<21:42,  4.89it/s]
2022-03-21 08:05:53,322 - INFO - tqdm - f1: 0.8775, accuracy: 0.8780, batch_loss: 0.1533, loss: 0.3548 ||:  12%|#1        | 862/7188 [03:22<24:55,  4.23it/s]
2022-03-21 08:06:03,350 - INFO - tqdm - f1: 0.8785, accuracy: 0.8790, batch_loss: 0.2925, loss: 0.3515 ||:  13%|#2        | 911/7188 [03:32<19:51,  5.27it/s]
2022-03-21 08:06:13,537 - INFO - tqdm - f1: 0.8804, accuracy: 0.8807, batch_loss: 0.0588, loss: 0.3464 ||:  13%|#3        | 960/7188 [03:42<22:33,  4.60it/s]
2022-03-21 08:06:23,762 - INFO - tqdm - f1: 0.8818, accuracy: 0.8820, batch_loss: 0.4215, loss: 0.3428 ||:  14%|#4        | 1010/7188 [03:52<22:17,  4.62it/s]
2022-03-21 08:06:33,767 - INFO - tqdm - f1: 0.8828, accuracy: 0.8830, batch_loss: 0.3141, loss: 0.3402 ||:  15%|#4        | 1060/7188 [04:02<20:24,  5.00it/s]
2022-03-21 08:06:43,812 - INFO - tqdm - f1: 0.8828, accuracy: 0.8831, batch_loss: 0.1365, loss: 0.3392 ||:  15%|#5        | 1109/7188 [04:12<21:14,  4.77it/s]
2022-03-21 08:06:53,821 - INFO - tqdm - f1: 0.8836, accuracy: 0.8837, batch_loss: 0.0305, loss: 0.3364 ||:  16%|#6        | 1157/7188 [04:22<20:38,  4.87it/s]
2022-03-21 08:07:04,013 - INFO - tqdm - f1: 0.8846, accuracy: 0.8847, batch_loss: 0.2645, loss: 0.3331 ||:  17%|#6        | 1206/7188 [04:33<21:56,  4.54it/s]
2022-03-21 08:07:14,157 - INFO - tqdm - f1: 0.8856, accuracy: 0.8858, batch_loss: 0.2110, loss: 0.3303 ||:  17%|#7        | 1255/7188 [04:43<21:07,  4.68it/s]
2022-03-21 08:07:24,174 - INFO - tqdm - f1: 0.8867, accuracy: 0.8868, batch_loss: 0.0702, loss: 0.3272 ||:  18%|#8        | 1303/7188 [04:53<17:50,  5.50it/s]
2022-03-21 08:07:34,382 - INFO - tqdm - f1: 0.8878, accuracy: 0.8879, batch_loss: 0.3074, loss: 0.3247 ||:  19%|#8        | 1351/7188 [05:03<22:20,  4.35it/s]
2022-03-21 08:07:44,391 - INFO - tqdm - f1: 0.8882, accuracy: 0.8883, batch_loss: 0.3574, loss: 0.3233 ||:  19%|#9        | 1399/7188 [05:13<21:55,  4.40it/s]
2022-03-21 08:07:54,400 - INFO - tqdm - f1: 0.8893, accuracy: 0.8893, batch_loss: 0.0986, loss: 0.3215 ||:  20%|##        | 1447/7188 [05:23<19:01,  5.03it/s]
2022-03-21 08:08:04,425 - INFO - tqdm - f1: 0.8898, accuracy: 0.8899, batch_loss: 0.1076, loss: 0.3196 ||:  21%|##        | 1495/7188 [05:33<22:57,  4.13it/s]
2022-03-21 08:08:14,591 - INFO - tqdm - f1: 0.8901, accuracy: 0.8902, batch_loss: 0.1850, loss: 0.3184 ||:  21%|##1       | 1544/7188 [05:43<21:00,  4.48it/s]
2022-03-21 08:08:24,598 - INFO - tqdm - f1: 0.8908, accuracy: 0.8909, batch_loss: 0.4018, loss: 0.3155 ||:  22%|##2       | 1592/7188 [05:53<18:55,  4.93it/s]
2022-03-21 08:08:34,619 - INFO - tqdm - f1: 0.8911, accuracy: 0.8912, batch_loss: 0.4188, loss: 0.3145 ||:  23%|##2       | 1640/7188 [06:03<19:05,  4.84it/s]
2022-03-21 08:08:44,656 - INFO - tqdm - f1: 0.8913, accuracy: 0.8914, batch_loss: 0.3506, loss: 0.3135 ||:  23%|##3       | 1688/7188 [06:13<18:49,  4.87it/s]
2022-03-21 08:08:54,663 - INFO - tqdm - f1: 0.8917, accuracy: 0.8918, batch_loss: 0.0534, loss: 0.3124 ||:  24%|##4       | 1737/7188 [06:23<18:32,  4.90it/s]
2022-03-21 08:09:04,679 - INFO - tqdm - f1: 0.8924, accuracy: 0.8925, batch_loss: 0.1984, loss: 0.3104 ||:  25%|##4       | 1784/7188 [06:33<20:28,  4.40it/s]
2022-03-21 08:09:14,807 - INFO - tqdm - f1: 0.8928, accuracy: 0.8930, batch_loss: 0.1618, loss: 0.3090 ||:  25%|##5       | 1831/7188 [06:43<17:30,  5.10it/s]
2022-03-21 08:09:24,831 - INFO - tqdm - f1: 0.8933, accuracy: 0.8935, batch_loss: 0.1778, loss: 0.3067 ||:  26%|##6       | 1879/7188 [06:53<17:12,  5.14it/s]
2022-03-21 08:09:35,010 - INFO - tqdm - f1: 0.8939, accuracy: 0.8941, batch_loss: 0.1863, loss: 0.3051 ||:  27%|##6       | 1926/7188 [07:04<20:04,  4.37it/s]
2022-03-21 08:09:45,195 - INFO - tqdm - f1: 0.8939, accuracy: 0.8940, batch_loss: 0.5057, loss: 0.3048 ||:  27%|##7       | 1975/7188 [07:14<19:24,  4.48it/s]
2022-03-21 08:09:55,214 - INFO - tqdm - f1: 0.8946, accuracy: 0.8946, batch_loss: 0.1280, loss: 0.3028 ||:  28%|##8       | 2021/7188 [07:24<20:20,  4.23it/s]
2022-03-21 08:10:05,349 - INFO - tqdm - f1: 0.8954, accuracy: 0.8954, batch_loss: 0.0475, loss: 0.3011 ||:  29%|##8       | 2069/7188 [07:34<18:38,  4.58it/s]
2022-03-21 08:10:15,589 - INFO - tqdm - f1: 0.8959, accuracy: 0.8959, batch_loss: 0.6819, loss: 0.2999 ||:  29%|##9       | 2116/7188 [07:44<17:42,  4.77it/s]
2022-03-21 08:10:25,793 - INFO - tqdm - f1: 0.8966, accuracy: 0.8966, batch_loss: 0.1025, loss: 0.2982 ||:  30%|###       | 2164/7188 [07:54<17:20,  4.83it/s]
2022-03-21 08:10:35,836 - INFO - tqdm - f1: 0.8975, accuracy: 0.8974, batch_loss: 0.0971, loss: 0.2958 ||:  31%|###       | 2213/7188 [08:04<18:37,  4.45it/s]
2022-03-21 08:10:45,876 - INFO - tqdm - f1: 0.8980, accuracy: 0.8980, batch_loss: 0.1333, loss: 0.2941 ||:  31%|###1      | 2262/7188 [08:14<18:09,  4.52it/s]
2022-03-21 08:10:55,958 - INFO - tqdm - f1: 0.8982, accuracy: 0.8982, batch_loss: 0.4408, loss: 0.2933 ||:  32%|###2      | 2310/7188 [08:25<17:01,  4.78it/s]
2022-03-21 08:11:05,977 - INFO - tqdm - f1: 0.8981, accuracy: 0.8981, batch_loss: 0.0346, loss: 0.2932 ||:  33%|###2      | 2358/7188 [08:35<16:39,  4.83it/s]
2022-03-21 08:11:16,018 - INFO - tqdm - f1: 0.8986, accuracy: 0.8986, batch_loss: 0.3388, loss: 0.2922 ||:  33%|###3      | 2406/7188 [08:45<18:03,  4.41it/s]
2022-03-21 08:11:26,031 - INFO - tqdm - f1: 0.8991, accuracy: 0.8991, batch_loss: 0.2275, loss: 0.2908 ||:  34%|###4      | 2453/7188 [08:55<18:54,  4.17it/s]
2022-03-21 08:11:36,033 - INFO - tqdm - f1: 0.8997, accuracy: 0.8996, batch_loss: 0.0622, loss: 0.2899 ||:  35%|###4      | 2502/7188 [09:05<18:01,  4.33it/s]
2022-03-21 08:11:46,115 - INFO - tqdm - f1: 0.9001, accuracy: 0.9000, batch_loss: 0.3841, loss: 0.2888 ||:  35%|###5      | 2550/7188 [09:15<15:24,  5.01it/s]
2022-03-21 08:11:56,235 - INFO - tqdm - f1: 0.9003, accuracy: 0.9002, batch_loss: 0.1482, loss: 0.2883 ||:  36%|###6      | 2599/7188 [09:25<13:52,  5.51it/s]
2022-03-21 08:12:06,281 - INFO - tqdm - f1: 0.9004, accuracy: 0.9002, batch_loss: 0.9725, loss: 0.2875 ||:  37%|###6      | 2647/7188 [09:35<14:08,  5.35it/s]
2022-03-21 08:12:16,283 - INFO - tqdm - f1: 0.9010, accuracy: 0.9009, batch_loss: 0.2471, loss: 0.2858 ||:  38%|###8      | 2765/7188 [09:45<08:28,  8.70it/s]
2022-03-21 08:12:26,495 - INFO - tqdm - f1: 0.9017, accuracy: 0.9016, batch_loss: 0.1575, loss: 0.2840 ||:  40%|###9      | 2846/7188 [09:55<08:03,  8.98it/s]
2022-03-21 08:12:36,556 - INFO - tqdm - f1: 0.9019, accuracy: 0.9018, batch_loss: 0.3182, loss: 0.2827 ||:  41%|####      | 2927/7188 [10:05<08:28,  8.38it/s]
2022-03-21 08:12:46,788 - INFO - tqdm - f1: 0.9022, accuracy: 0.9022, batch_loss: 0.1396, loss: 0.2814 ||:  42%|####1     | 2999/7188 [10:15<14:00,  4.98it/s]
2022-03-21 08:12:56,881 - INFO - tqdm - f1: 0.9026, accuracy: 0.9026, batch_loss: 0.1612, loss: 0.2803 ||:  42%|####2     | 3047/7188 [10:26<15:06,  4.57it/s]
2022-03-21 08:13:06,985 - INFO - tqdm - f1: 0.9029, accuracy: 0.9030, batch_loss: 0.0079, loss: 0.2794 ||:  43%|####3     | 3094/7188 [10:36<13:56,  4.89it/s]
2022-03-21 08:13:17,001 - INFO - tqdm - f1: 0.9033, accuracy: 0.9033, batch_loss: 0.3652, loss: 0.2785 ||:  44%|####3     | 3142/7188 [10:46<13:58,  4.82it/s]
2022-03-21 08:13:27,155 - INFO - tqdm - f1: 0.9035, accuracy: 0.9035, batch_loss: 0.1615, loss: 0.2776 ||:  44%|####4     | 3190/7188 [10:56<15:00,  4.44it/s]
2022-03-21 08:13:37,291 - INFO - tqdm - f1: 0.9035, accuracy: 0.9036, batch_loss: 0.2635, loss: 0.2775 ||:  45%|####5     | 3238/7188 [11:06<14:17,  4.60it/s]
2022-03-21 08:13:47,420 - INFO - tqdm - f1: 0.9040, accuracy: 0.9040, batch_loss: 0.4245, loss: 0.2766 ||:  46%|####5     | 3286/7188 [11:16<15:15,  4.26it/s]
2022-03-21 08:13:57,561 - INFO - tqdm - f1: 0.9044, accuracy: 0.9044, batch_loss: 0.1083, loss: 0.2754 ||:  46%|####6     | 3335/7188 [11:26<14:23,  4.46it/s]
2022-03-21 08:14:07,603 - INFO - tqdm - f1: 0.9046, accuracy: 0.9047, batch_loss: 0.3423, loss: 0.2745 ||:  47%|####7     | 3383/7188 [11:36<15:15,  4.16it/s]
2022-03-21 08:14:17,691 - INFO - tqdm - f1: 0.9052, accuracy: 0.9053, batch_loss: 0.2422, loss: 0.2733 ||:  48%|####7     | 3432/7188 [11:46<12:44,  4.91it/s]
2022-03-21 08:14:27,716 - INFO - tqdm - f1: 0.9056, accuracy: 0.9057, batch_loss: 0.1677, loss: 0.2721 ||:  48%|####8     | 3480/7188 [11:56<13:40,  4.52it/s]
2022-03-21 08:14:37,750 - INFO - tqdm - f1: 0.9059, accuracy: 0.9059, batch_loss: 0.4981, loss: 0.2717 ||:  49%|####9     | 3527/7188 [12:06<12:33,  4.86it/s]
2022-03-21 08:14:47,820 - INFO - tqdm - f1: 0.9060, accuracy: 0.9061, batch_loss: 0.0177, loss: 0.2710 ||:  50%|####9     | 3577/7188 [12:16<12:13,  4.93it/s]
2022-03-21 08:14:57,941 - INFO - tqdm - f1: 0.9062, accuracy: 0.9063, batch_loss: 0.3921, loss: 0.2705 ||:  50%|#####     | 3624/7188 [12:27<13:46,  4.31it/s]
2022-03-21 08:15:07,944 - INFO - tqdm - f1: 0.9064, accuracy: 0.9065, batch_loss: 0.3985, loss: 0.2698 ||:  51%|#####1    | 3672/7188 [12:37<11:24,  5.14it/s]
2022-03-21 08:15:17,998 - INFO - tqdm - f1: 0.9065, accuracy: 0.9065, batch_loss: 0.0729, loss: 0.2694 ||:  52%|#####1    | 3721/7188 [12:47<11:07,  5.19it/s]
2022-03-21 08:15:28,149 - INFO - tqdm - f1: 0.9066, accuracy: 0.9067, batch_loss: 0.1858, loss: 0.2693 ||:  52%|#####2    | 3768/7188 [12:57<13:02,  4.37it/s]
2022-03-21 08:15:38,363 - INFO - tqdm - f1: 0.9069, accuracy: 0.9070, batch_loss: 0.0424, loss: 0.2685 ||:  53%|#####3    | 3817/7188 [13:07<12:37,  4.45it/s]
2022-03-21 08:15:48,376 - INFO - tqdm - f1: 0.9071, accuracy: 0.9071, batch_loss: 0.1209, loss: 0.2681 ||:  54%|#####3    | 3864/7188 [13:17<11:24,  4.85it/s]
2022-03-21 08:15:58,497 - INFO - tqdm - f1: 0.9071, accuracy: 0.9071, batch_loss: 0.1193, loss: 0.2679 ||:  54%|#####4    | 3912/7188 [13:27<10:00,  5.46it/s]
2022-03-21 08:16:08,663 - INFO - tqdm - f1: 0.9075, accuracy: 0.9075, batch_loss: 0.0590, loss: 0.2671 ||:  55%|#####5    | 3959/7188 [13:37<11:22,  4.73it/s]
2022-03-21 08:16:18,713 - INFO - tqdm - f1: 0.9077, accuracy: 0.9077, batch_loss: 0.1377, loss: 0.2661 ||:  56%|#####5    | 4007/7188 [13:47<12:28,  4.25it/s]
2022-03-21 08:16:28,855 - INFO - tqdm - f1: 0.9079, accuracy: 0.9079, batch_loss: 0.0887, loss: 0.2658 ||:  56%|#####6    | 4053/7188 [13:57<12:29,  4.18it/s]
2022-03-21 08:16:39,031 - INFO - tqdm - f1: 0.9079, accuracy: 0.9079, batch_loss: 0.1608, loss: 0.2660 ||:  57%|#####7    | 4102/7188 [14:08<11:23,  4.52it/s]
2022-03-21 08:16:49,078 - INFO - tqdm - f1: 0.9080, accuracy: 0.9080, batch_loss: 0.3504, loss: 0.2655 ||:  58%|#####7    | 4149/7188 [14:18<09:46,  5.18it/s]
2022-03-21 08:16:59,280 - INFO - tqdm - f1: 0.9082, accuracy: 0.9082, batch_loss: 0.1332, loss: 0.2646 ||:  58%|#####8    | 4197/7188 [14:28<10:58,  4.54it/s]
2022-03-21 08:17:09,459 - INFO - tqdm - f1: 0.9082, accuracy: 0.9082, batch_loss: 0.4347, loss: 0.2646 ||:  59%|#####9    | 4246/7188 [14:38<10:19,  4.75it/s]
2022-03-21 08:17:19,478 - INFO - tqdm - f1: 0.9084, accuracy: 0.9084, batch_loss: 0.0909, loss: 0.2637 ||:  60%|#####9    | 4294/7188 [14:48<11:30,  4.19it/s]
2022-03-21 08:17:29,487 - INFO - tqdm - f1: 0.9085, accuracy: 0.9085, batch_loss: 0.2931, loss: 0.2637 ||:  60%|######    | 4341/7188 [14:58<10:49,  4.39it/s]
2022-03-21 08:17:39,582 - INFO - tqdm - f1: 0.9089, accuracy: 0.9090, batch_loss: 0.0822, loss: 0.2627 ||:  61%|######1   | 4388/7188 [15:08<09:15,  5.04it/s]
2022-03-21 08:17:49,822 - INFO - tqdm - f1: 0.9092, accuracy: 0.9092, batch_loss: 0.2628, loss: 0.2622 ||:  62%|######1   | 4436/7188 [15:18<10:57,  4.18it/s]
2022-03-21 08:17:59,952 - INFO - tqdm - f1: 0.9094, accuracy: 0.9095, batch_loss: 0.2872, loss: 0.2615 ||:  62%|######2   | 4483/7188 [15:29<09:48,  4.60it/s]
2022-03-21 08:18:10,084 - INFO - tqdm - f1: 0.9097, accuracy: 0.9097, batch_loss: 0.0901, loss: 0.2610 ||:  63%|######3   | 4532/7188 [15:39<08:11,  5.40it/s]
2022-03-21 08:18:20,320 - INFO - tqdm - f1: 0.9098, accuracy: 0.9098, batch_loss: 0.2018, loss: 0.2605 ||:  64%|######3   | 4579/7188 [15:49<09:44,  4.46it/s]
2022-03-21 08:18:30,375 - INFO - tqdm - f1: 0.9099, accuracy: 0.9100, batch_loss: 0.1246, loss: 0.2599 ||:  64%|######4   | 4627/7188 [15:59<09:02,  4.72it/s]
2022-03-21 08:18:40,537 - INFO - tqdm - f1: 0.9100, accuracy: 0.9100, batch_loss: 0.1235, loss: 0.2598 ||:  65%|######5   | 4675/7188 [16:09<08:32,  4.90it/s]
2022-03-21 08:18:50,656 - INFO - tqdm - f1: 0.9099, accuracy: 0.9099, batch_loss: 0.4603, loss: 0.2596 ||:  66%|######5   | 4722/7188 [16:19<07:29,  5.48it/s]
2022-03-21 08:19:00,899 - INFO - tqdm - f1: 0.9100, accuracy: 0.9100, batch_loss: 0.0806, loss: 0.2592 ||:  66%|######6   | 4771/7188 [16:30<08:13,  4.89it/s]
2022-03-21 08:19:10,914 - INFO - tqdm - f1: 0.9100, accuracy: 0.9100, batch_loss: 0.0910, loss: 0.2590 ||:  67%|######7   | 4819/7188 [16:40<07:54,  4.99it/s]
2022-03-21 08:19:20,957 - INFO - tqdm - f1: 0.9104, accuracy: 0.9104, batch_loss: 0.0715, loss: 0.2583 ||:  68%|######7   | 4866/7188 [16:50<09:22,  4.13it/s]
2022-03-21 08:19:30,966 - INFO - tqdm - f1: 0.9105, accuracy: 0.9105, batch_loss: 0.0291, loss: 0.2578 ||:  68%|######8   | 4912/7188 [17:00<08:32,  4.44it/s]
2022-03-21 08:19:40,980 - INFO - tqdm - f1: 0.9105, accuracy: 0.9106, batch_loss: 0.1569, loss: 0.2574 ||:  69%|######9   | 4960/7188 [17:10<08:26,  4.40it/s]
2022-03-21 08:19:51,083 - INFO - tqdm - f1: 0.9107, accuracy: 0.9108, batch_loss: 0.0188, loss: 0.2569 ||:  70%|######9   | 5007/7188 [17:20<08:33,  4.25it/s]
2022-03-21 08:20:01,193 - INFO - tqdm - f1: 0.9109, accuracy: 0.9110, batch_loss: 0.2809, loss: 0.2563 ||:  70%|#######   | 5054/7188 [17:30<07:43,  4.61it/s]
2022-03-21 08:20:11,285 - INFO - tqdm - f1: 0.9112, accuracy: 0.9113, batch_loss: 0.0546, loss: 0.2559 ||:  71%|#######1  | 5105/7188 [17:40<06:16,  5.53it/s]
2022-03-21 08:20:21,532 - INFO - tqdm - f1: 0.9112, accuracy: 0.9112, batch_loss: 0.4906, loss: 0.2559 ||:  72%|#######1  | 5154/7188 [17:50<06:57,  4.87it/s]
2022-03-21 08:20:31,550 - INFO - tqdm - f1: 0.9113, accuracy: 0.9113, batch_loss: 0.2438, loss: 0.2556 ||:  72%|#######2  | 5203/7188 [18:00<06:35,  5.01it/s]
2022-03-21 08:20:41,707 - INFO - tqdm - f1: 0.9113, accuracy: 0.9114, batch_loss: 0.0664, loss: 0.2553 ||:  73%|#######3  | 5250/7188 [18:10<07:39,  4.21it/s]
2022-03-21 08:20:51,869 - INFO - tqdm - f1: 0.9114, accuracy: 0.9115, batch_loss: 0.2575, loss: 0.2549 ||:  74%|#######3  | 5298/7188 [18:20<06:31,  4.83it/s]
2022-03-21 08:21:01,904 - INFO - tqdm - f1: 0.9116, accuracy: 0.9116, batch_loss: 0.2738, loss: 0.2546 ||:  74%|#######4  | 5347/7188 [18:31<05:41,  5.39it/s]
2022-03-21 08:21:11,963 - INFO - tqdm - f1: 0.9118, accuracy: 0.9118, batch_loss: 0.0178, loss: 0.2538 ||:  75%|#######5  | 5395/7188 [18:41<05:44,  5.20it/s]
2022-03-21 08:21:22,033 - INFO - tqdm - f1: 0.9119, accuracy: 0.9120, batch_loss: 0.0724, loss: 0.2533 ||:  76%|#######5  | 5443/7188 [18:51<06:02,  4.81it/s]
2022-03-21 08:21:32,155 - INFO - tqdm - f1: 0.9120, accuracy: 0.9121, batch_loss: 0.0233, loss: 0.2529 ||:  76%|#######6  | 5490/7188 [19:01<06:11,  4.56it/s]
2022-03-21 08:21:42,218 - INFO - tqdm - f1: 0.9120, accuracy: 0.9121, batch_loss: 0.2412, loss: 0.2525 ||:  77%|#######7  | 5538/7188 [19:11<05:52,  4.68it/s]
2022-03-21 08:21:52,253 - INFO - tqdm - f1: 0.9122, accuracy: 0.9123, batch_loss: 0.1020, loss: 0.2523 ||:  78%|#######7  | 5586/7188 [19:21<05:45,  4.63it/s]
2022-03-21 08:22:02,269 - INFO - tqdm - f1: 0.9124, accuracy: 0.9124, batch_loss: 0.1181, loss: 0.2518 ||:  78%|#######8  | 5635/7188 [19:31<05:25,  4.78it/s]
2022-03-21 08:22:12,437 - INFO - tqdm - f1: 0.9126, accuracy: 0.9127, batch_loss: 0.0720, loss: 0.2514 ||:  79%|#######9  | 5683/7188 [19:41<05:12,  4.82it/s]
2022-03-21 08:22:22,448 - INFO - tqdm - f1: 0.9128, accuracy: 0.9128, batch_loss: 0.4687, loss: 0.2510 ||:  80%|#######9  | 5731/7188 [19:51<05:02,  4.82it/s]
2022-03-21 08:22:32,500 - INFO - tqdm - f1: 0.9129, accuracy: 0.9129, batch_loss: 0.0448, loss: 0.2507 ||:  80%|########  | 5780/7188 [20:01<04:51,  4.83it/s]
2022-03-21 08:22:42,600 - INFO - tqdm - f1: 0.9130, accuracy: 0.9131, batch_loss: 0.8448, loss: 0.2505 ||:  81%|########1 | 5828/7188 [20:11<04:51,  4.67it/s]
2022-03-21 08:22:52,667 - INFO - tqdm - f1: 0.9130, accuracy: 0.9131, batch_loss: 0.0526, loss: 0.2503 ||:  82%|########1 | 5877/7188 [20:21<04:17,  5.10it/s]
2022-03-21 08:23:02,918 - INFO - tqdm - f1: 0.9130, accuracy: 0.9131, batch_loss: 0.2552, loss: 0.2501 ||:  82%|########2 | 5925/7188 [20:32<04:54,  4.29it/s]
2022-03-21 08:23:13,066 - INFO - tqdm - f1: 0.9131, accuracy: 0.9132, batch_loss: 0.1495, loss: 0.2498 ||:  83%|########3 | 5972/7188 [20:42<04:45,  4.26it/s]
2022-03-21 08:23:23,080 - INFO - tqdm - f1: 0.9131, accuracy: 0.9132, batch_loss: 0.3983, loss: 0.2498 ||:  84%|########3 | 6020/7188 [20:52<03:58,  4.89it/s]
2022-03-21 08:23:33,134 - INFO - tqdm - f1: 0.9132, accuracy: 0.9133, batch_loss: 0.1632, loss: 0.2494 ||:  84%|########4 | 6069/7188 [21:02<04:21,  4.28it/s]
2022-03-21 08:23:43,263 - INFO - tqdm - f1: 0.9133, accuracy: 0.9134, batch_loss: 0.6521, loss: 0.2490 ||:  85%|########5 | 6117/7188 [21:12<03:28,  5.15it/s]
2022-03-21 08:23:53,274 - INFO - tqdm - f1: 0.9134, accuracy: 0.9135, batch_loss: 0.1502, loss: 0.2489 ||:  86%|########5 | 6165/7188 [21:22<03:22,  5.04it/s]
2022-03-21 08:24:03,511 - INFO - tqdm - f1: 0.9135, accuracy: 0.9136, batch_loss: 0.0327, loss: 0.2487 ||:  86%|########6 | 6214/7188 [21:32<03:45,  4.33it/s]
2022-03-21 08:24:13,677 - INFO - tqdm - f1: 0.9136, accuracy: 0.9137, batch_loss: 0.2045, loss: 0.2482 ||:  87%|########7 | 6262/7188 [21:42<03:44,  4.12it/s]
2022-03-21 08:24:23,695 - INFO - tqdm - f1: 0.9137, accuracy: 0.9137, batch_loss: 0.4791, loss: 0.2481 ||:  88%|########7 | 6310/7188 [21:52<02:56,  4.96it/s]
2022-03-21 08:24:33,799 - INFO - tqdm - f1: 0.9138, accuracy: 0.9139, batch_loss: 0.1505, loss: 0.2476 ||:  88%|########8 | 6357/7188 [22:02<02:36,  5.30it/s]
2022-03-21 08:24:43,980 - INFO - tqdm - f1: 0.9139, accuracy: 0.9139, batch_loss: 0.0639, loss: 0.2474 ||:  89%|########9 | 6404/7188 [22:13<02:54,  4.49it/s]
2022-03-21 08:24:54,096 - INFO - tqdm - f1: 0.9141, accuracy: 0.9141, batch_loss: 0.0196, loss: 0.2470 ||:  90%|########9 | 6451/7188 [22:23<02:50,  4.32it/s]
2022-03-21 08:25:04,286 - INFO - tqdm - f1: 0.9141, accuracy: 0.9142, batch_loss: 0.1803, loss: 0.2469 ||:  90%|######### | 6501/7188 [22:33<02:26,  4.68it/s]
2022-03-21 08:25:14,516 - INFO - tqdm - f1: 0.9143, accuracy: 0.9143, batch_loss: 0.4620, loss: 0.2467 ||:  91%|#########1| 6549/7188 [22:43<02:23,  4.45it/s]
2022-03-21 08:25:24,691 - INFO - tqdm - f1: 0.9143, accuracy: 0.9143, batch_loss: 0.1261, loss: 0.2466 ||:  92%|#########1| 6596/7188 [22:53<02:12,  4.46it/s]
2022-03-21 08:25:34,745 - INFO - tqdm - f1: 0.9144, accuracy: 0.9144, batch_loss: 0.0926, loss: 0.2461 ||:  92%|#########2| 6644/7188 [23:03<01:52,  4.85it/s]
2022-03-21 08:25:44,879 - INFO - tqdm - f1: 0.9143, accuracy: 0.9143, batch_loss: 0.1095, loss: 0.2462 ||:  93%|#########3| 6691/7188 [23:13<01:40,  4.94it/s]
2022-03-21 08:25:54,945 - INFO - tqdm - f1: 0.9144, accuracy: 0.9144, batch_loss: 0.0306, loss: 0.2458 ||:  94%|#########3| 6738/7188 [23:24<01:37,  4.59it/s]
2022-03-21 08:26:05,186 - INFO - tqdm - f1: 0.9144, accuracy: 0.9145, batch_loss: 0.1030, loss: 0.2456 ||:  94%|#########4| 6786/7188 [23:34<01:34,  4.24it/s]
2022-03-21 08:26:15,262 - INFO - tqdm - f1: 0.9144, accuracy: 0.9144, batch_loss: 0.1582, loss: 0.2456 ||:  95%|#########5| 6835/7188 [23:44<01:14,  4.71it/s]
2022-03-21 08:26:25,399 - INFO - tqdm - f1: 0.9146, accuracy: 0.9146, batch_loss: 0.1637, loss: 0.2451 ||:  96%|#########5| 6883/7188 [23:54<00:57,  5.33it/s]
2022-03-21 08:26:35,410 - INFO - tqdm - f1: 0.9145, accuracy: 0.9145, batch_loss: 0.1493, loss: 0.2453 ||:  96%|#########6| 6932/7188 [24:04<00:54,  4.72it/s]
2022-03-21 08:26:45,443 - INFO - tqdm - f1: 0.9146, accuracy: 0.9146, batch_loss: 0.0177, loss: 0.2448 ||:  97%|#########7| 6979/7188 [24:14<00:46,  4.50it/s]
2022-03-21 08:26:55,529 - INFO - tqdm - f1: 0.9147, accuracy: 0.9147, batch_loss: 0.0911, loss: 0.2445 ||:  98%|#########7| 7028/7188 [24:24<00:29,  5.42it/s]
2022-03-21 08:27:05,591 - INFO - tqdm - f1: 0.9148, accuracy: 0.9148, batch_loss: 0.2219, loss: 0.2444 ||:  98%|#########8| 7077/7188 [24:34<00:20,  5.32it/s]
2022-03-21 08:27:15,607 - INFO - tqdm - f1: 0.9149, accuracy: 0.9149, batch_loss: 0.1175, loss: 0.2439 ||:  99%|#########9| 7126/7188 [24:44<00:11,  5.42it/s]
2022-03-21 08:27:21,506 - INFO - tqdm - f1: 0.9149, accuracy: 0.9149, batch_loss: 0.0291, loss: 0.2438 ||: 100%|#########9| 7153/7188 [24:50<00:06,  5.14it/s]
2022-03-21 08:27:21,754 - INFO - tqdm - f1: 0.9149, accuracy: 0.9149, batch_loss: 0.1012, loss: 0.2437 ||: 100%|#########9| 7154/7188 [24:50<00:07,  4.75it/s]
2022-03-21 08:27:21,956 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.0357, loss: 0.2437 ||: 100%|#########9| 7155/7188 [24:51<00:06,  4.81it/s]
2022-03-21 08:27:22,194 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.0839, loss: 0.2437 ||: 100%|#########9| 7156/7188 [24:51<00:06,  4.61it/s]
2022-03-21 08:27:22,482 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.0193, loss: 0.2436 ||: 100%|#########9| 7157/7188 [24:51<00:07,  4.19it/s]
2022-03-21 08:27:22,648 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.2230, loss: 0.2436 ||: 100%|#########9| 7158/7188 [24:51<00:06,  4.62it/s]
2022-03-21 08:27:22,889 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.0826, loss: 0.2436 ||: 100%|#########9| 7159/7188 [24:52<00:06,  4.46it/s]
2022-03-21 08:27:23,105 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.2930, loss: 0.2436 ||: 100%|#########9| 7160/7188 [24:52<00:06,  4.51it/s]
2022-03-21 08:27:23,251 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.4434, loss: 0.2437 ||: 100%|#########9| 7161/7188 [24:52<00:05,  5.03it/s]
2022-03-21 08:27:23,496 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.2237, loss: 0.2437 ||: 100%|#########9| 7162/7188 [24:52<00:05,  4.70it/s]
2022-03-21 08:27:23,698 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.3145, loss: 0.2437 ||: 100%|#########9| 7163/7188 [24:52<00:05,  4.78it/s]
2022-03-21 08:27:23,874 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.1966, loss: 0.2437 ||: 100%|#########9| 7164/7188 [24:52<00:04,  5.02it/s]
2022-03-21 08:27:24,109 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.8685, loss: 0.2437 ||: 100%|#########9| 7165/7188 [24:53<00:04,  4.76it/s]
2022-03-21 08:27:24,295 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.1819, loss: 0.2437 ||: 100%|#########9| 7166/7188 [24:53<00:04,  4.93it/s]
2022-03-21 08:27:24,448 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.0432, loss: 0.2437 ||: 100%|#########9| 7167/7188 [24:53<00:03,  5.32it/s]
2022-03-21 08:27:24,720 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.0169, loss: 0.2437 ||: 100%|#########9| 7168/7188 [24:53<00:04,  4.69it/s]
2022-03-21 08:27:24,905 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.2795, loss: 0.2437 ||: 100%|#########9| 7169/7188 [24:54<00:03,  4.89it/s]
2022-03-21 08:27:25,172 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.0180, loss: 0.2437 ||: 100%|#########9| 7170/7188 [24:54<00:04,  4.48it/s]
2022-03-21 08:27:25,417 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.1248, loss: 0.2436 ||: 100%|#########9| 7171/7188 [24:54<00:03,  4.35it/s]
2022-03-21 08:27:25,587 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.2791, loss: 0.2436 ||: 100%|#########9| 7172/7188 [24:54<00:03,  4.71it/s]
2022-03-21 08:27:25,836 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.0720, loss: 0.2436 ||: 100%|#########9| 7173/7188 [24:54<00:03,  4.49it/s]
2022-03-21 08:27:26,038 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.6245, loss: 0.2437 ||: 100%|#########9| 7174/7188 [24:55<00:03,  4.61it/s]
2022-03-21 08:27:26,186 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.0569, loss: 0.2436 ||: 100%|#########9| 7175/7188 [24:55<00:02,  5.10it/s]
2022-03-21 08:27:26,493 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.0391, loss: 0.2436 ||: 100%|#########9| 7176/7188 [24:55<00:02,  4.36it/s]
2022-03-21 08:27:26,730 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.1273, loss: 0.2436 ||: 100%|#########9| 7177/7188 [24:55<00:02,  4.32it/s]
2022-03-21 08:27:26,968 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.1917, loss: 0.2436 ||: 100%|#########9| 7178/7188 [24:56<00:02,  4.28it/s]
2022-03-21 08:27:27,195 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.1937, loss: 0.2436 ||: 100%|#########9| 7179/7188 [24:56<00:02,  4.32it/s]
2022-03-21 08:27:27,339 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.0786, loss: 0.2436 ||: 100%|#########9| 7180/7188 [24:56<00:01,  4.87it/s]
2022-03-21 08:27:27,591 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.2238, loss: 0.2436 ||: 100%|#########9| 7181/7188 [24:56<00:01,  4.56it/s]
2022-03-21 08:27:27,791 - INFO - tqdm - f1: 0.9150, accuracy: 0.9150, batch_loss: 0.1356, loss: 0.2435 ||: 100%|#########9| 7182/7188 [24:56<00:01,  4.68it/s]
2022-03-21 08:27:27,930 - INFO - tqdm - f1: 0.9150, accuracy: 0.9151, batch_loss: 0.1102, loss: 0.2435 ||: 100%|#########9| 7183/7188 [24:57<00:00,  5.23it/s]
2022-03-21 08:27:28,180 - INFO - tqdm - f1: 0.9151, accuracy: 0.9151, batch_loss: 0.1675, loss: 0.2435 ||: 100%|#########9| 7184/7188 [24:57<00:00,  4.79it/s]
2022-03-21 08:27:28,381 - INFO - tqdm - f1: 0.9150, accuracy: 0.9151, batch_loss: 0.3107, loss: 0.2435 ||: 100%|#########9| 7185/7188 [24:57<00:00,  4.84it/s]
2022-03-21 08:27:28,520 - INFO - tqdm - f1: 0.9151, accuracy: 0.9151, batch_loss: 0.0462, loss: 0.2435 ||: 100%|#########9| 7186/7188 [24:57<00:00,  5.37it/s]
2022-03-21 08:27:28,796 - INFO - tqdm - f1: 0.9151, accuracy: 0.9151, batch_loss: 0.0260, loss: 0.2435 ||: 100%|#########9| 7187/7188 [24:57<00:00,  4.70it/s]
2022-03-21 08:27:28,972 - INFO - tqdm - f1: 0.9151, accuracy: 0.9151, batch_loss: 0.2937, loss: 0.2435 ||: 100%|##########| 7188/7188 [24:58<00:00,  4.95it/s]
2022-03-21 08:27:29,013 - INFO - tqdm - f1: 0.9151, accuracy: 0.9151, batch_loss: 0.2937, loss: 0.2435 ||: 100%|##########| 7188/7188 [24:58<00:00,  4.80it/s]
2022-03-21 08:27:29,089 - INFO - allennlp.training.trainer - Validating
2022-03-21 08:27:29,093 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 08:27:29,099 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 08:27:29,100 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 08:27:39,121 - INFO - tqdm - f1: 0.9231, accuracy: 0.9230, batch_loss: 0.3877, loss: 0.2279 ||:  27%|##7       | 86/313 [00:10<00:26,  8.63it/s]
2022-03-21 08:27:49,203 - INFO - tqdm - f1: 0.9256, accuracy: 0.9254, batch_loss: 0.1339, loss: 0.2172 ||:  56%|#####6    | 176/313 [00:20<00:15,  8.73it/s]
2022-03-21 08:27:59,334 - INFO - tqdm - f1: 0.9269, accuracy: 0.9264, batch_loss: 0.2904, loss: 0.2122 ||:  84%|########3 | 262/313 [00:30<00:06,  8.38it/s]
2022-03-21 08:28:01,854 - INFO - tqdm - f1: 0.9300, accuracy: 0.9296, batch_loss: 0.2140, loss: 0.2042 ||: 100%|##########| 313/313 [00:32<00:00,  9.55it/s]
2022-03-21 08:28:01,867 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_base_hyper_small_seed_13/best.th'.
2022-03-21 08:28:04,427 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 08:28:04,428 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.915  |     0.930
2022-03-21 08:28:04,430 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.915  |     0.930
2022-03-21 08:28:04,431 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 08:28:04,432 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.243  |     0.204
2022-03-21 08:28:04,433 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7394.852  |       N/A
2022-03-21 08:28:04,434 - INFO - allennlp.training.trainer - Epoch duration: 0:25:33.628517
2022-03-21 08:28:04,436 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:50:02
2022-03-21 08:28:04,437 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-21 08:28:04,438 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 08:28:04,440 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 08:28:04,442 - INFO - allennlp.training.trainer - Training
2022-03-21 08:28:04,444 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 08:28:14,464 - INFO - tqdm - f1: 0.9398, accuracy: 0.9396, batch_loss: 0.5617, loss: 0.1648 ||:   1%|1         | 91/7188 [00:10<14:14,  8.31it/s]
2022-03-21 08:28:24,592 - INFO - tqdm - f1: 0.9388, accuracy: 0.9390, batch_loss: 0.0147, loss: 0.1681 ||:   2%|2         | 172/7188 [00:20<14:59,  7.80it/s]
2022-03-21 08:28:34,641 - INFO - tqdm - f1: 0.9427, accuracy: 0.9427, batch_loss: 0.0398, loss: 0.1619 ||:   4%|3         | 254/7188 [00:30<14:02,  8.23it/s]
2022-03-21 08:28:44,842 - INFO - tqdm - f1: 0.9397, accuracy: 0.9397, batch_loss: 0.0312, loss: 0.1707 ||:   4%|4         | 312/7188 [00:40<26:57,  4.25it/s]
2022-03-21 08:28:54,933 - INFO - tqdm - f1: 0.9398, accuracy: 0.9399, batch_loss: 0.1206, loss: 0.1683 ||:   5%|4         | 359/7188 [00:50<25:49,  4.41it/s]
2022-03-21 08:29:05,052 - INFO - tqdm - f1: 0.9408, accuracy: 0.9409, batch_loss: 0.0688, loss: 0.1671 ||:   6%|5         | 410/7188 [01:00<22:54,  4.93it/s]
2022-03-21 08:29:15,087 - INFO - tqdm - f1: 0.9424, accuracy: 0.9424, batch_loss: 0.2016, loss: 0.1632 ||:   6%|6         | 459/7188 [01:10<23:00,  4.87it/s]
2022-03-21 08:29:25,264 - INFO - tqdm - f1: 0.9423, accuracy: 0.9423, batch_loss: 0.2375, loss: 0.1655 ||:   7%|7         | 507/7188 [01:20<24:19,  4.58it/s]
2022-03-21 08:29:35,326 - INFO - tqdm - f1: 0.9423, accuracy: 0.9423, batch_loss: 0.2806, loss: 0.1670 ||:   8%|7         | 555/7188 [01:30<20:40,  5.35it/s]
2022-03-21 08:29:45,418 - INFO - tqdm - f1: 0.9431, accuracy: 0.9433, batch_loss: 0.0476, loss: 0.1669 ||:   8%|8         | 605/7188 [01:40<19:40,  5.58it/s]
2022-03-21 08:29:55,429 - INFO - tqdm - f1: 0.9436, accuracy: 0.9438, batch_loss: 0.0810, loss: 0.1661 ||:   9%|9         | 653/7188 [01:50<23:51,  4.56it/s]
2022-03-21 08:30:05,436 - INFO - tqdm - f1: 0.9438, accuracy: 0.9441, batch_loss: 0.0856, loss: 0.1649 ||:  10%|9         | 700/7188 [02:00<22:01,  4.91it/s]
2022-03-21 08:30:15,448 - INFO - tqdm - f1: 0.9441, accuracy: 0.9444, batch_loss: 0.1229, loss: 0.1637 ||:  10%|#         | 749/7188 [02:11<23:13,  4.62it/s]
2022-03-21 08:30:25,510 - INFO - tqdm - f1: 0.9438, accuracy: 0.9440, batch_loss: 0.0748, loss: 0.1648 ||:  11%|#1        | 798/7188 [02:21<19:43,  5.40it/s]
2022-03-21 08:30:35,739 - INFO - tqdm - f1: 0.9443, accuracy: 0.9445, batch_loss: 0.3037, loss: 0.1631 ||:  12%|#1        | 845/7188 [02:31<22:11,  4.77it/s]
2022-03-21 08:30:45,862 - INFO - tqdm - f1: 0.9437, accuracy: 0.9438, batch_loss: 0.0712, loss: 0.1642 ||:  12%|#2        | 895/7188 [02:41<22:02,  4.76it/s]
2022-03-21 08:30:56,078 - INFO - tqdm - f1: 0.9439, accuracy: 0.9440, batch_loss: 0.4083, loss: 0.1635 ||:  13%|#3        | 944/7188 [02:51<23:18,  4.46it/s]
2022-03-21 08:31:06,130 - INFO - tqdm - f1: 0.9438, accuracy: 0.9440, batch_loss: 0.3648, loss: 0.1630 ||:  14%|#3        | 992/7188 [03:01<23:09,  4.46it/s]
2022-03-21 08:31:16,180 - INFO - tqdm - f1: 0.9438, accuracy: 0.9440, batch_loss: 0.2170, loss: 0.1632 ||:  14%|#4        | 1040/7188 [03:11<21:26,  4.78it/s]
2022-03-21 08:31:26,233 - INFO - tqdm - f1: 0.9434, accuracy: 0.9436, batch_loss: 0.3872, loss: 0.1654 ||:  15%|#5        | 1088/7188 [03:21<21:03,  4.83it/s]
2022-03-21 08:31:36,372 - INFO - tqdm - f1: 0.9434, accuracy: 0.9436, batch_loss: 0.3535, loss: 0.1653 ||:  16%|#5        | 1136/7188 [03:31<18:48,  5.36it/s]
2022-03-21 08:31:46,443 - INFO - tqdm - f1: 0.9432, accuracy: 0.9434, batch_loss: 0.0447, loss: 0.1664 ||:  16%|#6        | 1184/7188 [03:41<20:57,  4.77it/s]
2022-03-21 08:31:56,642 - INFO - tqdm - f1: 0.9428, accuracy: 0.9430, batch_loss: 0.3614, loss: 0.1681 ||:  17%|#7        | 1231/7188 [03:52<21:31,  4.61it/s]
2022-03-21 08:32:06,847 - INFO - tqdm - f1: 0.9421, accuracy: 0.9423, batch_loss: 0.2400, loss: 0.1699 ||:  18%|#7        | 1281/7188 [04:02<20:19,  4.84it/s]
2022-03-21 08:32:16,896 - INFO - tqdm - f1: 0.9413, accuracy: 0.9414, batch_loss: 0.0678, loss: 0.1715 ||:  19%|#8        | 1331/7188 [04:12<20:26,  4.78it/s]
2022-03-21 08:32:26,985 - INFO - tqdm - f1: 0.9413, accuracy: 0.9415, batch_loss: 0.2767, loss: 0.1710 ||:  19%|#9        | 1381/7188 [04:22<20:05,  4.82it/s]
2022-03-21 08:32:37,003 - INFO - tqdm - f1: 0.9414, accuracy: 0.9415, batch_loss: 0.0404, loss: 0.1709 ||:  20%|#9        | 1429/7188 [04:32<22:36,  4.25it/s]
2022-03-21 08:32:47,140 - INFO - tqdm - f1: 0.9412, accuracy: 0.9413, batch_loss: 0.3584, loss: 0.1714 ||:  21%|##        | 1478/7188 [04:42<20:25,  4.66it/s]
2022-03-21 08:32:57,289 - INFO - tqdm - f1: 0.9412, accuracy: 0.9413, batch_loss: 0.5102, loss: 0.1718 ||:  21%|##1       | 1526/7188 [04:52<20:51,  4.52it/s]
2022-03-21 08:33:07,353 - INFO - tqdm - f1: 0.9413, accuracy: 0.9413, batch_loss: 0.1297, loss: 0.1719 ||:  22%|##1       | 1573/7188 [05:02<20:21,  4.60it/s]
2022-03-21 08:33:17,573 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0356, loss: 0.1722 ||:  23%|##2       | 1621/7188 [05:13<20:36,  4.50it/s]
2022-03-21 08:33:27,628 - INFO - tqdm - f1: 0.9408, accuracy: 0.9409, batch_loss: 0.0481, loss: 0.1731 ||:  23%|##3       | 1669/7188 [05:23<19:37,  4.69it/s]
2022-03-21 08:33:37,644 - INFO - tqdm - f1: 0.9409, accuracy: 0.9410, batch_loss: 0.0578, loss: 0.1729 ||:  24%|##3       | 1718/7188 [05:33<19:22,  4.70it/s]
2022-03-21 08:33:47,726 - INFO - tqdm - f1: 0.9407, accuracy: 0.9408, batch_loss: 0.2101, loss: 0.1731 ||:  25%|##4       | 1769/7188 [05:43<18:41,  4.83it/s]
2022-03-21 08:33:57,734 - INFO - tqdm - f1: 0.9409, accuracy: 0.9411, batch_loss: 0.0716, loss: 0.1729 ||:  25%|##5       | 1816/7188 [05:53<20:01,  4.47it/s]
2022-03-21 08:34:07,926 - INFO - tqdm - f1: 0.9408, accuracy: 0.9410, batch_loss: 0.1983, loss: 0.1733 ||:  26%|##5       | 1864/7188 [06:03<18:05,  4.90it/s]
2022-03-21 08:34:17,999 - INFO - tqdm - f1: 0.9410, accuracy: 0.9411, batch_loss: 0.5794, loss: 0.1730 ||:  27%|##6       | 1912/7188 [06:13<18:48,  4.67it/s]
2022-03-21 08:34:28,072 - INFO - tqdm - f1: 0.9411, accuracy: 0.9412, batch_loss: 0.1930, loss: 0.1726 ||:  27%|##7       | 1957/7188 [06:23<18:37,  4.68it/s]
2022-03-21 08:34:38,085 - INFO - tqdm - f1: 0.9410, accuracy: 0.9410, batch_loss: 0.1867, loss: 0.1730 ||:  28%|##7       | 2004/7188 [06:33<19:32,  4.42it/s]
2022-03-21 08:34:48,228 - INFO - tqdm - f1: 0.9408, accuracy: 0.9409, batch_loss: 0.3074, loss: 0.1730 ||:  29%|##8       | 2051/7188 [06:43<17:47,  4.81it/s]
2022-03-21 08:34:58,485 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.3284, loss: 0.1730 ||:  29%|##9       | 2099/7188 [06:54<19:43,  4.30it/s]
2022-03-21 08:35:08,541 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1989, loss: 0.1732 ||:  30%|##9       | 2148/7188 [07:04<17:10,  4.89it/s]
2022-03-21 08:35:18,565 - INFO - tqdm - f1: 0.9410, accuracy: 0.9410, batch_loss: 0.0533, loss: 0.1724 ||:  31%|###       | 2196/7188 [07:14<17:50,  4.66it/s]
2022-03-21 08:35:28,579 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0238, loss: 0.1728 ||:  31%|###1      | 2243/7188 [07:24<17:44,  4.64it/s]
2022-03-21 08:35:38,609 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0265, loss: 0.1729 ||:  32%|###1      | 2291/7188 [07:34<16:34,  4.92it/s]
2022-03-21 08:35:48,717 - INFO - tqdm - f1: 0.9410, accuracy: 0.9410, batch_loss: 0.1004, loss: 0.1721 ||:  33%|###2      | 2340/7188 [07:44<16:55,  4.77it/s]
2022-03-21 08:35:58,745 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.2154, loss: 0.1725 ||:  33%|###3      | 2388/7188 [07:54<16:58,  4.71it/s]
2022-03-21 08:36:08,820 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.2389, loss: 0.1724 ||:  34%|###3      | 2436/7188 [08:04<16:12,  4.89it/s]
2022-03-21 08:36:19,046 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1316, loss: 0.1725 ||:  35%|###4      | 2484/7188 [08:14<17:05,  4.59it/s]
2022-03-21 08:36:29,260 - INFO - tqdm - f1: 0.9407, accuracy: 0.9407, batch_loss: 0.5298, loss: 0.1731 ||:  35%|###5      | 2534/7188 [08:24<16:28,  4.71it/s]
2022-03-21 08:36:39,407 - INFO - tqdm - f1: 0.9406, accuracy: 0.9406, batch_loss: 0.0612, loss: 0.1735 ||:  36%|###5      | 2582/7188 [08:34<19:13,  3.99it/s]
2022-03-21 08:36:49,417 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0231, loss: 0.1729 ||:  37%|###6      | 2630/7188 [08:44<15:34,  4.88it/s]
2022-03-21 08:36:59,428 - INFO - tqdm - f1: 0.9406, accuracy: 0.9405, batch_loss: 0.0722, loss: 0.1736 ||:  37%|###7      | 2677/7188 [08:54<15:22,  4.89it/s]
2022-03-21 08:37:09,543 - INFO - tqdm - f1: 0.9406, accuracy: 0.9405, batch_loss: 0.0695, loss: 0.1735 ||:  38%|###7      | 2726/7188 [09:05<15:50,  4.69it/s]
2022-03-21 08:37:19,599 - INFO - tqdm - f1: 0.9407, accuracy: 0.9406, batch_loss: 0.5904, loss: 0.1733 ||:  39%|###8      | 2775/7188 [09:15<13:28,  5.46it/s]
2022-03-21 08:37:29,615 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0838, loss: 0.1734 ||:  39%|###9      | 2822/7188 [09:25<14:28,  5.03it/s]
2022-03-21 08:37:39,777 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.1150, loss: 0.1732 ||:  40%|###9      | 2870/7188 [09:35<16:23,  4.39it/s]
2022-03-21 08:37:49,939 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.1657, loss: 0.1735 ||:  41%|####      | 2919/7188 [09:45<15:15,  4.66it/s]
2022-03-21 08:38:00,007 - INFO - tqdm - f1: 0.9402, accuracy: 0.9401, batch_loss: 0.0268, loss: 0.1737 ||:  41%|####1     | 2965/7188 [09:55<16:03,  4.38it/s]
2022-03-21 08:38:10,108 - INFO - tqdm - f1: 0.9403, accuracy: 0.9402, batch_loss: 0.0291, loss: 0.1737 ||:  42%|####1     | 3013/7188 [10:05<14:07,  4.93it/s]
2022-03-21 08:38:20,307 - INFO - tqdm - f1: 0.9402, accuracy: 0.9401, batch_loss: 0.1229, loss: 0.1740 ||:  43%|####2     | 3061/7188 [10:15<14:15,  4.82it/s]
2022-03-21 08:38:30,335 - INFO - tqdm - f1: 0.9402, accuracy: 0.9401, batch_loss: 0.1052, loss: 0.1739 ||:  43%|####3     | 3108/7188 [10:25<15:03,  4.52it/s]
2022-03-21 08:38:40,426 - INFO - tqdm - f1: 0.9403, accuracy: 0.9402, batch_loss: 0.0678, loss: 0.1737 ||:  44%|####3     | 3154/7188 [10:35<14:11,  4.74it/s]
2022-03-21 08:38:50,577 - INFO - tqdm - f1: 0.9403, accuracy: 0.9402, batch_loss: 0.1470, loss: 0.1737 ||:  45%|####4     | 3203/7188 [10:46<14:52,  4.47it/s]
2022-03-21 08:39:00,739 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.3091, loss: 0.1738 ||:  45%|####5     | 3252/7188 [10:56<15:17,  4.29it/s]
2022-03-21 08:39:10,767 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.3129, loss: 0.1742 ||:  46%|####5     | 3300/7188 [11:06<13:26,  4.82it/s]
2022-03-21 08:39:20,845 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0606, loss: 0.1741 ||:  47%|####6     | 3348/7188 [11:16<14:27,  4.43it/s]
2022-03-21 08:39:30,894 - INFO - tqdm - f1: 0.9403, accuracy: 0.9402, batch_loss: 0.1037, loss: 0.1742 ||:  47%|####7     | 3393/7188 [11:26<11:59,  5.28it/s]
2022-03-21 08:39:41,027 - INFO - tqdm - f1: 0.9403, accuracy: 0.9402, batch_loss: 0.2980, loss: 0.1739 ||:  48%|####7     | 3442/7188 [11:36<12:37,  4.94it/s]
2022-03-21 08:39:51,259 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.3368, loss: 0.1739 ||:  49%|####8     | 3489/7188 [11:46<14:32,  4.24it/s]
2022-03-21 08:40:01,353 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0855, loss: 0.1738 ||:  49%|####9     | 3538/7188 [11:56<12:47,  4.75it/s]
2022-03-21 08:40:11,497 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0442, loss: 0.1738 ||:  50%|####9     | 3585/7188 [12:07<13:19,  4.50it/s]
2022-03-21 08:40:21,522 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.2022, loss: 0.1739 ||:  51%|#####     | 3632/7188 [12:17<12:11,  4.86it/s]
2022-03-21 08:40:31,675 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.2590, loss: 0.1739 ||:  51%|#####1    | 3680/7188 [12:27<10:54,  5.36it/s]
2022-03-21 08:40:41,712 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0379, loss: 0.1743 ||:  52%|#####1    | 3728/7188 [12:37<11:32,  5.00it/s]
2022-03-21 08:40:51,716 - INFO - tqdm - f1: 0.9406, accuracy: 0.9405, batch_loss: 0.0077, loss: 0.1737 ||:  53%|#####2    | 3775/7188 [12:47<11:52,  4.79it/s]
2022-03-21 08:41:01,838 - INFO - tqdm - f1: 0.9406, accuracy: 0.9406, batch_loss: 0.2612, loss: 0.1739 ||:  53%|#####3    | 3822/7188 [12:57<13:19,  4.21it/s]
2022-03-21 08:41:11,968 - INFO - tqdm - f1: 0.9406, accuracy: 0.9405, batch_loss: 0.2092, loss: 0.1739 ||:  54%|#####3    | 3869/7188 [13:07<12:10,  4.54it/s]
2022-03-21 08:41:22,166 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0494, loss: 0.1741 ||:  54%|#####4    | 3917/7188 [13:17<12:29,  4.36it/s]
2022-03-21 08:41:32,337 - INFO - tqdm - f1: 0.9403, accuracy: 0.9403, batch_loss: 0.1330, loss: 0.1742 ||:  55%|#####5    | 3966/7188 [13:27<11:11,  4.80it/s]
2022-03-21 08:41:42,374 - INFO - tqdm - f1: 0.9403, accuracy: 0.9402, batch_loss: 0.0762, loss: 0.1741 ||:  56%|#####5    | 4014/7188 [13:37<12:01,  4.40it/s]
2022-03-21 08:41:52,445 - INFO - tqdm - f1: 0.9403, accuracy: 0.9402, batch_loss: 0.0593, loss: 0.1743 ||:  57%|#####6    | 4062/7188 [13:47<11:15,  4.63it/s]
2022-03-21 08:42:02,452 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.0273, loss: 0.1738 ||:  57%|#####7    | 4109/7188 [13:58<10:35,  4.85it/s]
2022-03-21 08:42:12,552 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.1279, loss: 0.1734 ||:  58%|#####7    | 4158/7188 [14:08<11:33,  4.37it/s]
2022-03-21 08:42:22,575 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.0773, loss: 0.1734 ||:  58%|#####8    | 4204/7188 [14:18<10:17,  4.83it/s]
2022-03-21 08:42:32,806 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.2765, loss: 0.1734 ||:  59%|#####9    | 4251/7188 [14:28<11:14,  4.35it/s]
2022-03-21 08:42:43,057 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.1103, loss: 0.1732 ||:  60%|#####9    | 4298/7188 [14:38<11:23,  4.23it/s]
2022-03-21 08:42:53,090 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.8401, loss: 0.1734 ||:  60%|######    | 4345/7188 [14:48<09:57,  4.76it/s]
2022-03-21 08:43:03,143 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.1101, loss: 0.1737 ||:  61%|######1   | 4394/7188 [14:58<09:38,  4.83it/s]
2022-03-21 08:43:13,171 - INFO - tqdm - f1: 0.9406, accuracy: 0.9405, batch_loss: 0.1227, loss: 0.1735 ||:  62%|######1   | 4442/7188 [15:08<09:12,  4.97it/s]
2022-03-21 08:43:23,195 - INFO - tqdm - f1: 0.9407, accuracy: 0.9406, batch_loss: 0.1016, loss: 0.1733 ||:  62%|######2   | 4489/7188 [15:18<08:44,  5.15it/s]
2022-03-21 08:43:33,196 - INFO - tqdm - f1: 0.9408, accuracy: 0.9407, batch_loss: 0.0154, loss: 0.1731 ||:  63%|######3   | 4537/7188 [15:28<09:08,  4.83it/s]
2022-03-21 08:43:43,281 - INFO - tqdm - f1: 0.9410, accuracy: 0.9409, batch_loss: 0.0227, loss: 0.1729 ||:  64%|######3   | 4586/7188 [15:38<08:49,  4.91it/s]
2022-03-21 08:43:53,317 - INFO - tqdm - f1: 0.9409, accuracy: 0.9408, batch_loss: 0.0784, loss: 0.1730 ||:  64%|######4   | 4633/7188 [15:48<09:36,  4.43it/s]
2022-03-21 08:44:03,331 - INFO - tqdm - f1: 0.9409, accuracy: 0.9409, batch_loss: 0.3724, loss: 0.1729 ||:  66%|######5   | 4722/7188 [15:58<02:32, 16.16it/s]
2022-03-21 08:44:13,362 - INFO - tqdm - f1: 0.9407, accuracy: 0.9406, batch_loss: 0.1956, loss: 0.1738 ||:  67%|######7   | 4820/7188 [16:08<05:25,  7.26it/s]
2022-03-21 08:44:23,372 - INFO - tqdm - f1: 0.9408, accuracy: 0.9407, batch_loss: 0.1441, loss: 0.1735 ||:  68%|######8   | 4896/7188 [16:18<05:27,  7.00it/s]
2022-03-21 08:44:33,445 - INFO - tqdm - f1: 0.9408, accuracy: 0.9407, batch_loss: 0.1808, loss: 0.1737 ||:  69%|######9   | 4972/7188 [16:28<04:47,  7.70it/s]
2022-03-21 08:44:43,655 - INFO - tqdm - f1: 0.9408, accuracy: 0.9407, batch_loss: 0.0842, loss: 0.1737 ||:  70%|######9   | 5027/7188 [16:39<08:21,  4.31it/s]
2022-03-21 08:44:53,702 - INFO - tqdm - f1: 0.9407, accuracy: 0.9407, batch_loss: 0.0974, loss: 0.1737 ||:  71%|#######   | 5073/7188 [16:49<07:52,  4.47it/s]
2022-03-21 08:45:03,829 - INFO - tqdm - f1: 0.9408, accuracy: 0.9407, batch_loss: 0.1016, loss: 0.1738 ||:  71%|#######1  | 5122/7188 [16:59<07:12,  4.78it/s]
2022-03-21 08:45:14,015 - INFO - tqdm - f1: 0.9407, accuracy: 0.9406, batch_loss: 0.5785, loss: 0.1739 ||:  72%|#######1  | 5171/7188 [17:09<07:21,  4.57it/s]
2022-03-21 08:45:24,079 - INFO - tqdm - f1: 0.9408, accuracy: 0.9407, batch_loss: 0.2662, loss: 0.1737 ||:  73%|#######2  | 5219/7188 [17:19<06:25,  5.10it/s]
2022-03-21 08:45:34,250 - INFO - tqdm - f1: 0.9406, accuracy: 0.9405, batch_loss: 0.2834, loss: 0.1743 ||:  73%|#######3  | 5264/7188 [17:29<06:54,  4.64it/s]
2022-03-21 08:45:44,316 - INFO - tqdm - f1: 0.9407, accuracy: 0.9406, batch_loss: 0.0743, loss: 0.1740 ||:  74%|#######3  | 5312/7188 [17:39<06:32,  4.78it/s]
2022-03-21 08:45:54,348 - INFO - tqdm - f1: 0.9406, accuracy: 0.9405, batch_loss: 0.0932, loss: 0.1741 ||:  75%|#######4  | 5360/7188 [17:49<06:32,  4.66it/s]
2022-03-21 08:46:04,566 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.3763, loss: 0.1744 ||:  75%|#######5  | 5409/7188 [18:00<06:07,  4.84it/s]
2022-03-21 08:46:14,574 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.2811, loss: 0.1744 ||:  76%|#######5  | 5456/7188 [18:10<06:01,  4.79it/s]
2022-03-21 08:46:24,599 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.0292, loss: 0.1745 ||:  77%|#######6  | 5503/7188 [18:20<06:20,  4.43it/s]
2022-03-21 08:46:34,606 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.4772, loss: 0.1743 ||:  77%|#######7  | 5549/7188 [18:30<06:05,  4.48it/s]
2022-03-21 08:46:44,672 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0425, loss: 0.1746 ||:  78%|#######7  | 5598/7188 [18:40<05:27,  4.86it/s]
2022-03-21 08:46:54,827 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0118, loss: 0.1744 ||:  79%|#######8  | 5645/7188 [18:50<05:19,  4.83it/s]
2022-03-21 08:47:05,046 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.1437, loss: 0.1741 ||:  79%|#######9  | 5691/7188 [19:00<05:31,  4.51it/s]
2022-03-21 08:47:15,166 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.5329, loss: 0.1742 ||:  80%|#######9  | 5737/7188 [19:10<04:54,  4.93it/s]
2022-03-21 08:47:25,249 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.1384, loss: 0.1739 ||:  80%|########  | 5785/7188 [19:20<05:05,  4.60it/s]
2022-03-21 08:47:35,321 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0489, loss: 0.1741 ||:  81%|########1 | 5832/7188 [19:30<04:43,  4.79it/s]
2022-03-21 08:47:45,398 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.2242, loss: 0.1741 ||:  82%|########1 | 5878/7188 [19:40<04:42,  4.63it/s]
2022-03-21 08:47:55,438 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.1063, loss: 0.1740 ||:  82%|########2 | 5925/7188 [19:50<03:52,  5.44it/s]
2022-03-21 08:48:05,478 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0125, loss: 0.1741 ||:  83%|########3 | 5974/7188 [20:01<03:43,  5.43it/s]
2022-03-21 08:48:15,558 - INFO - tqdm - f1: 0.9403, accuracy: 0.9403, batch_loss: 0.2195, loss: 0.1742 ||:  84%|########3 | 6022/7188 [20:11<03:38,  5.34it/s]
2022-03-21 08:48:25,590 - INFO - tqdm - f1: 0.9403, accuracy: 0.9403, batch_loss: 0.0412, loss: 0.1742 ||:  84%|########4 | 6071/7188 [20:21<03:40,  5.06it/s]
2022-03-21 08:48:35,784 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.2592, loss: 0.1742 ||:  85%|########5 | 6119/7188 [20:31<04:06,  4.33it/s]
2022-03-21 08:48:45,966 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0969, loss: 0.1742 ||:  86%|########5 | 6165/7188 [20:41<04:01,  4.23it/s]
2022-03-21 08:48:56,066 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.5338, loss: 0.1742 ||:  86%|########6 | 6212/7188 [20:51<03:15,  4.99it/s]
2022-03-21 08:49:06,116 - INFO - tqdm - f1: 0.9403, accuracy: 0.9403, batch_loss: 0.1514, loss: 0.1742 ||:  87%|########7 | 6259/7188 [21:01<03:18,  4.67it/s]
2022-03-21 08:49:16,336 - INFO - tqdm - f1: 0.9403, accuracy: 0.9402, batch_loss: 0.2382, loss: 0.1743 ||:  88%|########7 | 6307/7188 [21:11<03:10,  4.62it/s]
2022-03-21 08:49:26,362 - INFO - tqdm - f1: 0.9403, accuracy: 0.9402, batch_loss: 0.1293, loss: 0.1741 ||:  88%|########8 | 6355/7188 [21:21<02:56,  4.72it/s]
2022-03-21 08:49:36,459 - INFO - tqdm - f1: 0.9403, accuracy: 0.9402, batch_loss: 0.0636, loss: 0.1742 ||:  89%|########9 | 6404/7188 [21:32<02:55,  4.48it/s]
2022-03-21 08:49:46,636 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0723, loss: 0.1737 ||:  90%|########9 | 6453/7188 [21:42<02:28,  4.94it/s]
2022-03-21 08:49:56,643 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.1455, loss: 0.1736 ||:  90%|######### | 6500/7188 [21:52<02:33,  4.47it/s]
2022-03-21 08:50:06,792 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.2675, loss: 0.1736 ||:  91%|#########1| 6547/7188 [22:02<02:32,  4.19it/s]
2022-03-21 08:50:17,021 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.2062, loss: 0.1734 ||:  92%|#########1| 6594/7188 [22:12<01:59,  4.96it/s]
2022-03-21 08:50:27,206 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.3056, loss: 0.1736 ||:  92%|#########2| 6642/7188 [22:22<02:02,  4.47it/s]
2022-03-21 08:50:37,271 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.2994, loss: 0.1739 ||:  93%|#########3| 6692/7188 [22:32<01:41,  4.89it/s]
2022-03-21 08:50:47,290 - INFO - tqdm - f1: 0.9403, accuracy: 0.9403, batch_loss: 0.3997, loss: 0.1739 ||:  94%|#########3| 6738/7188 [22:42<01:42,  4.40it/s]
2022-03-21 08:50:57,330 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.0954, loss: 0.1738 ||:  94%|#########4| 6786/7188 [22:52<01:20,  4.97it/s]
2022-03-21 08:51:07,347 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.4427, loss: 0.1740 ||:  95%|#########5| 6833/7188 [23:02<01:13,  4.84it/s]
2022-03-21 08:51:17,364 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.2725, loss: 0.1737 ||:  96%|#########5| 6880/7188 [23:12<01:04,  4.81it/s]
2022-03-21 08:51:27,460 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.0295, loss: 0.1735 ||:  96%|#########6| 6926/7188 [23:23<00:57,  4.59it/s]
2022-03-21 08:51:37,654 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.0211, loss: 0.1737 ||:  97%|#########7| 6973/7188 [23:33<00:44,  4.84it/s]
2022-03-21 08:51:47,808 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.4138, loss: 0.1738 ||:  98%|#########7| 7020/7188 [23:43<00:38,  4.36it/s]
2022-03-21 08:51:57,828 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.5600, loss: 0.1737 ||:  98%|#########8| 7067/7188 [23:53<00:27,  4.40it/s]
2022-03-21 08:52:07,848 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.2409, loss: 0.1737 ||:  99%|#########8| 7114/7188 [24:03<00:16,  4.50it/s]
2022-03-21 08:52:16,247 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0139, loss: 0.1734 ||: 100%|#########9| 7153/7188 [24:11<00:06,  5.11it/s]
2022-03-21 08:52:16,463 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0298, loss: 0.1734 ||: 100%|#########9| 7154/7188 [24:12<00:06,  4.95it/s]
2022-03-21 08:52:16,665 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.1947, loss: 0.1734 ||: 100%|#########9| 7155/7188 [24:12<00:06,  4.95it/s]
2022-03-21 08:52:16,805 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.4951, loss: 0.1734 ||: 100%|#########9| 7156/7188 [24:12<00:05,  5.46it/s]
2022-03-21 08:52:17,058 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0118, loss: 0.1734 ||: 100%|#########9| 7157/7188 [24:12<00:06,  4.90it/s]
2022-03-21 08:52:17,272 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0138, loss: 0.1734 ||: 100%|#########9| 7158/7188 [24:12<00:06,  4.83it/s]
2022-03-21 08:52:17,514 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0662, loss: 0.1734 ||: 100%|#########9| 7159/7188 [24:13<00:06,  4.60it/s]
2022-03-21 08:52:17,764 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.3553, loss: 0.1734 ||: 100%|#########9| 7160/7188 [24:13<00:06,  4.40it/s]
2022-03-21 08:52:17,945 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0066, loss: 0.1734 ||: 100%|#########9| 7161/7188 [24:13<00:05,  4.69it/s]
2022-03-21 08:52:18,236 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.3257, loss: 0.1734 ||: 100%|#########9| 7162/7188 [24:13<00:06,  4.22it/s]
2022-03-21 08:52:18,424 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.2213, loss: 0.1734 ||: 100%|#########9| 7163/7188 [24:13<00:05,  4.51it/s]
2022-03-21 08:52:18,654 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.2477, loss: 0.1734 ||: 100%|#########9| 7164/7188 [24:14<00:05,  4.45it/s]
2022-03-21 08:52:18,937 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.5608, loss: 0.1735 ||: 100%|#########9| 7165/7188 [24:14<00:05,  4.13it/s]
2022-03-21 08:52:19,078 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.4092, loss: 0.1735 ||: 100%|#########9| 7166/7188 [24:14<00:04,  4.72it/s]
2022-03-21 08:52:19,355 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.1128, loss: 0.1735 ||: 100%|#########9| 7167/7188 [24:14<00:04,  4.32it/s]
2022-03-21 08:52:19,549 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.2095, loss: 0.1735 ||: 100%|#########9| 7168/7188 [24:15<00:04,  4.55it/s]
2022-03-21 08:52:19,804 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.7755, loss: 0.1736 ||: 100%|#########9| 7169/7188 [24:15<00:04,  4.34it/s]
2022-03-21 08:52:20,040 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.1425, loss: 0.1736 ||: 100%|#########9| 7170/7188 [24:15<00:04,  4.31it/s]
2022-03-21 08:52:20,254 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.0297, loss: 0.1736 ||: 100%|#########9| 7171/7188 [24:15<00:03,  4.41it/s]
2022-03-21 08:52:20,493 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.0686, loss: 0.1736 ||: 100%|#########9| 7172/7188 [24:16<00:03,  4.34it/s]
2022-03-21 08:52:20,713 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.0532, loss: 0.1735 ||: 100%|#########9| 7173/7188 [24:16<00:03,  4.40it/s]
2022-03-21 08:52:20,849 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.1107, loss: 0.1735 ||: 100%|#########9| 7174/7188 [24:16<00:02,  5.00it/s]
2022-03-21 08:52:21,090 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.0336, loss: 0.1735 ||: 100%|#########9| 7175/7188 [24:16<00:02,  4.71it/s]
2022-03-21 08:52:21,311 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.1861, loss: 0.1735 ||: 100%|#########9| 7176/7188 [24:16<00:02,  4.66it/s]
2022-03-21 08:52:21,524 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0106, loss: 0.1735 ||: 100%|#########9| 7177/7188 [24:17<00:02,  4.67it/s]
2022-03-21 08:52:21,799 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0471, loss: 0.1735 ||: 100%|#########9| 7178/7188 [24:17<00:02,  4.30it/s]
2022-03-21 08:52:22,007 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.1166, loss: 0.1735 ||: 100%|#########9| 7179/7188 [24:17<00:02,  4.45it/s]
2022-03-21 08:52:22,247 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0099, loss: 0.1734 ||: 100%|#########9| 7180/7188 [24:17<00:01,  4.35it/s]
2022-03-21 08:52:22,470 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.4757, loss: 0.1735 ||: 100%|#########9| 7181/7188 [24:18<00:01,  4.40it/s]
2022-03-21 08:52:22,610 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0164, loss: 0.1735 ||: 100%|#########9| 7182/7188 [24:18<00:01,  4.97it/s]
2022-03-21 08:52:22,863 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0563, loss: 0.1734 ||: 100%|#########9| 7183/7188 [24:18<00:01,  4.61it/s]
2022-03-21 08:52:23,060 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.2500, loss: 0.1735 ||: 100%|#########9| 7184/7188 [24:18<00:00,  4.74it/s]
2022-03-21 08:52:23,259 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0597, loss: 0.1734 ||: 100%|#########9| 7185/7188 [24:18<00:00,  4.82it/s]
2022-03-21 08:52:23,532 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0919, loss: 0.1734 ||: 100%|#########9| 7186/7188 [24:19<00:00,  4.41it/s]
2022-03-21 08:52:23,767 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.1601, loss: 0.1734 ||: 100%|#########9| 7187/7188 [24:19<00:00,  4.36it/s]
2022-03-21 08:52:24,005 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.2371, loss: 0.1734 ||: 100%|##########| 7188/7188 [24:19<00:00,  4.31it/s]
2022-03-21 08:52:24,051 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.2371, loss: 0.1734 ||: 100%|##########| 7188/7188 [24:19<00:00,  4.92it/s]
2022-03-21 08:52:24,149 - INFO - allennlp.training.trainer - Validating
2022-03-21 08:52:24,176 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 08:52:34,328 - INFO - tqdm - f1: 0.9374, accuracy: 0.9375, batch_loss: 0.6778, loss: 0.1975 ||:  28%|##7       | 87/313 [00:10<00:27,  8.10it/s]
2022-03-21 08:52:44,487 - INFO - tqdm - f1: 0.9359, accuracy: 0.9360, batch_loss: 0.1040, loss: 0.1945 ||:  55%|#####4    | 172/313 [00:20<00:18,  7.83it/s]
2022-03-21 08:52:54,535 - INFO - tqdm - f1: 0.9359, accuracy: 0.9358, batch_loss: 0.5985, loss: 0.2006 ||:  82%|########1 | 256/313 [00:30<00:07,  7.42it/s]
2022-03-21 08:53:01,568 - INFO - tqdm - f1: 0.9358, accuracy: 0.9356, batch_loss: 0.1524, loss: 0.1975 ||: 100%|##########| 313/313 [00:37<00:00,  7.91it/s]
2022-03-21 08:53:01,571 - INFO - tqdm - f1: 0.9358, accuracy: 0.9356, batch_loss: 0.1524, loss: 0.1975 ||: 100%|##########| 313/313 [00:37<00:00,  8.37it/s]
2022-03-21 08:53:01,614 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_base_hyper_small_seed_13/best.th'.
2022-03-21 08:53:09,079 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 08:53:09,093 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.940  |     0.936
2022-03-21 08:53:09,105 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.941  |     0.936
2022-03-21 08:53:09,117 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 08:53:09,129 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.173  |     0.198
2022-03-21 08:53:09,141 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7578.898  |       N/A
2022-03-21 08:53:09,154 - INFO - allennlp.training.trainer - Epoch duration: 0:25:04.716551
2022-03-21 08:53:09,166 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:22:33
2022-03-21 08:53:09,178 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-21 08:53:09,191 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 08:53:09,203 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 08:53:09,230 - INFO - allennlp.training.trainer - Training
2022-03-21 08:53:09,245 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 08:53:19,321 - INFO - tqdm - f1: 0.9603, accuracy: 0.9593, batch_loss: 0.0391, loss: 0.1072 ||:   1%|          | 43/7188 [00:10<28:11,  4.22it/s]
2022-03-21 08:53:29,366 - INFO - tqdm - f1: 0.9512, accuracy: 0.9507, batch_loss: 0.0875, loss: 0.1306 ||:   1%|1         | 90/7188 [00:20<27:40,  4.28it/s]
2022-03-21 08:53:39,367 - INFO - tqdm - f1: 0.9542, accuracy: 0.9539, batch_loss: 0.2502, loss: 0.1271 ||:   2%|1         | 137/7188 [00:30<24:21,  4.82it/s]
2022-03-21 08:53:49,408 - INFO - tqdm - f1: 0.9548, accuracy: 0.9545, batch_loss: 0.3457, loss: 0.1257 ||:   3%|2         | 184/7188 [00:40<27:22,  4.26it/s]
2022-03-21 08:53:59,440 - INFO - tqdm - f1: 0.9518, accuracy: 0.9513, batch_loss: 0.1133, loss: 0.1374 ||:   3%|3         | 231/7188 [00:50<23:58,  4.84it/s]
2022-03-21 08:54:09,460 - INFO - tqdm - f1: 0.9505, accuracy: 0.9503, batch_loss: 0.0051, loss: 0.1396 ||:   4%|3         | 278/7188 [01:00<24:53,  4.63it/s]
2022-03-21 08:54:19,467 - INFO - tqdm - f1: 0.9512, accuracy: 0.9512, batch_loss: 0.0281, loss: 0.1401 ||:   4%|4         | 323/7188 [01:10<26:21,  4.34it/s]
2022-03-21 08:54:29,521 - INFO - tqdm - f1: 0.9507, accuracy: 0.9508, batch_loss: 0.3668, loss: 0.1398 ||:   5%|5         | 371/7188 [01:20<20:48,  5.46it/s]
2022-03-21 08:54:39,694 - INFO - tqdm - f1: 0.9506, accuracy: 0.9506, batch_loss: 0.3263, loss: 0.1416 ||:   6%|5         | 419/7188 [01:30<26:12,  4.30it/s]
2022-03-21 08:54:49,774 - INFO - tqdm - f1: 0.9517, accuracy: 0.9519, batch_loss: 0.0228, loss: 0.1383 ||:   6%|6         | 466/7188 [01:40<23:57,  4.68it/s]
2022-03-21 08:54:59,941 - INFO - tqdm - f1: 0.9529, accuracy: 0.9531, batch_loss: 0.0164, loss: 0.1351 ||:   7%|7         | 513/7188 [01:50<23:15,  4.78it/s]
2022-03-21 08:55:10,068 - INFO - tqdm - f1: 0.9535, accuracy: 0.9537, batch_loss: 0.0136, loss: 0.1340 ||:   8%|7         | 562/7188 [02:00<24:18,  4.54it/s]
2022-03-21 08:55:20,300 - INFO - tqdm - f1: 0.9537, accuracy: 0.9539, batch_loss: 0.3060, loss: 0.1333 ||:   8%|8         | 608/7188 [02:11<22:50,  4.80it/s]
2022-03-21 08:55:30,511 - INFO - tqdm - f1: 0.9537, accuracy: 0.9540, batch_loss: 0.1377, loss: 0.1335 ||:   9%|9         | 656/7188 [02:21<25:24,  4.28it/s]
2022-03-21 08:55:40,545 - INFO - tqdm - f1: 0.9535, accuracy: 0.9537, batch_loss: 0.7537, loss: 0.1344 ||:  10%|9         | 704/7188 [02:31<21:31,  5.02it/s]
2022-03-21 08:55:50,666 - INFO - tqdm - f1: 0.9531, accuracy: 0.9532, batch_loss: 0.0354, loss: 0.1364 ||:  10%|#         | 753/7188 [02:41<19:40,  5.45it/s]
2022-03-21 08:56:00,893 - INFO - tqdm - f1: 0.9529, accuracy: 0.9530, batch_loss: 0.5175, loss: 0.1375 ||:  11%|#1        | 800/7188 [02:51<24:57,  4.26it/s]
2022-03-21 08:56:10,923 - INFO - tqdm - f1: 0.9535, accuracy: 0.9537, batch_loss: 0.0064, loss: 0.1368 ||:  12%|#1        | 846/7188 [03:01<26:01,  4.06it/s]
2022-03-21 08:56:20,984 - INFO - tqdm - f1: 0.9531, accuracy: 0.9532, batch_loss: 0.3184, loss: 0.1385 ||:  12%|#2        | 892/7188 [03:11<23:58,  4.38it/s]
2022-03-21 08:56:31,059 - INFO - tqdm - f1: 0.9532, accuracy: 0.9533, batch_loss: 0.2007, loss: 0.1378 ||:  13%|#3        | 939/7188 [03:21<20:20,  5.12it/s]
2022-03-21 08:56:41,134 - INFO - tqdm - f1: 0.9531, accuracy: 0.9532, batch_loss: 0.0734, loss: 0.1379 ||:  14%|#3        | 988/7188 [03:31<19:06,  5.41it/s]
2022-03-21 08:56:51,217 - INFO - tqdm - f1: 0.9522, accuracy: 0.9522, batch_loss: 0.0408, loss: 0.1410 ||:  14%|#4        | 1036/7188 [03:41<21:03,  4.87it/s]
2022-03-21 08:57:01,602 - INFO - tqdm - f1: 0.9524, accuracy: 0.9524, batch_loss: 0.0073, loss: 0.1401 ||:  15%|#5        | 1083/7188 [03:52<28:13,  3.60it/s]
2022-03-21 08:57:11,828 - INFO - tqdm - f1: 0.9522, accuracy: 0.9522, batch_loss: 0.0672, loss: 0.1401 ||:  16%|#5        | 1130/7188 [04:02<30:50,  3.27it/s]
2022-03-21 08:57:21,985 - INFO - tqdm - f1: 0.9525, accuracy: 0.9524, batch_loss: 0.0369, loss: 0.1389 ||:  16%|#6        | 1178/7188 [04:12<20:17,  4.94it/s]
2022-03-21 08:57:32,082 - INFO - tqdm - f1: 0.9524, accuracy: 0.9524, batch_loss: 0.1068, loss: 0.1392 ||:  17%|#7        | 1228/7188 [04:22<20:37,  4.82it/s]
2022-03-21 08:57:42,114 - INFO - tqdm - f1: 0.9525, accuracy: 0.9524, batch_loss: 0.0388, loss: 0.1393 ||:  18%|#7        | 1276/7188 [04:32<20:15,  4.86it/s]
2022-03-21 08:57:52,157 - INFO - tqdm - f1: 0.9525, accuracy: 0.9524, batch_loss: 0.0300, loss: 0.1396 ||:  18%|#8        | 1324/7188 [04:42<21:52,  4.47it/s]
2022-03-21 08:58:02,256 - INFO - tqdm - f1: 0.9523, accuracy: 0.9523, batch_loss: 0.0235, loss: 0.1400 ||:  19%|#9        | 1371/7188 [04:53<21:07,  4.59it/s]
2022-03-21 08:58:12,294 - INFO - tqdm - f1: 0.9522, accuracy: 0.9523, batch_loss: 0.2152, loss: 0.1392 ||:  20%|#9        | 1419/7188 [05:03<18:04,  5.32it/s]
2022-03-21 08:58:22,350 - INFO - tqdm - f1: 0.9522, accuracy: 0.9522, batch_loss: 0.1247, loss: 0.1386 ||:  20%|##        | 1468/7188 [05:13<17:28,  5.45it/s]
2022-03-21 08:58:32,445 - INFO - tqdm - f1: 0.9520, accuracy: 0.9521, batch_loss: 0.0126, loss: 0.1384 ||:  21%|##1       | 1518/7188 [05:23<18:11,  5.20it/s]
2022-03-21 08:58:42,687 - INFO - tqdm - f1: 0.9520, accuracy: 0.9520, batch_loss: 0.0544, loss: 0.1383 ||:  22%|##1       | 1569/7188 [05:33<20:55,  4.48it/s]
2022-03-21 08:58:52,828 - INFO - tqdm - f1: 0.9520, accuracy: 0.9521, batch_loss: 0.1859, loss: 0.1383 ||:  23%|##2       | 1618/7188 [05:43<19:24,  4.78it/s]
2022-03-21 08:59:02,950 - INFO - tqdm - f1: 0.9520, accuracy: 0.9521, batch_loss: 0.0917, loss: 0.1383 ||:  23%|##3       | 1668/7188 [05:53<19:50,  4.64it/s]
2022-03-21 08:59:13,109 - INFO - tqdm - f1: 0.9519, accuracy: 0.9520, batch_loss: 0.1616, loss: 0.1383 ||:  24%|##3       | 1717/7188 [06:03<22:09,  4.12it/s]
2022-03-21 08:59:23,160 - INFO - tqdm - f1: 0.9516, accuracy: 0.9517, batch_loss: 0.1717, loss: 0.1383 ||:  25%|##4       | 1765/7188 [06:13<19:26,  4.65it/s]
2022-03-21 08:59:33,208 - INFO - tqdm - f1: 0.9519, accuracy: 0.9519, batch_loss: 0.0062, loss: 0.1381 ||:  25%|##5       | 1813/7188 [06:23<18:32,  4.83it/s]
2022-03-21 08:59:43,263 - INFO - tqdm - f1: 0.9519, accuracy: 0.9520, batch_loss: 0.6260, loss: 0.1388 ||:  26%|##5       | 1863/7188 [06:34<18:27,  4.81it/s]
2022-03-21 08:59:53,302 - INFO - tqdm - f1: 0.9520, accuracy: 0.9521, batch_loss: 0.0579, loss: 0.1389 ||:  27%|##7       | 1956/7188 [06:44<05:06, 17.05it/s]
2022-03-21 09:00:03,307 - INFO - tqdm - f1: 0.9524, accuracy: 0.9525, batch_loss: 0.0448, loss: 0.1377 ||:  29%|##9       | 2098/7188 [06:54<05:21, 15.85it/s]
2022-03-21 09:00:13,398 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0425, loss: 0.1368 ||:  31%|###       | 2206/7188 [07:04<05:12, 15.95it/s]
2022-03-21 09:00:23,426 - INFO - tqdm - f1: 0.9531, accuracy: 0.9532, batch_loss: 0.3100, loss: 0.1360 ||:  32%|###2      | 2314/7188 [07:14<05:00, 16.21it/s]
2022-03-21 09:00:34,512 - INFO - tqdm - f1: 0.9530, accuracy: 0.9531, batch_loss: 0.0329, loss: 0.1364 ||:  34%|###3      | 2426/7188 [07:25<16:41,  4.76it/s]
2022-03-21 09:00:44,563 - INFO - tqdm - f1: 0.9533, accuracy: 0.9533, batch_loss: 0.0566, loss: 0.1356 ||:  35%|###5      | 2534/7188 [07:35<13:31,  5.73it/s]
2022-03-21 09:00:54,593 - INFO - tqdm - f1: 0.9533, accuracy: 0.9533, batch_loss: 0.0327, loss: 0.1361 ||:  37%|###6      | 2642/7188 [07:45<13:17,  5.70it/s]
2022-03-21 09:01:04,621 - INFO - tqdm - f1: 0.9532, accuracy: 0.9532, batch_loss: 0.0373, loss: 0.1359 ||:  38%|###8      | 2748/7188 [07:55<10:31,  7.03it/s]
2022-03-21 09:01:14,648 - INFO - tqdm - f1: 0.9533, accuracy: 0.9533, batch_loss: 0.0910, loss: 0.1354 ||:  40%|###9      | 2856/7188 [08:05<09:52,  7.31it/s]
2022-03-21 09:01:24,747 - INFO - tqdm - f1: 0.9532, accuracy: 0.9531, batch_loss: 0.0146, loss: 0.1363 ||:  41%|####1     | 2964/7188 [08:15<08:30,  8.27it/s]
2022-03-21 09:01:34,846 - INFO - tqdm - f1: 0.9531, accuracy: 0.9530, batch_loss: 0.1832, loss: 0.1362 ||:  43%|####2     | 3070/7188 [08:25<07:19,  9.37it/s]
2022-03-21 09:01:44,912 - INFO - tqdm - f1: 0.9531, accuracy: 0.9530, batch_loss: 0.2572, loss: 0.1362 ||:  44%|####4     | 3178/7188 [08:35<05:26, 12.27it/s]
2022-03-21 09:01:54,950 - INFO - tqdm - f1: 0.9531, accuracy: 0.9531, batch_loss: 0.0122, loss: 0.1361 ||:  46%|####5     | 3286/7188 [08:45<05:21, 12.12it/s]
2022-03-21 09:02:05,024 - INFO - tqdm - f1: 0.9530, accuracy: 0.9529, batch_loss: 0.2202, loss: 0.1366 ||:  47%|####7     | 3394/7188 [08:55<05:03, 12.52it/s]
2022-03-21 09:02:15,080 - INFO - tqdm - f1: 0.9533, accuracy: 0.9532, batch_loss: 0.1344, loss: 0.1360 ||:  49%|####8     | 3502/7188 [09:05<04:23, 14.00it/s]
2022-03-21 09:02:25,231 - INFO - tqdm - f1: 0.9532, accuracy: 0.9531, batch_loss: 0.0439, loss: 0.1364 ||:  50%|#####     | 3606/7188 [09:15<06:52,  8.67it/s]
2022-03-21 09:02:35,293 - INFO - tqdm - f1: 0.9532, accuracy: 0.9531, batch_loss: 0.1877, loss: 0.1364 ||:  52%|#####1    | 3714/7188 [09:26<06:00,  9.62it/s]
2022-03-21 09:02:45,396 - INFO - tqdm - f1: 0.9531, accuracy: 0.9530, batch_loss: 0.2667, loss: 0.1363 ||:  53%|#####3    | 3822/7188 [09:36<05:13, 10.74it/s]
2022-03-21 09:02:55,445 - INFO - tqdm - f1: 0.9530, accuracy: 0.9529, batch_loss: 0.0681, loss: 0.1363 ||:  55%|#####4    | 3930/7188 [09:46<04:53, 11.08it/s]
2022-03-21 09:03:05,567 - INFO - tqdm - f1: 0.9529, accuracy: 0.9528, batch_loss: 0.0388, loss: 0.1368 ||:  56%|#####6    | 4038/7188 [09:56<04:22, 12.02it/s]
2022-03-21 09:03:15,579 - INFO - tqdm - f1: 0.9532, accuracy: 0.9531, batch_loss: 0.0078, loss: 0.1360 ||:  58%|#####7    | 4142/7188 [10:06<04:06, 12.37it/s]
2022-03-21 09:03:25,650 - INFO - tqdm - f1: 0.9531, accuracy: 0.9530, batch_loss: 0.0345, loss: 0.1365 ||:  59%|#####9    | 4252/7188 [10:16<03:35, 13.64it/s]
2022-03-21 09:03:35,747 - INFO - tqdm - f1: 0.9532, accuracy: 0.9531, batch_loss: 0.1837, loss: 0.1363 ||:  61%|######    | 4364/7188 [10:26<03:18, 14.25it/s]
2022-03-21 09:03:45,800 - INFO - tqdm - f1: 0.9532, accuracy: 0.9532, batch_loss: 0.0660, loss: 0.1365 ||:  62%|######2   | 4472/7188 [10:36<03:13, 14.01it/s]
2022-03-21 09:03:55,859 - INFO - tqdm - f1: 0.9532, accuracy: 0.9532, batch_loss: 0.2659, loss: 0.1370 ||:  64%|######3   | 4580/7188 [10:46<03:04, 14.14it/s]
2022-03-21 09:04:05,965 - INFO - tqdm - f1: 0.9531, accuracy: 0.9531, batch_loss: 0.0417, loss: 0.1375 ||:  65%|######5   | 4688/7188 [10:56<02:44, 15.16it/s]
2022-03-21 09:04:16,097 - INFO - tqdm - f1: 0.9532, accuracy: 0.9532, batch_loss: 0.1847, loss: 0.1372 ||:  67%|######6   | 4796/7188 [11:06<02:40, 14.92it/s]
2022-03-21 09:04:26,137 - INFO - tqdm - f1: 0.9531, accuracy: 0.9531, batch_loss: 0.0924, loss: 0.1376 ||:  68%|######8   | 4904/7188 [11:16<02:32, 14.96it/s]
2022-03-21 09:04:36,230 - INFO - tqdm - f1: 0.9532, accuracy: 0.9532, batch_loss: 0.1496, loss: 0.1373 ||:  70%|######9   | 5012/7188 [11:26<02:27, 14.76it/s]
2022-03-21 09:04:46,252 - INFO - tqdm - f1: 0.9532, accuracy: 0.9532, batch_loss: 0.1533, loss: 0.1372 ||:  71%|#######1  | 5122/7188 [11:36<02:16, 15.18it/s]
2022-03-21 09:04:56,372 - INFO - tqdm - f1: 0.9530, accuracy: 0.9530, batch_loss: 0.0120, loss: 0.1377 ||:  73%|#######2  | 5232/7188 [11:47<02:12, 14.71it/s]
2022-03-21 09:05:06,445 - INFO - tqdm - f1: 0.9529, accuracy: 0.9529, batch_loss: 0.0572, loss: 0.1380 ||:  74%|#######4  | 5342/7188 [11:57<01:54, 16.14it/s]
2022-03-21 09:05:16,476 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.0415, loss: 0.1385 ||:  76%|#######5  | 5452/7188 [12:07<01:54, 15.20it/s]
2022-03-21 09:05:26,514 - INFO - tqdm - f1: 0.9526, accuracy: 0.9526, batch_loss: 0.0049, loss: 0.1387 ||:  77%|#######7  | 5560/7188 [12:17<01:44, 15.51it/s]
2022-03-21 09:05:36,621 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0817, loss: 0.1387 ||:  79%|#######8  | 5670/7188 [12:27<01:33, 16.20it/s]
2022-03-21 09:05:46,626 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.0918, loss: 0.1385 ||:  80%|########  | 5778/7188 [12:37<01:26, 16.38it/s]
2022-03-21 09:05:57,772 - INFO - tqdm - f1: 0.9527, accuracy: 0.9528, batch_loss: 0.0375, loss: 0.1383 ||:  82%|########1 | 5886/7188 [12:48<04:49,  4.50it/s]
2022-03-21 09:06:07,985 - INFO - tqdm - f1: 0.9527, accuracy: 0.9528, batch_loss: 0.3180, loss: 0.1383 ||:  83%|########3 | 5996/7188 [12:58<04:25,  4.48it/s]
2022-03-21 09:06:18,000 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.0779, loss: 0.1385 ||:  85%|########4 | 6098/7188 [13:08<03:58,  4.58it/s]
2022-03-21 09:06:28,055 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0190, loss: 0.1387 ||:  86%|########6 | 6200/7188 [13:18<02:24,  6.82it/s]
2022-03-21 09:06:38,113 - INFO - tqdm - f1: 0.9526, accuracy: 0.9526, batch_loss: 0.1306, loss: 0.1389 ||:  88%|########7 | 6308/7188 [13:28<01:42,  8.55it/s]
2022-03-21 09:06:48,227 - INFO - tqdm - f1: 0.9525, accuracy: 0.9525, batch_loss: 0.0637, loss: 0.1393 ||:  89%|########9 | 6420/7188 [13:38<01:09, 11.05it/s]
2022-03-21 09:06:58,344 - INFO - tqdm - f1: 0.9526, accuracy: 0.9526, batch_loss: 0.0304, loss: 0.1393 ||:  91%|######### | 6532/7188 [13:49<00:52, 12.48it/s]
2022-03-21 09:07:08,358 - INFO - tqdm - f1: 0.9527, accuracy: 0.9526, batch_loss: 0.0161, loss: 0.1393 ||:  92%|#########2| 6642/7188 [13:59<00:40, 13.57it/s]
2022-03-21 09:07:18,448 - INFO - tqdm - f1: 0.9527, accuracy: 0.9526, batch_loss: 0.0541, loss: 0.1393 ||:  94%|#########3| 6752/7188 [14:09<00:31, 13.90it/s]
2022-03-21 09:07:28,477 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.2433, loss: 0.1390 ||:  95%|#########5| 6858/7188 [14:19<00:23, 14.33it/s]
2022-03-21 09:07:38,481 - INFO - tqdm - f1: 0.9526, accuracy: 0.9525, batch_loss: 0.1537, loss: 0.1392 ||:  97%|#########6| 6966/7188 [14:29<00:15, 14.39it/s]
2022-03-21 09:07:48,484 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0526, loss: 0.1390 ||:  98%|#########8| 7074/7188 [14:39<00:08, 14.00it/s]
2022-03-21 09:07:55,704 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0130, loss: 0.1390 ||: 100%|#########9| 7154/7188 [14:46<00:02, 14.91it/s]
2022-03-21 09:07:55,836 - INFO - tqdm - f1: 0.9528, accuracy: 0.9527, batch_loss: 0.0212, loss: 0.1389 ||: 100%|#########9| 7156/7188 [14:46<00:02, 14.96it/s]
2022-03-21 09:07:55,961 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0754, loss: 0.1389 ||: 100%|#########9| 7158/7188 [14:46<00:01, 15.27it/s]
2022-03-21 09:07:56,090 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.5011, loss: 0.1390 ||: 100%|#########9| 7160/7188 [14:46<00:01, 15.33it/s]
2022-03-21 09:07:56,218 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.1512, loss: 0.1390 ||: 100%|#########9| 7162/7188 [14:46<00:01, 15.42it/s]
2022-03-21 09:07:57,389 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.2391, loss: 0.1390 ||: 100%|#########9| 7164/7188 [14:48<00:05,  4.52it/s]
2022-03-21 09:07:57,533 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0490, loss: 0.1390 ||: 100%|#########9| 7166/7188 [14:48<00:03,  5.67it/s]
2022-03-21 09:07:57,670 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.5289, loss: 0.1390 ||: 100%|#########9| 7168/7188 [14:48<00:02,  6.95it/s]
2022-03-21 09:07:57,813 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0427, loss: 0.1390 ||: 100%|#########9| 7170/7188 [14:48<00:02,  8.19it/s]
2022-03-21 09:07:57,956 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.2027, loss: 0.1390 ||: 100%|#########9| 7172/7188 [14:48<00:01,  9.35it/s]
2022-03-21 09:07:58,094 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.2713, loss: 0.1390 ||: 100%|#########9| 7174/7188 [14:48<00:01, 10.46it/s]
2022-03-21 09:07:58,227 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.3700, loss: 0.1390 ||: 100%|#########9| 7176/7188 [14:48<00:01, 11.51it/s]
2022-03-21 09:07:58,351 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.3507, loss: 0.1390 ||: 100%|#########9| 7178/7188 [14:49<00:00, 12.59it/s]
2022-03-21 09:07:58,483 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0811, loss: 0.1390 ||: 100%|#########9| 7180/7188 [14:49<00:00, 13.27it/s]
2022-03-21 09:07:58,623 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0132, loss: 0.1390 ||: 100%|#########9| 7182/7188 [14:49<00:00, 13.55it/s]
2022-03-21 09:07:58,770 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.2441, loss: 0.1390 ||: 100%|#########9| 7184/7188 [14:49<00:00, 13.57it/s]
2022-03-21 09:07:58,923 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0283, loss: 0.1390 ||: 100%|#########9| 7186/7188 [14:49<00:00, 13.41it/s]
2022-03-21 09:07:59,057 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0083, loss: 0.1389 ||: 100%|##########| 7188/7188 [14:49<00:00, 13.83it/s]
2022-03-21 09:07:59,106 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0083, loss: 0.1389 ||: 100%|##########| 7188/7188 [14:49<00:00,  8.08it/s]
2022-03-21 09:07:59,125 - INFO - allennlp.training.trainer - Validating
2022-03-21 09:07:59,127 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 09:08:09,141 - INFO - tqdm - f1: 0.9361, accuracy: 0.9360, batch_loss: 0.1360, loss: 0.1983 ||:  99%|#########8| 309/313 [00:10<00:00, 41.77it/s]
2022-03-21 09:08:09,232 - INFO - tqdm - f1: 0.9363, accuracy: 0.9362, batch_loss: 0.1216, loss: 0.1978 ||: 100%|##########| 313/313 [00:10<00:00, 30.98it/s]
2022-03-21 09:08:09,248 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_base_hyper_small_seed_13/best.th'.
2022-03-21 09:08:12,874 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 09:08:12,883 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.953  |     0.936
2022-03-21 09:08:12,895 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.953  |     0.936
2022-03-21 09:08:12,906 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 09:08:12,908 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.139  |     0.198
2022-03-21 09:08:12,909 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7579.730  |       N/A
2022-03-21 09:08:12,916 - INFO - allennlp.training.trainer - Epoch duration: 0:15:03.737356
2022-03-21 09:08:12,922 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:33:18
2022-03-21 09:08:12,934 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-21 09:08:12,946 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 09:08:12,957 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 09:08:12,970 - INFO - allennlp.training.trainer - Training
2022-03-21 09:08:12,981 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 09:08:24,077 - INFO - tqdm - f1: 0.9627, accuracy: 0.9620, batch_loss: 0.0947, loss: 0.1048 ||:   1%|1         | 79/7188 [00:11<25:45,  4.60it/s]
2022-03-21 09:08:34,173 - INFO - tqdm - f1: 0.9644, accuracy: 0.9643, batch_loss: 0.1556, loss: 0.1083 ||:   3%|2         | 189/7188 [00:21<19:52,  5.87it/s]
2022-03-21 09:08:44,250 - INFO - tqdm - f1: 0.9648, accuracy: 0.9644, batch_loss: 0.0487, loss: 0.1051 ||:   4%|4         | 297/7188 [00:31<16:22,  7.01it/s]
2022-03-21 09:08:54,350 - INFO - tqdm - f1: 0.9648, accuracy: 0.9647, batch_loss: 0.0036, loss: 0.1049 ||:   6%|5         | 405/7188 [00:41<13:53,  8.14it/s]
2022-03-21 09:09:04,386 - INFO - tqdm - f1: 0.9653, accuracy: 0.9653, batch_loss: 0.0551, loss: 0.1034 ||:   7%|7         | 511/7188 [00:51<13:46,  8.08it/s]
2022-03-21 09:09:14,520 - INFO - tqdm - f1: 0.9651, accuracy: 0.9651, batch_loss: 0.0071, loss: 0.1031 ||:   9%|8         | 619/7188 [01:01<11:21,  9.64it/s]
2022-03-21 09:09:24,590 - INFO - tqdm - f1: 0.9633, accuracy: 0.9633, batch_loss: 0.2229, loss: 0.1068 ||:  10%|#         | 727/7188 [01:11<09:43, 11.08it/s]
2022-03-21 09:09:34,715 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.1031, loss: 0.1087 ||:  12%|#1        | 833/7188 [01:21<08:57, 11.81it/s]
2022-03-21 09:09:44,747 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0574, loss: 0.1079 ||:  13%|#3        | 939/7188 [01:31<07:21, 14.16it/s]
2022-03-21 09:09:54,767 - INFO - tqdm - f1: 0.9620, accuracy: 0.9619, batch_loss: 0.0113, loss: 0.1089 ||:  15%|#4        | 1049/7188 [01:41<07:17, 14.03it/s]
2022-03-21 09:10:04,856 - INFO - tqdm - f1: 0.9617, accuracy: 0.9616, batch_loss: 0.3655, loss: 0.1091 ||:  16%|#6        | 1159/7188 [01:51<07:11, 13.97it/s]
2022-03-21 09:10:14,959 - INFO - tqdm - f1: 0.9620, accuracy: 0.9619, batch_loss: 0.1964, loss: 0.1081 ||:  18%|#7        | 1269/7188 [02:01<07:50, 12.58it/s]
2022-03-21 09:10:25,001 - INFO - tqdm - f1: 0.9618, accuracy: 0.9617, batch_loss: 0.0077, loss: 0.1091 ||:  19%|#9        | 1377/7188 [02:12<07:19, 13.23it/s]
2022-03-21 09:10:35,092 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0210, loss: 0.1087 ||:  21%|##        | 1487/7188 [02:22<06:54, 13.76it/s]
2022-03-21 09:10:45,107 - INFO - tqdm - f1: 0.9617, accuracy: 0.9617, batch_loss: 0.0055, loss: 0.1086 ||:  22%|##2       | 1595/7188 [02:32<06:26, 14.48it/s]
2022-03-21 09:10:55,222 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.0668, loss: 0.1080 ||:  24%|##3       | 1703/7188 [02:42<06:24, 14.27it/s]
2022-03-21 09:11:05,255 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.1802, loss: 0.1083 ||:  25%|##5       | 1811/7188 [02:52<06:09, 14.56it/s]
2022-03-21 09:11:15,286 - INFO - tqdm - f1: 0.9619, accuracy: 0.9619, batch_loss: 0.1408, loss: 0.1091 ||:  27%|##6       | 1915/7188 [03:02<06:17, 13.96it/s]
2022-03-21 09:11:25,297 - INFO - tqdm - f1: 0.9618, accuracy: 0.9618, batch_loss: 0.0071, loss: 0.1096 ||:  28%|##8       | 2021/7188 [03:12<06:18, 13.66it/s]
2022-03-21 09:11:35,354 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.4577, loss: 0.1086 ||:  30%|##9       | 2129/7188 [03:22<06:03, 13.90it/s]
2022-03-21 09:11:45,398 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0149, loss: 0.1086 ||:  31%|###1      | 2237/7188 [03:32<05:31, 14.94it/s]
2022-03-21 09:11:55,422 - INFO - tqdm - f1: 0.9623, accuracy: 0.9624, batch_loss: 0.0222, loss: 0.1079 ||:  33%|###2      | 2343/7188 [03:42<06:03, 13.33it/s]
2022-03-21 09:12:05,529 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0036, loss: 0.1081 ||:  34%|###4      | 2451/7188 [03:52<05:36, 14.09it/s]
2022-03-21 09:12:15,593 - INFO - tqdm - f1: 0.9624, accuracy: 0.9624, batch_loss: 0.0262, loss: 0.1080 ||:  36%|###5      | 2559/7188 [04:02<05:06, 15.10it/s]
2022-03-21 09:12:25,682 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.1215, loss: 0.1084 ||:  37%|###7      | 2667/7188 [04:12<05:06, 14.74it/s]
2022-03-21 09:12:35,803 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.1899, loss: 0.1086 ||:  39%|###8      | 2775/7188 [04:22<04:56, 14.88it/s]
2022-03-21 09:12:45,878 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0251, loss: 0.1094 ||:  40%|####      | 2883/7188 [04:32<04:28, 16.02it/s]
2022-03-21 09:12:55,954 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.0274, loss: 0.1091 ||:  42%|####1     | 2995/7188 [04:42<04:16, 16.36it/s]
2022-03-21 09:13:06,009 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0277, loss: 0.1097 ||:  43%|####3     | 3105/7188 [04:53<04:14, 16.06it/s]
2022-03-21 09:13:17,095 - INFO - tqdm - f1: 0.9623, accuracy: 0.9622, batch_loss: 0.1263, loss: 0.1097 ||:  45%|####4     | 3215/7188 [05:04<14:29,  4.57it/s]
2022-03-21 09:13:27,208 - INFO - tqdm - f1: 0.9625, accuracy: 0.9624, batch_loss: 0.1066, loss: 0.1092 ||:  46%|####6     | 3325/7188 [05:14<09:01,  7.13it/s]
2022-03-21 09:13:37,242 - INFO - tqdm - f1: 0.9624, accuracy: 0.9624, batch_loss: 0.1228, loss: 0.1096 ||:  48%|####7     | 3435/7188 [05:24<07:24,  8.43it/s]
2022-03-21 09:13:47,354 - INFO - tqdm - f1: 0.9624, accuracy: 0.9623, batch_loss: 0.0685, loss: 0.1099 ||:  49%|####9     | 3545/7188 [05:34<06:08,  9.88it/s]
2022-03-21 09:13:57,386 - INFO - tqdm - f1: 0.9625, accuracy: 0.9624, batch_loss: 0.0362, loss: 0.1099 ||:  51%|#####     | 3653/7188 [05:44<05:22, 10.95it/s]
2022-03-21 09:14:07,492 - INFO - tqdm - f1: 0.9623, accuracy: 0.9622, batch_loss: 0.4298, loss: 0.1106 ||:  52%|#####2    | 3763/7188 [05:54<04:37, 12.36it/s]
2022-03-21 09:14:17,538 - INFO - tqdm - f1: 0.9623, accuracy: 0.9622, batch_loss: 0.0054, loss: 0.1107 ||:  54%|#####3    | 3871/7188 [06:04<04:34, 12.08it/s]
2022-03-21 09:14:27,623 - INFO - tqdm - f1: 0.9619, accuracy: 0.9619, batch_loss: 0.0089, loss: 0.1110 ||:  55%|#####5    | 3981/7188 [06:14<04:00, 13.34it/s]
2022-03-21 09:14:37,647 - INFO - tqdm - f1: 0.9619, accuracy: 0.9618, batch_loss: 0.0031, loss: 0.1110 ||:  57%|#####6    | 4089/7188 [06:24<03:39, 14.15it/s]
2022-03-21 09:14:47,762 - INFO - tqdm - f1: 0.9619, accuracy: 0.9618, batch_loss: 0.2335, loss: 0.1108 ||:  58%|#####8    | 4199/7188 [06:34<03:33, 13.97it/s]
2022-03-21 09:14:57,822 - INFO - tqdm - f1: 0.9616, accuracy: 0.9615, batch_loss: 0.2356, loss: 0.1120 ||:  60%|#####9    | 4307/7188 [06:44<03:20, 14.39it/s]
2022-03-21 09:15:07,843 - INFO - tqdm - f1: 0.9615, accuracy: 0.9614, batch_loss: 0.1529, loss: 0.1123 ||:  61%|######1   | 4415/7188 [06:54<03:05, 14.94it/s]
2022-03-21 09:15:17,908 - INFO - tqdm - f1: 0.9615, accuracy: 0.9615, batch_loss: 0.0194, loss: 0.1122 ||:  63%|######2   | 4525/7188 [07:04<02:58, 14.89it/s]
2022-03-21 09:15:27,943 - INFO - tqdm - f1: 0.9615, accuracy: 0.9615, batch_loss: 0.0066, loss: 0.1124 ||:  64%|######4   | 4635/7188 [07:14<02:51, 14.89it/s]
2022-03-21 09:15:37,973 - INFO - tqdm - f1: 0.9614, accuracy: 0.9613, batch_loss: 0.1974, loss: 0.1126 ||:  66%|######5   | 4743/7188 [07:24<02:42, 15.08it/s]
2022-03-21 09:15:48,065 - INFO - tqdm - f1: 0.9615, accuracy: 0.9614, batch_loss: 0.0084, loss: 0.1123 ||:  68%|######7   | 4853/7188 [07:35<02:36, 14.91it/s]
2022-03-21 09:15:58,150 - INFO - tqdm - f1: 0.9615, accuracy: 0.9615, batch_loss: 0.1996, loss: 0.1123 ||:  69%|######9   | 4963/7188 [07:45<02:20, 15.79it/s]
2022-03-21 09:16:08,186 - INFO - tqdm - f1: 0.9615, accuracy: 0.9615, batch_loss: 0.1223, loss: 0.1121 ||:  71%|#######   | 5069/7188 [07:55<02:14, 15.75it/s]
2022-03-21 09:16:18,201 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.0085, loss: 0.1117 ||:  72%|#######1  | 5175/7188 [08:05<02:12, 15.18it/s]
2022-03-21 09:16:28,274 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.3161, loss: 0.1120 ||:  73%|#######3  | 5283/7188 [08:15<02:08, 14.79it/s]
2022-03-21 09:16:38,291 - INFO - tqdm - f1: 0.9615, accuracy: 0.9614, batch_loss: 0.0230, loss: 0.1122 ||:  75%|#######5  | 5391/7188 [08:25<02:08, 13.97it/s]
2022-03-21 09:16:48,374 - INFO - tqdm - f1: 0.9614, accuracy: 0.9614, batch_loss: 0.0967, loss: 0.1124 ||:  77%|#######6  | 5499/7188 [08:35<01:51, 15.11it/s]
2022-03-21 09:16:58,421 - INFO - tqdm - f1: 0.9614, accuracy: 0.9613, batch_loss: 0.1784, loss: 0.1123 ||:  78%|#######7  | 5605/7188 [08:45<01:43, 15.23it/s]
2022-03-21 09:17:08,470 - INFO - tqdm - f1: 0.9615, accuracy: 0.9614, batch_loss: 0.1543, loss: 0.1123 ||:  80%|#######9  | 5715/7188 [08:55<01:34, 15.62it/s]
2022-03-21 09:17:18,493 - INFO - tqdm - f1: 0.9616, accuracy: 0.9615, batch_loss: 0.1874, loss: 0.1120 ||:  81%|########1 | 5825/7188 [09:05<01:19, 17.19it/s]
2022-03-21 09:17:29,619 - INFO - tqdm - f1: 0.9615, accuracy: 0.9615, batch_loss: 0.0617, loss: 0.1122 ||:  83%|########2 | 5935/7188 [09:16<04:32,  4.61it/s]
2022-03-21 09:17:39,673 - INFO - tqdm - f1: 0.9614, accuracy: 0.9614, batch_loss: 0.1691, loss: 0.1124 ||:  84%|########4 | 6045/7188 [09:26<02:42,  7.05it/s]
2022-03-21 09:17:49,749 - INFO - tqdm - f1: 0.9615, accuracy: 0.9615, batch_loss: 0.0335, loss: 0.1123 ||:  86%|########5 | 6153/7188 [09:36<01:48,  9.53it/s]
2022-03-21 09:17:59,818 - INFO - tqdm - f1: 0.9613, accuracy: 0.9613, batch_loss: 0.0347, loss: 0.1125 ||:  87%|########7 | 6263/7188 [09:46<01:25, 10.88it/s]
2022-03-21 09:18:09,874 - INFO - tqdm - f1: 0.9613, accuracy: 0.9613, batch_loss: 0.0331, loss: 0.1126 ||:  89%|########8 | 6371/7188 [09:56<01:05, 12.43it/s]
2022-03-21 09:18:19,929 - INFO - tqdm - f1: 0.9614, accuracy: 0.9614, batch_loss: 0.0502, loss: 0.1127 ||:  90%|######### | 6481/7188 [10:06<00:53, 13.13it/s]
2022-03-21 09:18:29,964 - INFO - tqdm - f1: 0.9616, accuracy: 0.9615, batch_loss: 0.0202, loss: 0.1126 ||:  92%|#########1| 6591/7188 [10:16<00:41, 14.38it/s]
2022-03-21 09:18:40,056 - INFO - tqdm - f1: 0.9617, accuracy: 0.9616, batch_loss: 0.0066, loss: 0.1125 ||:  93%|#########3| 6701/7188 [10:27<00:35, 13.72it/s]
2022-03-21 09:18:50,141 - INFO - tqdm - f1: 0.9617, accuracy: 0.9616, batch_loss: 0.5504, loss: 0.1125 ||:  95%|#########4| 6809/7188 [10:37<00:26, 14.29it/s]
2022-03-21 09:19:00,147 - INFO - tqdm - f1: 0.9617, accuracy: 0.9616, batch_loss: 0.0724, loss: 0.1124 ||:  96%|#########6| 6917/7188 [10:47<00:18, 14.42it/s]
2022-03-21 09:19:10,227 - INFO - tqdm - f1: 0.9617, accuracy: 0.9616, batch_loss: 0.0913, loss: 0.1125 ||:  98%|#########7| 7025/7188 [10:57<00:10, 16.14it/s]
2022-03-21 09:19:20,255 - INFO - tqdm - f1: 0.9617, accuracy: 0.9616, batch_loss: 0.1127, loss: 0.1125 ||:  99%|#########9| 7133/7188 [11:07<00:03, 15.63it/s]
2022-03-21 09:19:22,572 - INFO - tqdm - f1: 0.9617, accuracy: 0.9617, batch_loss: 0.0064, loss: 0.1124 ||: 100%|#########9| 7153/7188 [11:09<00:02, 14.57it/s]
2022-03-21 09:19:22,700 - INFO - tqdm - f1: 0.9617, accuracy: 0.9617, batch_loss: 0.1164, loss: 0.1124 ||: 100%|#########9| 7155/7188 [11:09<00:02, 14.88it/s]
2022-03-21 09:19:22,853 - INFO - tqdm - f1: 0.9617, accuracy: 0.9616, batch_loss: 0.3251, loss: 0.1124 ||: 100%|#########9| 7157/7188 [11:09<00:02, 14.27it/s]
2022-03-21 09:19:23,006 - INFO - tqdm - f1: 0.9617, accuracy: 0.9616, batch_loss: 0.3308, loss: 0.1124 ||: 100%|#########9| 7159/7188 [11:10<00:02, 13.90it/s]
2022-03-21 09:19:23,145 - INFO - tqdm - f1: 0.9617, accuracy: 0.9616, batch_loss: 0.2288, loss: 0.1124 ||: 100%|#########9| 7161/7188 [11:10<00:01, 14.05it/s]
2022-03-21 09:19:23,287 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.0651, loss: 0.1125 ||: 100%|#########9| 7163/7188 [11:10<00:01, 14.07it/s]
2022-03-21 09:19:23,405 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.0126, loss: 0.1125 ||: 100%|#########9| 7165/7188 [11:10<00:01, 14.79it/s]
2022-03-21 09:19:23,530 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.1633, loss: 0.1125 ||: 100%|#########9| 7167/7188 [11:10<00:01, 15.15it/s]
2022-03-21 09:19:24,778 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.0427, loss: 0.1125 ||: 100%|#########9| 7169/7188 [11:11<00:04,  4.28it/s]
2022-03-21 09:19:24,926 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.0218, loss: 0.1125 ||: 100%|#########9| 7171/7188 [11:11<00:03,  5.39it/s]
2022-03-21 09:19:25,065 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.2600, loss: 0.1125 ||: 100%|#########9| 7173/7188 [11:12<00:02,  6.63it/s]
2022-03-21 09:19:25,209 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.2125, loss: 0.1125 ||: 100%|#########9| 7175/7188 [11:12<00:01,  7.87it/s]
2022-03-21 09:19:25,342 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.0280, loss: 0.1125 ||: 100%|#########9| 7177/7188 [11:12<00:01,  9.18it/s]
2022-03-21 09:19:25,472 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.0235, loss: 0.1125 ||: 100%|#########9| 7179/7188 [11:12<00:00, 10.45it/s]
2022-03-21 09:19:25,597 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.1008, loss: 0.1125 ||: 100%|#########9| 7181/7188 [11:12<00:00, 11.66it/s]
2022-03-21 09:19:25,747 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.0609, loss: 0.1125 ||: 100%|#########9| 7183/7188 [11:12<00:00, 12.12it/s]
2022-03-21 09:19:25,884 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.1513, loss: 0.1125 ||: 100%|#########9| 7185/7188 [11:12<00:00, 12.76it/s]
2022-03-21 09:19:26,031 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.6831, loss: 0.1126 ||: 100%|#########9| 7187/7188 [11:13<00:00, 12.99it/s]
2022-03-21 09:19:26,154 - INFO - tqdm - f1: 0.9616, accuracy: 0.9616, batch_loss: 0.4373, loss: 0.1126 ||: 100%|##########| 7188/7188 [11:13<00:00, 10.68it/s]
2022-03-21 09:19:26,197 - INFO - allennlp.training.trainer - Validating
2022-03-21 09:19:26,215 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 09:19:36,271 - INFO - tqdm - f1: 0.9345, accuracy: 0.9344, batch_loss: 0.7157, loss: 0.2121 ||: 100%|##########| 313/313 [00:10<00:00, 31.17it/s]
2022-03-21 09:19:36,326 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 09:19:36,332 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.962  |     0.934
2022-03-21 09:19:36,347 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.962  |     0.935
2022-03-21 09:19:36,363 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 09:19:36,378 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.113  |     0.212
2022-03-21 09:19:36,393 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7579.891  |       N/A
2022-03-21 09:19:36,411 - INFO - allennlp.training.trainer - Epoch duration: 0:11:23.477132
2022-03-21 09:19:36,425 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:55:38
2022-03-21 09:19:36,439 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-21 09:19:36,457 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 09:19:36,472 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 09:19:36,488 - INFO - allennlp.training.trainer - Training
2022-03-21 09:19:36,503 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 09:19:46,608 - INFO - tqdm - f1: 0.9578, accuracy: 0.9592, batch_loss: 0.0196, loss: 0.1020 ||:   1%|1         | 101/7188 [00:10<07:28, 15.78it/s]
2022-03-21 09:19:56,717 - INFO - tqdm - f1: 0.9657, accuracy: 0.9662, batch_loss: 0.0096, loss: 0.0903 ||:   3%|2         | 211/7188 [00:20<07:17, 15.94it/s]
2022-03-21 09:20:07,856 - INFO - tqdm - f1: 0.9687, accuracy: 0.9688, batch_loss: 0.0396, loss: 0.0872 ||:   4%|4         | 321/7188 [00:31<24:50,  4.61it/s]
2022-03-21 09:20:17,886 - INFO - tqdm - f1: 0.9683, accuracy: 0.9685, batch_loss: 0.1635, loss: 0.0905 ||:   6%|5         | 429/7188 [00:41<24:18,  4.64it/s]
2022-03-21 09:20:27,906 - INFO - tqdm - f1: 0.9692, accuracy: 0.9695, batch_loss: 0.4877, loss: 0.0894 ||:   7%|7         | 537/7188 [00:51<19:21,  5.73it/s]
2022-03-21 09:20:37,935 - INFO - tqdm - f1: 0.9693, accuracy: 0.9695, batch_loss: 0.0880, loss: 0.0893 ||:   9%|8         | 645/7188 [01:01<15:07,  7.21it/s]
2022-03-21 09:20:48,057 - INFO - tqdm - f1: 0.9697, accuracy: 0.9699, batch_loss: 0.0175, loss: 0.0881 ||:  11%|#         | 755/7188 [01:11<10:56,  9.80it/s]
2022-03-21 09:20:58,169 - INFO - tqdm - f1: 0.9705, accuracy: 0.9707, batch_loss: 0.1461, loss: 0.0864 ||:  12%|#2        | 867/7188 [01:21<07:41, 13.71it/s]
2022-03-21 09:21:08,257 - INFO - tqdm - f1: 0.9708, accuracy: 0.9710, batch_loss: 0.0048, loss: 0.0865 ||:  14%|#3        | 975/7188 [01:31<07:30, 13.80it/s]
2022-03-21 09:21:18,377 - INFO - tqdm - f1: 0.9705, accuracy: 0.9707, batch_loss: 0.1583, loss: 0.0881 ||:  15%|#5        | 1085/7188 [01:41<06:43, 15.14it/s]
2022-03-21 09:21:28,399 - INFO - tqdm - f1: 0.9702, accuracy: 0.9703, batch_loss: 0.1225, loss: 0.0886 ||:  17%|#6        | 1195/7188 [01:51<06:45, 14.78it/s]
2022-03-21 09:21:38,441 - INFO - tqdm - f1: 0.9706, accuracy: 0.9707, batch_loss: 0.0996, loss: 0.0866 ||:  18%|#8        | 1309/7188 [02:01<06:09, 15.91it/s]
2022-03-21 09:21:48,505 - INFO - tqdm - f1: 0.9708, accuracy: 0.9709, batch_loss: 0.0161, loss: 0.0862 ||:  20%|#9        | 1423/7188 [02:11<06:19, 15.20it/s]
2022-03-21 09:21:58,542 - INFO - tqdm - f1: 0.9701, accuracy: 0.9701, batch_loss: 0.0320, loss: 0.0881 ||:  21%|##1       | 1533/7188 [02:22<06:17, 14.99it/s]
2022-03-21 09:22:08,616 - INFO - tqdm - f1: 0.9703, accuracy: 0.9704, batch_loss: 0.0126, loss: 0.0872 ||:  23%|##2       | 1643/7188 [02:32<06:07, 15.10it/s]
2022-03-21 09:22:18,709 - INFO - tqdm - f1: 0.9703, accuracy: 0.9704, batch_loss: 0.0152, loss: 0.0871 ||:  24%|##4       | 1751/7188 [02:42<06:12, 14.60it/s]
2022-03-21 09:22:28,724 - INFO - tqdm - f1: 0.9707, accuracy: 0.9708, batch_loss: 0.0089, loss: 0.0860 ||:  26%|##5       | 1855/7188 [02:52<06:22, 13.95it/s]
2022-03-21 09:22:38,843 - INFO - tqdm - f1: 0.9707, accuracy: 0.9708, batch_loss: 0.0141, loss: 0.0859 ||:  27%|##7       | 1959/7188 [03:02<06:23, 13.62it/s]
2022-03-21 09:22:48,964 - INFO - tqdm - f1: 0.9712, accuracy: 0.9714, batch_loss: 0.0423, loss: 0.0851 ||:  29%|##8       | 2069/7188 [03:12<05:39, 15.09it/s]
2022-03-21 09:22:59,086 - INFO - tqdm - f1: 0.9712, accuracy: 0.9713, batch_loss: 0.0144, loss: 0.0861 ||:  30%|###       | 2177/7188 [03:22<05:40, 14.73it/s]
2022-03-21 09:23:09,142 - INFO - tqdm - f1: 0.9709, accuracy: 0.9710, batch_loss: 0.0290, loss: 0.0868 ||:  32%|###1      | 2285/7188 [03:32<05:35, 14.61it/s]
2022-03-21 09:23:19,241 - INFO - tqdm - f1: 0.9706, accuracy: 0.9707, batch_loss: 0.0382, loss: 0.0875 ||:  33%|###3      | 2395/7188 [03:42<05:00, 15.96it/s]
2022-03-21 09:23:29,252 - INFO - tqdm - f1: 0.9705, accuracy: 0.9706, batch_loss: 0.4042, loss: 0.0875 ||:  35%|###4      | 2503/7188 [03:52<04:47, 16.29it/s]
2022-03-21 09:23:40,392 - INFO - tqdm - f1: 0.9706, accuracy: 0.9707, batch_loss: 0.0196, loss: 0.0872 ||:  36%|###6      | 2613/7188 [04:03<16:46,  4.55it/s]
2022-03-21 09:23:50,405 - INFO - tqdm - f1: 0.9705, accuracy: 0.9706, batch_loss: 0.1140, loss: 0.0876 ||:  38%|###7      | 2721/7188 [04:13<16:26,  4.53it/s]
2022-03-21 09:24:00,526 - INFO - tqdm - f1: 0.9705, accuracy: 0.9706, batch_loss: 0.1088, loss: 0.0875 ||:  39%|###9      | 2829/7188 [04:24<12:45,  5.70it/s]
2022-03-21 09:24:10,533 - INFO - tqdm - f1: 0.9705, accuracy: 0.9706, batch_loss: 0.0294, loss: 0.0874 ||:  41%|####      | 2935/7188 [04:34<10:05,  7.03it/s]
2022-03-21 09:24:20,623 - INFO - tqdm - f1: 0.9704, accuracy: 0.9705, batch_loss: 0.4181, loss: 0.0878 ||:  42%|####2     | 3041/7188 [04:44<08:53,  7.77it/s]
2022-03-21 09:24:30,750 - INFO - tqdm - f1: 0.9708, accuracy: 0.9708, batch_loss: 0.0104, loss: 0.0865 ||:  44%|####4     | 3173/7188 [04:54<04:43, 14.15it/s]
2022-03-21 09:24:40,822 - INFO - tqdm - f1: 0.9709, accuracy: 0.9709, batch_loss: 0.1365, loss: 0.0867 ||:  46%|####5     | 3303/7188 [05:04<04:51, 13.32it/s]
2022-03-21 09:24:50,918 - INFO - tqdm - f1: 0.9708, accuracy: 0.9708, batch_loss: 0.0998, loss: 0.0867 ||:  48%|####7     | 3447/7188 [05:14<04:12, 14.84it/s]
2022-03-21 09:25:01,047 - INFO - tqdm - f1: 0.9706, accuracy: 0.9706, batch_loss: 0.0585, loss: 0.0880 ||:  50%|####9     | 3591/7188 [05:24<04:11, 14.28it/s]
2022-03-21 09:25:11,113 - INFO - tqdm - f1: 0.9705, accuracy: 0.9705, batch_loss: 0.0394, loss: 0.0884 ||:  52%|#####2    | 3741/7188 [05:34<03:50, 14.96it/s]
2022-03-21 09:25:21,130 - INFO - tqdm - f1: 0.9703, accuracy: 0.9703, batch_loss: 0.1432, loss: 0.0885 ||:  54%|#####4    | 3891/7188 [05:44<03:30, 15.69it/s]
2022-03-21 09:25:31,213 - INFO - tqdm - f1: 0.9701, accuracy: 0.9702, batch_loss: 0.0739, loss: 0.0893 ||:  56%|#####6    | 4043/7188 [05:54<03:11, 16.43it/s]
2022-03-21 09:25:41,311 - INFO - tqdm - f1: 0.9704, accuracy: 0.9704, batch_loss: 0.0503, loss: 0.0888 ||:  58%|#####8    | 4199/7188 [06:04<03:11, 15.60it/s]
2022-03-21 09:25:51,316 - INFO - tqdm - f1: 0.9701, accuracy: 0.9701, batch_loss: 0.0325, loss: 0.0895 ||:  61%|######    | 4353/7188 [06:14<02:53, 16.35it/s]
2022-03-21 09:26:01,481 - INFO - tqdm - f1: 0.9699, accuracy: 0.9699, batch_loss: 0.4544, loss: 0.0898 ||:  63%|######2   | 4505/7188 [06:24<03:13, 13.87it/s]
2022-03-21 09:26:11,576 - INFO - tqdm - f1: 0.9699, accuracy: 0.9699, batch_loss: 0.0087, loss: 0.0898 ||:  65%|######4   | 4651/7188 [06:35<03:11, 13.28it/s]
2022-03-21 09:26:21,676 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0401, loss: 0.0900 ||:  67%|######6   | 4801/7188 [06:45<02:44, 14.47it/s]
2022-03-21 09:26:31,776 - INFO - tqdm - f1: 0.9697, accuracy: 0.9697, batch_loss: 0.0432, loss: 0.0902 ||:  69%|######8   | 4953/7188 [06:55<02:33, 14.57it/s]
2022-03-21 09:26:41,887 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.5009, loss: 0.0904 ||:  71%|#######   | 5103/7188 [07:05<02:15, 15.42it/s]
2022-03-21 09:26:51,920 - INFO - tqdm - f1: 0.9697, accuracy: 0.9697, batch_loss: 0.0035, loss: 0.0908 ||:  73%|#######3  | 5255/7188 [07:15<02:14, 14.38it/s]
2022-03-21 09:27:01,940 - INFO - tqdm - f1: 0.9696, accuracy: 0.9696, batch_loss: 0.0784, loss: 0.0908 ||:  75%|#######5  | 5403/7188 [07:25<02:13, 13.40it/s]
2022-03-21 09:27:11,992 - INFO - tqdm - f1: 0.9694, accuracy: 0.9694, batch_loss: 0.4827, loss: 0.0911 ||:  77%|#######7  | 5555/7188 [07:35<01:39, 16.37it/s]
2022-03-21 09:27:22,018 - INFO - tqdm - f1: 0.9693, accuracy: 0.9693, batch_loss: 0.1663, loss: 0.0913 ||:  79%|#######9  | 5707/7188 [07:45<01:43, 14.35it/s]
2022-03-21 09:27:32,065 - INFO - tqdm - f1: 0.9693, accuracy: 0.9694, batch_loss: 0.0289, loss: 0.0914 ||:  81%|########1 | 5857/7188 [07:55<01:30, 14.77it/s]
2022-03-21 09:27:42,171 - INFO - tqdm - f1: 0.9692, accuracy: 0.9692, batch_loss: 0.0273, loss: 0.0915 ||:  84%|########3 | 6013/7188 [08:05<01:11, 16.44it/s]
2022-03-21 09:27:52,280 - INFO - tqdm - f1: 0.9692, accuracy: 0.9692, batch_loss: 0.0600, loss: 0.0915 ||:  86%|########5 | 6161/7188 [08:15<01:13, 14.05it/s]
2022-03-21 09:28:02,363 - INFO - tqdm - f1: 0.9692, accuracy: 0.9692, batch_loss: 0.0945, loss: 0.0917 ||:  88%|########7 | 6311/7188 [08:25<00:57, 15.37it/s]
2022-03-21 09:28:12,407 - INFO - tqdm - f1: 0.9693, accuracy: 0.9692, batch_loss: 0.0474, loss: 0.0916 ||:  90%|########9 | 6463/7188 [08:35<00:46, 15.75it/s]
2022-03-21 09:28:22,460 - INFO - tqdm - f1: 0.9692, accuracy: 0.9692, batch_loss: 0.1259, loss: 0.0918 ||:  92%|#########2| 6615/7188 [08:45<00:37, 15.32it/s]
2022-03-21 09:28:32,540 - INFO - tqdm - f1: 0.9693, accuracy: 0.9693, batch_loss: 0.1023, loss: 0.0918 ||:  94%|#########4| 6763/7188 [08:56<00:27, 15.72it/s]
2022-03-21 09:28:42,559 - INFO - tqdm - f1: 0.9692, accuracy: 0.9692, batch_loss: 0.0136, loss: 0.0920 ||:  96%|#########6| 6907/7188 [09:06<00:19, 14.46it/s]
2022-03-21 09:28:52,648 - INFO - tqdm - f1: 0.9692, accuracy: 0.9692, batch_loss: 0.0071, loss: 0.0920 ||:  98%|#########8| 7055/7188 [09:16<00:09, 14.14it/s]
2022-03-21 09:28:59,043 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.4406, loss: 0.0923 ||: 100%|#########9| 7153/7188 [09:22<00:02, 14.94it/s]
2022-03-21 09:28:59,172 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0742, loss: 0.0923 ||: 100%|#########9| 7155/7188 [09:22<00:02, 15.13it/s]
2022-03-21 09:28:59,297 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0404, loss: 0.0923 ||: 100%|#########9| 7157/7188 [09:22<00:02, 15.36it/s]
2022-03-21 09:28:59,439 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0824, loss: 0.0923 ||: 100%|#########9| 7159/7188 [09:22<00:01, 14.98it/s]
2022-03-21 09:28:59,559 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0053, loss: 0.0923 ||: 100%|#########9| 7161/7188 [09:23<00:01, 15.45it/s]
2022-03-21 09:28:59,672 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.1271, loss: 0.0923 ||: 100%|#########9| 7163/7188 [09:23<00:01, 16.04it/s]
2022-03-21 09:28:59,841 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0709, loss: 0.0923 ||: 100%|#########9| 7165/7188 [09:23<00:01, 14.50it/s]
2022-03-21 09:28:59,973 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.2459, loss: 0.0923 ||: 100%|#########9| 7167/7188 [09:23<00:01, 14.68it/s]
2022-03-21 09:29:00,091 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0340, loss: 0.0923 ||: 100%|#########9| 7169/7188 [09:23<00:01, 15.30it/s]
2022-03-21 09:29:00,220 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0157, loss: 0.0923 ||: 100%|#########9| 7171/7188 [09:23<00:01, 15.36it/s]
2022-03-21 09:29:00,363 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0607, loss: 0.0923 ||: 100%|#########9| 7173/7188 [09:23<00:01, 14.91it/s]
2022-03-21 09:29:00,496 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.2178, loss: 0.0924 ||: 100%|#########9| 7175/7188 [09:23<00:00, 14.97it/s]
2022-03-21 09:29:00,676 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0048, loss: 0.0923 ||: 100%|#########9| 7177/7188 [09:24<00:00, 13.55it/s]
2022-03-21 09:29:00,851 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0515, loss: 0.0923 ||: 100%|#########9| 7179/7188 [09:24<00:00, 12.84it/s]
2022-03-21 09:29:00,983 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0676, loss: 0.0923 ||: 100%|#########9| 7181/7188 [09:24<00:00, 13.45it/s]
2022-03-21 09:29:01,123 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.2066, loss: 0.0923 ||: 100%|#########9| 7183/7188 [09:24<00:00, 13.70it/s]
2022-03-21 09:29:01,257 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0044, loss: 0.0923 ||: 100%|#########9| 7185/7188 [09:24<00:00, 14.03it/s]
2022-03-21 09:29:01,401 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0582, loss: 0.0923 ||: 100%|#########9| 7187/7188 [09:24<00:00, 13.99it/s]
2022-03-21 09:29:01,540 - INFO - tqdm - f1: 0.9691, accuracy: 0.9691, batch_loss: 0.0292, loss: 0.0923 ||: 100%|##########| 7188/7188 [09:25<00:00, 12.72it/s]
2022-03-21 09:29:01,588 - INFO - allennlp.training.trainer - Validating
2022-03-21 09:29:01,621 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 09:29:09,327 - INFO - tqdm - f1: 0.9348, accuracy: 0.9346, batch_loss: 0.0051, loss: 0.2277 ||: 100%|##########| 313/313 [00:07<00:00, 40.75it/s]
2022-03-21 09:29:09,336 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 09:29:09,338 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.969  |     0.935
2022-03-21 09:29:09,339 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.969  |     0.935
2022-03-21 09:29:09,340 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 09:29:09,341 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.092  |     0.228
2022-03-21 09:29:09,342 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7579.891  |       N/A
2022-03-21 09:29:09,344 - INFO - allennlp.training.trainer - Epoch duration: 0:09:32.904858
2022-03-21 09:29:09,346 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:26:38
2022-03-21 09:29:09,347 - INFO - allennlp.training.trainer - Epoch 5/9
2022-03-21 09:29:09,349 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 09:29:09,350 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 09:29:09,353 - INFO - allennlp.training.trainer - Training
2022-03-21 09:29:09,354 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 09:29:19,448 - INFO - tqdm - f1: 0.9819, accuracy: 0.9823, batch_loss: 0.2241, loss: 0.0606 ||:   2%|1         | 141/7188 [00:10<07:45, 15.14it/s]
2022-03-21 09:29:29,528 - INFO - tqdm - f1: 0.9759, accuracy: 0.9758, batch_loss: 0.0449, loss: 0.0694 ||:   4%|3         | 287/7188 [00:20<10:09, 11.32it/s]
2022-03-21 09:29:39,762 - INFO - tqdm - f1: 0.9744, accuracy: 0.9744, batch_loss: 0.0349, loss: 0.0716 ||:   5%|5         | 374/7188 [00:30<24:55,  4.56it/s]
2022-03-21 09:29:49,804 - INFO - tqdm - f1: 0.9751, accuracy: 0.9750, batch_loss: 0.0301, loss: 0.0705 ||:   7%|6         | 485/7188 [00:40<08:42, 12.83it/s]
2022-03-21 09:29:59,872 - INFO - tqdm - f1: 0.9763, accuracy: 0.9763, batch_loss: 0.0063, loss: 0.0672 ||:   9%|8         | 617/7188 [00:50<07:21, 14.88it/s]
2022-03-21 09:30:09,935 - INFO - tqdm - f1: 0.9764, accuracy: 0.9763, batch_loss: 0.0044, loss: 0.0690 ||:  11%|#         | 761/7188 [01:00<07:22, 14.53it/s]
2022-03-21 09:30:19,988 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0609, loss: 0.0702 ||:  13%|#2        | 909/7188 [01:10<06:52, 15.23it/s]
2022-03-21 09:30:30,050 - INFO - tqdm - f1: 0.9757, accuracy: 0.9758, batch_loss: 0.0056, loss: 0.0693 ||:  15%|#4        | 1057/7188 [01:20<06:38, 15.40it/s]
2022-03-21 09:30:40,188 - INFO - tqdm - f1: 0.9753, accuracy: 0.9754, batch_loss: 0.0101, loss: 0.0720 ||:  17%|#6        | 1207/7188 [01:30<07:01, 14.20it/s]
2022-03-21 09:30:50,305 - INFO - tqdm - f1: 0.9754, accuracy: 0.9755, batch_loss: 0.1367, loss: 0.0720 ||:  19%|#8        | 1359/7188 [01:40<06:36, 14.70it/s]
2022-03-21 09:31:00,412 - INFO - tqdm - f1: 0.9758, accuracy: 0.9759, batch_loss: 0.1013, loss: 0.0718 ||:  21%|##1       | 1511/7188 [01:51<06:43, 14.07it/s]
2022-03-21 09:31:10,436 - INFO - tqdm - f1: 0.9763, accuracy: 0.9765, batch_loss: 0.2616, loss: 0.0709 ||:  23%|##3       | 1657/7188 [02:01<06:36, 13.96it/s]
2022-03-21 09:31:20,462 - INFO - tqdm - f1: 0.9762, accuracy: 0.9763, batch_loss: 0.0037, loss: 0.0711 ||:  25%|##5       | 1803/7188 [02:11<06:40, 13.46it/s]
2022-03-21 09:31:30,474 - INFO - tqdm - f1: 0.9759, accuracy: 0.9760, batch_loss: 0.2757, loss: 0.0717 ||:  27%|##7       | 1949/7188 [02:21<06:18, 13.83it/s]
2022-03-21 09:31:40,591 - INFO - tqdm - f1: 0.9758, accuracy: 0.9759, batch_loss: 0.0915, loss: 0.0722 ||:  29%|##9       | 2099/7188 [02:31<05:43, 14.80it/s]
2022-03-21 09:31:50,642 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.0086, loss: 0.0724 ||:  31%|###1      | 2247/7188 [02:41<05:45, 14.30it/s]
2022-03-21 09:32:00,751 - INFO - tqdm - f1: 0.9757, accuracy: 0.9758, batch_loss: 0.0110, loss: 0.0728 ||:  33%|###3      | 2399/7188 [02:51<05:00, 15.95it/s]
2022-03-21 09:32:10,794 - INFO - tqdm - f1: 0.9758, accuracy: 0.9759, batch_loss: 0.0281, loss: 0.0729 ||:  35%|###5      | 2547/7188 [03:01<05:01, 15.41it/s]
2022-03-21 09:32:20,865 - INFO - tqdm - f1: 0.9759, accuracy: 0.9759, batch_loss: 0.0153, loss: 0.0729 ||:  37%|###7      | 2695/7188 [03:11<04:40, 15.99it/s]
2022-03-21 09:32:30,968 - INFO - tqdm - f1: 0.9757, accuracy: 0.9758, batch_loss: 0.0040, loss: 0.0733 ||:  40%|###9      | 2843/7188 [03:21<04:38, 15.61it/s]
2022-03-21 09:32:40,983 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.0506, loss: 0.0732 ||:  42%|####1     | 2989/7188 [03:31<04:45, 14.69it/s]
2022-03-21 09:32:51,065 - INFO - tqdm - f1: 0.9756, accuracy: 0.9757, batch_loss: 0.0211, loss: 0.0731 ||:  44%|####3     | 3135/7188 [03:41<04:22, 15.46it/s]
2022-03-21 09:33:01,132 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.0994, loss: 0.0735 ||:  46%|####5     | 3283/7188 [03:51<04:27, 14.59it/s]
2022-03-21 09:33:11,158 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.1134, loss: 0.0732 ||:  48%|####7     | 3429/7188 [04:01<04:08, 15.10it/s]
2022-03-21 09:33:21,217 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.1204, loss: 0.0734 ||:  50%|####9     | 3575/7188 [04:11<04:04, 14.80it/s]
2022-03-21 09:33:31,229 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.0220, loss: 0.0732 ||:  52%|#####1    | 3723/7188 [04:21<03:57, 14.56it/s]
2022-03-21 09:33:41,297 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.0378, loss: 0.0729 ||:  54%|#####3    | 3863/7188 [04:31<04:12, 13.14it/s]
2022-03-21 09:33:51,345 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.1265, loss: 0.0730 ||:  56%|#####5    | 4011/7188 [04:41<03:47, 13.97it/s]
2022-03-21 09:34:01,386 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.0091, loss: 0.0734 ||:  58%|#####7    | 4161/7188 [04:52<03:18, 15.25it/s]
2022-03-21 09:34:11,524 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.1487, loss: 0.0732 ||:  60%|#####9    | 4307/7188 [05:02<03:20, 14.37it/s]
2022-03-21 09:34:21,602 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.0543, loss: 0.0736 ||:  62%|######1   | 4455/7188 [05:12<03:04, 14.78it/s]
2022-03-21 09:34:31,639 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0876, loss: 0.0737 ||:  64%|######4   | 4603/7188 [05:22<02:51, 15.10it/s]
2022-03-21 09:34:41,644 - INFO - tqdm - f1: 0.9749, accuracy: 0.9749, batch_loss: 0.0723, loss: 0.0742 ||:  66%|######6   | 4751/7188 [05:32<02:47, 14.53it/s]
2022-03-21 09:34:51,725 - INFO - tqdm - f1: 0.9750, accuracy: 0.9750, batch_loss: 0.0088, loss: 0.0743 ||:  68%|######8   | 4897/7188 [05:42<02:28, 15.47it/s]
2022-03-21 09:35:01,787 - INFO - tqdm - f1: 0.9749, accuracy: 0.9749, batch_loss: 0.0368, loss: 0.0742 ||:  70%|#######   | 5043/7188 [05:52<02:18, 15.54it/s]
2022-03-21 09:35:11,833 - INFO - tqdm - f1: 0.9747, accuracy: 0.9747, batch_loss: 0.1507, loss: 0.0745 ||:  72%|#######2  | 5191/7188 [06:02<02:14, 14.88it/s]
2022-03-21 09:35:21,942 - INFO - tqdm - f1: 0.9747, accuracy: 0.9747, batch_loss: 0.0065, loss: 0.0748 ||:  74%|#######4  | 5347/7188 [06:12<01:54, 16.09it/s]
2022-03-21 09:35:32,088 - INFO - tqdm - f1: 0.9747, accuracy: 0.9747, batch_loss: 0.0020, loss: 0.0747 ||:  77%|#######6  | 5501/7188 [06:22<01:51, 15.16it/s]
2022-03-21 09:35:42,196 - INFO - tqdm - f1: 0.9745, accuracy: 0.9745, batch_loss: 0.3252, loss: 0.0750 ||:  79%|#######8  | 5653/7188 [06:32<01:38, 15.65it/s]
2022-03-21 09:35:52,271 - INFO - tqdm - f1: 0.9744, accuracy: 0.9743, batch_loss: 0.0291, loss: 0.0755 ||:  81%|########  | 5803/7188 [06:42<01:30, 15.23it/s]
2022-03-21 09:36:02,279 - INFO - tqdm - f1: 0.9742, accuracy: 0.9742, batch_loss: 0.0037, loss: 0.0761 ||:  83%|########2 | 5951/7188 [06:52<01:26, 14.24it/s]
2022-03-21 09:36:12,395 - INFO - tqdm - f1: 0.9740, accuracy: 0.9740, batch_loss: 0.1651, loss: 0.0765 ||:  85%|########4 | 6097/7188 [07:03<01:18, 13.92it/s]
2022-03-21 09:36:22,499 - INFO - tqdm - f1: 0.9741, accuracy: 0.9741, batch_loss: 0.0124, loss: 0.0764 ||:  87%|########6 | 6245/7188 [07:13<01:08, 13.85it/s]
2022-03-21 09:36:32,514 - INFO - tqdm - f1: 0.9740, accuracy: 0.9739, batch_loss: 0.0310, loss: 0.0768 ||:  89%|########8 | 6393/7188 [07:23<00:55, 14.24it/s]
2022-03-21 09:36:42,648 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0327, loss: 0.0771 ||:  91%|#########1| 6543/7188 [07:33<00:48, 13.25it/s]
2022-03-21 09:36:52,679 - INFO - tqdm - f1: 0.9740, accuracy: 0.9740, batch_loss: 0.0473, loss: 0.0767 ||:  93%|#########3| 6695/7188 [07:43<00:32, 14.96it/s]
2022-03-21 09:37:02,706 - INFO - tqdm - f1: 0.9740, accuracy: 0.9740, batch_loss: 0.0103, loss: 0.0769 ||:  95%|#########5| 6847/7188 [07:53<00:22, 15.00it/s]
2022-03-21 09:37:12,707 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0118, loss: 0.0773 ||:  97%|#########7| 6987/7188 [08:03<00:14, 13.63it/s]
2022-03-21 09:37:22,825 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0190, loss: 0.0775 ||:  99%|#########9| 7133/7188 [08:13<00:03, 14.51it/s]
2022-03-21 09:37:24,187 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0818, loss: 0.0774 ||: 100%|#########9| 7153/7188 [08:14<00:02, 14.36it/s]
2022-03-21 09:37:24,357 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0995, loss: 0.0774 ||: 100%|#########9| 7155/7188 [08:15<00:02, 13.49it/s]
2022-03-21 09:37:24,528 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0398, loss: 0.0774 ||: 100%|#########9| 7157/7188 [08:15<00:02, 12.88it/s]
2022-03-21 09:37:24,699 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0251, loss: 0.0774 ||: 100%|#########9| 7159/7188 [08:15<00:02, 12.50it/s]
2022-03-21 09:37:24,835 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0126, loss: 0.0774 ||: 100%|#########9| 7161/7188 [08:15<00:02, 13.10it/s]
2022-03-21 09:37:24,977 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0774, loss: 0.0774 ||: 100%|#########9| 7163/7188 [08:15<00:01, 13.37it/s]
2022-03-21 09:37:25,104 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0113, loss: 0.0774 ||: 100%|#########9| 7165/7188 [08:15<00:01, 14.03it/s]
2022-03-21 09:37:25,258 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.1140, loss: 0.0774 ||: 100%|#########9| 7167/7188 [08:15<00:01, 13.69it/s]
2022-03-21 09:37:25,428 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0046, loss: 0.0774 ||: 100%|#########9| 7169/7188 [08:16<00:01, 13.06it/s]
2022-03-21 09:37:25,600 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0330, loss: 0.0774 ||: 100%|#########9| 7171/7188 [08:16<00:01, 12.58it/s]
2022-03-21 09:37:25,756 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0057, loss: 0.0774 ||: 100%|#########9| 7173/7188 [08:16<00:01, 12.65it/s]
2022-03-21 09:37:25,900 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0894, loss: 0.0774 ||: 100%|#########9| 7175/7188 [08:16<00:00, 13.01it/s]
2022-03-21 09:37:26,035 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0924, loss: 0.0774 ||: 100%|#########9| 7177/7188 [08:16<00:00, 13.49it/s]
2022-03-21 09:37:26,168 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0234, loss: 0.0774 ||: 100%|#########9| 7179/7188 [08:16<00:00, 13.91it/s]
2022-03-21 09:37:26,328 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.1366, loss: 0.0774 ||: 100%|#########9| 7181/7188 [08:16<00:00, 13.47it/s]
2022-03-21 09:37:26,494 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0099, loss: 0.0774 ||: 100%|#########9| 7183/7188 [08:17<00:00, 13.01it/s]
2022-03-21 09:37:26,662 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.0978, loss: 0.0773 ||: 100%|#########9| 7185/7188 [08:17<00:00, 12.66it/s]
2022-03-21 09:37:26,812 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.2041, loss: 0.0774 ||: 100%|#########9| 7187/7188 [08:17<00:00, 12.86it/s]
2022-03-21 09:37:26,929 - INFO - tqdm - f1: 0.9739, accuracy: 0.9739, batch_loss: 0.1269, loss: 0.0774 ||: 100%|##########| 7188/7188 [08:17<00:00, 14.45it/s]
2022-03-21 09:37:26,974 - INFO - allennlp.training.trainer - Validating
2022-03-21 09:37:26,977 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 09:37:34,575 - INFO - tqdm - f1: 0.9410, accuracy: 0.9410, batch_loss: 0.0056, loss: 0.2502 ||: 100%|##########| 313/313 [00:07<00:00, 41.20it/s]
2022-03-21 09:37:34,634 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_base_hyper_small_seed_13/best.th'.
2022-03-21 09:37:39,004 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 09:37:39,021 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.974  |     0.941
2022-03-21 09:37:39,040 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.974  |     0.941
2022-03-21 09:37:39,058 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 09:37:39,077 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.077  |     0.250
2022-03-21 09:37:39,096 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7579.891  |       N/A
2022-03-21 09:37:39,115 - INFO - allennlp.training.trainer - Epoch duration: 0:08:29.767723
2022-03-21 09:37:39,134 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:03:25
2022-03-21 09:37:39,135 - INFO - allennlp.training.trainer - Epoch 6/9
2022-03-21 09:37:39,136 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 09:37:39,138 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 09:37:39,162 - INFO - allennlp.training.trainer - Training
2022-03-21 09:37:39,181 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 09:37:49,201 - INFO - tqdm - f1: 0.9837, accuracy: 0.9840, batch_loss: 0.0112, loss: 0.0447 ||:   2%|1         | 141/7188 [00:10<07:28, 15.73it/s]
2022-03-21 09:37:59,289 - INFO - tqdm - f1: 0.9832, accuracy: 0.9835, batch_loss: 0.0021, loss: 0.0433 ||:   4%|4         | 291/7188 [00:20<07:32, 15.23it/s]
2022-03-21 09:38:09,407 - INFO - tqdm - f1: 0.9834, accuracy: 0.9836, batch_loss: 0.0653, loss: 0.0467 ||:   6%|6         | 437/7188 [00:30<07:52, 14.29it/s]
2022-03-21 09:38:19,515 - INFO - tqdm - f1: 0.9831, accuracy: 0.9832, batch_loss: 0.0115, loss: 0.0480 ||:   8%|8         | 583/7188 [00:40<08:07, 13.55it/s]
2022-03-21 09:38:29,576 - INFO - tqdm - f1: 0.9844, accuracy: 0.9845, batch_loss: 0.0041, loss: 0.0444 ||:  10%|#         | 729/7188 [00:50<07:57, 13.52it/s]
2022-03-21 09:38:39,612 - INFO - tqdm - f1: 0.9834, accuracy: 0.9835, batch_loss: 0.0139, loss: 0.0471 ||:  12%|#2        | 879/7188 [01:00<07:22, 14.25it/s]
2022-03-21 09:38:49,732 - INFO - tqdm - f1: 0.9830, accuracy: 0.9831, batch_loss: 0.0013, loss: 0.0490 ||:  14%|#4        | 1029/7188 [01:10<07:26, 13.80it/s]
2022-03-21 09:38:59,837 - INFO - tqdm - f1: 0.9833, accuracy: 0.9834, batch_loss: 0.0278, loss: 0.0485 ||:  16%|#6        | 1175/7188 [01:20<06:55, 14.49it/s]
2022-03-21 09:39:09,862 - INFO - tqdm - f1: 0.9830, accuracy: 0.9831, batch_loss: 0.0044, loss: 0.0491 ||:  18%|#8        | 1321/7188 [01:30<06:37, 14.75it/s]
2022-03-21 09:39:19,893 - INFO - tqdm - f1: 0.9829, accuracy: 0.9830, batch_loss: 0.1031, loss: 0.0500 ||:  20%|##        | 1465/7188 [01:40<06:36, 14.43it/s]
2022-03-21 09:39:29,944 - INFO - tqdm - f1: 0.9829, accuracy: 0.9829, batch_loss: 0.0530, loss: 0.0507 ||:  22%|##2       | 1611/7188 [01:50<06:18, 14.74it/s]
2022-03-21 09:39:40,093 - INFO - tqdm - f1: 0.9824, accuracy: 0.9824, batch_loss: 0.4753, loss: 0.0525 ||:  24%|##4       | 1759/7188 [02:00<06:12, 14.57it/s]
2022-03-21 09:39:50,145 - INFO - tqdm - f1: 0.9825, accuracy: 0.9825, batch_loss: 0.0196, loss: 0.0520 ||:  27%|##6       | 1905/7188 [02:10<06:33, 13.43it/s]
2022-03-21 09:40:00,148 - INFO - tqdm - f1: 0.9823, accuracy: 0.9823, batch_loss: 0.0492, loss: 0.0519 ||:  29%|##8       | 2051/7188 [02:20<05:28, 15.63it/s]
2022-03-21 09:40:10,183 - INFO - tqdm - f1: 0.9817, accuracy: 0.9817, batch_loss: 0.1446, loss: 0.0535 ||:  31%|###       | 2203/7188 [02:30<05:27, 15.22it/s]
2022-03-21 09:40:20,185 - INFO - tqdm - f1: 0.9818, accuracy: 0.9818, batch_loss: 0.0589, loss: 0.0532 ||:  33%|###2      | 2349/7188 [02:40<05:15, 15.33it/s]
2022-03-21 09:40:30,300 - INFO - tqdm - f1: 0.9816, accuracy: 0.9817, batch_loss: 0.0026, loss: 0.0538 ||:  35%|###4      | 2497/7188 [02:51<05:03, 15.47it/s]
2022-03-21 09:40:40,487 - INFO - tqdm - f1: 0.9815, accuracy: 0.9815, batch_loss: 0.0022, loss: 0.0543 ||:  37%|###6      | 2645/7188 [03:01<05:40, 13.34it/s]
2022-03-21 09:40:50,616 - INFO - tqdm - f1: 0.9810, accuracy: 0.9810, batch_loss: 0.0347, loss: 0.0556 ||:  39%|###8      | 2795/7188 [03:11<04:56, 14.79it/s]
2022-03-21 09:41:00,616 - INFO - tqdm - f1: 0.9809, accuracy: 0.9809, batch_loss: 0.0074, loss: 0.0564 ||:  41%|####      | 2943/7188 [03:21<04:57, 14.25it/s]
2022-03-21 09:41:10,740 - INFO - tqdm - f1: 0.9806, accuracy: 0.9806, batch_loss: 0.0159, loss: 0.0572 ||:  43%|####3     | 3095/7188 [03:31<04:27, 15.28it/s]
2022-03-21 09:41:20,823 - INFO - tqdm - f1: 0.9808, accuracy: 0.9808, batch_loss: 0.0045, loss: 0.0569 ||:  45%|####5     | 3243/7188 [03:41<04:42, 13.96it/s]
2022-03-21 09:41:30,844 - INFO - tqdm - f1: 0.9806, accuracy: 0.9807, batch_loss: 0.1275, loss: 0.0574 ||:  47%|####7     | 3389/7188 [03:51<04:31, 13.98it/s]
2022-03-21 09:41:40,905 - INFO - tqdm - f1: 0.9805, accuracy: 0.9806, batch_loss: 0.1781, loss: 0.0578 ||:  49%|####9     | 3539/7188 [04:01<04:07, 14.73it/s]
2022-03-21 09:41:50,943 - INFO - tqdm - f1: 0.9804, accuracy: 0.9805, batch_loss: 0.0457, loss: 0.0581 ||:  51%|#####1    | 3689/7188 [04:11<03:59, 14.63it/s]
2022-03-21 09:42:01,039 - INFO - tqdm - f1: 0.9804, accuracy: 0.9804, batch_loss: 0.0024, loss: 0.0583 ||:  53%|#####3    | 3837/7188 [04:21<03:47, 14.71it/s]
2022-03-21 09:42:11,093 - INFO - tqdm - f1: 0.9802, accuracy: 0.9802, batch_loss: 0.3137, loss: 0.0589 ||:  55%|#####5    | 3987/7188 [04:31<03:25, 15.60it/s]
2022-03-21 09:42:21,201 - INFO - tqdm - f1: 0.9802, accuracy: 0.9802, batch_loss: 0.2398, loss: 0.0594 ||:  58%|#####7    | 4139/7188 [04:42<03:12, 15.83it/s]
2022-03-21 09:42:31,324 - INFO - tqdm - f1: 0.9801, accuracy: 0.9801, batch_loss: 0.2819, loss: 0.0597 ||:  60%|#####9    | 4291/7188 [04:52<03:11, 15.15it/s]
2022-03-21 09:42:41,361 - INFO - tqdm - f1: 0.9797, accuracy: 0.9797, batch_loss: 0.0036, loss: 0.0608 ||:  62%|######1   | 4441/7188 [05:02<02:50, 16.08it/s]
2022-03-21 09:42:51,477 - INFO - tqdm - f1: 0.9798, accuracy: 0.9798, batch_loss: 0.0338, loss: 0.0607 ||:  64%|######3   | 4595/7188 [05:12<02:41, 16.07it/s]
2022-03-21 09:43:01,484 - INFO - tqdm - f1: 0.9798, accuracy: 0.9798, batch_loss: 0.0079, loss: 0.0608 ||:  66%|######6   | 4747/7188 [05:22<02:36, 15.65it/s]
2022-03-21 09:43:11,623 - INFO - tqdm - f1: 0.9796, accuracy: 0.9797, batch_loss: 0.0212, loss: 0.0610 ||:  68%|######8   | 4899/7188 [05:32<02:36, 14.64it/s]
2022-03-21 09:43:21,699 - INFO - tqdm - f1: 0.9795, accuracy: 0.9795, batch_loss: 0.0048, loss: 0.0615 ||:  70%|#######   | 5049/7188 [05:42<02:19, 15.33it/s]
2022-03-21 09:43:31,825 - INFO - tqdm - f1: 0.9794, accuracy: 0.9795, batch_loss: 0.0611, loss: 0.0615 ||:  72%|#######2  | 5199/7188 [05:52<02:09, 15.42it/s]
2022-03-21 09:43:41,916 - INFO - tqdm - f1: 0.9795, accuracy: 0.9795, batch_loss: 0.0063, loss: 0.0614 ||:  74%|#######4  | 5351/7188 [06:02<01:58, 15.48it/s]
2022-03-21 09:43:51,925 - INFO - tqdm - f1: 0.9795, accuracy: 0.9795, batch_loss: 0.0359, loss: 0.0615 ||:  77%|#######6  | 5501/7188 [06:12<01:53, 14.88it/s]
2022-03-21 09:44:02,034 - INFO - tqdm - f1: 0.9794, accuracy: 0.9794, batch_loss: 0.0042, loss: 0.0617 ||:  79%|#######8  | 5657/7188 [06:22<01:42, 14.89it/s]
2022-03-21 09:44:12,134 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0034, loss: 0.0622 ||:  81%|########  | 5811/7188 [06:32<01:24, 16.27it/s]
2022-03-21 09:44:22,197 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.1096, loss: 0.0623 ||:  83%|########2 | 5963/7188 [06:42<01:20, 15.28it/s]
2022-03-21 09:44:32,234 - INFO - tqdm - f1: 0.9794, accuracy: 0.9794, batch_loss: 0.0020, loss: 0.0621 ||:  85%|########5 | 6111/7188 [06:53<01:11, 14.99it/s]
2022-03-21 09:44:42,307 - INFO - tqdm - f1: 0.9793, accuracy: 0.9793, batch_loss: 0.0121, loss: 0.0624 ||:  87%|########7 | 6257/7188 [07:03<01:00, 15.30it/s]
2022-03-21 09:44:52,394 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0013, loss: 0.0625 ||:  89%|########9 | 6407/7188 [07:13<00:48, 16.16it/s]
2022-03-21 09:45:02,423 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0453, loss: 0.0627 ||:  91%|#########1| 6555/7188 [07:23<00:40, 15.78it/s]
2022-03-21 09:45:12,515 - INFO - tqdm - f1: 0.9791, accuracy: 0.9791, batch_loss: 0.0049, loss: 0.0627 ||:  93%|#########3| 6705/7188 [07:33<00:32, 14.66it/s]
2022-03-21 09:45:22,555 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0011, loss: 0.0629 ||:  95%|#########5| 6853/7188 [07:43<00:21, 15.34it/s]
2022-03-21 09:45:32,699 - INFO - tqdm - f1: 0.9789, accuracy: 0.9788, batch_loss: 0.1081, loss: 0.0634 ||:  98%|#########7| 7009/7188 [07:53<00:12, 14.40it/s]
2022-03-21 09:45:42,429 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.0058, loss: 0.0635 ||: 100%|#########9| 7153/7188 [08:03<00:02, 15.73it/s]
2022-03-21 09:45:42,587 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.0034, loss: 0.0635 ||: 100%|#########9| 7155/7188 [08:03<00:02, 14.68it/s]
2022-03-21 09:45:42,740 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.1551, loss: 0.0635 ||: 100%|#########9| 7157/7188 [08:03<00:02, 14.14it/s]
2022-03-21 09:45:42,917 - INFO - tqdm - f1: 0.9789, accuracy: 0.9788, batch_loss: 0.0392, loss: 0.0635 ||: 100%|#########9| 7159/7188 [08:03<00:02, 13.16it/s]
2022-03-21 09:45:43,063 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.0530, loss: 0.0635 ||: 100%|#########9| 7161/7188 [08:03<00:02, 13.31it/s]
2022-03-21 09:45:43,182 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.2611, loss: 0.0635 ||: 100%|#########9| 7163/7188 [08:03<00:01, 14.19it/s]
2022-03-21 09:45:43,316 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.2554, loss: 0.0636 ||: 100%|#########9| 7165/7188 [08:04<00:01, 14.42it/s]
2022-03-21 09:45:43,441 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.0034, loss: 0.0636 ||: 100%|#########9| 7167/7188 [08:04<00:01, 14.86it/s]
2022-03-21 09:45:43,576 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.3038, loss: 0.0636 ||: 100%|#########9| 7169/7188 [08:04<00:01, 14.85it/s]
2022-03-21 09:45:43,725 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.4024, loss: 0.0637 ||: 100%|#########9| 7171/7188 [08:04<00:01, 14.36it/s]
2022-03-21 09:45:43,914 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.0059, loss: 0.0636 ||: 100%|#########9| 7173/7188 [08:04<00:01, 12.99it/s]
2022-03-21 09:45:44,044 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.0025, loss: 0.0636 ||: 100%|#########9| 7175/7188 [08:04<00:00, 13.63it/s]
2022-03-21 09:45:44,177 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.0340, loss: 0.0636 ||: 100%|#########9| 7177/7188 [08:04<00:00, 14.02it/s]
2022-03-21 09:45:44,311 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.0209, loss: 0.0636 ||: 100%|#########9| 7179/7188 [08:05<00:00, 14.28it/s]
2022-03-21 09:45:44,453 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.5355, loss: 0.0637 ||: 100%|#########9| 7181/7188 [08:05<00:00, 14.20it/s]
2022-03-21 09:45:44,621 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.5441, loss: 0.0637 ||: 100%|#########9| 7183/7188 [08:05<00:00, 13.43it/s]
2022-03-21 09:45:44,789 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.0235, loss: 0.0637 ||: 100%|#########9| 7185/7188 [08:05<00:00, 12.94it/s]
2022-03-21 09:45:44,955 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.0435, loss: 0.0638 ||: 100%|#########9| 7187/7188 [08:05<00:00, 12.66it/s]
2022-03-21 09:45:45,070 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.0243, loss: 0.0637 ||: 100%|##########| 7188/7188 [08:05<00:00, 14.79it/s]
2022-03-21 09:45:45,090 - INFO - allennlp.training.trainer - Validating
2022-03-21 09:45:45,093 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 09:45:53,117 - INFO - tqdm - f1: 0.9333, accuracy: 0.9334, batch_loss: 0.0099, loss: 0.2562 ||: 100%|##########| 313/313 [00:08<00:00, 39.01it/s]
2022-03-21 09:45:53,159 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 09:45:53,170 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.979  |     0.933
2022-03-21 09:45:53,184 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.979  |     0.933
2022-03-21 09:45:53,198 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 09:45:53,212 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.064  |     0.256
2022-03-21 09:45:53,226 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7579.891  |       N/A
2022-03-21 09:45:53,240 - INFO - allennlp.training.trainer - Epoch duration: 0:08:14.105525
2022-03-21 09:45:53,255 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:44:18
2022-03-21 09:45:53,269 - INFO - allennlp.training.trainer - Epoch 7/9
2022-03-21 09:45:53,283 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 09:45:53,284 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 09:45:53,287 - INFO - allennlp.training.trainer - Training
2022-03-21 09:45:53,288 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 09:46:03,297 - INFO - tqdm - f1: 0.9835, accuracy: 0.9839, batch_loss: 0.0035, loss: 0.0484 ||:   1%|1         | 105/7188 [00:10<07:27, 15.84it/s]
2022-03-21 09:46:13,390 - INFO - tqdm - f1: 0.9838, accuracy: 0.9838, batch_loss: 0.0076, loss: 0.0461 ||:   4%|3         | 259/7188 [00:20<07:26, 15.52it/s]
2022-03-21 09:46:23,451 - INFO - tqdm - f1: 0.9829, accuracy: 0.9830, batch_loss: 0.0051, loss: 0.0478 ||:   6%|5         | 407/7188 [00:30<07:26, 15.19it/s]
2022-03-21 09:46:33,488 - INFO - tqdm - f1: 0.9829, accuracy: 0.9831, batch_loss: 0.0056, loss: 0.0490 ||:   8%|7         | 557/7188 [00:40<06:52, 16.08it/s]
2022-03-21 09:46:43,605 - INFO - tqdm - f1: 0.9838, accuracy: 0.9839, batch_loss: 0.1125, loss: 0.0484 ||:  10%|9         | 707/7188 [00:50<06:55, 15.58it/s]
2022-03-21 09:46:53,735 - INFO - tqdm - f1: 0.9836, accuracy: 0.9837, batch_loss: 0.0413, loss: 0.0508 ||:  12%|#1        | 861/7188 [01:00<07:09, 14.75it/s]
2022-03-21 09:47:03,876 - INFO - tqdm - f1: 0.9843, accuracy: 0.9842, batch_loss: 0.2982, loss: 0.0491 ||:  14%|#4        | 1015/7188 [01:10<07:39, 13.43it/s]
2022-03-21 09:47:13,966 - INFO - tqdm - f1: 0.9841, accuracy: 0.9840, batch_loss: 0.1961, loss: 0.0500 ||:  16%|#6        | 1167/7188 [01:20<06:48, 14.73it/s]
2022-03-21 09:47:24,005 - INFO - tqdm - f1: 0.9846, accuracy: 0.9846, batch_loss: 0.0877, loss: 0.0487 ||:  18%|#8        | 1317/7188 [01:30<06:40, 14.64it/s]
2022-03-21 09:47:34,079 - INFO - tqdm - f1: 0.9839, accuracy: 0.9839, batch_loss: 0.1925, loss: 0.0502 ||:  20%|##        | 1469/7188 [01:40<06:19, 15.05it/s]
2022-03-21 09:47:44,138 - INFO - tqdm - f1: 0.9839, accuracy: 0.9839, batch_loss: 0.1082, loss: 0.0499 ||:  23%|##2       | 1621/7188 [01:50<05:52, 15.79it/s]
2022-03-21 09:47:54,158 - INFO - tqdm - f1: 0.9839, accuracy: 0.9839, batch_loss: 0.0120, loss: 0.0499 ||:  25%|##4       | 1767/7188 [02:00<06:55, 13.03it/s]
2022-03-21 09:48:04,194 - INFO - tqdm - f1: 0.9839, accuracy: 0.9839, batch_loss: 0.0057, loss: 0.0497 ||:  27%|##6       | 1917/7188 [02:10<06:01, 14.57it/s]
2022-03-21 09:48:14,272 - INFO - tqdm - f1: 0.9837, accuracy: 0.9838, batch_loss: 0.0065, loss: 0.0500 ||:  29%|##8       | 2065/7188 [02:20<05:34, 15.33it/s]
2022-03-21 09:48:24,382 - INFO - tqdm - f1: 0.9837, accuracy: 0.9837, batch_loss: 0.4632, loss: 0.0511 ||:  31%|###       | 2215/7188 [02:31<05:17, 15.67it/s]
2022-03-21 09:48:34,409 - INFO - tqdm - f1: 0.9837, accuracy: 0.9837, batch_loss: 0.0020, loss: 0.0513 ||:  33%|###2      | 2367/7188 [02:41<04:52, 16.51it/s]
2022-03-21 09:48:44,520 - INFO - tqdm - f1: 0.9837, accuracy: 0.9838, batch_loss: 0.0050, loss: 0.0513 ||:  35%|###5      | 2525/7188 [02:51<04:47, 16.20it/s]
2022-03-21 09:48:54,655 - INFO - tqdm - f1: 0.9838, accuracy: 0.9838, batch_loss: 0.1739, loss: 0.0511 ||:  37%|###7      | 2681/7188 [03:01<04:53, 15.35it/s]
2022-03-21 09:49:04,733 - INFO - tqdm - f1: 0.9835, accuracy: 0.9835, batch_loss: 0.0044, loss: 0.0518 ||:  39%|###9      | 2833/7188 [03:11<05:02, 14.40it/s]
2022-03-21 09:49:14,739 - INFO - tqdm - f1: 0.9834, accuracy: 0.9834, batch_loss: 0.6114, loss: 0.0523 ||:  42%|####1     | 2985/7188 [03:21<04:33, 15.39it/s]
2022-03-21 09:49:24,771 - INFO - tqdm - f1: 0.9832, accuracy: 0.9832, batch_loss: 0.0351, loss: 0.0525 ||:  44%|####3     | 3129/7188 [03:31<04:54, 13.78it/s]
2022-03-21 09:49:34,874 - INFO - tqdm - f1: 0.9830, accuracy: 0.9830, batch_loss: 0.0088, loss: 0.0527 ||:  46%|####5     | 3281/7188 [03:41<04:07, 15.80it/s]
2022-03-21 09:49:44,969 - INFO - tqdm - f1: 0.9829, accuracy: 0.9830, batch_loss: 0.0021, loss: 0.0528 ||:  48%|####7     | 3439/7188 [03:51<04:14, 14.71it/s]
2022-03-21 09:49:54,975 - INFO - tqdm - f1: 0.9829, accuracy: 0.9830, batch_loss: 0.0037, loss: 0.0529 ||:  50%|####9     | 3585/7188 [04:01<04:23, 13.69it/s]
2022-03-21 09:50:05,079 - INFO - tqdm - f1: 0.9827, accuracy: 0.9827, batch_loss: 0.0418, loss: 0.0533 ||:  52%|#####1    | 3729/7188 [04:11<04:10, 13.82it/s]
2022-03-21 09:50:15,216 - INFO - tqdm - f1: 0.9826, accuracy: 0.9827, batch_loss: 0.0146, loss: 0.0533 ||:  53%|#####3    | 3838/7188 [04:21<10:18,  5.41it/s]
2022-03-21 09:50:25,255 - INFO - tqdm - f1: 0.9827, accuracy: 0.9827, batch_loss: 0.0017, loss: 0.0533 ||:  54%|#####4    | 3902/7188 [04:31<04:38, 11.82it/s]
2022-03-21 09:50:35,388 - INFO - tqdm - f1: 0.9827, accuracy: 0.9828, batch_loss: 0.0856, loss: 0.0531 ||:  55%|#####5    | 3961/7188 [04:42<11:03,  4.87it/s]
2022-03-21 09:50:45,484 - INFO - tqdm - f1: 0.9828, accuracy: 0.9828, batch_loss: 0.0030, loss: 0.0530 ||:  56%|#####6    | 4027/7188 [04:52<08:34,  6.14it/s]
2022-03-21 09:50:55,598 - INFO - tqdm - f1: 0.9828, accuracy: 0.9828, batch_loss: 0.0612, loss: 0.0531 ||:  57%|#####6    | 4095/7188 [05:02<08:05,  6.37it/s]
2022-03-21 09:51:05,704 - INFO - tqdm - f1: 0.9828, accuracy: 0.9828, batch_loss: 0.0048, loss: 0.0531 ||:  58%|#####7    | 4152/7188 [05:12<08:30,  5.94it/s]
2022-03-21 09:51:15,791 - INFO - tqdm - f1: 0.9828, accuracy: 0.9828, batch_loss: 0.0687, loss: 0.0531 ||:  59%|#####8    | 4217/7188 [05:22<09:29,  5.21it/s]
2022-03-21 09:51:25,977 - INFO - tqdm - f1: 0.9828, accuracy: 0.9828, batch_loss: 0.0050, loss: 0.0530 ||:  60%|#####9    | 4282/7188 [05:32<09:16,  5.22it/s]
2022-03-21 09:51:36,060 - INFO - tqdm - f1: 0.9829, accuracy: 0.9829, batch_loss: 0.0030, loss: 0.0528 ||:  60%|######    | 4346/7188 [05:42<04:19, 10.96it/s]
2022-03-21 09:51:46,077 - INFO - tqdm - f1: 0.9829, accuracy: 0.9829, batch_loss: 0.0033, loss: 0.0528 ||:  61%|######1   | 4400/7188 [05:52<08:32,  5.44it/s]
2022-03-21 09:51:56,190 - INFO - tqdm - f1: 0.9829, accuracy: 0.9829, batch_loss: 0.0041, loss: 0.0530 ||:  62%|######2   | 4466/7188 [06:02<08:09,  5.56it/s]
2022-03-21 09:52:06,190 - INFO - tqdm - f1: 0.9828, accuracy: 0.9829, batch_loss: 0.0825, loss: 0.0530 ||:  63%|######3   | 4530/7188 [06:12<07:18,  6.07it/s]
2022-03-21 09:52:16,239 - INFO - tqdm - f1: 0.9827, accuracy: 0.9828, batch_loss: 0.1070, loss: 0.0530 ||:  64%|######3   | 4588/7188 [06:22<07:59,  5.43it/s]
2022-03-21 09:52:26,344 - INFO - tqdm - f1: 0.9827, accuracy: 0.9827, batch_loss: 0.0240, loss: 0.0531 ||:  65%|######4   | 4649/7188 [06:33<06:31,  6.49it/s]
2022-03-21 09:52:36,344 - INFO - tqdm - f1: 0.9827, accuracy: 0.9828, batch_loss: 0.0427, loss: 0.0530 ||:  66%|######5   | 4716/7188 [06:43<06:18,  6.53it/s]
2022-03-21 09:52:46,376 - INFO - tqdm - f1: 0.9827, accuracy: 0.9828, batch_loss: 0.0274, loss: 0.0530 ||:  67%|######6   | 4782/7188 [06:53<03:19, 12.05it/s]
2022-03-21 09:52:56,481 - INFO - tqdm - f1: 0.9828, accuracy: 0.9828, batch_loss: 0.0063, loss: 0.0530 ||:  68%|######7   | 4887/7188 [07:03<02:25, 15.79it/s]
2022-03-21 09:53:06,511 - INFO - tqdm - f1: 0.9826, accuracy: 0.9826, batch_loss: 0.0114, loss: 0.0534 ||:  70%|#######   | 5037/7188 [07:13<02:17, 15.62it/s]
2022-03-21 09:53:16,638 - INFO - tqdm - f1: 0.9824, accuracy: 0.9824, batch_loss: 0.0026, loss: 0.0536 ||:  72%|#######2  | 5191/7188 [07:23<02:14, 14.81it/s]
2022-03-21 09:53:26,737 - INFO - tqdm - f1: 0.9824, accuracy: 0.9824, batch_loss: 0.0137, loss: 0.0538 ||:  74%|#######4  | 5343/7188 [07:33<02:07, 14.49it/s]
2022-03-21 09:53:36,903 - INFO - tqdm - f1: 0.9824, accuracy: 0.9824, batch_loss: 0.0223, loss: 0.0538 ||:  76%|#######6  | 5493/7188 [07:43<02:32, 11.10it/s]
2022-03-21 09:53:46,907 - INFO - tqdm - f1: 0.9825, accuracy: 0.9825, batch_loss: 0.0223, loss: 0.0538 ||:  79%|#######8  | 5645/7188 [07:53<01:35, 16.08it/s]
2022-03-21 09:53:56,993 - INFO - tqdm - f1: 0.9824, accuracy: 0.9824, batch_loss: 0.0121, loss: 0.0541 ||:  81%|########  | 5797/7188 [08:03<01:31, 15.23it/s]
2022-03-21 09:54:07,025 - INFO - tqdm - f1: 0.9823, accuracy: 0.9824, batch_loss: 0.0350, loss: 0.0540 ||:  83%|########2 | 5951/7188 [08:13<01:24, 14.59it/s]
2022-03-21 09:54:17,131 - INFO - tqdm - f1: 0.9822, accuracy: 0.9822, batch_loss: 0.0070, loss: 0.0542 ||:  85%|########4 | 6105/7188 [08:23<01:09, 15.53it/s]
2022-03-21 09:54:27,133 - INFO - tqdm - f1: 0.9821, accuracy: 0.9821, batch_loss: 0.0661, loss: 0.0547 ||:  87%|########7 | 6257/7188 [08:33<00:58, 15.82it/s]
2022-03-21 09:54:37,237 - INFO - tqdm - f1: 0.9820, accuracy: 0.9820, batch_loss: 0.0034, loss: 0.0551 ||:  89%|########9 | 6413/7188 [08:43<00:53, 14.61it/s]
2022-03-21 09:54:47,310 - INFO - tqdm - f1: 0.9819, accuracy: 0.9819, batch_loss: 0.2701, loss: 0.0554 ||:  91%|#########1| 6565/7188 [08:54<00:37, 16.65it/s]
2022-03-21 09:54:57,374 - INFO - tqdm - f1: 0.9818, accuracy: 0.9817, batch_loss: 0.0080, loss: 0.0556 ||:  93%|#########3| 6715/7188 [09:04<00:32, 14.59it/s]
2022-03-21 09:55:07,454 - INFO - tqdm - f1: 0.9817, accuracy: 0.9817, batch_loss: 0.4294, loss: 0.0557 ||:  96%|#########5| 6867/7188 [09:14<00:21, 14.72it/s]
2022-03-21 09:55:17,536 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0658, loss: 0.0561 ||:  98%|#########7| 7021/7188 [09:24<00:10, 15.74it/s]
2022-03-21 09:55:26,384 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0060, loss: 0.0561 ||: 100%|#########9| 7153/7188 [09:33<00:02, 14.94it/s]
2022-03-21 09:55:26,518 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0182, loss: 0.0561 ||: 100%|#########9| 7155/7188 [09:33<00:02, 14.93it/s]
2022-03-21 09:55:26,646 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0144, loss: 0.0561 ||: 100%|#########9| 7157/7188 [09:33<00:02, 15.15it/s]
2022-03-21 09:55:26,774 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0407, loss: 0.0561 ||: 100%|#########9| 7159/7188 [09:33<00:01, 15.26it/s]
2022-03-21 09:55:26,903 - INFO - tqdm - f1: 0.9816, accuracy: 0.9815, batch_loss: 0.1335, loss: 0.0561 ||: 100%|#########9| 7161/7188 [09:33<00:01, 15.33it/s]
2022-03-21 09:55:27,044 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0066, loss: 0.0561 ||: 100%|#########9| 7163/7188 [09:33<00:01, 14.97it/s]
2022-03-21 09:55:27,231 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0055, loss: 0.0561 ||: 100%|#########9| 7165/7188 [09:33<00:01, 13.38it/s]
2022-03-21 09:55:27,357 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0041, loss: 0.0561 ||: 100%|#########9| 7167/7188 [09:34<00:01, 14.05it/s]
2022-03-21 09:55:27,486 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0047, loss: 0.0561 ||: 100%|#########9| 7169/7188 [09:34<00:01, 14.45it/s]
2022-03-21 09:55:27,605 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0109, loss: 0.0561 ||: 100%|#########9| 7171/7188 [09:34<00:01, 15.09it/s]
2022-03-21 09:55:27,785 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0222, loss: 0.0561 ||: 100%|#########9| 7173/7188 [09:34<00:01, 13.63it/s]
2022-03-21 09:55:27,968 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0057, loss: 0.0560 ||: 100%|#########9| 7175/7188 [09:34<00:01, 12.67it/s]
2022-03-21 09:55:28,105 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0284, loss: 0.0560 ||: 100%|#########9| 7177/7188 [09:34<00:00, 13.19it/s]
2022-03-21 09:55:28,239 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0029, loss: 0.0560 ||: 100%|#########9| 7179/7188 [09:34<00:00, 13.69it/s]
2022-03-21 09:55:28,374 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0252, loss: 0.0560 ||: 100%|#########9| 7181/7188 [09:35<00:00, 13.99it/s]
2022-03-21 09:55:28,495 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0217, loss: 0.0560 ||: 100%|#########9| 7183/7188 [09:35<00:00, 14.68it/s]
2022-03-21 09:55:28,627 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0251, loss: 0.0560 ||: 100%|#########9| 7185/7188 [09:35<00:00, 14.82it/s]
2022-03-21 09:55:28,783 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.0811, loss: 0.0560 ||: 100%|#########9| 7187/7188 [09:35<00:00, 14.16it/s]
2022-03-21 09:55:28,936 - INFO - tqdm - f1: 0.9816, accuracy: 0.9816, batch_loss: 0.2897, loss: 0.0560 ||: 100%|##########| 7188/7188 [09:35<00:00, 12.49it/s]
2022-03-21 09:55:28,976 - INFO - allennlp.training.trainer - Validating
2022-03-21 09:55:28,991 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 09:55:37,635 - INFO - tqdm - f1: 0.9339, accuracy: 0.9338, batch_loss: 0.0030, loss: 0.3241 ||: 100%|##########| 313/313 [00:08<00:00, 36.27it/s]
2022-03-21 09:55:37,679 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 09:55:37,685 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.982  |     0.934
2022-03-21 09:55:37,699 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.982  |     0.934
2022-03-21 09:55:37,713 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 09:55:37,727 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.056  |     0.324
2022-03-21 09:55:37,729 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7579.891  |       N/A
2022-03-21 09:55:37,730 - INFO - allennlp.training.trainer - Epoch duration: 0:09:44.461356
2022-03-21 09:55:37,731 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:28:16
2022-03-21 09:55:37,733 - INFO - allennlp.training.trainer - Epoch 8/9
2022-03-21 09:55:37,734 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 09:55:37,752 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 09:55:37,767 - INFO - allennlp.training.trainer - Training
2022-03-21 09:55:37,780 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 09:55:47,929 - INFO - tqdm - f1: 0.9815, accuracy: 0.9814, batch_loss: 0.2407, loss: 0.0529 ||:   2%|2         | 151/7188 [00:10<08:16, 14.17it/s]
2022-03-21 09:55:57,944 - INFO - tqdm - f1: 0.9831, accuracy: 0.9831, batch_loss: 0.0996, loss: 0.0492 ||:   4%|4         | 307/7188 [00:20<07:26, 15.41it/s]
2022-03-21 09:56:07,995 - INFO - tqdm - f1: 0.9849, accuracy: 0.9850, batch_loss: 0.0010, loss: 0.0447 ||:   6%|6         | 461/7188 [00:30<07:08, 15.68it/s]
2022-03-21 09:56:18,168 - INFO - tqdm - f1: 0.9844, accuracy: 0.9845, batch_loss: 0.0061, loss: 0.0458 ||:   9%|8         | 615/7188 [00:40<08:34, 12.78it/s]
2022-03-21 09:56:28,252 - INFO - tqdm - f1: 0.9857, accuracy: 0.9858, batch_loss: 0.0013, loss: 0.0429 ||:  11%|#         | 767/7188 [00:50<06:58, 15.35it/s]
2022-03-21 09:56:38,330 - INFO - tqdm - f1: 0.9849, accuracy: 0.9850, batch_loss: 0.0216, loss: 0.0443 ||:  13%|#2        | 923/7188 [01:00<06:56, 15.03it/s]
2022-03-21 09:56:48,349 - INFO - tqdm - f1: 0.9846, accuracy: 0.9847, batch_loss: 0.0831, loss: 0.0456 ||:  15%|#4        | 1077/7188 [01:10<06:42, 15.17it/s]
2022-03-21 09:56:58,388 - INFO - tqdm - f1: 0.9843, accuracy: 0.9844, batch_loss: 0.0048, loss: 0.0467 ||:  17%|#7        | 1231/7188 [01:20<06:18, 15.74it/s]
2022-03-21 09:57:08,460 - INFO - tqdm - f1: 0.9843, accuracy: 0.9844, batch_loss: 0.0078, loss: 0.0473 ||:  19%|#9        | 1387/7188 [01:30<06:04, 15.91it/s]
2022-03-21 09:57:18,527 - INFO - tqdm - f1: 0.9846, accuracy: 0.9847, batch_loss: 0.0062, loss: 0.0467 ||:  21%|##1       | 1543/7188 [01:40<05:46, 16.28it/s]
2022-03-21 09:57:28,637 - INFO - tqdm - f1: 0.9845, accuracy: 0.9845, batch_loss: 0.0312, loss: 0.0467 ||:  24%|##3       | 1695/7188 [01:50<05:58, 15.33it/s]
2022-03-21 09:57:38,682 - INFO - tqdm - f1: 0.9843, accuracy: 0.9844, batch_loss: 0.0496, loss: 0.0469 ||:  26%|##5       | 1843/7188 [02:00<05:43, 15.56it/s]
2022-03-21 09:57:48,776 - INFO - tqdm - f1: 0.9846, accuracy: 0.9846, batch_loss: 0.0180, loss: 0.0466 ||:  28%|##7       | 1995/7188 [02:10<05:20, 16.22it/s]
2022-03-21 09:57:58,924 - INFO - tqdm - f1: 0.9846, accuracy: 0.9847, batch_loss: 0.0039, loss: 0.0467 ||:  30%|##9       | 2143/7188 [02:21<05:56, 14.17it/s]
2022-03-21 09:58:09,038 - INFO - tqdm - f1: 0.9847, accuracy: 0.9847, batch_loss: 0.0020, loss: 0.0460 ||:  32%|###1      | 2295/7188 [02:31<05:04, 16.08it/s]
2022-03-21 09:58:19,052 - INFO - tqdm - f1: 0.9846, accuracy: 0.9846, batch_loss: 0.1136, loss: 0.0459 ||:  34%|###4      | 2449/7188 [02:41<05:10, 15.28it/s]
2022-03-21 09:58:29,201 - INFO - tqdm - f1: 0.9846, accuracy: 0.9846, batch_loss: 0.0404, loss: 0.0466 ||:  36%|###6      | 2605/7188 [02:51<05:22, 14.21it/s]
2022-03-21 09:58:39,354 - INFO - tqdm - f1: 0.9848, accuracy: 0.9848, batch_loss: 0.2628, loss: 0.0464 ||:  38%|###8      | 2759/7188 [03:01<05:12, 14.19it/s]
2022-03-21 09:58:49,444 - INFO - tqdm - f1: 0.9846, accuracy: 0.9847, batch_loss: 0.0019, loss: 0.0467 ||:  40%|####      | 2909/7188 [03:11<04:28, 15.93it/s]
2022-03-21 09:58:59,467 - INFO - tqdm - f1: 0.9846, accuracy: 0.9847, batch_loss: 0.2618, loss: 0.0466 ||:  43%|####2     | 3063/7188 [03:21<04:21, 15.79it/s]
2022-03-21 09:59:09,497 - INFO - tqdm - f1: 0.9845, accuracy: 0.9846, batch_loss: 0.0053, loss: 0.0468 ||:  45%|####4     | 3217/7188 [03:31<04:00, 16.51it/s]
2022-03-21 09:59:19,608 - INFO - tqdm - f1: 0.9844, accuracy: 0.9844, batch_loss: 0.0023, loss: 0.0475 ||:  47%|####6     | 3371/7188 [03:41<04:05, 15.53it/s]
2022-03-21 09:59:29,721 - INFO - tqdm - f1: 0.9845, accuracy: 0.9845, batch_loss: 0.0012, loss: 0.0474 ||:  49%|####9     | 3529/7188 [03:51<04:03, 15.00it/s]
2022-03-21 09:59:39,721 - INFO - tqdm - f1: 0.9843, accuracy: 0.9844, batch_loss: 0.0631, loss: 0.0478 ||:  51%|#####1    | 3681/7188 [04:01<03:34, 16.35it/s]
2022-03-21 09:59:49,771 - INFO - tqdm - f1: 0.9844, accuracy: 0.9844, batch_loss: 0.0220, loss: 0.0476 ||:  53%|#####3    | 3833/7188 [04:11<03:31, 15.89it/s]
2022-03-21 09:59:59,868 - INFO - tqdm - f1: 0.9846, accuracy: 0.9846, batch_loss: 0.0169, loss: 0.0474 ||:  55%|#####5    | 3985/7188 [04:22<03:33, 14.99it/s]
2022-03-21 10:00:09,985 - INFO - tqdm - f1: 0.9847, accuracy: 0.9847, batch_loss: 0.0446, loss: 0.0473 ||:  57%|#####7    | 4133/7188 [04:32<03:17, 15.50it/s]
2022-03-21 10:00:20,097 - INFO - tqdm - f1: 0.9848, accuracy: 0.9848, batch_loss: 0.0093, loss: 0.0473 ||:  60%|#####9    | 4279/7188 [04:42<03:09, 15.34it/s]
2022-03-21 10:00:30,176 - INFO - tqdm - f1: 0.9848, accuracy: 0.9848, batch_loss: 0.0013, loss: 0.0474 ||:  62%|######1   | 4433/7188 [04:52<02:54, 15.81it/s]
2022-03-21 10:00:40,182 - INFO - tqdm - f1: 0.9847, accuracy: 0.9847, batch_loss: 0.0244, loss: 0.0475 ||:  64%|######3   | 4585/7188 [05:02<02:52, 15.07it/s]
2022-03-21 10:00:50,275 - INFO - tqdm - f1: 0.9846, accuracy: 0.9847, batch_loss: 0.2168, loss: 0.0476 ||:  66%|######5   | 4737/7188 [05:12<02:48, 14.58it/s]
2022-03-21 10:01:00,385 - INFO - tqdm - f1: 0.9847, accuracy: 0.9847, batch_loss: 0.0026, loss: 0.0476 ||:  68%|######8   | 4889/7188 [05:22<02:34, 14.88it/s]
2022-03-21 10:01:10,449 - INFO - tqdm - f1: 0.9846, accuracy: 0.9847, batch_loss: 0.0046, loss: 0.0478 ||:  70%|#######   | 5043/7188 [05:32<02:17, 15.66it/s]
2022-03-21 10:01:20,514 - INFO - tqdm - f1: 0.9848, accuracy: 0.9848, batch_loss: 0.0046, loss: 0.0477 ||:  72%|#######2  | 5197/7188 [05:42<02:12, 15.03it/s]
2022-03-21 10:01:30,542 - INFO - tqdm - f1: 0.9846, accuracy: 0.9847, batch_loss: 0.0481, loss: 0.0480 ||:  74%|#######4  | 5345/7188 [05:52<01:58, 15.55it/s]
2022-03-21 10:01:40,566 - INFO - tqdm - f1: 0.9846, accuracy: 0.9846, batch_loss: 0.0023, loss: 0.0483 ||:  76%|#######6  | 5497/7188 [06:02<01:46, 15.90it/s]
2022-03-21 10:01:50,585 - INFO - tqdm - f1: 0.9845, accuracy: 0.9845, batch_loss: 0.0555, loss: 0.0484 ||:  79%|#######8  | 5651/7188 [06:12<01:38, 15.60it/s]
2022-03-21 10:02:00,612 - INFO - tqdm - f1: 0.9843, accuracy: 0.9843, batch_loss: 0.0783, loss: 0.0487 ||:  81%|########  | 5803/7188 [06:22<01:30, 15.31it/s]
2022-03-21 10:02:10,676 - INFO - tqdm - f1: 0.9842, accuracy: 0.9842, batch_loss: 0.0077, loss: 0.0487 ||:  83%|########2 | 5955/7188 [06:32<01:17, 16.01it/s]
2022-03-21 10:02:20,713 - INFO - tqdm - f1: 0.9842, accuracy: 0.9842, batch_loss: 0.0095, loss: 0.0490 ||:  85%|########4 | 6109/7188 [06:42<01:06, 16.21it/s]
2022-03-21 10:02:30,714 - INFO - tqdm - f1: 0.9840, accuracy: 0.9840, batch_loss: 0.0011, loss: 0.0492 ||:  87%|########7 | 6261/7188 [06:52<00:57, 16.17it/s]
2022-03-21 10:02:40,779 - INFO - tqdm - f1: 0.9839, accuracy: 0.9839, batch_loss: 0.0108, loss: 0.0491 ||:  89%|########9 | 6415/7188 [07:02<00:48, 16.01it/s]
2022-03-21 10:02:50,839 - INFO - tqdm - f1: 0.9840, accuracy: 0.9840, batch_loss: 0.0053, loss: 0.0492 ||:  91%|#########1| 6567/7188 [07:13<00:42, 14.72it/s]
2022-03-21 10:03:00,914 - INFO - tqdm - f1: 0.9838, accuracy: 0.9838, batch_loss: 0.0159, loss: 0.0497 ||:  94%|#########3| 6721/7188 [07:23<00:30, 15.35it/s]
2022-03-21 10:03:10,990 - INFO - tqdm - f1: 0.9838, accuracy: 0.9838, batch_loss: 0.0527, loss: 0.0497 ||:  96%|#########5| 6873/7188 [07:33<00:21, 14.39it/s]
2022-03-21 10:03:20,992 - INFO - tqdm - f1: 0.9837, accuracy: 0.9837, batch_loss: 0.0925, loss: 0.0498 ||:  98%|#########7| 7019/7188 [07:43<00:11, 14.29it/s]
2022-03-21 10:03:30,056 - INFO - tqdm - f1: 0.9837, accuracy: 0.9837, batch_loss: 0.0800, loss: 0.0500 ||: 100%|#########9| 7153/7188 [07:52<00:02, 14.17it/s]
2022-03-21 10:03:30,246 - INFO - tqdm - f1: 0.9837, accuracy: 0.9837, batch_loss: 0.0035, loss: 0.0500 ||: 100%|#########9| 7155/7188 [07:52<00:02, 12.81it/s]
2022-03-21 10:03:30,384 - INFO - tqdm - f1: 0.9837, accuracy: 0.9837, batch_loss: 0.0020, loss: 0.0500 ||: 100%|#########9| 7157/7188 [07:52<00:02, 13.30it/s]
2022-03-21 10:03:30,509 - INFO - tqdm - f1: 0.9837, accuracy: 0.9837, batch_loss: 0.0020, loss: 0.0500 ||: 100%|#########9| 7159/7188 [07:52<00:02, 13.99it/s]
2022-03-21 10:03:30,643 - INFO - tqdm - f1: 0.9837, accuracy: 0.9837, batch_loss: 0.1329, loss: 0.0500 ||: 100%|#########9| 7161/7188 [07:52<00:01, 14.28it/s]
2022-03-21 10:03:30,774 - INFO - tqdm - f1: 0.9837, accuracy: 0.9837, batch_loss: 0.0057, loss: 0.0500 ||: 100%|#########9| 7163/7188 [07:52<00:01, 14.53it/s]
2022-03-21 10:03:30,927 - INFO - tqdm - f1: 0.9837, accuracy: 0.9837, batch_loss: 0.3247, loss: 0.0500 ||: 100%|#########9| 7165/7188 [07:53<00:01, 14.08it/s]
2022-03-21 10:03:31,073 - INFO - tqdm - f1: 0.9837, accuracy: 0.9836, batch_loss: 0.0031, loss: 0.0500 ||: 100%|#########9| 7167/7188 [07:53<00:01, 13.97it/s]
2022-03-21 10:03:31,250 - INFO - tqdm - f1: 0.9836, accuracy: 0.9836, batch_loss: 0.0913, loss: 0.0501 ||: 100%|#########9| 7169/7188 [07:53<00:01, 13.05it/s]
2022-03-21 10:03:31,387 - INFO - tqdm - f1: 0.9836, accuracy: 0.9836, batch_loss: 0.0063, loss: 0.0501 ||: 100%|#########9| 7171/7188 [07:53<00:01, 13.46it/s]
2022-03-21 10:03:31,525 - INFO - tqdm - f1: 0.9837, accuracy: 0.9836, batch_loss: 0.0062, loss: 0.0501 ||: 100%|#########9| 7173/7188 [07:53<00:01, 13.75it/s]
2022-03-21 10:03:31,656 - INFO - tqdm - f1: 0.9837, accuracy: 0.9836, batch_loss: 0.0568, loss: 0.0500 ||: 100%|#########9| 7175/7188 [07:53<00:00, 14.18it/s]
2022-03-21 10:03:31,796 - INFO - tqdm - f1: 0.9836, accuracy: 0.9836, batch_loss: 0.0637, loss: 0.0500 ||: 100%|#########9| 7177/7188 [07:54<00:00, 14.21it/s]
2022-03-21 10:03:31,933 - INFO - tqdm - f1: 0.9836, accuracy: 0.9836, batch_loss: 0.0021, loss: 0.0501 ||: 100%|#########9| 7179/7188 [07:54<00:00, 14.34it/s]
2022-03-21 10:03:32,069 - INFO - tqdm - f1: 0.9836, accuracy: 0.9836, batch_loss: 0.0811, loss: 0.0501 ||: 100%|#########9| 7181/7188 [07:54<00:00, 14.42it/s]
2022-03-21 10:03:32,246 - INFO - tqdm - f1: 0.9836, accuracy: 0.9836, batch_loss: 0.0015, loss: 0.0501 ||: 100%|#########9| 7183/7188 [07:54<00:00, 13.34it/s]
2022-03-21 10:03:32,397 - INFO - tqdm - f1: 0.9836, accuracy: 0.9836, batch_loss: 0.0021, loss: 0.0501 ||: 100%|#########9| 7185/7188 [07:54<00:00, 13.31it/s]
2022-03-21 10:03:32,535 - INFO - tqdm - f1: 0.9837, accuracy: 0.9836, batch_loss: 0.0161, loss: 0.0501 ||: 100%|#########9| 7187/7188 [07:54<00:00, 13.65it/s]
2022-03-21 10:03:32,652 - INFO - tqdm - f1: 0.9837, accuracy: 0.9837, batch_loss: 0.0327, loss: 0.0501 ||: 100%|##########| 7188/7188 [07:54<00:00, 15.14it/s]
2022-03-21 10:03:32,679 - INFO - allennlp.training.trainer - Validating
2022-03-21 10:03:32,682 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 10:03:41,655 - INFO - tqdm - f1: 0.9378, accuracy: 0.9378, batch_loss: 0.0012, loss: 0.3006 ||: 100%|#########9| 312/313 [00:08<00:00, 39.27it/s]
2022-03-21 10:03:41,687 - INFO - tqdm - f1: 0.9372, accuracy: 0.9372, batch_loss: 1.0184, loss: 0.3029 ||: 100%|##########| 313/313 [00:09<00:00, 34.76it/s]
2022-03-21 10:03:41,693 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-21 10:03:41,706 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-21 10:03:42,105 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-21 10:03:42,125 - INFO - allennlp.training.util - Iterating over dataset
2022-03-21 10:03:42,135 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-21 10:03:42,170 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 10:03:42,179 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 10:03:52,172 - INFO - tqdm - f1: 0.94, accuracy: 0.94, loss: 0.25 ||: : 351it [00:10, 32.26it/s]
2022-03-21 10:03:55,674 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 5,
  "peak_worker_0_memory_MB": 7579.890625,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "1:53:06.844455",
  "training_start_epoch": 0,
  "training_epochs": 7,
  "epoch": 7,
  "training_f1": 0.9816053062677383,
  "training_accuracy": 0.9816,
  "training_loss": 0.056016138739998306,
  "training_worker_0_memory_MB": 7579.890625,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.9338645339012146,
  "validation_accuracy": 0.9338,
  "validation_loss": 0.3241323653332214,
  "best_validation_f1": 0.9409764409065247,
  "best_validation_accuracy": 0.941,
  "best_validation_loss": 0.25023066954030404,
  "test_f1": 0.9350604712963104,
  "test_accuracy": 0.9351315789473684,
  "test_loss": 0.2568677654546244
}
2022-03-21 10:03:55,756 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/ag_base_hyper_small_seed_13/model.tar.gz
