2022-03-21 12:47:45,093 - INFO - allennlp.common.params - random_seed = 177
2022-03-21 12:47:45,096 - INFO - allennlp.common.params - numpy_seed = 177
2022-03-21 12:47:45,097 - INFO - allennlp.common.params - pytorch_seed = 177
2022-03-21 12:47:45,103 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-21 12:47:45,106 - INFO - allennlp.common.params - type = default
2022-03-21 12:47:45,108 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-21 12:47:45,110 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 12:47:45,112 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 12:47:45,113 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 12:47:45,114 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 12:47:45,116 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 12:47:45,117 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 12:47:58,638 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 12:47:58,640 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 12:47:58,641 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 12:47:58,642 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-21 12:47:58,643 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-21 12:47:58,645 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 12:47:58,646 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-21 12:47:58,647 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-21 12:47:58,648 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-21 12:47:58,650 - INFO - allennlp.common.params - train_data_path = datasets/ag/train.jsonl
2022-03-21 12:47:58,653 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7fd620443210>
2022-03-21 12:47:58,655 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-21 12:47:58,656 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-21 12:47:58,658 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 12:47:58,659 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 12:47:58,661 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 12:47:58,662 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 12:47:58,663 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 12:47:58,665 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 12:47:58,667 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 12:47:58,668 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 12:47:58,670 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 12:47:58,671 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-21 12:47:58,673 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-21 12:47:58,674 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 12:47:58,675 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-21 12:47:58,677 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-21 12:47:58,678 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-21 12:47:58,680 - INFO - allennlp.common.params - validation_data_path = datasets/ag/dev.jsonl
2022-03-21 12:47:58,681 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-21 12:47:58,683 - INFO - allennlp.common.params - test_data_path = datasets/ag/test.jsonl
2022-03-21 12:47:58,684 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-21 12:47:58,686 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-21 12:47:58,691 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 12:47:58,693 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 12:47:58,694 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 12:47:58,696 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 12:47:58,697 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 12:47:58,699 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 12:47:58,700 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 12:47:58,702 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 12:47:58,703 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 12:47:58,704 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 12:47:58,705 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 12:47:58,706 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 12:47:58,708 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 12:47:58,709 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 12:47:58,712 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 12:48:08,735 - INFO - tqdm - loading instances: 31588it [00:10, 3704.42it/s]
2022-03-21 12:48:18,768 - INFO - tqdm - loading instances: 63142it [00:20, 3781.53it/s]
2022-03-21 12:48:28,855 - INFO - tqdm - loading instances: 94324it [00:30, 3571.85it/s]
2022-03-21 12:48:35,665 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 12:48:35,679 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 12:48:35,683 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 12:48:35,692 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 12:48:35,702 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 12:48:35,711 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 12:48:35,719 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 12:48:35,728 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 12:48:35,737 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 12:48:35,745 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 12:48:35,754 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 12:48:35,762 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 12:48:35,771 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 12:48:35,780 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 12:48:35,789 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 12:48:37,160 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 12:48:37,167 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 12:48:37,175 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 12:48:37,184 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 12:48:37,194 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 12:48:37,201 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 12:48:37,209 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 12:48:37,221 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 12:48:37,231 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 12:48:37,241 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 12:48:37,251 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 12:48:37,261 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 12:48:37,271 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 12:48:37,281 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 12:48:37,292 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 12:48:39,350 - INFO - allennlp.common.params - type = from_instances
2022-03-21 12:48:39,355 - INFO - allennlp.common.params - min_count = None
2022-03-21 12:48:39,363 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-21 12:48:39,371 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-21 12:48:39,380 - INFO - allennlp.common.params - pretrained_files = None
2022-03-21 12:48:39,389 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-21 12:48:39,398 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-21 12:48:39,407 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-21 12:48:39,416 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-21 12:48:39,424 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-21 12:48:39,433 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-21 12:48:39,441 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-21 12:48:40,143 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-21 12:48:40,146 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-21 12:48:40,147 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-21 12:48:40,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-21 12:48:40,150 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-21 12:48:40,152 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-21 12:48:40,153 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-21 12:48:40,154 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-21 12:48:40,156 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-21 12:48:40,166 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-21 12:48:40,174 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-21 12:48:40,183 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-21 12:48:40,184 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-21 12:48:46,439 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-21 12:48:46,445 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-21 12:48:46,454 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-21 12:48:46,456 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-21 12:48:46,465 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-21 12:48:46,473 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-21 12:48:46,482 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-21 12:48:46,490 - INFO - allennlp.common.params - type = tanh
2022-03-21 12:48:46,492 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-21 12:48:46,505 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-21 12:48:46,509 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-21 12:48:46,518 - INFO - allennlp.common.params - model.num_labels = None
2022-03-21 12:48:46,526 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-21 12:48:46,535 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fd791f1b290>
2022-03-21 12:48:46,544 - INFO - allennlp.common.params - model.regularizer = None
2022-03-21 12:48:46,553 - INFO - allennlp.common.params - model.track_weights = False
2022-03-21 12:48:46,561 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-21 12:48:46,563 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-21 12:48:46,565 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-21 12:48:46,566 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-21 12:48:46,567 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-21 12:48:46,569 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-21 12:48:46,570 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-21 12:48:46,571 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 12:48:46,582 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 12:48:46,590 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 12:48:46,600 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 12:48:46,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 12:48:46,616 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 12:48:46,624 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 12:48:46,633 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 12:48:46,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 12:48:46,649 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 12:48:46,658 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 12:48:46,666 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 12:48:46,675 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 12:48:46,683 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 12:48:46,684 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 12:48:46,686 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 12:48:46,694 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 12:48:46,703 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 12:48:46,711 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 12:48:46,720 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 12:48:46,728 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 12:48:46,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 12:48:46,744 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 12:48:46,753 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 12:48:46,761 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 12:48:46,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 12:48:46,777 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 12:48:46,786 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 12:48:46,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 12:48:46,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 12:48:46,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 12:48:46,799 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 12:48:46,800 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 12:48:46,801 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 12:48:46,803 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 12:48:46,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 12:48:46,814 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 12:48:46,822 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 12:48:46,832 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 12:48:46,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 12:48:46,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 12:48:46,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 12:48:46,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 12:48:46,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 12:48:46,874 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 12:48:46,883 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 12:48:46,892 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 12:48:46,900 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 12:48:46,909 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 12:48:46,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 12:48:46,925 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 12:48:46,934 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 12:48:46,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 12:48:46,951 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 12:48:46,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 12:48:46,968 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 12:48:46,977 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 12:48:46,985 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 12:48:46,993 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 12:48:47,002 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 12:48:47,011 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 12:48:47,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 12:48:47,027 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 12:48:47,036 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 12:48:47,044 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 12:48:47,052 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 12:48:47,061 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 12:48:47,069 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 12:48:47,077 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 12:48:47,086 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 12:48:47,094 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 12:48:47,103 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 12:48:47,111 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 12:48:47,119 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 12:48:47,128 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 12:48:47,136 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 12:48:47,145 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 12:48:47,153 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 12:48:47,161 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 12:48:47,170 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 12:48:47,178 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 12:48:47,187 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 12:48:47,195 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 12:48:47,203 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 12:48:47,204 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 12:48:47,206 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 12:48:47,208 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 12:48:47,217 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 12:48:47,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 12:48:47,234 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 12:48:47,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 12:48:47,251 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 12:48:47,259 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 12:48:47,268 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 12:48:47,276 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 12:48:47,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 12:48:47,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 12:48:47,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 12:48:47,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 12:48:47,319 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 12:48:47,327 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 12:48:47,335 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 12:48:47,344 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 12:48:47,354 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 12:48:47,361 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 12:48:47,369 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 12:48:47,378 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 12:48:47,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 12:48:47,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 12:48:47,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 12:48:47,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 12:48:47,426 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 12:48:47,438 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 12:48:47,447 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 12:48:47,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 12:48:47,467 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 12:48:47,477 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 12:48:47,488 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 12:48:47,498 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 12:48:47,507 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 12:48:47,518 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 12:48:47,527 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 12:48:47,537 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 12:48:47,547 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 12:48:47,557 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 12:48:47,567 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 12:48:47,577 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 12:48:47,587 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 12:48:47,597 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 12:48:47,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 12:48:47,617 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 12:48:47,627 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 12:48:47,636 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 12:48:47,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 12:48:47,647 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 12:48:47,649 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 12:48:47,650 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 12:48:47,663 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 12:48:47,672 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 12:48:47,682 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 12:48:47,691 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 12:48:47,701 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 12:48:47,711 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 12:48:47,720 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 12:48:47,730 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 12:48:47,740 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 12:48:47,749 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 12:48:47,759 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 12:48:47,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 12:48:47,778 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 12:48:47,787 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 12:48:47,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 12:48:47,798 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 12:48:47,799 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 12:48:47,800 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 12:48:47,801 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 12:48:47,803 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 12:48:47,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 12:48:47,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 12:48:47,816 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 12:48:47,826 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 12:48:47,836 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 12:48:47,844 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 12:48:47,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 12:48:47,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 12:48:47,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 12:48:47,881 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 12:48:47,891 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 12:48:47,900 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 12:48:47,909 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 12:48:47,918 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 12:48:47,928 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 12:48:47,937 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 12:48:47,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 12:48:47,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 12:48:47,948 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 12:48:47,949 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 12:48:47,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 12:48:47,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 12:48:47,962 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 12:48:47,963 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 12:48:47,964 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 12:48:47,966 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 12:48:47,967 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 12:48:47,977 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 12:48:47,986 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 12:48:47,996 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 12:48:48,003 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 12:48:48,012 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 12:48:48,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 12:48:48,030 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 12:48:48,039 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 12:48:48,047 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 12:48:48,056 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 12:48:48,065 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 12:48:48,074 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 12:48:48,083 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 12:48:48,091 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 12:48:48,100 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 12:48:54,082 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-21 12:48:54,084 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-21 12:48:54,085 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-21 12:48:54,086 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-21 12:48:54,089 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-21 12:48:54,090 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-21 12:48:54,092 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-21 12:48:54,093 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-21 12:48:54,094 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-21 12:48:54,095 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-21 12:48:54,097 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-21 12:48:54,098 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-21 12:48:54,099 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-21 12:48:54,101 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-21 12:48:54,102 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-21 12:48:54,103 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-21 12:48:54,105 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-21 12:49:01,021 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-21 12:49:01,029 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-21 12:49:01,033 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-21 12:49:01,042 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-21 12:49:01,051 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-21 12:49:01,060 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-21 12:49:01,069 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-21 12:49:01,071 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias'], {'weight_decay': 0}
2022-03-21 12:49:01,073 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight'], {}
2022-03-21 12:49:01,083 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-21 12:49:01,090 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125239300
2022-03-21 12:49:01,098 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-21 12:49:01,107 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-21 12:49:01,115 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 12:49:01,123 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 12:49:01,132 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 12:49:01,141 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 12:49:01,142 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 12:49:01,151 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 12:49:01,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 12:49:01,169 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 12:49:01,179 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 12:49:01,187 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 12:49:01,195 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 12:49:01,203 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 12:49:01,212 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 12:49:01,221 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 12:49:01,229 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 12:49:01,238 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 12:49:01,239 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 12:49:01,241 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 12:49:01,249 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 12:49:01,258 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 12:49:01,266 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 12:49:01,275 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 12:49:01,283 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 12:49:01,292 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 12:49:01,301 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 12:49:01,309 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 12:49:01,317 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 12:49:01,326 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 12:49:01,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 12:49:01,336 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 12:49:01,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 12:49:01,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 12:49:01,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 12:49:01,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 12:49:01,372 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 12:49:01,380 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 12:49:01,381 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 12:49:01,383 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 12:49:01,384 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 12:49:01,393 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 12:49:01,395 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 12:49:01,404 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 12:49:01,413 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 12:49:01,422 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 12:49:01,430 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 12:49:01,431 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 12:49:01,433 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 12:49:01,434 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 12:49:01,435 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 12:49:01,436 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 12:49:01,448 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 12:49:01,457 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 12:49:01,466 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 12:49:01,475 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 12:49:01,484 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 12:49:01,493 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 12:49:01,502 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 12:49:01,504 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 12:49:01,505 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 12:49:01,514 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 12:49:01,523 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 12:49:01,532 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 12:49:01,541 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 12:49:01,550 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 12:49:01,563 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 12:49:01,567 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 12:49:01,568 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 12:49:01,570 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 12:49:01,572 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 12:49:01,573 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 12:49:01,574 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 12:49:01,582 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 12:49:01,591 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 12:49:01,600 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 12:49:01,611 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 12:49:01,618 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 12:49:01,619 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 12:49:01,621 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 12:49:01,630 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 12:49:01,639 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 12:49:01,648 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 12:49:01,657 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 12:49:01,666 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 12:49:01,667 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 12:49:01,668 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 12:49:01,677 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 12:49:01,687 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 12:49:01,695 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 12:49:01,704 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 12:49:01,705 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 12:49:01,707 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 12:49:01,715 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 12:49:01,724 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 12:49:01,733 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 12:49:01,743 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 12:49:01,744 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 12:49:01,745 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 12:49:01,754 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 12:49:01,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 12:49:01,771 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 12:49:01,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 12:49:01,789 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 12:49:01,798 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 12:49:01,806 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 12:49:01,815 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 12:49:01,816 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 12:49:01,818 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 12:49:01,819 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 12:49:01,828 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 12:49:01,837 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 12:49:01,846 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 12:49:01,855 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 12:49:01,864 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 12:49:01,872 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 12:49:01,881 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 12:49:01,890 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 12:49:01,891 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 12:49:01,893 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 12:49:01,894 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 12:49:01,903 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 12:49:01,913 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 12:49:01,926 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 12:49:01,930 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 12:49:01,939 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 12:49:01,947 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 12:49:01,956 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 12:49:01,965 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 12:49:01,973 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 12:49:01,982 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 12:49:01,991 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 12:49:02,000 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 12:49:02,001 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 12:49:02,002 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 12:49:02,004 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 12:49:02,005 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 12:49:02,006 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 12:49:02,008 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 12:49:02,009 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 12:49:02,010 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 12:49:02,012 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 12:49:02,013 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 12:49:02,024 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 12:49:02,033 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 12:49:02,042 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 12:49:02,050 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 12:49:02,060 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 12:49:02,068 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 12:49:02,077 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 12:49:02,085 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 12:49:02,087 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 12:49:02,088 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 12:49:02,089 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 12:49:02,091 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 12:49:02,092 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 12:49:02,093 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 12:49:02,094 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 12:49:02,096 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 12:49:02,097 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 12:49:02,108 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 12:49:02,117 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 12:49:02,125 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 12:49:02,127 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 12:49:02,128 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 12:49:02,129 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 12:49:02,138 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 12:49:02,148 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 12:49:02,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 12:49:02,165 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 12:49:02,174 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 12:49:02,175 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 12:49:02,176 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 12:49:02,178 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 12:49:02,179 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 12:49:02,188 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 12:49:02,199 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 12:49:02,207 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 12:49:02,208 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 12:49:02,209 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 12:49:02,210 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 12:49:02,220 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 12:49:02,229 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 12:49:02,238 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 12:49:02,247 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 12:49:02,256 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 12:49:02,264 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 12:49:02,273 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 12:49:02,282 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 12:49:02,290 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 12:49:02,292 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 12:49:02,293 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 12:49:02,295 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 12:49:02,296 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 12:49:02,297 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 12:49:02,298 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 12:49:02,300 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 12:49:02,301 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 12:49:02,302 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 12:49:02,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 12:49:02,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 12:49:02,307 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-21 12:49:02,308 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-21 12:49:02,309 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-21 12:49:02,310 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-21 12:49:02,312 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-21 12:49:02,313 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-21 12:49:02,315 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-21 12:49:02,316 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-21 12:49:02,317 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-21 12:49:02,319 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-21 12:49:02,327 - INFO - allennlp.training.trainer - Beginning training.
2022-03-21 12:49:02,328 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-21 12:49:02,330 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.2G
2022-03-21 12:49:02,331 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 12:49:02,334 - INFO - allennlp.training.trainer - Training
2022-03-21 12:49:02,335 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 12:49:02,455 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 12:49:02,456 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 12:49:12,429 - INFO - tqdm - f1: 0.7468, accuracy: 0.7486, batch_loss: 0.2823, loss: 0.6947 ||:   1%|1         | 89/7188 [00:10<07:56, 14.90it/s]
2022-03-21 12:49:22,524 - INFO - tqdm - f1: 0.8133, accuracy: 0.8131, batch_loss: 0.5837, loss: 0.5327 ||:   3%|2         | 199/7188 [00:20<08:03, 14.45it/s]
2022-03-21 12:49:32,569 - INFO - tqdm - f1: 0.8447, accuracy: 0.8446, batch_loss: 0.2463, loss: 0.4559 ||:   5%|4         | 349/7188 [00:30<07:39, 14.90it/s]
2022-03-21 12:49:42,594 - INFO - tqdm - f1: 0.8604, accuracy: 0.8604, batch_loss: 0.1972, loss: 0.4153 ||:   7%|7         | 505/7188 [00:40<07:03, 15.78it/s]
2022-03-21 12:49:52,652 - INFO - tqdm - f1: 0.8679, accuracy: 0.8678, batch_loss: 0.2722, loss: 0.3875 ||:   9%|9         | 661/7188 [00:50<07:06, 15.30it/s]
2022-03-21 12:50:02,679 - INFO - tqdm - f1: 0.8740, accuracy: 0.8741, batch_loss: 0.2833, loss: 0.3674 ||:  11%|#1        | 819/7188 [01:00<06:33, 16.19it/s]
2022-03-21 12:50:12,774 - INFO - tqdm - f1: 0.8798, accuracy: 0.8800, batch_loss: 0.5235, loss: 0.3519 ||:  14%|#3        | 975/7188 [01:10<06:45, 15.31it/s]
2022-03-21 12:50:22,849 - INFO - tqdm - f1: 0.8827, accuracy: 0.8831, batch_loss: 0.0519, loss: 0.3409 ||:  16%|#5        | 1131/7188 [01:20<06:33, 15.39it/s]
2022-03-21 12:50:32,893 - INFO - tqdm - f1: 0.8870, accuracy: 0.8876, batch_loss: 0.1231, loss: 0.3279 ||:  18%|#7        | 1289/7188 [01:30<06:11, 15.88it/s]
2022-03-21 12:50:42,982 - INFO - tqdm - f1: 0.8889, accuracy: 0.8894, batch_loss: 0.5162, loss: 0.3209 ||:  20%|##        | 1447/7188 [01:40<06:05, 15.73it/s]
2022-03-21 12:50:53,081 - INFO - tqdm - f1: 0.8911, accuracy: 0.8914, batch_loss: 0.0493, loss: 0.3140 ||:  22%|##2       | 1605/7188 [01:50<05:55, 15.71it/s]
2022-03-21 12:51:03,134 - INFO - tqdm - f1: 0.8935, accuracy: 0.8938, batch_loss: 0.2222, loss: 0.3089 ||:  25%|##4       | 1763/7188 [02:00<05:43, 15.79it/s]
2022-03-21 12:51:13,238 - INFO - tqdm - f1: 0.8952, accuracy: 0.8955, batch_loss: 0.3568, loss: 0.3035 ||:  27%|##6       | 1923/7188 [02:10<05:45, 15.22it/s]
2022-03-21 12:51:23,262 - INFO - tqdm - f1: 0.8968, accuracy: 0.8971, batch_loss: 0.3023, loss: 0.2992 ||:  29%|##8       | 2081/7188 [02:20<05:24, 15.74it/s]
2022-03-21 12:51:33,373 - INFO - tqdm - f1: 0.8983, accuracy: 0.8986, batch_loss: 0.2779, loss: 0.2948 ||:  31%|###1      | 2239/7188 [02:31<05:23, 15.31it/s]
2022-03-21 12:51:43,475 - INFO - tqdm - f1: 0.8992, accuracy: 0.8994, batch_loss: 0.0880, loss: 0.2911 ||:  33%|###3      | 2397/7188 [02:41<05:05, 15.66it/s]
2022-03-21 12:51:53,578 - INFO - tqdm - f1: 0.9009, accuracy: 0.9012, batch_loss: 0.2040, loss: 0.2851 ||:  36%|###5      | 2555/7188 [02:51<05:03, 15.27it/s]
2022-03-21 12:52:03,645 - INFO - tqdm - f1: 0.9023, accuracy: 0.9027, batch_loss: 0.3064, loss: 0.2807 ||:  38%|###7      | 2715/7188 [03:01<04:47, 15.58it/s]
2022-03-21 12:52:13,695 - INFO - tqdm - f1: 0.9029, accuracy: 0.9033, batch_loss: 0.0997, loss: 0.2785 ||:  40%|###9      | 2871/7188 [03:11<04:31, 15.90it/s]
2022-03-21 12:52:23,698 - INFO - tqdm - f1: 0.9039, accuracy: 0.9042, batch_loss: 0.1361, loss: 0.2765 ||:  42%|####2     | 3029/7188 [03:21<04:25, 15.66it/s]
2022-03-21 12:52:33,779 - INFO - tqdm - f1: 0.9049, accuracy: 0.9052, batch_loss: 0.2703, loss: 0.2741 ||:  44%|####4     | 3187/7188 [03:31<04:14, 15.69it/s]
2022-03-21 12:52:43,842 - INFO - tqdm - f1: 0.9060, accuracy: 0.9064, batch_loss: 0.3295, loss: 0.2707 ||:  47%|####6     | 3345/7188 [03:41<04:07, 15.55it/s]
2022-03-21 12:52:53,955 - INFO - tqdm - f1: 0.9070, accuracy: 0.9075, batch_loss: 0.0226, loss: 0.2678 ||:  49%|####8     | 3503/7188 [03:51<04:01, 15.27it/s]
2022-03-21 12:53:03,983 - INFO - tqdm - f1: 0.9074, accuracy: 0.9078, batch_loss: 0.0417, loss: 0.2676 ||:  51%|#####     | 3659/7188 [04:01<03:47, 15.53it/s]
2022-03-21 12:53:13,986 - INFO - tqdm - f1: 0.9075, accuracy: 0.9080, batch_loss: 0.2762, loss: 0.2659 ||:  53%|#####3    | 3813/7188 [04:11<03:28, 16.20it/s]
2022-03-21 12:53:24,010 - INFO - tqdm - f1: 0.9082, accuracy: 0.9086, batch_loss: 0.1138, loss: 0.2639 ||:  55%|#####5    | 3967/7188 [04:21<03:47, 14.13it/s]
2022-03-21 12:53:34,104 - INFO - tqdm - f1: 0.9090, accuracy: 0.9093, batch_loss: 0.3910, loss: 0.2621 ||:  57%|#####7    | 4121/7188 [04:31<03:12, 15.90it/s]
2022-03-21 12:53:44,122 - INFO - tqdm - f1: 0.9095, accuracy: 0.9098, batch_loss: 0.1557, loss: 0.2606 ||:  59%|#####9    | 4273/7188 [04:41<03:14, 14.96it/s]
2022-03-21 12:53:54,205 - INFO - tqdm - f1: 0.9100, accuracy: 0.9103, batch_loss: 0.2198, loss: 0.2594 ||:  62%|######1   | 4431/7188 [04:51<02:50, 16.16it/s]
2022-03-21 12:54:04,209 - INFO - tqdm - f1: 0.9105, accuracy: 0.9108, batch_loss: 0.3027, loss: 0.2579 ||:  64%|######3   | 4587/7188 [05:01<02:45, 15.72it/s]
2022-03-21 12:54:14,235 - INFO - tqdm - f1: 0.9108, accuracy: 0.9111, batch_loss: 0.0927, loss: 0.2566 ||:  66%|######6   | 4745/7188 [05:11<02:20, 17.38it/s]
2022-03-21 12:54:24,351 - INFO - tqdm - f1: 0.9111, accuracy: 0.9113, batch_loss: 0.1063, loss: 0.2558 ||:  68%|######8   | 4902/7188 [05:22<02:28, 15.39it/s]
2022-03-21 12:54:34,382 - INFO - tqdm - f1: 0.9116, accuracy: 0.9118, batch_loss: 0.2882, loss: 0.2548 ||:  70%|#######   | 5056/7188 [05:32<02:21, 15.07it/s]
2022-03-21 12:54:44,429 - INFO - tqdm - f1: 0.9120, accuracy: 0.9122, batch_loss: 0.2255, loss: 0.2537 ||:  72%|#######2  | 5208/7188 [05:42<02:07, 15.58it/s]
2022-03-21 12:54:54,463 - INFO - tqdm - f1: 0.9123, accuracy: 0.9125, batch_loss: 0.3971, loss: 0.2527 ||:  75%|#######4  | 5368/7188 [05:52<01:58, 15.42it/s]
2022-03-21 12:55:04,516 - INFO - tqdm - f1: 0.9128, accuracy: 0.9130, batch_loss: 0.0757, loss: 0.2518 ||:  77%|#######6  | 5526/7188 [06:02<01:43, 16.00it/s]
2022-03-21 12:55:14,606 - INFO - tqdm - f1: 0.9131, accuracy: 0.9132, batch_loss: 0.0932, loss: 0.2508 ||:  79%|#######9  | 5684/7188 [06:12<01:41, 14.81it/s]
2022-03-21 12:55:24,652 - INFO - tqdm - f1: 0.9135, accuracy: 0.9136, batch_loss: 0.1268, loss: 0.2494 ||:  81%|########1 | 5840/7188 [06:22<01:33, 14.46it/s]
2022-03-21 12:55:34,659 - INFO - tqdm - f1: 0.9139, accuracy: 0.9140, batch_loss: 0.1817, loss: 0.2485 ||:  83%|########2 | 5952/7188 [06:32<01:29, 13.80it/s]
2022-03-21 12:55:44,701 - INFO - tqdm - f1: 0.9142, accuracy: 0.9144, batch_loss: 0.1596, loss: 0.2476 ||:  84%|########4 | 6058/7188 [06:42<01:20, 14.01it/s]
2022-03-21 12:55:54,791 - INFO - tqdm - f1: 0.9144, accuracy: 0.9146, batch_loss: 0.5397, loss: 0.2471 ||:  86%|########5 | 6168/7188 [06:52<01:08, 14.84it/s]
2022-03-21 12:56:04,906 - INFO - tqdm - f1: 0.9146, accuracy: 0.9147, batch_loss: 0.2262, loss: 0.2466 ||:  87%|########7 | 6276/7188 [07:02<01:02, 14.63it/s]
2022-03-21 12:56:14,990 - INFO - tqdm - f1: 0.9147, accuracy: 0.9149, batch_loss: 0.0351, loss: 0.2459 ||:  89%|########8 | 6382/7188 [07:12<00:56, 14.27it/s]
2022-03-21 12:56:25,025 - INFO - tqdm - f1: 0.9149, accuracy: 0.9150, batch_loss: 0.2171, loss: 0.2456 ||:  90%|######### | 6486/7188 [07:22<00:47, 14.64it/s]
2022-03-21 12:56:35,043 - INFO - tqdm - f1: 0.9152, accuracy: 0.9153, batch_loss: 0.0446, loss: 0.2449 ||:  92%|#########1| 6592/7188 [07:32<00:40, 14.59it/s]
2022-03-21 12:56:45,411 - INFO - tqdm - f1: 0.9155, accuracy: 0.9156, batch_loss: 0.1408, loss: 0.2442 ||:  93%|#########3| 6685/7188 [07:43<01:54,  4.39it/s]
2022-03-21 12:56:55,503 - INFO - tqdm - f1: 0.9158, accuracy: 0.9158, batch_loss: 0.2738, loss: 0.2435 ||:  95%|#########5| 6833/7188 [07:53<00:22, 15.87it/s]
2022-03-21 12:57:05,604 - INFO - tqdm - f1: 0.9160, accuracy: 0.9161, batch_loss: 0.2386, loss: 0.2430 ||:  97%|#########7| 6991/7188 [08:03<00:12, 15.37it/s]
2022-03-21 12:57:15,609 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.0368, loss: 0.2424 ||:  99%|#########9| 7149/7188 [08:13<00:02, 15.53it/s]
2022-03-21 12:57:15,854 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.0863, loss: 0.2424 ||: 100%|#########9| 7153/7188 [08:13<00:02, 15.96it/s]
2022-03-21 12:57:15,993 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.1197, loss: 0.2424 ||: 100%|#########9| 7155/7188 [08:13<00:02, 15.45it/s]
2022-03-21 12:57:16,142 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.2066, loss: 0.2424 ||: 100%|#########9| 7157/7188 [08:13<00:02, 14.79it/s]
2022-03-21 12:57:16,286 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.9548, loss: 0.2425 ||: 100%|#########9| 7159/7188 [08:13<00:01, 14.50it/s]
2022-03-21 12:57:16,422 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.1136, loss: 0.2424 ||: 100%|#########9| 7161/7188 [08:14<00:01, 14.58it/s]
2022-03-21 12:57:16,553 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.1258, loss: 0.2424 ||: 100%|#########9| 7163/7188 [08:14<00:01, 14.75it/s]
2022-03-21 12:57:16,697 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.3852, loss: 0.2424 ||: 100%|#########9| 7165/7188 [08:14<00:01, 14.48it/s]
2022-03-21 12:57:16,839 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.1033, loss: 0.2424 ||: 100%|#########9| 7167/7188 [08:14<00:01, 14.36it/s]
2022-03-21 12:57:16,994 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.1039, loss: 0.2423 ||: 100%|#########9| 7169/7188 [08:14<00:01, 13.91it/s]
2022-03-21 12:57:17,130 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.0487, loss: 0.2423 ||: 100%|#########9| 7171/7188 [08:14<00:01, 14.12it/s]
2022-03-21 12:57:17,265 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.3308, loss: 0.2423 ||: 100%|#########9| 7173/7188 [08:14<00:01, 14.34it/s]
2022-03-21 12:57:17,404 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.1727, loss: 0.2423 ||: 100%|#########9| 7175/7188 [08:15<00:00, 14.35it/s]
2022-03-21 12:57:17,538 - INFO - tqdm - f1: 0.9163, accuracy: 0.9164, batch_loss: 0.0526, loss: 0.2422 ||: 100%|#########9| 7177/7188 [08:15<00:00, 14.53it/s]
2022-03-21 12:57:17,659 - INFO - tqdm - f1: 0.9163, accuracy: 0.9164, batch_loss: 0.2501, loss: 0.2422 ||: 100%|#########9| 7179/7188 [08:15<00:00, 15.07it/s]
2022-03-21 12:57:17,790 - INFO - tqdm - f1: 0.9164, accuracy: 0.9164, batch_loss: 0.4808, loss: 0.2422 ||: 100%|#########9| 7181/7188 [08:15<00:00, 15.12it/s]
2022-03-21 12:57:17,937 - INFO - tqdm - f1: 0.9164, accuracy: 0.9164, batch_loss: 0.1701, loss: 0.2422 ||: 100%|#########9| 7183/7188 [08:15<00:00, 14.65it/s]
2022-03-21 12:57:18,087 - INFO - tqdm - f1: 0.9164, accuracy: 0.9164, batch_loss: 0.0442, loss: 0.2421 ||: 100%|#########9| 7185/7188 [08:15<00:00, 14.21it/s]
2022-03-21 12:57:18,224 - INFO - tqdm - f1: 0.9164, accuracy: 0.9164, batch_loss: 0.1747, loss: 0.2421 ||: 100%|#########9| 7187/7188 [08:15<00:00, 14.33it/s]
2022-03-21 12:57:18,353 - INFO - tqdm - f1: 0.9164, accuracy: 0.9164, batch_loss: 0.0199, loss: 0.2420 ||: 100%|##########| 7188/7188 [08:16<00:00, 14.49it/s]
2022-03-21 12:57:18,364 - INFO - allennlp.training.trainer - Validating
2022-03-21 12:57:18,371 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 12:57:18,388 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 12:57:18,389 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 12:57:24,542 - INFO - tqdm - f1: 0.9382, accuracy: 0.9382, batch_loss: 0.0420, loss: 0.1909 ||: 100%|##########| 313/313 [00:06<00:00, 50.82it/s]
2022-03-21 12:57:24,584 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_base_hyper_small_seed_177/best.th'.
2022-03-21 12:57:28,255 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 12:57:28,259 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.916  |     0.938
2022-03-21 12:57:28,271 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.916  |     0.938
2022-03-21 12:57:28,282 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 12:57:28,294 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.242  |     0.191
2022-03-21 12:57:28,305 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7399.273  |       N/A
2022-03-21 12:57:28,317 - INFO - allennlp.training.trainer - Epoch duration: 0:08:25.988866
2022-03-21 12:57:28,328 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:15:54
2022-03-21 12:57:28,340 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-21 12:57:28,352 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 12:57:28,364 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 12:57:28,366 - INFO - allennlp.training.trainer - Training
2022-03-21 12:57:28,368 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 12:57:38,494 - INFO - tqdm - f1: 0.9396, accuracy: 0.9392, batch_loss: 0.1258, loss: 0.1773 ||:   2%|2         | 147/7188 [00:10<07:45, 15.14it/s]
2022-03-21 12:57:48,516 - INFO - tqdm - f1: 0.9396, accuracy: 0.9398, batch_loss: 0.2847, loss: 0.1759 ||:   4%|4         | 303/7188 [00:20<07:26, 15.41it/s]
2022-03-21 12:57:58,590 - INFO - tqdm - f1: 0.9387, accuracy: 0.9393, batch_loss: 0.0393, loss: 0.1744 ||:   6%|6         | 463/7188 [00:30<07:04, 15.85it/s]
2022-03-21 12:58:08,615 - INFO - tqdm - f1: 0.9382, accuracy: 0.9388, batch_loss: 0.0543, loss: 0.1766 ||:   9%|8         | 619/7188 [00:40<07:07, 15.37it/s]
2022-03-21 12:58:18,693 - INFO - tqdm - f1: 0.9394, accuracy: 0.9398, batch_loss: 0.1543, loss: 0.1742 ||:  11%|#         | 775/7188 [00:50<06:50, 15.63it/s]
2022-03-21 12:58:28,811 - INFO - tqdm - f1: 0.9384, accuracy: 0.9387, batch_loss: 0.0251, loss: 0.1754 ||:  13%|#2        | 933/7188 [01:00<06:48, 15.31it/s]
2022-03-21 12:58:38,927 - INFO - tqdm - f1: 0.9396, accuracy: 0.9399, batch_loss: 0.0193, loss: 0.1739 ||:  15%|#5        | 1091/7188 [01:10<06:17, 16.15it/s]
2022-03-21 12:58:49,012 - INFO - tqdm - f1: 0.9399, accuracy: 0.9401, batch_loss: 0.0839, loss: 0.1746 ||:  17%|#7        | 1251/7188 [01:20<05:55, 16.70it/s]
2022-03-21 12:58:59,132 - INFO - tqdm - f1: 0.9406, accuracy: 0.9406, batch_loss: 0.5320, loss: 0.1735 ||:  20%|#9        | 1411/7188 [01:30<06:16, 15.34it/s]
2022-03-21 12:59:09,133 - INFO - tqdm - f1: 0.9407, accuracy: 0.9408, batch_loss: 0.0241, loss: 0.1724 ||:  22%|##1       | 1569/7188 [01:40<05:38, 16.61it/s]
2022-03-21 12:59:19,196 - INFO - tqdm - f1: 0.9400, accuracy: 0.9402, batch_loss: 0.1654, loss: 0.1740 ||:  24%|##4       | 1727/7188 [01:50<05:34, 16.34it/s]
2022-03-21 12:59:29,278 - INFO - tqdm - f1: 0.9399, accuracy: 0.9400, batch_loss: 0.0429, loss: 0.1742 ||:  26%|##6       | 1885/7188 [02:00<05:42, 15.49it/s]
2022-03-21 12:59:39,404 - INFO - tqdm - f1: 0.9406, accuracy: 0.9407, batch_loss: 0.1528, loss: 0.1716 ||:  28%|##8       | 2043/7188 [02:11<05:46, 14.83it/s]
2022-03-21 12:59:49,474 - INFO - tqdm - f1: 0.9406, accuracy: 0.9408, batch_loss: 0.1612, loss: 0.1710 ||:  31%|###       | 2201/7188 [02:21<05:18, 15.68it/s]
2022-03-21 12:59:59,544 - INFO - tqdm - f1: 0.9407, accuracy: 0.9407, batch_loss: 0.5639, loss: 0.1709 ||:  33%|###2      | 2359/7188 [02:31<05:07, 15.72it/s]
2022-03-21 13:00:09,643 - INFO - tqdm - f1: 0.9406, accuracy: 0.9407, batch_loss: 0.3229, loss: 0.1710 ||:  35%|###5      | 2517/7188 [02:41<04:43, 16.47it/s]
2022-03-21 13:00:19,655 - INFO - tqdm - f1: 0.9405, accuracy: 0.9406, batch_loss: 0.0111, loss: 0.1709 ||:  37%|###7      | 2673/7188 [02:51<05:03, 14.89it/s]
2022-03-21 13:00:29,702 - INFO - tqdm - f1: 0.9410, accuracy: 0.9411, batch_loss: 0.1793, loss: 0.1699 ||:  39%|###9      | 2829/7188 [03:01<04:39, 15.61it/s]
2022-03-21 13:00:39,748 - INFO - tqdm - f1: 0.9413, accuracy: 0.9414, batch_loss: 0.4610, loss: 0.1695 ||:  42%|####1     | 2985/7188 [03:11<04:29, 15.58it/s]
2022-03-21 13:00:49,775 - INFO - tqdm - f1: 0.9410, accuracy: 0.9411, batch_loss: 0.0920, loss: 0.1703 ||:  44%|####3     | 3143/7188 [03:21<04:15, 15.86it/s]
2022-03-21 13:00:59,827 - INFO - tqdm - f1: 0.9411, accuracy: 0.9412, batch_loss: 0.1798, loss: 0.1700 ||:  46%|####5     | 3301/7188 [03:31<04:12, 15.41it/s]
2022-03-21 13:01:09,835 - INFO - tqdm - f1: 0.9412, accuracy: 0.9413, batch_loss: 0.0348, loss: 0.1699 ||:  48%|####8     | 3457/7188 [03:41<04:05, 15.22it/s]
2022-03-21 13:01:19,910 - INFO - tqdm - f1: 0.9413, accuracy: 0.9414, batch_loss: 0.0350, loss: 0.1694 ||:  50%|#####     | 3615/7188 [03:51<03:42, 16.03it/s]
2022-03-21 13:01:29,944 - INFO - tqdm - f1: 0.9413, accuracy: 0.9414, batch_loss: 0.1408, loss: 0.1689 ||:  52%|#####2    | 3771/7188 [04:01<03:33, 16.01it/s]
2022-03-21 13:01:39,959 - INFO - tqdm - f1: 0.9411, accuracy: 0.9412, batch_loss: 0.2794, loss: 0.1697 ||:  55%|#####4    | 3931/7188 [04:11<03:19, 16.30it/s]
2022-03-21 13:01:50,015 - INFO - tqdm - f1: 0.9410, accuracy: 0.9410, batch_loss: 0.0478, loss: 0.1703 ||:  57%|#####6    | 4089/7188 [04:21<03:12, 16.12it/s]
2022-03-21 13:02:00,080 - INFO - tqdm - f1: 0.9410, accuracy: 0.9411, batch_loss: 0.3108, loss: 0.1701 ||:  59%|#####9    | 4245/7188 [04:31<03:09, 15.56it/s]
2022-03-21 13:02:10,156 - INFO - tqdm - f1: 0.9409, accuracy: 0.9409, batch_loss: 0.1673, loss: 0.1707 ||:  61%|######1   | 4399/7188 [04:41<03:03, 15.17it/s]
2022-03-21 13:02:20,251 - INFO - tqdm - f1: 0.9409, accuracy: 0.9410, batch_loss: 0.0879, loss: 0.1708 ||:  63%|######3   | 4553/7188 [04:51<02:53, 15.19it/s]
2022-03-21 13:02:30,269 - INFO - tqdm - f1: 0.9410, accuracy: 0.9411, batch_loss: 0.0689, loss: 0.1709 ||:  65%|######5   | 4707/7188 [05:01<02:44, 15.05it/s]
2022-03-21 13:02:40,397 - INFO - tqdm - f1: 0.9410, accuracy: 0.9410, batch_loss: 0.0343, loss: 0.1715 ||:  68%|######7   | 4863/7188 [05:12<02:38, 14.65it/s]
2022-03-21 13:02:50,530 - INFO - tqdm - f1: 0.9410, accuracy: 0.9410, batch_loss: 0.0355, loss: 0.1711 ||:  70%|######9   | 5015/7188 [05:22<02:39, 13.63it/s]
2022-03-21 13:03:00,663 - INFO - tqdm - f1: 0.9411, accuracy: 0.9412, batch_loss: 0.0647, loss: 0.1708 ||:  72%|#######1  | 5143/7188 [05:32<05:09,  6.60it/s]
2022-03-21 13:03:10,718 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.3166, loss: 0.1710 ||:  73%|#######3  | 5249/7188 [05:42<02:42, 11.94it/s]
2022-03-21 13:03:20,804 - INFO - tqdm - f1: 0.9411, accuracy: 0.9411, batch_loss: 0.0700, loss: 0.1713 ||:  74%|#######4  | 5355/7188 [05:52<02:30, 12.21it/s]
2022-03-21 13:03:30,810 - INFO - tqdm - f1: 0.9411, accuracy: 0.9411, batch_loss: 0.1786, loss: 0.1711 ||:  76%|#######5  | 5461/7188 [06:02<02:23, 12.05it/s]
2022-03-21 13:03:40,858 - INFO - tqdm - f1: 0.9410, accuracy: 0.9410, batch_loss: 0.0403, loss: 0.1712 ||:  77%|#######7  | 5565/7188 [06:12<03:58,  6.81it/s]
2022-03-21 13:03:50,899 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.0148, loss: 0.1709 ||:  79%|#######8  | 5669/7188 [06:22<03:41,  6.86it/s]
2022-03-21 13:04:00,955 - INFO - tqdm - f1: 0.9413, accuracy: 0.9413, batch_loss: 0.3391, loss: 0.1705 ||:  80%|########  | 5773/7188 [06:32<04:12,  5.61it/s]
2022-03-21 13:04:11,578 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.3314, loss: 0.1709 ||:  82%|########1 | 5883/7188 [06:43<05:05,  4.28it/s]
2022-03-21 13:04:22,214 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.2078, loss: 0.1708 ||:  83%|########3 | 5997/7188 [06:53<04:25,  4.48it/s]
2022-03-21 13:04:32,336 - INFO - tqdm - f1: 0.9411, accuracy: 0.9411, batch_loss: 0.0800, loss: 0.1712 ||:  85%|########4 | 6105/7188 [07:03<03:08,  5.76it/s]
2022-03-21 13:04:42,466 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.3898, loss: 0.1710 ||:  86%|########6 | 6213/7188 [07:14<02:17,  7.09it/s]
2022-03-21 13:04:52,595 - INFO - tqdm - f1: 0.9410, accuracy: 0.9410, batch_loss: 0.0121, loss: 0.1716 ||:  88%|########7 | 6319/7188 [07:24<02:37,  5.52it/s]
2022-03-21 13:05:02,724 - INFO - tqdm - f1: 0.9410, accuracy: 0.9410, batch_loss: 0.0131, loss: 0.1715 ||:  89%|########9 | 6427/7188 [07:34<01:31,  8.35it/s]
2022-03-21 13:05:12,783 - INFO - tqdm - f1: 0.9411, accuracy: 0.9411, batch_loss: 0.4368, loss: 0.1711 ||:  91%|######### | 6535/7188 [07:44<01:52,  5.83it/s]
2022-03-21 13:05:22,889 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.2865, loss: 0.1708 ||:  93%|#########2| 6657/7188 [07:54<00:34, 15.21it/s]
2022-03-21 13:05:32,901 - INFO - tqdm - f1: 0.9413, accuracy: 0.9412, batch_loss: 0.4007, loss: 0.1706 ||:  94%|#########4| 6759/7188 [08:04<00:29, 14.71it/s]
2022-03-21 13:05:42,966 - INFO - tqdm - f1: 0.9411, accuracy: 0.9411, batch_loss: 0.0856, loss: 0.1710 ||:  95%|#########5| 6861/7188 [08:14<00:28, 11.42it/s]
2022-03-21 13:05:53,015 - INFO - tqdm - f1: 0.9410, accuracy: 0.9410, batch_loss: 0.4121, loss: 0.1713 ||:  97%|#########7| 6999/7188 [08:24<00:11, 16.07it/s]
2022-03-21 13:06:03,088 - INFO - tqdm - f1: 0.9413, accuracy: 0.9412, batch_loss: 0.0787, loss: 0.1707 ||: 100%|#########9| 7153/7188 [08:34<00:02, 14.44it/s]
2022-03-21 13:06:03,230 - INFO - tqdm - f1: 0.9413, accuracy: 0.9412, batch_loss: 0.0557, loss: 0.1706 ||: 100%|#########9| 7155/7188 [08:34<00:02, 14.30it/s]
2022-03-21 13:06:03,361 - INFO - tqdm - f1: 0.9413, accuracy: 0.9412, batch_loss: 0.1601, loss: 0.1706 ||: 100%|#########9| 7157/7188 [08:34<00:02, 14.59it/s]
2022-03-21 13:06:03,524 - INFO - tqdm - f1: 0.9413, accuracy: 0.9412, batch_loss: 0.0646, loss: 0.1706 ||: 100%|#########9| 7159/7188 [08:35<00:02, 13.80it/s]
2022-03-21 13:06:03,744 - INFO - tqdm - f1: 0.9413, accuracy: 0.9412, batch_loss: 0.2536, loss: 0.1706 ||: 100%|#########9| 7161/7188 [08:35<00:02, 11.94it/s]
2022-03-21 13:06:03,907 - INFO - tqdm - f1: 0.9413, accuracy: 0.9412, batch_loss: 0.1760, loss: 0.1706 ||: 100%|#########9| 7163/7188 [08:35<00:02, 12.04it/s]
2022-03-21 13:06:04,066 - INFO - tqdm - f1: 0.9413, accuracy: 0.9412, batch_loss: 0.0754, loss: 0.1706 ||: 100%|#########9| 7165/7188 [08:35<00:01, 12.19it/s]
2022-03-21 13:06:04,239 - INFO - tqdm - f1: 0.9413, accuracy: 0.9412, batch_loss: 0.2257, loss: 0.1706 ||: 100%|#########9| 7167/7188 [08:35<00:01, 12.00it/s]
2022-03-21 13:06:04,395 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.2659, loss: 0.1707 ||: 100%|#########9| 7169/7188 [08:36<00:01, 12.23it/s]
2022-03-21 13:06:04,524 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.5680, loss: 0.1707 ||: 100%|#########9| 7171/7188 [08:36<00:01, 13.06it/s]
2022-03-21 13:06:04,681 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.0912, loss: 0.1707 ||: 100%|#########9| 7173/7188 [08:36<00:01, 12.97it/s]
2022-03-21 13:06:04,837 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.5100, loss: 0.1708 ||: 100%|#########9| 7175/7188 [08:36<00:01, 12.93it/s]
2022-03-21 13:06:04,980 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.0458, loss: 0.1707 ||: 100%|#########9| 7177/7188 [08:36<00:00, 13.23it/s]
2022-03-21 13:06:05,117 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.0916, loss: 0.1707 ||: 100%|#########9| 7179/7188 [08:36<00:00, 13.60it/s]
2022-03-21 13:06:05,246 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.2983, loss: 0.1707 ||: 100%|#########9| 7181/7188 [08:36<00:00, 14.11it/s]
2022-03-21 13:06:05,394 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.3488, loss: 0.1707 ||: 100%|#########9| 7183/7188 [08:37<00:00, 13.93it/s]
2022-03-21 13:06:05,574 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.1392, loss: 0.1707 ||: 100%|#########9| 7185/7188 [08:37<00:00, 12.96it/s]
2022-03-21 13:06:05,771 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.0709, loss: 0.1708 ||: 100%|#########9| 7187/7188 [08:37<00:00, 11.97it/s]
2022-03-21 13:06:05,925 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.0204, loss: 0.1708 ||: 100%|##########| 7188/7188 [08:37<00:00, 13.89it/s]
2022-03-21 13:06:05,947 - INFO - allennlp.training.trainer - Validating
2022-03-21 13:06:05,985 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 13:06:12,450 - INFO - tqdm - f1: 0.9370, accuracy: 0.9368, batch_loss: 0.1643, loss: 0.1990 ||: 100%|##########| 313/313 [00:06<00:00, 48.72it/s]
2022-03-21 13:06:12,494 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 13:06:12,508 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.941  |     0.937
2022-03-21 13:06:12,522 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.941  |     0.937
2022-03-21 13:06:12,536 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 13:06:12,550 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.171  |     0.199
2022-03-21 13:06:12,564 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7583.660  |       N/A
2022-03-21 13:06:12,578 - INFO - allennlp.training.trainer - Epoch duration: 0:08:44.237916
2022-03-21 13:06:12,592 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:08:41
2022-03-21 13:06:12,605 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-21 13:06:12,619 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 13:06:12,633 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 13:06:12,636 - INFO - allennlp.training.trainer - Training
2022-03-21 13:06:12,637 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 13:06:22,745 - INFO - tqdm - f1: 0.9547, accuracy: 0.9553, batch_loss: 0.2990, loss: 0.1345 ||:   2%|2         | 151/7188 [00:10<07:28, 15.68it/s]
2022-03-21 13:06:32,852 - INFO - tqdm - f1: 0.9550, accuracy: 0.9552, batch_loss: 0.1290, loss: 0.1386 ||:   4%|4         | 311/7188 [00:20<07:05, 16.17it/s]
2022-03-21 13:06:42,901 - INFO - tqdm - f1: 0.9551, accuracy: 0.9555, batch_loss: 0.0839, loss: 0.1347 ||:   7%|6         | 473/7188 [00:30<07:18, 15.32it/s]
2022-03-21 13:06:52,905 - INFO - tqdm - f1: 0.9549, accuracy: 0.9553, batch_loss: 0.1395, loss: 0.1348 ||:   9%|8         | 633/7188 [00:40<07:00, 15.59it/s]
2022-03-21 13:07:02,934 - INFO - tqdm - f1: 0.9568, accuracy: 0.9571, batch_loss: 0.3953, loss: 0.1315 ||:  11%|#1        | 798/7188 [00:50<06:49, 15.59it/s]
2022-03-21 13:07:12,976 - INFO - tqdm - f1: 0.9576, accuracy: 0.9577, batch_loss: 0.2301, loss: 0.1297 ||:  13%|#3        | 960/7188 [01:00<06:28, 16.02it/s]
2022-03-21 13:07:23,067 - INFO - tqdm - f1: 0.9567, accuracy: 0.9569, batch_loss: 0.1465, loss: 0.1305 ||:  16%|#5        | 1122/7188 [01:10<06:15, 16.16it/s]
2022-03-21 13:07:33,117 - INFO - tqdm - f1: 0.9564, accuracy: 0.9566, batch_loss: 0.0734, loss: 0.1306 ||:  18%|#7        | 1282/7188 [01:20<05:55, 16.61it/s]
2022-03-21 13:07:43,219 - INFO - tqdm - f1: 0.9563, accuracy: 0.9564, batch_loss: 0.0311, loss: 0.1309 ||:  20%|##        | 1448/7188 [01:30<05:47, 16.50it/s]
2022-03-21 13:07:53,334 - INFO - tqdm - f1: 0.9557, accuracy: 0.9559, batch_loss: 0.0780, loss: 0.1312 ||:  22%|##2       | 1610/7188 [01:40<05:53, 15.78it/s]
2022-03-21 13:08:03,362 - INFO - tqdm - f1: 0.9559, accuracy: 0.9560, batch_loss: 0.0383, loss: 0.1314 ||:  25%|##4       | 1770/7188 [01:50<05:11, 17.40it/s]
2022-03-21 13:08:13,454 - INFO - tqdm - f1: 0.9549, accuracy: 0.9550, batch_loss: 0.0206, loss: 0.1331 ||:  27%|##6       | 1933/7188 [02:00<05:03, 17.30it/s]
2022-03-21 13:08:23,466 - INFO - tqdm - f1: 0.9541, accuracy: 0.9542, batch_loss: 0.3038, loss: 0.1347 ||:  29%|##9       | 2091/7188 [02:10<05:25, 15.67it/s]
2022-03-21 13:08:33,502 - INFO - tqdm - f1: 0.9545, accuracy: 0.9545, batch_loss: 0.5955, loss: 0.1341 ||:  31%|###1      | 2251/7188 [02:20<05:17, 15.55it/s]
2022-03-21 13:08:43,558 - INFO - tqdm - f1: 0.9541, accuracy: 0.9542, batch_loss: 0.0441, loss: 0.1343 ||:  34%|###3      | 2411/7188 [02:30<04:53, 16.27it/s]
2022-03-21 13:08:53,658 - INFO - tqdm - f1: 0.9539, accuracy: 0.9540, batch_loss: 0.1534, loss: 0.1344 ||:  36%|###5      | 2573/7188 [02:41<04:26, 17.33it/s]
2022-03-21 13:09:03,777 - INFO - tqdm - f1: 0.9539, accuracy: 0.9540, batch_loss: 0.0915, loss: 0.1344 ||:  38%|###7      | 2731/7188 [02:51<04:46, 15.57it/s]
2022-03-21 13:09:13,787 - INFO - tqdm - f1: 0.9538, accuracy: 0.9539, batch_loss: 0.0820, loss: 0.1341 ||:  40%|####      | 2890/7188 [03:01<04:25, 16.19it/s]
2022-03-21 13:09:23,893 - INFO - tqdm - f1: 0.9540, accuracy: 0.9540, batch_loss: 0.0391, loss: 0.1337 ||:  42%|####2     | 3050/7188 [03:11<04:27, 15.44it/s]
2022-03-21 13:09:33,909 - INFO - tqdm - f1: 0.9541, accuracy: 0.9542, batch_loss: 0.1252, loss: 0.1336 ||:  45%|####4     | 3208/7188 [03:21<04:05, 16.24it/s]
2022-03-21 13:09:43,912 - INFO - tqdm - f1: 0.9540, accuracy: 0.9541, batch_loss: 0.0445, loss: 0.1347 ||:  47%|####6     | 3366/7188 [03:31<04:09, 15.33it/s]
2022-03-21 13:09:53,926 - INFO - tqdm - f1: 0.9539, accuracy: 0.9539, batch_loss: 0.4958, loss: 0.1350 ||:  49%|####9     | 3524/7188 [03:41<03:50, 15.90it/s]
2022-03-21 13:10:04,042 - INFO - tqdm - f1: 0.9541, accuracy: 0.9542, batch_loss: 0.1107, loss: 0.1347 ||:  51%|#####1    | 3684/7188 [03:51<03:53, 15.03it/s]
2022-03-21 13:10:14,116 - INFO - tqdm - f1: 0.9542, accuracy: 0.9542, batch_loss: 0.0177, loss: 0.1344 ||:  53%|#####3    | 3844/7188 [04:01<03:29, 15.97it/s]
2022-03-21 13:10:24,189 - INFO - tqdm - f1: 0.9543, accuracy: 0.9544, batch_loss: 0.7928, loss: 0.1343 ||:  56%|#####5    | 4004/7188 [04:11<03:31, 15.08it/s]
2022-03-21 13:10:34,202 - INFO - tqdm - f1: 0.9541, accuracy: 0.9541, batch_loss: 0.0154, loss: 0.1350 ||:  58%|#####7    | 4160/7188 [04:21<03:08, 16.06it/s]
2022-03-21 13:10:44,246 - INFO - tqdm - f1: 0.9539, accuracy: 0.9539, batch_loss: 0.2364, loss: 0.1353 ||:  60%|######    | 4320/7188 [04:31<03:02, 15.68it/s]
2022-03-21 13:10:54,273 - INFO - tqdm - f1: 0.9536, accuracy: 0.9536, batch_loss: 0.2128, loss: 0.1363 ||:  62%|######2   | 4480/7188 [04:41<02:45, 16.37it/s]
2022-03-21 13:11:04,338 - INFO - tqdm - f1: 0.9536, accuracy: 0.9536, batch_loss: 0.0922, loss: 0.1363 ||:  65%|######4   | 4640/7188 [04:51<02:43, 15.54it/s]
2022-03-21 13:11:14,389 - INFO - tqdm - f1: 0.9537, accuracy: 0.9536, batch_loss: 0.0522, loss: 0.1358 ||:  67%|######6   | 4798/7188 [05:01<02:42, 14.73it/s]
2022-03-21 13:11:24,455 - INFO - tqdm - f1: 0.9535, accuracy: 0.9535, batch_loss: 0.0131, loss: 0.1361 ||:  69%|######8   | 4958/7188 [05:11<02:19, 15.96it/s]
2022-03-21 13:11:34,543 - INFO - tqdm - f1: 0.9535, accuracy: 0.9535, batch_loss: 0.0094, loss: 0.1359 ||:  71%|#######1  | 5118/7188 [05:21<02:10, 15.92it/s]
2022-03-21 13:11:44,566 - INFO - tqdm - f1: 0.9533, accuracy: 0.9532, batch_loss: 0.3653, loss: 0.1362 ||:  73%|#######3  | 5280/7188 [05:31<01:56, 16.37it/s]
2022-03-21 13:11:54,608 - INFO - tqdm - f1: 0.9533, accuracy: 0.9533, batch_loss: 0.3699, loss: 0.1359 ||:  76%|#######5  | 5442/7188 [05:41<01:47, 16.25it/s]
2022-03-21 13:12:04,679 - INFO - tqdm - f1: 0.9532, accuracy: 0.9532, batch_loss: 0.0219, loss: 0.1359 ||:  78%|#######7  | 5604/7188 [05:52<01:36, 16.35it/s]
2022-03-21 13:12:14,783 - INFO - tqdm - f1: 0.9532, accuracy: 0.9531, batch_loss: 0.0319, loss: 0.1360 ||:  80%|########  | 5766/7188 [06:02<01:27, 16.23it/s]
2022-03-21 13:12:24,793 - INFO - tqdm - f1: 0.9530, accuracy: 0.9530, batch_loss: 0.1623, loss: 0.1364 ||:  82%|########2 | 5924/7188 [06:12<01:16, 16.52it/s]
2022-03-21 13:12:34,908 - INFO - tqdm - f1: 0.9530, accuracy: 0.9530, batch_loss: 0.0729, loss: 0.1364 ||:  85%|########4 | 6086/7188 [06:22<01:10, 15.57it/s]
2022-03-21 13:12:44,961 - INFO - tqdm - f1: 0.9529, accuracy: 0.9529, batch_loss: 0.6664, loss: 0.1366 ||:  87%|########6 | 6242/7188 [06:32<00:58, 16.31it/s]
2022-03-21 13:12:55,008 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.0245, loss: 0.1367 ||:  89%|########9 | 6402/7188 [06:42<00:49, 15.98it/s]
2022-03-21 13:13:05,060 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.2257, loss: 0.1367 ||:  91%|#########1| 6562/7188 [06:52<00:38, 16.23it/s]
2022-03-21 13:13:15,100 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.0645, loss: 0.1370 ||:  93%|#########3| 6720/7188 [07:02<00:30, 15.51it/s]
2022-03-21 13:13:25,138 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0434, loss: 0.1373 ||:  96%|#########5| 6878/7188 [07:12<00:19, 15.77it/s]
2022-03-21 13:13:35,222 - INFO - tqdm - f1: 0.9526, accuracy: 0.9526, batch_loss: 0.0273, loss: 0.1374 ||:  98%|#########7| 7037/7188 [07:22<00:09, 15.12it/s]
2022-03-21 13:13:42,702 - INFO - tqdm - f1: 0.9525, accuracy: 0.9525, batch_loss: 0.0431, loss: 0.1378 ||: 100%|#########9| 7154/7188 [07:30<00:02, 15.45it/s]
2022-03-21 13:13:42,850 - INFO - tqdm - f1: 0.9525, accuracy: 0.9525, batch_loss: 0.0416, loss: 0.1378 ||: 100%|#########9| 7156/7188 [07:30<00:02, 14.81it/s]
2022-03-21 13:13:43,000 - INFO - tqdm - f1: 0.9525, accuracy: 0.9525, batch_loss: 0.0278, loss: 0.1378 ||: 100%|#########9| 7158/7188 [07:30<00:02, 14.34it/s]
2022-03-21 13:13:43,152 - INFO - tqdm - f1: 0.9526, accuracy: 0.9525, batch_loss: 0.0483, loss: 0.1377 ||: 100%|#########9| 7160/7188 [07:30<00:02, 13.96it/s]
2022-03-21 13:13:43,293 - INFO - tqdm - f1: 0.9526, accuracy: 0.9525, batch_loss: 0.0226, loss: 0.1377 ||: 100%|#########9| 7162/7188 [07:30<00:01, 14.03it/s]
2022-03-21 13:13:43,419 - INFO - tqdm - f1: 0.9526, accuracy: 0.9525, batch_loss: 0.2736, loss: 0.1378 ||: 100%|#########9| 7164/7188 [07:30<00:01, 14.56it/s]
2022-03-21 13:13:43,557 - INFO - tqdm - f1: 0.9525, accuracy: 0.9525, batch_loss: 0.2321, loss: 0.1378 ||: 100%|#########9| 7166/7188 [07:30<00:01, 14.52it/s]
2022-03-21 13:13:43,696 - INFO - tqdm - f1: 0.9525, accuracy: 0.9525, batch_loss: 0.0972, loss: 0.1378 ||: 100%|#########9| 7168/7188 [07:31<00:01, 14.49it/s]
2022-03-21 13:13:43,839 - INFO - tqdm - f1: 0.9525, accuracy: 0.9525, batch_loss: 0.6560, loss: 0.1378 ||: 100%|#########9| 7170/7188 [07:31<00:01, 14.33it/s]
2022-03-21 13:13:43,970 - INFO - tqdm - f1: 0.9525, accuracy: 0.9525, batch_loss: 0.0738, loss: 0.1378 ||: 100%|#########9| 7172/7188 [07:31<00:01, 14.59it/s]
2022-03-21 13:13:44,110 - INFO - tqdm - f1: 0.9525, accuracy: 0.9525, batch_loss: 0.0265, loss: 0.1378 ||: 100%|#########9| 7174/7188 [07:31<00:00, 14.50it/s]
2022-03-21 13:13:44,259 - INFO - tqdm - f1: 0.9526, accuracy: 0.9525, batch_loss: 0.1082, loss: 0.1378 ||: 100%|#########9| 7176/7188 [07:31<00:00, 14.17it/s]
2022-03-21 13:13:44,398 - INFO - tqdm - f1: 0.9526, accuracy: 0.9525, batch_loss: 0.0137, loss: 0.1377 ||: 100%|#########9| 7178/7188 [07:31<00:00, 14.23it/s]
2022-03-21 13:13:44,537 - INFO - tqdm - f1: 0.9526, accuracy: 0.9525, batch_loss: 0.3252, loss: 0.1378 ||: 100%|#########9| 7180/7188 [07:31<00:00, 14.28it/s]
2022-03-21 13:13:44,680 - INFO - tqdm - f1: 0.9526, accuracy: 0.9525, batch_loss: 0.1887, loss: 0.1378 ||: 100%|#########9| 7182/7188 [07:32<00:00, 14.18it/s]
2022-03-21 13:13:44,826 - INFO - tqdm - f1: 0.9526, accuracy: 0.9525, batch_loss: 0.0259, loss: 0.1378 ||: 100%|#########9| 7184/7188 [07:32<00:00, 14.05it/s]
2022-03-21 13:13:44,948 - INFO - tqdm - f1: 0.9526, accuracy: 0.9525, batch_loss: 0.1885, loss: 0.1378 ||: 100%|#########9| 7186/7188 [07:32<00:00, 14.68it/s]
2022-03-21 13:13:45,080 - INFO - tqdm - f1: 0.9526, accuracy: 0.9525, batch_loss: 0.0584, loss: 0.1378 ||: 100%|##########| 7188/7188 [07:32<00:00, 14.81it/s]
2022-03-21 13:13:45,123 - INFO - tqdm - f1: 0.9526, accuracy: 0.9525, batch_loss: 0.0584, loss: 0.1378 ||: 100%|##########| 7188/7188 [07:32<00:00, 15.89it/s]
2022-03-21 13:13:45,129 - INFO - allennlp.training.trainer - Validating
2022-03-21 13:13:45,132 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 13:13:51,556 - INFO - tqdm - f1: 0.9415, accuracy: 0.9414, batch_loss: 0.6938, loss: 0.1910 ||: 100%|##########| 313/313 [00:06<00:00, 48.74it/s]
2022-03-21 13:13:51,611 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_base_hyper_small_seed_177/best.th'.
2022-03-21 13:13:55,887 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 13:13:55,900 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.953  |     0.941
2022-03-21 13:13:55,915 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.953  |     0.942
2022-03-21 13:13:55,929 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 13:13:55,945 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.138  |     0.191
2022-03-21 13:13:55,963 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7583.660  |       N/A
2022-03-21 13:13:55,981 - INFO - allennlp.training.trainer - Epoch duration: 0:07:43.375585
2022-03-21 13:13:55,996 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:58:05
2022-03-21 13:13:56,012 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-21 13:13:56,027 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 13:13:56,043 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 13:13:56,059 - INFO - allennlp.training.trainer - Training
2022-03-21 13:13:56,076 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 13:14:06,101 - INFO - tqdm - f1: 0.9608, accuracy: 0.9614, batch_loss: 0.0034, loss: 0.1053 ||:   1%|1         | 107/7188 [00:10<07:04, 16.70it/s]
2022-03-21 13:14:16,161 - INFO - tqdm - f1: 0.9608, accuracy: 0.9610, batch_loss: 0.3312, loss: 0.1127 ||:   4%|3         | 263/7188 [00:20<07:33, 15.27it/s]
2022-03-21 13:14:26,260 - INFO - tqdm - f1: 0.9626, accuracy: 0.9625, batch_loss: 0.0963, loss: 0.1030 ||:   6%|5         | 425/7188 [00:30<07:18, 15.42it/s]
2022-03-21 13:14:36,374 - INFO - tqdm - f1: 0.9597, accuracy: 0.9595, batch_loss: 0.0088, loss: 0.1094 ||:   8%|8         | 583/7188 [00:40<07:11, 15.31it/s]
2022-03-21 13:14:46,451 - INFO - tqdm - f1: 0.9599, accuracy: 0.9596, batch_loss: 0.3410, loss: 0.1117 ||:  10%|#         | 741/7188 [00:50<07:14, 14.85it/s]
2022-03-21 13:14:56,454 - INFO - tqdm - f1: 0.9606, accuracy: 0.9603, batch_loss: 0.0116, loss: 0.1120 ||:  12%|#2        | 897/7188 [01:00<06:51, 15.28it/s]
2022-03-21 13:15:06,475 - INFO - tqdm - f1: 0.9607, accuracy: 0.9606, batch_loss: 0.0577, loss: 0.1119 ||:  15%|#4        | 1052/7188 [01:10<06:44, 15.17it/s]
2022-03-21 13:15:16,569 - INFO - tqdm - f1: 0.9618, accuracy: 0.9617, batch_loss: 0.0650, loss: 0.1103 ||:  17%|#6        | 1212/7188 [01:20<06:14, 15.97it/s]
2022-03-21 13:15:26,586 - INFO - tqdm - f1: 0.9614, accuracy: 0.9614, batch_loss: 0.0558, loss: 0.1100 ||:  19%|#9        | 1366/7188 [01:30<06:11, 15.67it/s]
2022-03-21 13:15:36,597 - INFO - tqdm - f1: 0.9615, accuracy: 0.9614, batch_loss: 0.0143, loss: 0.1105 ||:  21%|##1       | 1520/7188 [01:40<06:07, 15.44it/s]
2022-03-21 13:15:46,622 - INFO - tqdm - f1: 0.9615, accuracy: 0.9614, batch_loss: 0.0411, loss: 0.1101 ||:  23%|##3       | 1678/7188 [01:50<05:43, 16.02it/s]
2022-03-21 13:15:56,676 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.3054, loss: 0.1075 ||:  26%|##5       | 1838/7188 [02:00<05:32, 16.09it/s]
2022-03-21 13:16:06,718 - INFO - tqdm - f1: 0.9628, accuracy: 0.9627, batch_loss: 0.0389, loss: 0.1073 ||:  28%|##7       | 1996/7188 [02:10<05:10, 16.72it/s]
2022-03-21 13:16:16,741 - INFO - tqdm - f1: 0.9629, accuracy: 0.9629, batch_loss: 0.0043, loss: 0.1071 ||:  29%|##9       | 2110/7188 [02:20<08:28,  9.99it/s]
2022-03-21 13:16:26,862 - INFO - tqdm - f1: 0.9629, accuracy: 0.9629, batch_loss: 0.0274, loss: 0.1073 ||:  31%|###       | 2221/7188 [02:30<07:14, 11.43it/s]
2022-03-21 13:16:36,994 - INFO - tqdm - f1: 0.9629, accuracy: 0.9629, batch_loss: 0.1322, loss: 0.1069 ||:  33%|###2      | 2339/7188 [02:40<05:09, 15.67it/s]
2022-03-21 13:16:47,045 - INFO - tqdm - f1: 0.9627, accuracy: 0.9627, batch_loss: 0.0980, loss: 0.1078 ||:  35%|###4      | 2495/7188 [02:50<05:00, 15.63it/s]
2022-03-21 13:16:57,101 - INFO - tqdm - f1: 0.9628, accuracy: 0.9628, batch_loss: 0.0547, loss: 0.1081 ||:  37%|###6      | 2653/7188 [03:01<04:41, 16.09it/s]
2022-03-21 13:17:07,141 - INFO - tqdm - f1: 0.9626, accuracy: 0.9627, batch_loss: 0.3059, loss: 0.1085 ||:  39%|###8      | 2797/7188 [03:11<04:41, 15.61it/s]
2022-03-21 13:17:17,173 - INFO - tqdm - f1: 0.9624, accuracy: 0.9624, batch_loss: 0.4282, loss: 0.1090 ||:  41%|####      | 2930/7188 [03:21<08:15,  8.60it/s]
2022-03-21 13:17:27,233 - INFO - tqdm - f1: 0.9627, accuracy: 0.9628, batch_loss: 0.0024, loss: 0.1084 ||:  42%|####1     | 3006/7188 [03:31<08:32,  8.16it/s]
2022-03-21 13:17:37,239 - INFO - tqdm - f1: 0.9629, accuracy: 0.9629, batch_loss: 0.2589, loss: 0.1083 ||:  43%|####2     | 3081/7188 [03:41<09:28,  7.22it/s]
2022-03-21 13:17:47,335 - INFO - tqdm - f1: 0.9630, accuracy: 0.9630, batch_loss: 0.0143, loss: 0.1080 ||:  44%|####3     | 3149/7188 [03:51<14:48,  4.55it/s]
2022-03-21 13:17:57,492 - INFO - tqdm - f1: 0.9630, accuracy: 0.9631, batch_loss: 0.1866, loss: 0.1078 ||:  44%|####4     | 3197/7188 [04:01<14:03,  4.73it/s]
2022-03-21 13:18:07,655 - INFO - tqdm - f1: 0.9628, accuracy: 0.9629, batch_loss: 0.3438, loss: 0.1081 ||:  45%|####5     | 3245/7188 [04:11<13:36,  4.83it/s]
2022-03-21 13:18:17,819 - INFO - tqdm - f1: 0.9628, accuracy: 0.9629, batch_loss: 0.2255, loss: 0.1081 ||:  46%|####5     | 3293/7188 [04:21<14:37,  4.44it/s]
2022-03-21 13:18:27,946 - INFO - tqdm - f1: 0.9628, accuracy: 0.9628, batch_loss: 0.0609, loss: 0.1081 ||:  46%|####6     | 3339/7188 [04:31<13:53,  4.62it/s]
2022-03-21 13:18:37,949 - INFO - tqdm - f1: 0.9627, accuracy: 0.9627, batch_loss: 0.2037, loss: 0.1083 ||:  47%|####7     | 3385/7188 [04:41<14:49,  4.27it/s]
2022-03-21 13:18:47,989 - INFO - tqdm - f1: 0.9627, accuracy: 0.9628, batch_loss: 0.1529, loss: 0.1082 ||:  48%|####7     | 3432/7188 [04:51<12:59,  4.82it/s]
2022-03-21 13:18:58,094 - INFO - tqdm - f1: 0.9628, accuracy: 0.9628, batch_loss: 0.0332, loss: 0.1078 ||:  48%|####8     | 3480/7188 [05:02<12:53,  4.79it/s]
2022-03-21 13:19:08,192 - INFO - tqdm - f1: 0.9629, accuracy: 0.9629, batch_loss: 0.0110, loss: 0.1075 ||:  49%|####9     | 3527/7188 [05:12<13:48,  4.42it/s]
2022-03-21 13:19:18,243 - INFO - tqdm - f1: 0.9627, accuracy: 0.9627, batch_loss: 0.0076, loss: 0.1079 ||:  50%|####9     | 3575/7188 [05:22<12:59,  4.64it/s]
2022-03-21 13:19:28,285 - INFO - tqdm - f1: 0.9628, accuracy: 0.9628, batch_loss: 0.0197, loss: 0.1078 ||:  50%|#####     | 3622/7188 [05:32<13:21,  4.45it/s]
2022-03-21 13:19:38,444 - INFO - tqdm - f1: 0.9627, accuracy: 0.9628, batch_loss: 0.0931, loss: 0.1079 ||:  51%|#####1    | 3671/7188 [05:42<08:58,  6.53it/s]
2022-03-21 13:19:48,577 - INFO - tqdm - f1: 0.9628, accuracy: 0.9628, batch_loss: 0.0915, loss: 0.1076 ||:  52%|#####1    | 3718/7188 [05:52<13:05,  4.42it/s]
2022-03-21 13:19:58,734 - INFO - tqdm - f1: 0.9628, accuracy: 0.9629, batch_loss: 0.0425, loss: 0.1077 ||:  52%|#####2    | 3766/7188 [06:02<12:07,  4.70it/s]
2022-03-21 13:20:08,911 - INFO - tqdm - f1: 0.9629, accuracy: 0.9629, batch_loss: 0.0414, loss: 0.1077 ||:  53%|#####3    | 3815/7188 [06:12<11:46,  4.77it/s]
2022-03-21 13:20:19,015 - INFO - tqdm - f1: 0.9629, accuracy: 0.9629, batch_loss: 0.4522, loss: 0.1073 ||:  54%|#####3    | 3862/7188 [06:22<11:51,  4.67it/s]
2022-03-21 13:20:29,184 - INFO - tqdm - f1: 0.9628, accuracy: 0.9628, batch_loss: 0.0111, loss: 0.1077 ||:  54%|#####4    | 3910/7188 [06:33<11:21,  4.81it/s]
2022-03-21 13:20:39,309 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.2665, loss: 0.1080 ||:  55%|#####5    | 3957/7188 [06:43<11:09,  4.83it/s]
2022-03-21 13:20:49,464 - INFO - tqdm - f1: 0.9628, accuracy: 0.9628, batch_loss: 0.0084, loss: 0.1077 ||:  56%|#####5    | 4005/7188 [06:53<11:06,  4.77it/s]
2022-03-21 13:20:59,655 - INFO - tqdm - f1: 0.9629, accuracy: 0.9629, batch_loss: 0.0831, loss: 0.1074 ||:  56%|#####6    | 4054/7188 [07:03<11:58,  4.36it/s]
2022-03-21 13:21:09,820 - INFO - tqdm - f1: 0.9629, accuracy: 0.9629, batch_loss: 0.1093, loss: 0.1073 ||:  57%|#####7    | 4102/7188 [07:13<10:14,  5.02it/s]
2022-03-21 13:21:19,943 - INFO - tqdm - f1: 0.9628, accuracy: 0.9628, batch_loss: 0.1079, loss: 0.1075 ||:  58%|#####7    | 4151/7188 [07:23<10:15,  4.94it/s]
2022-03-21 13:21:30,025 - INFO - tqdm - f1: 0.9627, accuracy: 0.9627, batch_loss: 0.4085, loss: 0.1075 ||:  58%|#####8    | 4197/7188 [07:33<10:37,  4.69it/s]
2022-03-21 13:21:40,189 - INFO - tqdm - f1: 0.9627, accuracy: 0.9626, batch_loss: 0.1062, loss: 0.1079 ||:  59%|#####9    | 4245/7188 [07:44<10:19,  4.75it/s]
2022-03-21 13:21:50,377 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.0085, loss: 0.1079 ||:  60%|#####9    | 4295/7188 [07:54<10:15,  4.70it/s]
2022-03-21 13:22:00,471 - INFO - tqdm - f1: 0.9627, accuracy: 0.9627, batch_loss: 0.0018, loss: 0.1075 ||:  60%|######    | 4341/7188 [08:04<11:09,  4.25it/s]
2022-03-21 13:22:10,653 - INFO - tqdm - f1: 0.9628, accuracy: 0.9627, batch_loss: 0.0393, loss: 0.1075 ||:  61%|######1   | 4388/7188 [08:14<10:33,  4.42it/s]
2022-03-21 13:22:20,807 - INFO - tqdm - f1: 0.9627, accuracy: 0.9627, batch_loss: 0.0212, loss: 0.1074 ||:  62%|######1   | 4435/7188 [08:24<10:04,  4.56it/s]
2022-03-21 13:22:30,958 - INFO - tqdm - f1: 0.9628, accuracy: 0.9628, batch_loss: 0.0405, loss: 0.1073 ||:  62%|######2   | 4482/7188 [08:34<10:00,  4.51it/s]
2022-03-21 13:22:41,063 - INFO - tqdm - f1: 0.9629, accuracy: 0.9628, batch_loss: 0.0078, loss: 0.1072 ||:  63%|######3   | 4530/7188 [08:44<09:47,  4.52it/s]
2022-03-21 13:22:51,294 - INFO - tqdm - f1: 0.9628, accuracy: 0.9628, batch_loss: 0.0163, loss: 0.1075 ||:  64%|######3   | 4577/7188 [08:55<10:15,  4.24it/s]
2022-03-21 13:23:01,447 - INFO - tqdm - f1: 0.9630, accuracy: 0.9630, batch_loss: 0.0162, loss: 0.1073 ||:  64%|######4   | 4625/7188 [09:05<10:06,  4.22it/s]
2022-03-21 13:23:11,459 - INFO - tqdm - f1: 0.9630, accuracy: 0.9630, batch_loss: 0.0248, loss: 0.1073 ||:  65%|######4   | 4672/7188 [09:15<09:50,  4.26it/s]
2022-03-21 13:23:21,544 - INFO - tqdm - f1: 0.9630, accuracy: 0.9630, batch_loss: 0.0485, loss: 0.1074 ||:  66%|######5   | 4719/7188 [09:25<08:07,  5.07it/s]
2022-03-21 13:23:31,717 - INFO - tqdm - f1: 0.9630, accuracy: 0.9629, batch_loss: 0.0392, loss: 0.1076 ||:  66%|######6   | 4766/7188 [09:35<08:58,  4.50it/s]
2022-03-21 13:23:41,893 - INFO - tqdm - f1: 0.9631, accuracy: 0.9631, batch_loss: 0.1160, loss: 0.1075 ||:  67%|######6   | 4814/7188 [09:45<08:04,  4.90it/s]
2022-03-21 13:23:51,905 - INFO - tqdm - f1: 0.9630, accuracy: 0.9630, batch_loss: 0.0087, loss: 0.1078 ||:  68%|######7   | 4864/7188 [09:55<07:13,  5.36it/s]
2022-03-21 13:24:02,001 - INFO - tqdm - f1: 0.9631, accuracy: 0.9631, batch_loss: 0.0804, loss: 0.1077 ||:  68%|######8   | 4911/7188 [10:05<08:19,  4.56it/s]
2022-03-21 13:24:12,058 - INFO - tqdm - f1: 0.9631, accuracy: 0.9631, batch_loss: 0.0414, loss: 0.1078 ||:  69%|######8   | 4959/7188 [10:15<08:36,  4.32it/s]
2022-03-21 13:24:22,166 - INFO - tqdm - f1: 0.9631, accuracy: 0.9630, batch_loss: 0.2181, loss: 0.1078 ||:  70%|######9   | 5005/7188 [10:26<07:40,  4.74it/s]
2022-03-21 13:24:32,268 - INFO - tqdm - f1: 0.9630, accuracy: 0.9630, batch_loss: 0.0749, loss: 0.1079 ||:  70%|#######   | 5051/7188 [10:36<07:30,  4.74it/s]
2022-03-21 13:24:42,277 - INFO - tqdm - f1: 0.9629, accuracy: 0.9628, batch_loss: 0.0533, loss: 0.1082 ||:  71%|#######   | 5100/7188 [10:46<07:27,  4.67it/s]
2022-03-21 13:24:52,489 - INFO - tqdm - f1: 0.9630, accuracy: 0.9629, batch_loss: 0.1635, loss: 0.1080 ||:  72%|#######1  | 5149/7188 [10:56<07:11,  4.73it/s]
2022-03-21 13:25:02,580 - INFO - tqdm - f1: 0.9631, accuracy: 0.9630, batch_loss: 0.0048, loss: 0.1078 ||:  72%|#######2  | 5196/7188 [11:06<06:48,  4.88it/s]
2022-03-21 13:25:12,692 - INFO - tqdm - f1: 0.9631, accuracy: 0.9631, batch_loss: 0.1764, loss: 0.1076 ||:  73%|#######2  | 5242/7188 [11:16<07:33,  4.29it/s]
2022-03-21 13:25:22,819 - INFO - tqdm - f1: 0.9631, accuracy: 0.9631, batch_loss: 0.1105, loss: 0.1077 ||:  74%|#######3  | 5289/7188 [11:26<07:01,  4.51it/s]
2022-03-21 13:25:32,956 - INFO - tqdm - f1: 0.9631, accuracy: 0.9631, batch_loss: 0.0110, loss: 0.1077 ||:  74%|#######4  | 5339/7188 [11:36<05:40,  5.44it/s]
2022-03-21 13:25:43,009 - INFO - tqdm - f1: 0.9630, accuracy: 0.9630, batch_loss: 0.2035, loss: 0.1079 ||:  75%|#######4  | 5387/7188 [11:46<06:19,  4.74it/s]
2022-03-21 13:25:53,127 - INFO - tqdm - f1: 0.9630, accuracy: 0.9629, batch_loss: 0.1072, loss: 0.1080 ||:  76%|#######5  | 5433/7188 [11:57<06:11,  4.72it/s]
2022-03-21 13:26:03,264 - INFO - tqdm - f1: 0.9629, accuracy: 0.9629, batch_loss: 0.0670, loss: 0.1082 ||:  76%|#######6  | 5481/7188 [12:07<05:55,  4.80it/s]
2022-03-21 13:26:13,396 - INFO - tqdm - f1: 0.9628, accuracy: 0.9627, batch_loss: 0.0823, loss: 0.1086 ||:  77%|#######6  | 5529/7188 [12:17<06:37,  4.18it/s]
2022-03-21 13:26:23,420 - INFO - tqdm - f1: 0.9627, accuracy: 0.9626, batch_loss: 0.0279, loss: 0.1087 ||:  78%|#######7  | 5575/7188 [12:27<06:25,  4.18it/s]
2022-03-21 13:26:33,557 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.0740, loss: 0.1088 ||:  78%|#######8  | 5624/7188 [12:37<05:43,  4.55it/s]
2022-03-21 13:26:43,608 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.1252, loss: 0.1088 ||:  79%|#######8  | 5670/7188 [12:47<05:27,  4.63it/s]
2022-03-21 13:26:53,693 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.0057, loss: 0.1088 ||:  80%|#######9  | 5717/7188 [12:57<05:37,  4.36it/s]
2022-03-21 13:27:03,893 - INFO - tqdm - f1: 0.9627, accuracy: 0.9626, batch_loss: 0.0081, loss: 0.1089 ||:  80%|########  | 5767/7188 [13:07<04:51,  4.88it/s]
2022-03-21 13:27:14,025 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.0699, loss: 0.1090 ||:  81%|########  | 5814/7188 [13:17<04:52,  4.69it/s]
2022-03-21 13:27:24,174 - INFO - tqdm - f1: 0.9626, accuracy: 0.9625, batch_loss: 0.0959, loss: 0.1091 ||:  82%|########1 | 5863/7188 [13:28<04:19,  5.10it/s]
2022-03-21 13:27:34,354 - INFO - tqdm - f1: 0.9626, accuracy: 0.9625, batch_loss: 0.0762, loss: 0.1090 ||:  82%|########2 | 5910/7188 [13:38<04:27,  4.78it/s]
2022-03-21 13:27:44,430 - INFO - tqdm - f1: 0.9625, accuracy: 0.9625, batch_loss: 0.2907, loss: 0.1092 ||:  83%|########2 | 5961/7188 [13:48<03:44,  5.47it/s]
2022-03-21 13:27:54,494 - INFO - tqdm - f1: 0.9624, accuracy: 0.9623, batch_loss: 0.0170, loss: 0.1097 ||:  84%|########3 | 6010/7188 [13:58<04:15,  4.61it/s]
2022-03-21 13:28:04,636 - INFO - tqdm - f1: 0.9623, accuracy: 0.9622, batch_loss: 0.1209, loss: 0.1099 ||:  84%|########4 | 6057/7188 [14:08<03:59,  4.72it/s]
2022-03-21 13:28:14,637 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.1460, loss: 0.1102 ||:  85%|########4 | 6107/7188 [14:18<03:37,  4.96it/s]
2022-03-21 13:28:24,796 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0583, loss: 0.1104 ||:  86%|########5 | 6155/7188 [14:28<03:32,  4.86it/s]
2022-03-21 13:28:34,933 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0449, loss: 0.1105 ||:  86%|########6 | 6201/7188 [14:38<03:35,  4.58it/s]
2022-03-21 13:28:45,056 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.1387, loss: 0.1106 ||:  87%|########6 | 6247/7188 [14:48<03:24,  4.61it/s]
2022-03-21 13:28:55,099 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0361, loss: 0.1106 ||:  88%|########7 | 6294/7188 [14:59<03:28,  4.28it/s]
2022-03-21 13:29:05,174 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.0277, loss: 0.1105 ||:  88%|########8 | 6342/7188 [15:09<03:10,  4.44it/s]
2022-03-21 13:29:15,378 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.2317, loss: 0.1106 ||:  89%|########8 | 6388/7188 [15:19<03:11,  4.17it/s]
2022-03-21 13:29:25,422 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0953, loss: 0.1110 ||:  90%|########9 | 6435/7188 [15:29<02:48,  4.48it/s]
2022-03-21 13:29:35,666 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.0034, loss: 0.1108 ||:  90%|######### | 6482/7188 [15:39<02:47,  4.20it/s]
2022-03-21 13:29:45,803 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0569, loss: 0.1111 ||:  91%|######### | 6529/7188 [15:49<02:19,  4.72it/s]
2022-03-21 13:29:55,932 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0186, loss: 0.1111 ||:  91%|#########1| 6575/7188 [15:59<02:19,  4.39it/s]
2022-03-21 13:30:05,983 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0551, loss: 0.1111 ||:  92%|#########2| 6622/7188 [16:09<01:55,  4.88it/s]
2022-03-21 13:30:16,134 - INFO - tqdm - f1: 0.9621, accuracy: 0.9620, batch_loss: 0.0102, loss: 0.1111 ||:  93%|#########2| 6670/7188 [16:20<01:59,  4.33it/s]
2022-03-21 13:30:26,308 - INFO - tqdm - f1: 0.9621, accuracy: 0.9620, batch_loss: 0.1719, loss: 0.1112 ||:  93%|#########3| 6718/7188 [16:30<01:43,  4.54it/s]
2022-03-21 13:30:36,372 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0362, loss: 0.1109 ||:  94%|#########4| 6764/7188 [16:40<01:27,  4.83it/s]
2022-03-21 13:30:46,549 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.2836, loss: 0.1109 ||:  95%|#########4| 6813/7188 [16:50<01:14,  5.00it/s]
2022-03-21 13:30:56,715 - INFO - tqdm - f1: 0.9623, accuracy: 0.9622, batch_loss: 0.0172, loss: 0.1108 ||:  95%|#########5| 6862/7188 [17:00<01:04,  5.03it/s]
2022-03-21 13:31:06,889 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.2742, loss: 0.1106 ||:  96%|#########6| 6911/7188 [17:10<00:55,  4.96it/s]
2022-03-21 13:31:17,006 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.2494, loss: 0.1107 ||:  97%|#########6| 6961/7188 [17:20<00:44,  5.15it/s]
2022-03-21 13:31:27,118 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0141, loss: 0.1107 ||:  97%|#########7| 7008/7188 [17:31<00:32,  5.53it/s]
2022-03-21 13:31:37,145 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0473, loss: 0.1107 ||:  98%|#########8| 7057/7188 [17:41<00:27,  4.80it/s]
2022-03-21 13:31:47,317 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.0596, loss: 0.1109 ||:  99%|#########8| 7106/7188 [17:51<00:16,  4.83it/s]
2022-03-21 13:31:56,906 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.1166, loss: 0.1111 ||: 100%|#########9| 7153/7188 [18:00<00:07,  4.63it/s]
2022-03-21 13:31:57,063 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0678, loss: 0.1111 ||: 100%|#########9| 7154/7188 [18:00<00:06,  5.05it/s]
2022-03-21 13:31:57,303 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0563, loss: 0.1111 ||: 100%|#########9| 7155/7188 [18:01<00:06,  4.75it/s]
2022-03-21 13:31:57,515 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.1028, loss: 0.1111 ||: 100%|#########9| 7156/7188 [18:01<00:06,  4.73it/s]
2022-03-21 13:31:57,658 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0859, loss: 0.1110 ||: 100%|#########9| 7157/7188 [18:01<00:05,  5.24it/s]
2022-03-21 13:31:57,900 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.2282, loss: 0.1111 ||: 100%|#########9| 7158/7188 [18:01<00:06,  4.85it/s]
2022-03-21 13:31:58,123 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0334, loss: 0.1111 ||: 100%|#########9| 7159/7188 [18:02<00:06,  4.74it/s]
2022-03-21 13:31:58,276 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0178, loss: 0.1110 ||: 100%|#########9| 7160/7188 [18:02<00:05,  5.16it/s]
2022-03-21 13:31:58,527 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0102, loss: 0.1110 ||: 100%|#########9| 7161/7188 [18:02<00:05,  4.74it/s]
2022-03-21 13:31:58,727 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0596, loss: 0.1110 ||: 100%|#########9| 7162/7188 [18:02<00:05,  4.81it/s]
2022-03-21 13:31:58,876 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.1457, loss: 0.1110 ||: 100%|#########9| 7163/7188 [18:02<00:04,  5.26it/s]
2022-03-21 13:31:59,117 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.2112, loss: 0.1110 ||: 100%|#########9| 7164/7188 [18:03<00:04,  4.87it/s]
2022-03-21 13:31:59,328 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0498, loss: 0.1110 ||: 100%|#########9| 7165/7188 [18:03<00:04,  4.83it/s]
2022-03-21 13:31:59,474 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.3464, loss: 0.1111 ||: 100%|#########9| 7166/7188 [18:03<00:04,  5.30it/s]
2022-03-21 13:31:59,731 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.2479, loss: 0.1111 ||: 100%|#########9| 7167/7188 [18:03<00:04,  4.78it/s]
2022-03-21 13:31:59,948 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0051, loss: 0.1111 ||: 100%|#########9| 7168/7188 [18:03<00:04,  4.73it/s]
2022-03-21 13:32:00,220 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0322, loss: 0.1111 ||: 100%|#########9| 7169/7188 [18:04<00:04,  4.36it/s]
2022-03-21 13:32:00,483 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0322, loss: 0.1110 ||: 100%|#########9| 7170/7188 [18:04<00:04,  4.17it/s]
2022-03-21 13:32:00,784 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.1695, loss: 0.1110 ||: 100%|#########9| 7172/7188 [18:04<00:03,  5.03it/s]
2022-03-21 13:32:01,063 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0199, loss: 0.1110 ||: 100%|#########9| 7173/7188 [18:04<00:03,  4.58it/s]
2022-03-21 13:32:01,232 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0521, loss: 0.1110 ||: 100%|#########9| 7174/7188 [18:05<00:02,  4.86it/s]
2022-03-21 13:32:01,472 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0135, loss: 0.1110 ||: 100%|#########9| 7175/7188 [18:05<00:02,  4.65it/s]
2022-03-21 13:32:01,700 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0830, loss: 0.1110 ||: 100%|#########9| 7176/7188 [18:05<00:02,  4.57it/s]
2022-03-21 13:32:01,854 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.1143, loss: 0.1110 ||: 100%|#########9| 7177/7188 [18:05<00:02,  5.00it/s]
2022-03-21 13:32:02,134 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0970, loss: 0.1110 ||: 100%|#########9| 7178/7188 [18:06<00:02,  4.48it/s]
2022-03-21 13:32:02,323 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0401, loss: 0.1110 ||: 100%|#########9| 7179/7188 [18:06<00:01,  4.69it/s]
2022-03-21 13:32:02,566 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0110, loss: 0.1110 ||: 100%|#########9| 7180/7188 [18:06<00:01,  4.51it/s]
2022-03-21 13:32:02,822 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.3092, loss: 0.1110 ||: 100%|#########9| 7181/7188 [18:06<00:01,  4.31it/s]
2022-03-21 13:32:03,012 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0079, loss: 0.1110 ||: 100%|#########9| 7182/7188 [18:06<00:01,  4.55it/s]
2022-03-21 13:32:03,257 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.1794, loss: 0.1110 ||: 100%|#########9| 7183/7188 [18:07<00:01,  4.40it/s]
2022-03-21 13:32:03,486 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0489, loss: 0.1110 ||: 100%|#########9| 7184/7188 [18:07<00:00,  4.39it/s]
2022-03-21 13:32:03,635 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0756, loss: 0.1110 ||: 100%|#########9| 7185/7188 [18:07<00:00,  4.90it/s]
2022-03-21 13:32:03,887 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.1677, loss: 0.1110 ||: 100%|#########9| 7186/7188 [18:07<00:00,  4.57it/s]
2022-03-21 13:32:04,087 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0421, loss: 0.1110 ||: 100%|#########9| 7187/7188 [18:07<00:00,  4.69it/s]
2022-03-21 13:32:04,233 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0167, loss: 0.1110 ||: 100%|##########| 7188/7188 [18:08<00:00,  5.19it/s]
2022-03-21 13:32:04,276 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0167, loss: 0.1110 ||: 100%|##########| 7188/7188 [18:08<00:00,  6.61it/s]
2022-03-21 13:32:04,346 - INFO - allennlp.training.trainer - Validating
2022-03-21 13:32:04,350 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 13:32:14,496 - INFO - tqdm - f1: 0.9461, accuracy: 0.9459, batch_loss: 0.0693, loss: 0.1888 ||:  26%|##6       | 82/313 [00:10<00:30,  7.57it/s]
2022-03-21 13:32:24,507 - INFO - tqdm - f1: 0.9389, accuracy: 0.9388, batch_loss: 0.0485, loss: 0.2039 ||:  52%|#####2    | 164/313 [00:20<00:15,  9.84it/s]
2022-03-21 13:32:34,638 - INFO - tqdm - f1: 0.9393, accuracy: 0.9392, batch_loss: 0.0197, loss: 0.2011 ||:  79%|#######8  | 246/313 [00:30<00:08,  7.84it/s]
2022-03-21 13:32:42,600 - INFO - tqdm - f1: 0.9395, accuracy: 0.9394, batch_loss: 0.4342, loss: 0.2040 ||: 100%|#########9| 312/313 [00:38<00:00,  9.41it/s]
2022-03-21 13:32:42,793 - INFO - tqdm - f1: 0.9397, accuracy: 0.9396, batch_loss: 0.0735, loss: 0.2035 ||: 100%|##########| 313/313 [00:38<00:00,  8.14it/s]
2022-03-21 13:32:42,875 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 13:32:42,878 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.962  |     0.940
2022-03-21 13:32:42,880 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.962  |     0.940
2022-03-21 13:32:42,882 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 13:32:42,884 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.111  |     0.204
2022-03-21 13:32:42,886 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7584.363  |       N/A
2022-03-21 13:32:42,889 - INFO - allennlp.training.trainer - Epoch duration: 0:18:46.877512
2022-03-21 13:32:42,892 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:05:30
2022-03-21 13:32:42,894 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-21 13:32:42,896 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 13:32:42,899 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 13:32:42,902 - INFO - allennlp.training.trainer - Training
2022-03-21 13:32:42,905 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 13:32:52,955 - INFO - tqdm - f1: 0.9828, accuracy: 0.9830, batch_loss: 0.0067, loss: 0.0594 ||:   1%|          | 44/7188 [00:10<24:25,  4.88it/s]
2022-03-21 13:33:03,076 - INFO - tqdm - f1: 0.9719, accuracy: 0.9715, batch_loss: 0.1229, loss: 0.0850 ||:   1%|1         | 92/7188 [00:20<25:38,  4.61it/s]
2022-03-21 13:33:13,274 - INFO - tqdm - f1: 0.9739, accuracy: 0.9734, batch_loss: 0.0086, loss: 0.0850 ||:   2%|1         | 141/7188 [00:30<24:38,  4.77it/s]
2022-03-21 13:33:23,333 - INFO - tqdm - f1: 0.9724, accuracy: 0.9721, batch_loss: 0.1142, loss: 0.0807 ||:   3%|3         | 251/7188 [00:40<15:49,  7.30it/s]
2022-03-21 13:33:33,353 - INFO - tqdm - f1: 0.9728, accuracy: 0.9725, batch_loss: 0.6102, loss: 0.0862 ||:   4%|4         | 323/7188 [00:50<15:44,  7.27it/s]
2022-03-21 13:33:43,457 - INFO - tqdm - f1: 0.9740, accuracy: 0.9738, batch_loss: 0.0031, loss: 0.0823 ||:   6%|5         | 400/7188 [01:00<13:43,  8.24it/s]
2022-03-21 13:33:53,705 - INFO - tqdm - f1: 0.9740, accuracy: 0.9738, batch_loss: 0.1465, loss: 0.0809 ||:   7%|6         | 474/7188 [01:10<25:08,  4.45it/s]
2022-03-21 13:34:03,838 - INFO - tqdm - f1: 0.9732, accuracy: 0.9730, batch_loss: 0.1196, loss: 0.0832 ||:   7%|7         | 521/7188 [01:20<23:48,  4.67it/s]
2022-03-21 13:34:13,961 - INFO - tqdm - f1: 0.9720, accuracy: 0.9717, batch_loss: 0.0940, loss: 0.0855 ||:   8%|7         | 568/7188 [01:31<22:19,  4.94it/s]
2022-03-21 13:34:24,127 - INFO - tqdm - f1: 0.9712, accuracy: 0.9708, batch_loss: 0.0160, loss: 0.0873 ||:   9%|8         | 617/7188 [01:41<23:30,  4.66it/s]
2022-03-21 13:34:34,269 - INFO - tqdm - f1: 0.9709, accuracy: 0.9706, batch_loss: 0.0103, loss: 0.0871 ||:   9%|9         | 664/7188 [01:51<22:50,  4.76it/s]
2022-03-21 13:34:44,369 - INFO - tqdm - f1: 0.9716, accuracy: 0.9713, batch_loss: 0.0122, loss: 0.0853 ||:  10%|9         | 711/7188 [02:01<24:15,  4.45it/s]
2022-03-21 13:34:54,542 - INFO - tqdm - f1: 0.9719, accuracy: 0.9716, batch_loss: 0.0315, loss: 0.0846 ||:  11%|#         | 759/7188 [02:11<22:34,  4.75it/s]
2022-03-21 13:35:04,727 - INFO - tqdm - f1: 0.9716, accuracy: 0.9713, batch_loss: 0.0616, loss: 0.0857 ||:  11%|#1        | 806/7188 [02:21<23:50,  4.46it/s]
2022-03-21 13:35:14,845 - INFO - tqdm - f1: 0.9722, accuracy: 0.9719, batch_loss: 0.0113, loss: 0.0854 ||:  12%|#1        | 853/7188 [02:31<20:57,  5.04it/s]
2022-03-21 13:35:24,911 - INFO - tqdm - f1: 0.9726, accuracy: 0.9724, batch_loss: 0.0177, loss: 0.0844 ||:  13%|#2        | 900/7188 [02:42<23:29,  4.46it/s]
2022-03-21 13:35:34,960 - INFO - tqdm - f1: 0.9726, accuracy: 0.9724, batch_loss: 0.0051, loss: 0.0842 ||:  13%|#3        | 948/7188 [02:52<22:49,  4.56it/s]
2022-03-21 13:35:45,034 - INFO - tqdm - f1: 0.9725, accuracy: 0.9724, batch_loss: 0.0074, loss: 0.0845 ||:  14%|#3        | 997/7188 [03:02<23:08,  4.46it/s]
2022-03-21 13:35:55,185 - INFO - tqdm - f1: 0.9722, accuracy: 0.9720, batch_loss: 0.0369, loss: 0.0847 ||:  15%|#4        | 1044/7188 [03:12<21:12,  4.83it/s]
2022-03-21 13:36:05,195 - INFO - tqdm - f1: 0.9726, accuracy: 0.9724, batch_loss: 0.0136, loss: 0.0835 ||:  15%|#5        | 1093/7188 [03:22<22:32,  4.51it/s]
2022-03-21 13:36:15,462 - INFO - tqdm - f1: 0.9726, accuracy: 0.9724, batch_loss: 0.0158, loss: 0.0829 ||:  16%|#5        | 1140/7188 [03:32<23:55,  4.21it/s]
2022-03-21 13:36:25,547 - INFO - tqdm - f1: 0.9727, accuracy: 0.9725, batch_loss: 0.0089, loss: 0.0826 ||:  17%|#6        | 1187/7188 [03:42<21:20,  4.69it/s]
2022-03-21 13:36:35,723 - INFO - tqdm - f1: 0.9725, accuracy: 0.9723, batch_loss: 0.0322, loss: 0.0828 ||:  17%|#7        | 1234/7188 [03:52<21:11,  4.68it/s]
2022-03-21 13:36:45,841 - INFO - tqdm - f1: 0.9721, accuracy: 0.9719, batch_loss: 0.0113, loss: 0.0832 ||:  18%|#7        | 1281/7188 [04:02<23:19,  4.22it/s]
2022-03-21 13:36:55,932 - INFO - tqdm - f1: 0.9722, accuracy: 0.9720, batch_loss: 0.0711, loss: 0.0824 ||:  18%|#8        | 1328/7188 [04:13<20:32,  4.75it/s]
2022-03-21 13:37:06,090 - INFO - tqdm - f1: 0.9721, accuracy: 0.9720, batch_loss: 0.2349, loss: 0.0830 ||:  19%|#9        | 1375/7188 [04:23<23:09,  4.18it/s]
2022-03-21 13:37:16,244 - INFO - tqdm - f1: 0.9721, accuracy: 0.9719, batch_loss: 0.0155, loss: 0.0832 ||:  20%|#9        | 1423/7188 [04:33<20:01,  4.80it/s]
2022-03-21 13:37:26,321 - INFO - tqdm - f1: 0.9719, accuracy: 0.9718, batch_loss: 0.0638, loss: 0.0836 ||:  20%|##        | 1470/7188 [04:43<19:32,  4.87it/s]
2022-03-21 13:37:36,322 - INFO - tqdm - f1: 0.9720, accuracy: 0.9718, batch_loss: 0.0139, loss: 0.0836 ||:  21%|##1       | 1517/7188 [04:53<20:33,  4.60it/s]
2022-03-21 13:37:46,322 - INFO - tqdm - f1: 0.9722, accuracy: 0.9720, batch_loss: 0.0191, loss: 0.0832 ||:  22%|##1       | 1565/7188 [05:03<17:49,  5.26it/s]
2022-03-21 13:37:56,351 - INFO - tqdm - f1: 0.9724, accuracy: 0.9723, batch_loss: 0.0790, loss: 0.0826 ||:  22%|##2       | 1612/7188 [05:13<19:44,  4.71it/s]
2022-03-21 13:38:06,519 - INFO - tqdm - f1: 0.9722, accuracy: 0.9720, batch_loss: 0.1340, loss: 0.0836 ||:  23%|##3       | 1659/7188 [05:23<19:38,  4.69it/s]
2022-03-21 13:38:16,654 - INFO - tqdm - f1: 0.9723, accuracy: 0.9721, batch_loss: 0.0048, loss: 0.0836 ||:  24%|##3       | 1706/7188 [05:33<20:37,  4.43it/s]
2022-03-21 13:38:26,841 - INFO - tqdm - f1: 0.9727, accuracy: 0.9725, batch_loss: 0.0072, loss: 0.0828 ||:  24%|##4       | 1755/7188 [05:43<18:54,  4.79it/s]
2022-03-21 13:38:37,022 - INFO - tqdm - f1: 0.9725, accuracy: 0.9724, batch_loss: 0.0265, loss: 0.0826 ||:  25%|##5       | 1803/7188 [05:54<18:49,  4.77it/s]
2022-03-21 13:38:47,174 - INFO - tqdm - f1: 0.9727, accuracy: 0.9726, batch_loss: 0.0208, loss: 0.0819 ||:  26%|##5       | 1851/7188 [06:04<20:28,  4.34it/s]
2022-03-21 13:38:57,273 - INFO - tqdm - f1: 0.9728, accuracy: 0.9727, batch_loss: 0.0064, loss: 0.0818 ||:  26%|##6       | 1897/7188 [06:14<18:58,  4.65it/s]
2022-03-21 13:39:07,479 - INFO - tqdm - f1: 0.9726, accuracy: 0.9725, batch_loss: 0.0609, loss: 0.0825 ||:  27%|##7       | 1946/7188 [06:24<19:24,  4.50it/s]
2022-03-21 13:39:17,588 - INFO - tqdm - f1: 0.9727, accuracy: 0.9726, batch_loss: 0.0238, loss: 0.0824 ||:  28%|##7       | 1992/7188 [06:34<19:46,  4.38it/s]
2022-03-21 13:39:27,693 - INFO - tqdm - f1: 0.9723, accuracy: 0.9723, batch_loss: 0.1195, loss: 0.0830 ||:  28%|##8       | 2039/7188 [06:44<16:39,  5.15it/s]
2022-03-21 13:39:37,767 - INFO - tqdm - f1: 0.9721, accuracy: 0.9721, batch_loss: 0.1168, loss: 0.0837 ||:  29%|##9       | 2089/7188 [06:54<17:03,  4.98it/s]
2022-03-21 13:39:47,953 - INFO - tqdm - f1: 0.9722, accuracy: 0.9721, batch_loss: 0.0022, loss: 0.0837 ||:  30%|##9       | 2137/7188 [07:05<17:47,  4.73it/s]
2022-03-21 13:39:58,062 - INFO - tqdm - f1: 0.9722, accuracy: 0.9721, batch_loss: 0.1433, loss: 0.0835 ||:  30%|###       | 2184/7188 [07:15<17:48,  4.68it/s]
2022-03-21 13:40:08,258 - INFO - tqdm - f1: 0.9721, accuracy: 0.9720, batch_loss: 0.0189, loss: 0.0833 ||:  31%|###1      | 2230/7188 [07:25<18:35,  4.45it/s]
2022-03-21 13:40:18,430 - INFO - tqdm - f1: 0.9722, accuracy: 0.9721, batch_loss: 0.0020, loss: 0.0831 ||:  32%|###1      | 2280/7188 [07:35<17:34,  4.65it/s]
2022-03-21 13:40:28,454 - INFO - tqdm - f1: 0.9720, accuracy: 0.9719, batch_loss: 0.2060, loss: 0.0836 ||:  32%|###2      | 2326/7188 [07:45<16:09,  5.02it/s]
2022-03-21 13:40:38,590 - INFO - tqdm - f1: 0.9721, accuracy: 0.9720, batch_loss: 0.0533, loss: 0.0832 ||:  33%|###3      | 2373/7188 [07:55<16:59,  4.72it/s]
2022-03-21 13:40:48,788 - INFO - tqdm - f1: 0.9721, accuracy: 0.9720, batch_loss: 0.0029, loss: 0.0831 ||:  34%|###3      | 2422/7188 [08:05<16:02,  4.95it/s]
2022-03-21 13:40:58,946 - INFO - tqdm - f1: 0.9720, accuracy: 0.9719, batch_loss: 0.0692, loss: 0.0835 ||:  34%|###4      | 2469/7188 [08:16<18:16,  4.30it/s]
2022-03-21 13:41:09,209 - INFO - tqdm - f1: 0.9720, accuracy: 0.9719, batch_loss: 0.0110, loss: 0.0840 ||:  35%|###5      | 2519/7188 [08:26<17:14,  4.51it/s]
2022-03-21 13:41:19,220 - INFO - tqdm - f1: 0.9718, accuracy: 0.9717, batch_loss: 0.6704, loss: 0.0847 ||:  36%|###5      | 2563/7188 [08:36<19:10,  4.02it/s]
2022-03-21 13:41:29,270 - INFO - tqdm - f1: 0.9717, accuracy: 0.9716, batch_loss: 0.0650, loss: 0.0845 ||:  36%|###6      | 2611/7188 [08:46<16:42,  4.57it/s]
2022-03-21 13:41:39,298 - INFO - tqdm - f1: 0.9717, accuracy: 0.9716, batch_loss: 0.0410, loss: 0.0849 ||:  37%|###6      | 2659/7188 [08:56<14:13,  5.31it/s]
2022-03-21 13:41:49,385 - INFO - tqdm - f1: 0.9716, accuracy: 0.9715, batch_loss: 0.1508, loss: 0.0851 ||:  38%|###7      | 2709/7188 [09:06<16:02,  4.65it/s]
2022-03-21 13:41:59,456 - INFO - tqdm - f1: 0.9716, accuracy: 0.9715, batch_loss: 0.2155, loss: 0.0850 ||:  38%|###8      | 2755/7188 [09:16<16:39,  4.44it/s]
2022-03-21 13:42:09,685 - INFO - tqdm - f1: 0.9717, accuracy: 0.9716, batch_loss: 0.0951, loss: 0.0847 ||:  39%|###9      | 2805/7188 [09:26<14:52,  4.91it/s]
2022-03-21 13:42:19,789 - INFO - tqdm - f1: 0.9719, accuracy: 0.9718, batch_loss: 0.0176, loss: 0.0841 ||:  40%|###9      | 2854/7188 [09:36<14:56,  4.84it/s]
2022-03-21 13:42:29,869 - INFO - tqdm - f1: 0.9719, accuracy: 0.9718, batch_loss: 0.0628, loss: 0.0845 ||:  40%|####      | 2902/7188 [09:46<13:13,  5.40it/s]
2022-03-21 13:42:39,918 - INFO - tqdm - f1: 0.9718, accuracy: 0.9717, batch_loss: 0.0077, loss: 0.0848 ||:  41%|####1     | 2950/7188 [09:57<14:48,  4.77it/s]
2022-03-21 13:42:49,947 - INFO - tqdm - f1: 0.9717, accuracy: 0.9716, batch_loss: 0.0173, loss: 0.0851 ||:  42%|####1     | 2999/7188 [10:07<14:54,  4.68it/s]
2022-03-21 13:42:59,994 - INFO - tqdm - f1: 0.9715, accuracy: 0.9714, batch_loss: 0.0152, loss: 0.0857 ||:  42%|####2     | 3046/7188 [10:17<15:50,  4.36it/s]
2022-03-21 13:43:10,247 - INFO - tqdm - f1: 0.9715, accuracy: 0.9714, batch_loss: 0.1140, loss: 0.0857 ||:  43%|####3     | 3093/7188 [10:27<14:52,  4.59it/s]
2022-03-21 13:43:20,357 - INFO - tqdm - f1: 0.9713, accuracy: 0.9713, batch_loss: 0.2710, loss: 0.0864 ||:  44%|####3     | 3141/7188 [10:37<13:41,  4.93it/s]
2022-03-21 13:43:30,486 - INFO - tqdm - f1: 0.9713, accuracy: 0.9712, batch_loss: 0.0333, loss: 0.0868 ||:  44%|####4     | 3190/7188 [10:47<14:34,  4.57it/s]
2022-03-21 13:43:40,535 - INFO - tqdm - f1: 0.9713, accuracy: 0.9713, batch_loss: 0.1504, loss: 0.0866 ||:  45%|####5     | 3236/7188 [10:57<14:40,  4.49it/s]
2022-03-21 13:43:50,559 - INFO - tqdm - f1: 0.9713, accuracy: 0.9713, batch_loss: 0.1686, loss: 0.0867 ||:  46%|####5     | 3283/7188 [11:07<13:34,  4.80it/s]
2022-03-21 13:44:00,686 - INFO - tqdm - f1: 0.9711, accuracy: 0.9711, batch_loss: 0.4700, loss: 0.0869 ||:  46%|####6     | 3330/7188 [11:17<15:05,  4.26it/s]
2022-03-21 13:44:10,866 - INFO - tqdm - f1: 0.9712, accuracy: 0.9712, batch_loss: 0.0049, loss: 0.0867 ||:  47%|####6     | 3377/7188 [11:27<13:06,  4.85it/s]
2022-03-21 13:44:21,028 - INFO - tqdm - f1: 0.9712, accuracy: 0.9712, batch_loss: 0.1399, loss: 0.0867 ||:  48%|####7     | 3425/7188 [11:38<13:23,  4.69it/s]
2022-03-21 13:44:31,216 - INFO - tqdm - f1: 0.9712, accuracy: 0.9711, batch_loss: 0.0461, loss: 0.0869 ||:  48%|####8     | 3474/7188 [11:48<12:58,  4.77it/s]
2022-03-21 13:44:41,345 - INFO - tqdm - f1: 0.9711, accuracy: 0.9710, batch_loss: 0.0167, loss: 0.0871 ||:  49%|####8     | 3521/7188 [11:58<12:59,  4.71it/s]
2022-03-21 13:44:51,424 - INFO - tqdm - f1: 0.9708, accuracy: 0.9707, batch_loss: 0.0934, loss: 0.0877 ||:  50%|####9     | 3567/7188 [12:08<13:37,  4.43it/s]
2022-03-21 13:45:01,491 - INFO - tqdm - f1: 0.9708, accuracy: 0.9707, batch_loss: 0.0179, loss: 0.0876 ||:  50%|#####     | 3614/7188 [12:18<13:23,  4.45it/s]
2022-03-21 13:45:11,520 - INFO - tqdm - f1: 0.9708, accuracy: 0.9707, batch_loss: 0.0526, loss: 0.0874 ||:  51%|#####     | 3661/7188 [12:28<13:05,  4.49it/s]
2022-03-21 13:45:21,685 - INFO - tqdm - f1: 0.9706, accuracy: 0.9706, batch_loss: 0.0171, loss: 0.0874 ||:  52%|#####1    | 3709/7188 [12:38<11:38,  4.98it/s]
2022-03-21 13:45:31,734 - INFO - tqdm - f1: 0.9706, accuracy: 0.9706, batch_loss: 0.1428, loss: 0.0875 ||:  52%|#####2    | 3760/7188 [12:48<11:47,  4.85it/s]
2022-03-21 13:45:41,890 - INFO - tqdm - f1: 0.9706, accuracy: 0.9705, batch_loss: 0.0273, loss: 0.0879 ||:  53%|#####2    | 3807/7188 [12:58<12:51,  4.38it/s]
2022-03-21 13:45:52,115 - INFO - tqdm - f1: 0.9706, accuracy: 0.9706, batch_loss: 0.0403, loss: 0.0878 ||:  54%|#####3    | 3857/7188 [13:09<11:35,  4.79it/s]
2022-03-21 13:46:02,255 - INFO - tqdm - f1: 0.9707, accuracy: 0.9706, batch_loss: 0.3967, loss: 0.0876 ||:  54%|#####4    | 3905/7188 [13:19<12:14,  4.47it/s]
2022-03-21 13:46:12,256 - INFO - tqdm - f1: 0.9706, accuracy: 0.9705, batch_loss: 0.2136, loss: 0.0879 ||:  55%|#####4    | 3952/7188 [13:29<11:33,  4.66it/s]
2022-03-21 13:46:22,383 - INFO - tqdm - f1: 0.9705, accuracy: 0.9705, batch_loss: 0.0846, loss: 0.0882 ||:  56%|#####5    | 4000/7188 [13:39<11:19,  4.69it/s]
2022-03-21 13:46:32,541 - INFO - tqdm - f1: 0.9705, accuracy: 0.9704, batch_loss: 0.2799, loss: 0.0881 ||:  56%|#####6    | 4049/7188 [13:49<10:44,  4.87it/s]
2022-03-21 13:46:42,713 - INFO - tqdm - f1: 0.9705, accuracy: 0.9705, batch_loss: 0.0292, loss: 0.0879 ||:  57%|#####6    | 4097/7188 [13:59<10:48,  4.77it/s]
2022-03-21 13:46:52,859 - INFO - tqdm - f1: 0.9706, accuracy: 0.9705, batch_loss: 0.0092, loss: 0.0877 ||:  58%|#####7    | 4146/7188 [14:09<10:22,  4.89it/s]
2022-03-21 13:47:03,034 - INFO - tqdm - f1: 0.9706, accuracy: 0.9705, batch_loss: 0.2746, loss: 0.0878 ||:  58%|#####8    | 4196/7188 [14:20<10:04,  4.95it/s]
2022-03-21 13:47:13,070 - INFO - tqdm - f1: 0.9706, accuracy: 0.9706, batch_loss: 0.0750, loss: 0.0876 ||:  59%|#####9    | 4245/7188 [14:30<09:46,  5.01it/s]
2022-03-21 13:47:23,154 - INFO - tqdm - f1: 0.9707, accuracy: 0.9706, batch_loss: 0.0260, loss: 0.0875 ||:  60%|#####9    | 4292/7188 [14:40<10:44,  4.49it/s]
2022-03-21 13:47:33,180 - INFO - tqdm - f1: 0.9707, accuracy: 0.9707, batch_loss: 0.0688, loss: 0.0875 ||:  60%|######    | 4342/7188 [14:50<09:08,  5.19it/s]
2022-03-21 13:47:43,315 - INFO - tqdm - f1: 0.9707, accuracy: 0.9706, batch_loss: 0.0407, loss: 0.0875 ||:  61%|######1   | 4389/7188 [15:00<10:57,  4.26it/s]
2022-03-21 13:47:53,502 - INFO - tqdm - f1: 0.9705, accuracy: 0.9705, batch_loss: 0.0145, loss: 0.0876 ||:  62%|######1   | 4437/7188 [15:10<09:28,  4.84it/s]
2022-03-21 13:48:03,685 - INFO - tqdm - f1: 0.9705, accuracy: 0.9704, batch_loss: 0.5268, loss: 0.0877 ||:  62%|######2   | 4485/7188 [15:20<10:23,  4.34it/s]
2022-03-21 13:48:13,892 - INFO - tqdm - f1: 0.9704, accuracy: 0.9704, batch_loss: 0.0273, loss: 0.0879 ||:  63%|######3   | 4533/7188 [15:30<09:24,  4.70it/s]
2022-03-21 13:48:23,983 - INFO - tqdm - f1: 0.9705, accuracy: 0.9704, batch_loss: 0.0030, loss: 0.0875 ||:  64%|######3   | 4581/7188 [15:41<08:43,  4.98it/s]
2022-03-21 13:48:34,206 - INFO - tqdm - f1: 0.9706, accuracy: 0.9705, batch_loss: 0.0544, loss: 0.0872 ||:  64%|######4   | 4630/7188 [15:51<08:45,  4.87it/s]
2022-03-21 13:48:44,391 - INFO - tqdm - f1: 0.9706, accuracy: 0.9705, batch_loss: 0.0364, loss: 0.0870 ||:  65%|######5   | 4679/7188 [16:01<08:48,  4.75it/s]
2022-03-21 13:48:54,536 - INFO - tqdm - f1: 0.9706, accuracy: 0.9706, batch_loss: 0.0023, loss: 0.0870 ||:  66%|######5   | 4727/7188 [16:11<08:14,  4.97it/s]
2022-03-21 13:49:04,747 - INFO - tqdm - f1: 0.9706, accuracy: 0.9705, batch_loss: 0.0626, loss: 0.0870 ||:  66%|######6   | 4776/7188 [16:21<08:26,  4.76it/s]
2022-03-21 13:49:14,931 - INFO - tqdm - f1: 0.9706, accuracy: 0.9705, batch_loss: 0.0806, loss: 0.0871 ||:  67%|######7   | 4824/7188 [16:32<08:26,  4.66it/s]
2022-03-21 13:49:25,051 - INFO - tqdm - f1: 0.9706, accuracy: 0.9705, batch_loss: 0.2124, loss: 0.0870 ||:  68%|######7   | 4872/7188 [16:42<08:41,  4.44it/s]
2022-03-21 13:49:35,114 - INFO - tqdm - f1: 0.9704, accuracy: 0.9703, batch_loss: 0.1683, loss: 0.0876 ||:  69%|######9   | 4989/7188 [16:52<04:47,  7.65it/s]
2022-03-21 13:49:45,160 - INFO - tqdm - f1: 0.9703, accuracy: 0.9702, batch_loss: 0.0892, loss: 0.0880 ||:  70%|#######   | 5066/7188 [17:02<04:22,  8.09it/s]
2022-03-21 13:49:55,285 - INFO - tqdm - f1: 0.9702, accuracy: 0.9701, batch_loss: 0.0428, loss: 0.0880 ||:  72%|#######1  | 5143/7188 [17:12<04:09,  8.19it/s]
2022-03-21 13:50:05,435 - INFO - tqdm - f1: 0.9703, accuracy: 0.9702, batch_loss: 0.0140, loss: 0.0878 ||:  73%|#######2  | 5214/7188 [17:22<07:51,  4.19it/s]
2022-03-21 13:50:15,584 - INFO - tqdm - f1: 0.9703, accuracy: 0.9702, batch_loss: 0.1292, loss: 0.0878 ||:  73%|#######3  | 5261/7188 [17:32<06:46,  4.74it/s]
2022-03-21 13:50:25,773 - INFO - tqdm - f1: 0.9703, accuracy: 0.9701, batch_loss: 0.1644, loss: 0.0882 ||:  74%|#######3  | 5309/7188 [17:42<06:57,  4.50it/s]
2022-03-21 13:50:35,923 - INFO - tqdm - f1: 0.9703, accuracy: 0.9702, batch_loss: 0.1268, loss: 0.0880 ||:  75%|#######4  | 5357/7188 [17:53<06:34,  4.64it/s]
2022-03-21 13:50:46,078 - INFO - tqdm - f1: 0.9704, accuracy: 0.9703, batch_loss: 0.0035, loss: 0.0879 ||:  75%|#######5  | 5405/7188 [18:03<06:54,  4.30it/s]
2022-03-21 13:50:56,262 - INFO - tqdm - f1: 0.9705, accuracy: 0.9703, batch_loss: 0.0320, loss: 0.0878 ||:  76%|#######5  | 5453/7188 [18:13<06:22,  4.53it/s]
2022-03-21 13:51:06,311 - INFO - tqdm - f1: 0.9704, accuracy: 0.9703, batch_loss: 0.0228, loss: 0.0880 ||:  77%|#######6  | 5499/7188 [18:23<05:56,  4.73it/s]
2022-03-21 13:51:16,357 - INFO - tqdm - f1: 0.9704, accuracy: 0.9703, batch_loss: 0.4770, loss: 0.0879 ||:  77%|#######7  | 5546/7188 [18:33<05:59,  4.57it/s]
2022-03-21 13:51:26,624 - INFO - tqdm - f1: 0.9704, accuracy: 0.9703, batch_loss: 0.0250, loss: 0.0880 ||:  78%|#######7  | 5594/7188 [18:43<05:43,  4.64it/s]
2022-03-21 13:51:36,669 - INFO - tqdm - f1: 0.9704, accuracy: 0.9703, batch_loss: 0.0219, loss: 0.0878 ||:  78%|#######8  | 5640/7188 [18:53<05:36,  4.59it/s]
2022-03-21 13:51:46,781 - INFO - tqdm - f1: 0.9704, accuracy: 0.9703, batch_loss: 0.0683, loss: 0.0880 ||:  79%|#######9  | 5690/7188 [19:03<04:54,  5.09it/s]
2022-03-21 13:51:56,794 - INFO - tqdm - f1: 0.9704, accuracy: 0.9703, batch_loss: 0.0789, loss: 0.0879 ||:  80%|#######9  | 5737/7188 [19:13<05:02,  4.79it/s]
2022-03-21 13:52:06,917 - INFO - tqdm - f1: 0.9705, accuracy: 0.9704, batch_loss: 0.0024, loss: 0.0877 ||:  80%|########  | 5784/7188 [19:24<04:47,  4.88it/s]
2022-03-21 13:52:17,098 - INFO - tqdm - f1: 0.9705, accuracy: 0.9704, batch_loss: 0.0033, loss: 0.0877 ||:  81%|########1 | 5833/7188 [19:34<04:42,  4.80it/s]
2022-03-21 13:52:27,262 - INFO - tqdm - f1: 0.9705, accuracy: 0.9704, batch_loss: 0.0605, loss: 0.0879 ||:  82%|########1 | 5881/7188 [19:44<04:38,  4.70it/s]
2022-03-21 13:52:37,436 - INFO - tqdm - f1: 0.9705, accuracy: 0.9704, batch_loss: 0.0044, loss: 0.0880 ||:  82%|########2 | 5929/7188 [19:54<04:25,  4.74it/s]
2022-03-21 13:52:47,631 - INFO - tqdm - f1: 0.9704, accuracy: 0.9703, batch_loss: 0.0316, loss: 0.0880 ||:  83%|########3 | 5978/7188 [20:04<04:15,  4.73it/s]
2022-03-21 13:52:57,802 - INFO - tqdm - f1: 0.9704, accuracy: 0.9703, batch_loss: 0.0180, loss: 0.0880 ||:  84%|########3 | 6026/7188 [20:14<03:59,  4.84it/s]
2022-03-21 13:53:07,995 - INFO - tqdm - f1: 0.9704, accuracy: 0.9703, batch_loss: 0.0318, loss: 0.0880 ||:  85%|########4 | 6076/7188 [20:25<03:52,  4.78it/s]
2022-03-21 13:53:18,120 - INFO - tqdm - f1: 0.9704, accuracy: 0.9703, batch_loss: 0.2376, loss: 0.0880 ||:  85%|########5 | 6123/7188 [20:35<03:36,  4.92it/s]
2022-03-21 13:53:28,301 - INFO - tqdm - f1: 0.9703, accuracy: 0.9702, batch_loss: 0.0707, loss: 0.0881 ||:  86%|########5 | 6171/7188 [20:45<03:33,  4.77it/s]
2022-03-21 13:53:38,417 - INFO - tqdm - f1: 0.9702, accuracy: 0.9702, batch_loss: 0.1113, loss: 0.0883 ||:  87%|########6 | 6220/7188 [20:55<03:44,  4.31it/s]
2022-03-21 13:53:48,490 - INFO - tqdm - f1: 0.9703, accuracy: 0.9702, batch_loss: 0.0320, loss: 0.0881 ||:  87%|########7 | 6267/7188 [21:05<03:18,  4.63it/s]
2022-03-21 13:53:58,596 - INFO - tqdm - f1: 0.9703, accuracy: 0.9703, batch_loss: 0.0832, loss: 0.0883 ||:  88%|########7 | 6318/7188 [21:15<02:48,  5.17it/s]
2022-03-21 13:54:08,654 - INFO - tqdm - f1: 0.9702, accuracy: 0.9702, batch_loss: 0.2678, loss: 0.0885 ||:  89%|########8 | 6365/7188 [21:25<02:53,  4.75it/s]
2022-03-21 13:54:18,668 - INFO - tqdm - f1: 0.9702, accuracy: 0.9701, batch_loss: 0.0342, loss: 0.0887 ||:  89%|########9 | 6411/7188 [21:35<02:54,  4.46it/s]
2022-03-21 13:54:28,741 - INFO - tqdm - f1: 0.9702, accuracy: 0.9701, batch_loss: 0.2578, loss: 0.0887 ||:  90%|########9 | 6459/7188 [21:45<02:30,  4.85it/s]
2022-03-21 13:54:38,928 - INFO - tqdm - f1: 0.9701, accuracy: 0.9700, batch_loss: 0.1119, loss: 0.0889 ||:  91%|######### | 6507/7188 [21:56<02:29,  4.57it/s]
2022-03-21 13:54:48,943 - INFO - tqdm - f1: 0.9701, accuracy: 0.9700, batch_loss: 0.2441, loss: 0.0889 ||:  91%|#########1| 6555/7188 [22:06<02:16,  4.65it/s]
2022-03-21 13:54:58,996 - INFO - tqdm - f1: 0.9700, accuracy: 0.9700, batch_loss: 0.0175, loss: 0.0891 ||:  92%|#########1| 6603/7188 [22:16<02:10,  4.49it/s]
2022-03-21 13:55:09,113 - INFO - tqdm - f1: 0.9701, accuracy: 0.9701, batch_loss: 0.0304, loss: 0.0890 ||:  93%|#########2| 6651/7188 [22:26<01:41,  5.31it/s]
2022-03-21 13:55:19,206 - INFO - tqdm - f1: 0.9700, accuracy: 0.9700, batch_loss: 0.1621, loss: 0.0892 ||:  93%|#########3| 6700/7188 [22:36<01:43,  4.71it/s]
2022-03-21 13:55:29,238 - INFO - tqdm - f1: 0.9700, accuracy: 0.9700, batch_loss: 0.2462, loss: 0.0892 ||:  94%|#########3| 6748/7188 [22:46<01:34,  4.64it/s]
2022-03-21 13:55:39,365 - INFO - tqdm - f1: 0.9700, accuracy: 0.9699, batch_loss: 0.0567, loss: 0.0894 ||:  95%|#########4| 6796/7188 [22:56<01:25,  4.59it/s]
2022-03-21 13:55:49,467 - INFO - tqdm - f1: 0.9700, accuracy: 0.9700, batch_loss: 0.1024, loss: 0.0893 ||:  95%|#########5| 6844/7188 [23:06<01:19,  4.32it/s]
2022-03-21 13:55:59,735 - INFO - tqdm - f1: 0.9700, accuracy: 0.9700, batch_loss: 0.0059, loss: 0.0892 ||:  96%|#########5| 6892/7188 [23:16<01:03,  4.64it/s]
2022-03-21 13:56:09,970 - INFO - tqdm - f1: 0.9700, accuracy: 0.9700, batch_loss: 0.0051, loss: 0.0895 ||:  97%|#########6| 6939/7188 [23:27<01:00,  4.14it/s]
2022-03-21 13:56:20,113 - INFO - tqdm - f1: 0.9700, accuracy: 0.9699, batch_loss: 0.0083, loss: 0.0896 ||:  97%|#########7| 6987/7188 [23:37<00:41,  4.88it/s]
2022-03-21 13:56:30,293 - INFO - tqdm - f1: 0.9699, accuracy: 0.9699, batch_loss: 0.1559, loss: 0.0896 ||:  98%|#########7| 7035/7188 [23:47<00:32,  4.72it/s]
2022-03-21 13:56:40,381 - INFO - tqdm - f1: 0.9699, accuracy: 0.9699, batch_loss: 0.1226, loss: 0.0895 ||:  99%|#########8| 7081/7188 [23:57<00:22,  4.70it/s]
2022-03-21 13:56:50,389 - INFO - tqdm - f1: 0.9699, accuracy: 0.9699, batch_loss: 0.3872, loss: 0.0896 ||:  99%|#########9| 7128/7188 [24:07<00:14,  4.18it/s]
2022-03-21 13:56:55,923 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0889, loss: 0.0897 ||: 100%|#########9| 7153/7188 [24:13<00:07,  4.61it/s]
2022-03-21 13:56:56,192 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0047, loss: 0.0897 ||: 100%|#########9| 7154/7188 [24:13<00:07,  4.30it/s]
2022-03-21 13:56:56,441 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0567, loss: 0.0897 ||: 100%|#########9| 7155/7188 [24:13<00:07,  4.21it/s]
2022-03-21 13:56:56,610 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.1843, loss: 0.0897 ||: 100%|#########9| 7156/7188 [24:13<00:06,  4.61it/s]
2022-03-21 13:56:56,893 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0610, loss: 0.0897 ||: 100%|#########9| 7157/7188 [24:13<00:07,  4.22it/s]
2022-03-21 13:56:57,084 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.1053, loss: 0.0897 ||: 100%|#########9| 7158/7188 [24:14<00:06,  4.48it/s]
2022-03-21 13:56:57,220 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0205, loss: 0.0897 ||: 100%|#########9| 7159/7188 [24:14<00:05,  5.08it/s]
2022-03-21 13:56:57,492 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0363, loss: 0.0897 ||: 100%|#########9| 7160/7188 [24:14<00:06,  4.56it/s]
2022-03-21 13:56:57,681 - INFO - tqdm - f1: 0.9699, accuracy: 0.9699, batch_loss: 0.0510, loss: 0.0897 ||: 100%|#########9| 7161/7188 [24:14<00:05,  4.75it/s]
2022-03-21 13:56:57,829 - INFO - tqdm - f1: 0.9699, accuracy: 0.9699, batch_loss: 0.0115, loss: 0.0896 ||: 100%|#########9| 7162/7188 [24:14<00:04,  5.22it/s]
2022-03-21 13:56:58,091 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.2235, loss: 0.0897 ||: 100%|#########9| 7163/7188 [24:15<00:05,  4.70it/s]
2022-03-21 13:56:58,281 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.1506, loss: 0.0897 ||: 100%|#########9| 7164/7188 [24:15<00:04,  4.86it/s]
2022-03-21 13:56:58,421 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0321, loss: 0.0897 ||: 100%|#########9| 7165/7188 [24:15<00:04,  5.37it/s]
2022-03-21 13:56:58,661 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0024, loss: 0.0896 ||: 100%|#########9| 7166/7188 [24:15<00:04,  4.95it/s]
2022-03-21 13:56:58,883 - INFO - tqdm - f1: 0.9699, accuracy: 0.9699, batch_loss: 0.0297, loss: 0.0896 ||: 100%|#########9| 7167/7188 [24:15<00:04,  4.80it/s]
2022-03-21 13:56:59,023 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.1260, loss: 0.0896 ||: 100%|#########9| 7168/7188 [24:16<00:03,  5.32it/s]
2022-03-21 13:56:59,268 - INFO - tqdm - f1: 0.9699, accuracy: 0.9699, batch_loss: 0.0023, loss: 0.0896 ||: 100%|#########9| 7169/7188 [24:16<00:03,  4.88it/s]
2022-03-21 13:56:59,479 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0969, loss: 0.0896 ||: 100%|#########9| 7170/7188 [24:16<00:03,  4.84it/s]
2022-03-21 13:56:59,623 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.1035, loss: 0.0896 ||: 100%|#########9| 7171/7188 [24:16<00:03,  5.32it/s]
2022-03-21 13:56:59,897 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0224, loss: 0.0896 ||: 100%|#########9| 7172/7188 [24:16<00:03,  4.68it/s]
2022-03-21 13:57:00,102 - INFO - tqdm - f1: 0.9699, accuracy: 0.9699, batch_loss: 0.0176, loss: 0.0896 ||: 100%|#########9| 7173/7188 [24:17<00:03,  4.73it/s]
2022-03-21 13:57:00,373 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.1272, loss: 0.0896 ||: 100%|#########9| 7174/7188 [24:17<00:03,  4.37it/s]
2022-03-21 13:57:00,626 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0043, loss: 0.0896 ||: 100%|#########9| 7175/7188 [24:17<00:03,  4.23it/s]
2022-03-21 13:57:00,800 - INFO - tqdm - f1: 0.9699, accuracy: 0.9699, batch_loss: 0.0613, loss: 0.0896 ||: 100%|#########9| 7176/7188 [24:17<00:02,  4.60it/s]
2022-03-21 13:57:01,060 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.4936, loss: 0.0897 ||: 100%|#########9| 7177/7188 [24:18<00:02,  4.34it/s]
2022-03-21 13:57:01,261 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.3267, loss: 0.0897 ||: 100%|#########9| 7178/7188 [24:18<00:02,  4.51it/s]
2022-03-21 13:57:01,395 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0311, loss: 0.0897 ||: 100%|#########9| 7179/7188 [24:18<00:01,  5.12it/s]
2022-03-21 13:57:01,620 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.2237, loss: 0.0897 ||: 100%|#########9| 7180/7188 [24:18<00:01,  4.90it/s]
2022-03-21 13:57:01,861 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0649, loss: 0.0897 ||: 100%|#########9| 7181/7188 [24:18<00:01,  4.65it/s]
2022-03-21 13:57:02,001 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0106, loss: 0.0897 ||: 100%|#########9| 7182/7188 [24:19<00:01,  5.19it/s]
2022-03-21 13:57:02,249 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0795, loss: 0.0897 ||: 100%|#########9| 7183/7188 [24:19<00:01,  4.78it/s]
2022-03-21 13:57:02,461 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0672, loss: 0.0897 ||: 100%|#########9| 7184/7188 [24:19<00:00,  4.76it/s]
2022-03-21 13:57:02,601 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0196, loss: 0.0897 ||: 100%|#########9| 7185/7188 [24:19<00:00,  5.29it/s]
2022-03-21 13:57:02,881 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0394, loss: 0.0897 ||: 100%|#########9| 7186/7188 [24:19<00:00,  4.62it/s]
2022-03-21 13:57:03,062 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0572, loss: 0.0897 ||: 100%|#########9| 7187/7188 [24:20<00:00,  4.86it/s]
2022-03-21 13:57:03,202 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0290, loss: 0.0897 ||: 100%|##########| 7188/7188 [24:20<00:00,  5.38it/s]
2022-03-21 13:57:03,245 - INFO - tqdm - f1: 0.9699, accuracy: 0.9698, batch_loss: 0.0290, loss: 0.0897 ||: 100%|##########| 7188/7188 [24:20<00:00,  4.92it/s]
2022-03-21 13:57:03,314 - INFO - allennlp.training.trainer - Validating
2022-03-21 13:57:03,317 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 13:57:13,475 - INFO - tqdm - f1: 0.9317, accuracy: 0.9314, batch_loss: 0.4138, loss: 0.2777 ||:  26%|##6       | 82/313 [00:10<00:32,  7.18it/s]
2022-03-21 13:57:23,583 - INFO - tqdm - f1: 0.9320, accuracy: 0.9318, batch_loss: 0.3693, loss: 0.2598 ||:  54%|#####4    | 170/313 [00:20<00:15,  9.24it/s]
2022-03-21 13:57:33,664 - INFO - tqdm - f1: 0.9331, accuracy: 0.9331, batch_loss: 0.0884, loss: 0.2528 ||:  83%|########3 | 261/313 [00:30<00:05,  9.36it/s]
2022-03-21 13:57:39,535 - INFO - tqdm - f1: 0.9354, accuracy: 0.9352, batch_loss: 0.0274, loss: 0.2442 ||: 100%|##########| 313/313 [00:36<00:00,  8.64it/s]
2022-03-21 13:57:39,614 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 13:57:39,615 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.970  |     0.935
2022-03-21 13:57:39,616 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.970  |     0.935
2022-03-21 13:57:39,617 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 13:57:39,618 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.090  |     0.244
2022-03-21 13:57:39,620 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7584.363  |       N/A
2022-03-21 13:57:39,621 - INFO - allennlp.training.trainer - Epoch duration: 0:24:56.727619
2022-03-21 13:57:39,622 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:08:37
2022-03-21 13:57:39,624 - INFO - allennlp.training.trainer - Epoch 5/9
2022-03-21 13:57:39,625 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 13:57:39,627 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 13:57:39,629 - INFO - allennlp.training.trainer - Training
2022-03-21 13:57:39,631 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 13:57:49,854 - INFO - tqdm - f1: 0.9747, accuracy: 0.9742, batch_loss: 0.0107, loss: 0.0565 ||:   1%|          | 46/7188 [00:10<24:48,  4.80it/s]
2022-03-21 13:57:59,980 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.0039, loss: 0.0609 ||:   1%|1         | 94/7188 [00:20<25:49,  4.58it/s]
2022-03-21 13:58:10,223 - INFO - tqdm - f1: 0.9736, accuracy: 0.9738, batch_loss: 0.0075, loss: 0.0633 ||:   2%|1         | 143/7188 [00:30<24:49,  4.73it/s]
2022-03-21 13:58:20,445 - INFO - tqdm - f1: 0.9753, accuracy: 0.9755, batch_loss: 0.0082, loss: 0.0613 ||:   3%|2         | 191/7188 [00:40<26:10,  4.46it/s]
2022-03-21 13:58:30,510 - INFO - tqdm - f1: 0.9775, accuracy: 0.9777, batch_loss: 0.0267, loss: 0.0564 ||:   3%|3         | 238/7188 [00:50<28:21,  4.09it/s]
2022-03-21 13:58:40,735 - INFO - tqdm - f1: 0.9776, accuracy: 0.9779, batch_loss: 0.0025, loss: 0.0580 ||:   4%|4         | 289/7188 [01:01<24:19,  4.73it/s]
2022-03-21 13:58:50,826 - INFO - tqdm - f1: 0.9785, accuracy: 0.9788, batch_loss: 0.4178, loss: 0.0561 ||:   5%|4         | 336/7188 [01:11<25:25,  4.49it/s]
2022-03-21 13:59:01,068 - INFO - tqdm - f1: 0.9789, accuracy: 0.9791, batch_loss: 0.0103, loss: 0.0573 ||:   5%|5         | 386/7188 [01:21<23:31,  4.82it/s]
2022-03-21 13:59:11,294 - INFO - tqdm - f1: 0.9790, accuracy: 0.9792, batch_loss: 0.0120, loss: 0.0578 ||:   6%|6         | 436/7188 [01:31<23:54,  4.71it/s]
2022-03-21 13:59:21,484 - INFO - tqdm - f1: 0.9788, accuracy: 0.9791, batch_loss: 0.0021, loss: 0.0580 ||:   7%|6         | 485/7188 [01:41<24:23,  4.58it/s]
2022-03-21 13:59:31,661 - INFO - tqdm - f1: 0.9788, accuracy: 0.9790, batch_loss: 0.0836, loss: 0.0589 ||:   7%|7         | 534/7188 [01:52<23:40,  4.69it/s]
2022-03-21 13:59:41,900 - INFO - tqdm - f1: 0.9787, accuracy: 0.9790, batch_loss: 0.3528, loss: 0.0601 ||:   8%|8         | 584/7188 [02:02<25:06,  4.38it/s]
2022-03-21 13:59:51,955 - INFO - tqdm - f1: 0.9787, accuracy: 0.9790, batch_loss: 0.0480, loss: 0.0615 ||:   9%|8         | 633/7188 [02:12<20:50,  5.24it/s]
2022-03-21 14:00:02,017 - INFO - tqdm - f1: 0.9789, accuracy: 0.9791, batch_loss: 0.4657, loss: 0.0626 ||:   9%|9         | 681/7188 [02:22<21:57,  4.94it/s]
2022-03-21 14:00:12,084 - INFO - tqdm - f1: 0.9788, accuracy: 0.9790, batch_loss: 0.0149, loss: 0.0631 ||:  10%|#         | 728/7188 [02:32<25:10,  4.28it/s]
2022-03-21 14:00:22,114 - INFO - tqdm - f1: 0.9789, accuracy: 0.9790, batch_loss: 0.0018, loss: 0.0631 ||:  11%|#         | 776/7188 [02:42<23:01,  4.64it/s]
2022-03-21 14:00:32,352 - INFO - tqdm - f1: 0.9779, accuracy: 0.9780, batch_loss: 0.0101, loss: 0.0644 ||:  11%|#1        | 822/7188 [02:52<25:42,  4.13it/s]
2022-03-21 14:00:42,477 - INFO - tqdm - f1: 0.9783, accuracy: 0.9784, batch_loss: 0.3013, loss: 0.0634 ||:  12%|#2        | 870/7188 [03:02<22:49,  4.61it/s]
2022-03-21 14:00:52,751 - INFO - tqdm - f1: 0.9781, accuracy: 0.9782, batch_loss: 0.0090, loss: 0.0639 ||:  13%|#2        | 920/7188 [03:13<24:33,  4.25it/s]
2022-03-21 14:01:02,772 - INFO - tqdm - f1: 0.9778, accuracy: 0.9779, batch_loss: 0.0018, loss: 0.0652 ||:  13%|#3        | 968/7188 [03:23<21:22,  4.85it/s]
2022-03-21 14:01:12,990 - INFO - tqdm - f1: 0.9779, accuracy: 0.9780, batch_loss: 0.0135, loss: 0.0645 ||:  14%|#4        | 1015/7188 [03:33<24:03,  4.28it/s]
2022-03-21 14:01:23,048 - INFO - tqdm - f1: 0.9785, accuracy: 0.9785, batch_loss: 0.0368, loss: 0.0639 ||:  15%|#4        | 1063/7188 [03:43<20:47,  4.91it/s]
2022-03-21 14:01:33,234 - INFO - tqdm - f1: 0.9787, accuracy: 0.9788, batch_loss: 0.1812, loss: 0.0633 ||:  15%|#5        | 1111/7188 [03:53<22:29,  4.50it/s]
2022-03-21 14:01:43,411 - INFO - tqdm - f1: 0.9783, accuracy: 0.9784, batch_loss: 0.1094, loss: 0.0649 ||:  16%|#6        | 1159/7188 [04:03<21:49,  4.60it/s]
2022-03-21 14:01:53,586 - INFO - tqdm - f1: 0.9777, accuracy: 0.9779, batch_loss: 0.0130, loss: 0.0657 ||:  17%|#6        | 1208/7188 [04:13<21:24,  4.66it/s]
2022-03-21 14:02:03,730 - INFO - tqdm - f1: 0.9779, accuracy: 0.9780, batch_loss: 0.0208, loss: 0.0662 ||:  17%|#7        | 1257/7188 [04:24<20:22,  4.85it/s]
2022-03-21 14:02:13,769 - INFO - tqdm - f1: 0.9779, accuracy: 0.9780, batch_loss: 0.0068, loss: 0.0665 ||:  18%|#8        | 1304/7188 [04:34<21:31,  4.56it/s]
2022-03-21 14:02:23,815 - INFO - tqdm - f1: 0.9779, accuracy: 0.9780, batch_loss: 0.0178, loss: 0.0665 ||:  19%|#8        | 1351/7188 [04:44<18:48,  5.17it/s]
2022-03-21 14:02:33,829 - INFO - tqdm - f1: 0.9779, accuracy: 0.9780, batch_loss: 0.1958, loss: 0.0670 ||:  19%|#9        | 1397/7188 [04:54<20:18,  4.75it/s]
2022-03-21 14:02:43,972 - INFO - tqdm - f1: 0.9781, accuracy: 0.9782, batch_loss: 0.1316, loss: 0.0669 ||:  20%|##        | 1444/7188 [05:04<19:59,  4.79it/s]
2022-03-21 14:02:54,146 - INFO - tqdm - f1: 0.9780, accuracy: 0.9781, batch_loss: 0.0298, loss: 0.0670 ||:  21%|##        | 1493/7188 [05:14<19:39,  4.83it/s]
2022-03-21 14:03:04,280 - INFO - tqdm - f1: 0.9777, accuracy: 0.9778, batch_loss: 0.1050, loss: 0.0677 ||:  21%|##1       | 1540/7188 [05:24<20:19,  4.63it/s]
2022-03-21 14:03:14,382 - INFO - tqdm - f1: 0.9774, accuracy: 0.9775, batch_loss: 0.0342, loss: 0.0679 ||:  22%|##2       | 1588/7188 [05:34<20:37,  4.53it/s]
2022-03-21 14:03:24,409 - INFO - tqdm - f1: 0.9775, accuracy: 0.9775, batch_loss: 0.0033, loss: 0.0676 ||:  23%|##2       | 1639/7188 [05:44<17:14,  5.36it/s]
2022-03-21 14:03:34,556 - INFO - tqdm - f1: 0.9775, accuracy: 0.9775, batch_loss: 0.2613, loss: 0.0677 ||:  23%|##3       | 1687/7188 [05:54<20:24,  4.49it/s]
2022-03-21 14:03:44,599 - INFO - tqdm - f1: 0.9773, accuracy: 0.9773, batch_loss: 0.0195, loss: 0.0679 ||:  24%|##4       | 1735/7188 [06:04<18:53,  4.81it/s]
2022-03-21 14:03:54,723 - INFO - tqdm - f1: 0.9773, accuracy: 0.9773, batch_loss: 0.0030, loss: 0.0688 ||:  25%|##4       | 1783/7188 [06:15<18:44,  4.81it/s]
2022-03-21 14:04:04,820 - INFO - tqdm - f1: 0.9771, accuracy: 0.9772, batch_loss: 0.0101, loss: 0.0689 ||:  25%|##5       | 1829/7188 [06:25<18:59,  4.70it/s]
2022-03-21 14:04:14,985 - INFO - tqdm - f1: 0.9773, accuracy: 0.9774, batch_loss: 0.0243, loss: 0.0687 ||:  26%|##6       | 1878/7188 [06:35<18:26,  4.80it/s]
2022-03-21 14:04:25,182 - INFO - tqdm - f1: 0.9771, accuracy: 0.9771, batch_loss: 0.3285, loss: 0.0695 ||:  27%|##6       | 1928/7188 [06:45<18:19,  4.78it/s]
2022-03-21 14:04:35,317 - INFO - tqdm - f1: 0.9771, accuracy: 0.9772, batch_loss: 0.0858, loss: 0.0695 ||:  27%|##7       | 1976/7188 [06:55<18:11,  4.77it/s]
2022-03-21 14:04:45,360 - INFO - tqdm - f1: 0.9769, accuracy: 0.9769, batch_loss: 0.0130, loss: 0.0700 ||:  28%|##8       | 2026/7188 [07:05<17:57,  4.79it/s]
2022-03-21 14:04:55,557 - INFO - tqdm - f1: 0.9769, accuracy: 0.9770, batch_loss: 0.1249, loss: 0.0699 ||:  29%|##8       | 2075/7188 [07:15<19:47,  4.31it/s]
2022-03-21 14:05:05,764 - INFO - tqdm - f1: 0.9768, accuracy: 0.9768, batch_loss: 0.0125, loss: 0.0704 ||:  30%|##9       | 2124/7188 [07:26<18:31,  4.56it/s]
2022-03-21 14:05:15,901 - INFO - tqdm - f1: 0.9766, accuracy: 0.9767, batch_loss: 0.0060, loss: 0.0711 ||:  30%|###       | 2173/7188 [07:36<17:26,  4.79it/s]
2022-03-21 14:05:25,974 - INFO - tqdm - f1: 0.9765, accuracy: 0.9765, batch_loss: 0.0362, loss: 0.0713 ||:  31%|###       | 2221/7188 [07:46<18:49,  4.40it/s]
2022-03-21 14:05:36,039 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0771, loss: 0.0714 ||:  32%|###1      | 2293/7188 [07:56<05:05, 16.04it/s]
2022-03-21 14:05:46,137 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.1548, loss: 0.0714 ||:  33%|###3      | 2397/7188 [08:06<09:49,  8.13it/s]
2022-03-21 14:05:56,167 - INFO - tqdm - f1: 0.9765, accuracy: 0.9765, batch_loss: 0.0319, loss: 0.0711 ||:  34%|###4      | 2473/7188 [08:16<11:21,  6.92it/s]
2022-03-21 14:06:06,304 - INFO - tqdm - f1: 0.9766, accuracy: 0.9766, batch_loss: 0.0104, loss: 0.0710 ||:  35%|###5      | 2549/7188 [08:26<10:57,  7.06it/s]
2022-03-21 14:06:16,305 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0875, loss: 0.0713 ||:  36%|###6      | 2604/7188 [08:36<16:14,  4.70it/s]
2022-03-21 14:06:26,490 - INFO - tqdm - f1: 0.9765, accuracy: 0.9765, batch_loss: 0.3193, loss: 0.0713 ||:  37%|###6      | 2650/7188 [08:46<16:28,  4.59it/s]
2022-03-21 14:06:36,594 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.2752, loss: 0.0715 ||:  38%|###7      | 2699/7188 [08:56<15:34,  4.80it/s]
2022-03-21 14:06:46,776 - INFO - tqdm - f1: 0.9763, accuracy: 0.9763, batch_loss: 0.1200, loss: 0.0718 ||:  38%|###8      | 2748/7188 [09:07<15:22,  4.81it/s]
2022-03-21 14:06:56,948 - INFO - tqdm - f1: 0.9763, accuracy: 0.9763, batch_loss: 0.6321, loss: 0.0722 ||:  39%|###8      | 2797/7188 [09:17<15:30,  4.72it/s]
2022-03-21 14:07:07,054 - INFO - tqdm - f1: 0.9763, accuracy: 0.9763, batch_loss: 0.0458, loss: 0.0723 ||:  40%|###9      | 2843/7188 [09:27<17:10,  4.22it/s]
2022-03-21 14:07:17,232 - INFO - tqdm - f1: 0.9762, accuracy: 0.9762, batch_loss: 0.2676, loss: 0.0725 ||:  40%|####      | 2891/7188 [09:37<15:32,  4.61it/s]
2022-03-21 14:07:27,315 - INFO - tqdm - f1: 0.9761, accuracy: 0.9761, batch_loss: 0.0695, loss: 0.0728 ||:  41%|####      | 2938/7188 [09:47<16:31,  4.29it/s]
2022-03-21 14:07:37,361 - INFO - tqdm - f1: 0.9763, accuracy: 0.9763, batch_loss: 0.0121, loss: 0.0726 ||:  42%|####1     | 2986/7188 [09:57<14:27,  4.84it/s]
2022-03-21 14:07:47,491 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0300, loss: 0.0726 ||:  42%|####2     | 3035/7188 [10:07<14:17,  4.84it/s]
2022-03-21 14:07:57,710 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.3858, loss: 0.0726 ||:  43%|####2     | 3082/7188 [10:18<16:02,  4.27it/s]
2022-03-21 14:08:07,793 - INFO - tqdm - f1: 0.9763, accuracy: 0.9763, batch_loss: 0.1539, loss: 0.0729 ||:  44%|####3     | 3128/7188 [10:28<15:52,  4.26it/s]
2022-03-21 14:08:17,957 - INFO - tqdm - f1: 0.9762, accuracy: 0.9762, batch_loss: 0.0204, loss: 0.0729 ||:  44%|####4     | 3178/7188 [10:38<13:39,  4.89it/s]
2022-03-21 14:08:27,997 - INFO - tqdm - f1: 0.9762, accuracy: 0.9762, batch_loss: 0.0179, loss: 0.0730 ||:  45%|####4     | 3226/7188 [10:48<13:43,  4.81it/s]
2022-03-21 14:08:38,093 - INFO - tqdm - f1: 0.9761, accuracy: 0.9761, batch_loss: 0.0738, loss: 0.0732 ||:  46%|####5     | 3273/7188 [10:58<13:44,  4.75it/s]
2022-03-21 14:08:48,283 - INFO - tqdm - f1: 0.9762, accuracy: 0.9762, batch_loss: 0.0237, loss: 0.0733 ||:  46%|####6     | 3321/7188 [11:08<13:30,  4.77it/s]
2022-03-21 14:08:58,417 - INFO - tqdm - f1: 0.9762, accuracy: 0.9762, batch_loss: 0.0487, loss: 0.0734 ||:  47%|####6     | 3368/7188 [11:18<13:47,  4.62it/s]
2022-03-21 14:09:08,585 - INFO - tqdm - f1: 0.9761, accuracy: 0.9761, batch_loss: 0.4259, loss: 0.0737 ||:  48%|####7     | 3416/7188 [11:28<13:13,  4.75it/s]
2022-03-21 14:09:18,727 - INFO - tqdm - f1: 0.9762, accuracy: 0.9761, batch_loss: 0.1225, loss: 0.0734 ||:  48%|####8     | 3465/7188 [11:39<13:19,  4.65it/s]
2022-03-21 14:09:28,763 - INFO - tqdm - f1: 0.9762, accuracy: 0.9762, batch_loss: 0.0128, loss: 0.0732 ||:  49%|####8     | 3513/7188 [11:49<13:20,  4.59it/s]
2022-03-21 14:09:38,869 - INFO - tqdm - f1: 0.9762, accuracy: 0.9762, batch_loss: 0.0031, loss: 0.0732 ||:  50%|####9     | 3561/7188 [11:59<13:39,  4.43it/s]
2022-03-21 14:09:49,010 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0521, loss: 0.0728 ||:  50%|#####     | 3610/7188 [12:09<13:24,  4.45it/s]
2022-03-21 14:09:59,234 - INFO - tqdm - f1: 0.9762, accuracy: 0.9762, batch_loss: 0.1377, loss: 0.0732 ||:  51%|#####     | 3658/7188 [12:19<12:52,  4.57it/s]
2022-03-21 14:10:09,388 - INFO - tqdm - f1: 0.9762, accuracy: 0.9762, batch_loss: 0.0067, loss: 0.0730 ||:  52%|#####1    | 3706/7188 [12:29<12:26,  4.66it/s]
2022-03-21 14:10:19,394 - INFO - tqdm - f1: 0.9762, accuracy: 0.9762, batch_loss: 0.0349, loss: 0.0734 ||:  52%|#####2    | 3756/7188 [12:39<10:46,  5.31it/s]
2022-03-21 14:10:29,423 - INFO - tqdm - f1: 0.9761, accuracy: 0.9761, batch_loss: 0.0075, loss: 0.0736 ||:  53%|#####2    | 3803/7188 [12:49<11:39,  4.84it/s]
2022-03-21 14:10:39,602 - INFO - tqdm - f1: 0.9762, accuracy: 0.9761, batch_loss: 0.0175, loss: 0.0736 ||:  54%|#####3    | 3850/7188 [12:59<11:49,  4.70it/s]
2022-03-21 14:10:49,712 - INFO - tqdm - f1: 0.9760, accuracy: 0.9760, batch_loss: 0.0087, loss: 0.0739 ||:  54%|#####4    | 3897/7188 [13:10<12:40,  4.33it/s]
2022-03-21 14:10:59,726 - INFO - tqdm - f1: 0.9759, accuracy: 0.9759, batch_loss: 0.1230, loss: 0.0743 ||:  55%|#####4    | 3946/7188 [13:20<11:25,  4.73it/s]
2022-03-21 14:11:09,862 - INFO - tqdm - f1: 0.9758, accuracy: 0.9758, batch_loss: 0.0260, loss: 0.0743 ||:  56%|#####5    | 3994/7188 [13:30<10:49,  4.92it/s]
2022-03-21 14:11:20,014 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.0547, loss: 0.0745 ||:  56%|#####6    | 4042/7188 [13:40<11:58,  4.38it/s]
2022-03-21 14:11:30,223 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.0081, loss: 0.0745 ||:  57%|#####6    | 4092/7188 [13:50<10:23,  4.96it/s]
2022-03-21 14:11:40,462 - INFO - tqdm - f1: 0.9758, accuracy: 0.9758, batch_loss: 0.4749, loss: 0.0743 ||:  58%|#####7    | 4141/7188 [14:00<11:28,  4.43it/s]
2022-03-21 14:11:50,564 - INFO - tqdm - f1: 0.9758, accuracy: 0.9758, batch_loss: 0.0073, loss: 0.0743 ||:  58%|#####8    | 4188/7188 [14:10<11:54,  4.20it/s]
2022-03-21 14:12:00,751 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.0163, loss: 0.0744 ||:  59%|#####8    | 4240/7188 [14:21<10:42,  4.59it/s]
2022-03-21 14:12:10,888 - INFO - tqdm - f1: 0.9756, accuracy: 0.9756, batch_loss: 0.0068, loss: 0.0748 ||:  60%|#####9    | 4288/7188 [14:31<10:36,  4.56it/s]
2022-03-21 14:12:20,995 - INFO - tqdm - f1: 0.9755, accuracy: 0.9754, batch_loss: 0.0269, loss: 0.0749 ||:  60%|######    | 4336/7188 [14:41<10:30,  4.53it/s]
2022-03-21 14:12:31,153 - INFO - tqdm - f1: 0.9755, accuracy: 0.9754, batch_loss: 0.2128, loss: 0.0750 ||:  61%|######    | 4383/7188 [14:51<10:58,  4.26it/s]
2022-03-21 14:12:41,361 - INFO - tqdm - f1: 0.9756, accuracy: 0.9755, batch_loss: 0.0582, loss: 0.0746 ||:  62%|######1   | 4432/7188 [15:01<09:37,  4.77it/s]
2022-03-21 14:12:51,400 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.0116, loss: 0.0747 ||:  62%|######2   | 4479/7188 [15:11<10:01,  4.51it/s]
2022-03-21 14:13:01,652 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.0113, loss: 0.0746 ||:  63%|######2   | 4526/7188 [15:22<10:52,  4.08it/s]
2022-03-21 14:13:11,664 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.0039, loss: 0.0745 ||:  64%|######3   | 4573/7188 [15:32<09:49,  4.43it/s]
2022-03-21 14:13:21,679 - INFO - tqdm - f1: 0.9756, accuracy: 0.9755, batch_loss: 0.0026, loss: 0.0744 ||:  64%|######4   | 4620/7188 [15:42<09:39,  4.43it/s]
2022-03-21 14:13:31,694 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.3795, loss: 0.0747 ||:  65%|######4   | 4669/7188 [15:52<08:27,  4.97it/s]
2022-03-21 14:13:41,711 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.1353, loss: 0.0752 ||:  66%|######5   | 4716/7188 [16:02<09:13,  4.46it/s]
2022-03-21 14:13:51,864 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.0108, loss: 0.0752 ||:  66%|######6   | 4763/7188 [16:12<08:41,  4.65it/s]
2022-03-21 14:14:01,962 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.1858, loss: 0.0756 ||:  67%|######6   | 4813/7188 [16:22<07:44,  5.11it/s]
2022-03-21 14:14:12,099 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0039, loss: 0.0756 ||:  68%|######7   | 4861/7188 [16:32<08:20,  4.65it/s]
2022-03-21 14:14:22,246 - INFO - tqdm - f1: 0.9752, accuracy: 0.9751, batch_loss: 0.0055, loss: 0.0755 ||:  68%|######8   | 4909/7188 [16:42<08:07,  4.67it/s]
2022-03-21 14:14:32,367 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0283, loss: 0.0754 ||:  69%|######8   | 4956/7188 [16:52<08:13,  4.52it/s]
2022-03-21 14:14:42,546 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0141, loss: 0.0753 ||:  70%|######9   | 5004/7188 [17:02<07:55,  4.59it/s]
2022-03-21 14:14:52,664 - INFO - tqdm - f1: 0.9753, accuracy: 0.9752, batch_loss: 0.0097, loss: 0.0754 ||:  70%|#######   | 5052/7188 [17:13<07:18,  4.87it/s]
2022-03-21 14:15:02,806 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.0076, loss: 0.0753 ||:  71%|#######   | 5100/7188 [17:23<07:09,  4.86it/s]
2022-03-21 14:15:12,990 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.0024, loss: 0.0751 ||:  72%|#######1  | 5147/7188 [17:33<07:31,  4.52it/s]
2022-03-21 14:15:23,136 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.2762, loss: 0.0752 ||:  72%|#######2  | 5196/7188 [17:43<06:40,  4.97it/s]
2022-03-21 14:15:33,328 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.0252, loss: 0.0751 ||:  73%|#######2  | 5244/7188 [17:53<06:57,  4.65it/s]
2022-03-21 14:15:43,479 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.0193, loss: 0.0749 ||:  74%|#######3  | 5291/7188 [18:03<07:02,  4.49it/s]
2022-03-21 14:15:53,620 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.0971, loss: 0.0749 ||:  74%|#######4  | 5338/7188 [18:13<06:39,  4.63it/s]
2022-03-21 14:16:03,633 - INFO - tqdm - f1: 0.9755, accuracy: 0.9754, batch_loss: 0.2208, loss: 0.0749 ||:  75%|#######4  | 5385/7188 [18:24<06:36,  4.55it/s]
2022-03-21 14:16:13,675 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.0041, loss: 0.0748 ||:  76%|#######5  | 5432/7188 [18:34<06:35,  4.44it/s]
2022-03-21 14:16:23,817 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.0025, loss: 0.0748 ||:  76%|#######6  | 5479/7188 [18:44<06:11,  4.60it/s]
2022-03-21 14:16:33,866 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.0817, loss: 0.0749 ||:  77%|#######6  | 5526/7188 [18:54<05:45,  4.81it/s]
2022-03-21 14:16:44,020 - INFO - tqdm - f1: 0.9755, accuracy: 0.9754, batch_loss: 0.0021, loss: 0.0748 ||:  78%|#######7  | 5574/7188 [19:04<05:36,  4.80it/s]
2022-03-21 14:16:54,205 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.1252, loss: 0.0750 ||:  78%|#######8  | 5624/7188 [19:14<05:23,  4.83it/s]
2022-03-21 14:17:04,234 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.0045, loss: 0.0749 ||:  79%|#######8  | 5673/7188 [19:24<05:16,  4.79it/s]
2022-03-21 14:17:14,414 - INFO - tqdm - f1: 0.9754, accuracy: 0.9753, batch_loss: 0.1345, loss: 0.0749 ||:  80%|#######9  | 5722/7188 [19:34<05:13,  4.68it/s]
2022-03-21 14:17:24,542 - INFO - tqdm - f1: 0.9754, accuracy: 0.9753, batch_loss: 0.1789, loss: 0.0751 ||:  80%|########  | 5769/7188 [19:44<05:12,  4.54it/s]
2022-03-21 14:17:34,732 - INFO - tqdm - f1: 0.9754, accuracy: 0.9753, batch_loss: 0.0039, loss: 0.0751 ||:  81%|########  | 5818/7188 [19:55<04:49,  4.73it/s]
2022-03-21 14:17:44,822 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.0029, loss: 0.0748 ||:  82%|########1 | 5868/7188 [20:05<04:07,  5.33it/s]
2022-03-21 14:17:54,890 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.0479, loss: 0.0748 ||:  82%|########2 | 5917/7188 [20:15<04:25,  4.79it/s]
2022-03-21 14:18:04,905 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.5099, loss: 0.0748 ||:  83%|########2 | 5965/7188 [20:25<04:29,  4.54it/s]
2022-03-21 14:18:15,086 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.0513, loss: 0.0746 ||:  84%|########3 | 6014/7188 [20:35<04:05,  4.79it/s]
2022-03-21 14:18:25,131 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.1673, loss: 0.0749 ||:  84%|########4 | 6062/7188 [20:45<04:13,  4.44it/s]
2022-03-21 14:18:35,169 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.0096, loss: 0.0750 ||:  85%|########5 | 6110/7188 [20:55<03:20,  5.37it/s]
2022-03-21 14:18:45,283 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.0062, loss: 0.0748 ||:  86%|########5 | 6157/7188 [21:05<04:00,  4.29it/s]
2022-03-21 14:18:55,320 - INFO - tqdm - f1: 0.9754, accuracy: 0.9753, batch_loss: 0.1007, loss: 0.0749 ||:  86%|########6 | 6204/7188 [21:15<03:30,  4.68it/s]
2022-03-21 14:19:05,445 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.1489, loss: 0.0750 ||:  87%|########6 | 6251/7188 [21:25<03:30,  4.44it/s]
2022-03-21 14:19:15,578 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.5773, loss: 0.0752 ||:  88%|########7 | 6299/7188 [21:35<03:33,  4.15it/s]
2022-03-21 14:19:25,800 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0406, loss: 0.0755 ||:  88%|########8 | 6348/7188 [21:46<02:55,  4.78it/s]
2022-03-21 14:19:35,935 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0045, loss: 0.0754 ||:  89%|########8 | 6396/7188 [21:56<02:48,  4.70it/s]
2022-03-21 14:19:46,060 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.0268, loss: 0.0752 ||:  90%|########9 | 6444/7188 [22:06<02:59,  4.14it/s]
2022-03-21 14:19:56,217 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0289, loss: 0.0754 ||:  90%|######### | 6494/7188 [22:16<02:33,  4.53it/s]
2022-03-21 14:20:06,356 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.1306, loss: 0.0754 ||:  91%|######### | 6540/7188 [22:26<02:15,  4.77it/s]
2022-03-21 14:20:16,430 - INFO - tqdm - f1: 0.9751, accuracy: 0.9751, batch_loss: 0.0046, loss: 0.0755 ||:  92%|#########1| 6586/7188 [22:36<02:18,  4.33it/s]
2022-03-21 14:20:26,450 - INFO - tqdm - f1: 0.9751, accuracy: 0.9751, batch_loss: 0.0051, loss: 0.0755 ||:  92%|#########2| 6634/7188 [22:46<01:52,  4.92it/s]
2022-03-21 14:20:36,479 - INFO - tqdm - f1: 0.9751, accuracy: 0.9751, batch_loss: 0.1538, loss: 0.0756 ||:  93%|#########2| 6681/7188 [22:56<01:54,  4.44it/s]
2022-03-21 14:20:46,602 - INFO - tqdm - f1: 0.9751, accuracy: 0.9751, batch_loss: 0.1566, loss: 0.0756 ||:  94%|#########3| 6729/7188 [23:06<01:49,  4.18it/s]
2022-03-21 14:20:56,740 - INFO - tqdm - f1: 0.9751, accuracy: 0.9751, batch_loss: 0.0404, loss: 0.0755 ||:  94%|#########4| 6776/7188 [23:17<01:34,  4.35it/s]
2022-03-21 14:21:06,820 - INFO - tqdm - f1: 0.9751, accuracy: 0.9751, batch_loss: 0.0348, loss: 0.0755 ||:  95%|#########4| 6823/7188 [23:27<01:22,  4.41it/s]
2022-03-21 14:21:17,049 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.1624, loss: 0.0754 ||:  96%|#########5| 6871/7188 [23:37<01:12,  4.39it/s]
2022-03-21 14:21:27,184 - INFO - tqdm - f1: 0.9752, accuracy: 0.9751, batch_loss: 0.0390, loss: 0.0754 ||:  96%|#########6| 6918/7188 [23:47<00:58,  4.62it/s]
2022-03-21 14:21:37,289 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.1042, loss: 0.0753 ||:  97%|#########6| 6965/7188 [23:57<00:48,  4.62it/s]
2022-03-21 14:21:47,360 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0050, loss: 0.0753 ||:  98%|#########8| 7045/7188 [24:07<00:09, 14.76it/s]
2022-03-21 14:21:57,527 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0123, loss: 0.0753 ||:  99%|#########9| 7143/7188 [24:17<00:05,  8.29it/s]
2022-03-21 14:21:58,918 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0055, loss: 0.0753 ||: 100%|#########9| 7153/7188 [24:19<00:04,  7.26it/s]
2022-03-21 14:21:59,068 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0839, loss: 0.0753 ||: 100%|#########9| 7154/7188 [24:19<00:04,  7.11it/s]
2022-03-21 14:21:59,214 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.5510, loss: 0.0753 ||: 100%|#########9| 7155/7188 [24:19<00:04,  7.04it/s]
2022-03-21 14:21:59,448 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0063, loss: 0.0753 ||: 100%|#########9| 7157/7188 [24:19<00:04,  7.61it/s]
2022-03-21 14:21:59,596 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0170, loss: 0.0753 ||: 100%|#########9| 7158/7188 [24:19<00:04,  7.39it/s]
2022-03-21 14:21:59,743 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0612, loss: 0.0753 ||: 100%|#########9| 7159/7188 [24:20<00:04,  7.24it/s]
2022-03-21 14:21:59,887 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0423, loss: 0.0753 ||: 100%|#########9| 7160/7188 [24:20<00:03,  7.16it/s]
2022-03-21 14:22:00,031 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0025, loss: 0.0753 ||: 100%|#########9| 7161/7188 [24:20<00:03,  7.10it/s]
2022-03-21 14:22:00,177 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0025, loss: 0.0753 ||: 100%|#########9| 7162/7188 [24:20<00:03,  7.02it/s]
2022-03-21 14:22:00,323 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.5032, loss: 0.0753 ||: 100%|#########9| 7163/7188 [24:20<00:03,  6.98it/s]
2022-03-21 14:22:00,468 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0018, loss: 0.0753 ||: 100%|#########9| 7164/7188 [24:20<00:03,  6.95it/s]
2022-03-21 14:22:00,612 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0079, loss: 0.0753 ||: 100%|#########9| 7165/7188 [24:20<00:03,  6.95it/s]
2022-03-21 14:22:00,763 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0167, loss: 0.0753 ||: 100%|#########9| 7166/7188 [24:21<00:03,  6.86it/s]
2022-03-21 14:22:00,953 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0033, loss: 0.0753 ||: 100%|#########9| 7167/7188 [24:21<00:03,  6.29it/s]
2022-03-21 14:22:01,105 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0260, loss: 0.0753 ||: 100%|#########9| 7168/7188 [24:21<00:03,  6.37it/s]
2022-03-21 14:22:01,245 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.1613, loss: 0.0753 ||: 100%|#########9| 7169/7188 [24:21<00:02,  6.59it/s]
2022-03-21 14:22:01,403 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0267, loss: 0.0753 ||: 100%|#########9| 7170/7188 [24:21<00:02,  6.51it/s]
2022-03-21 14:22:01,542 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0395, loss: 0.0753 ||: 100%|#########9| 7171/7188 [24:21<00:02,  6.70it/s]
2022-03-21 14:22:01,687 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0034, loss: 0.0753 ||: 100%|#########9| 7172/7188 [24:22<00:02,  6.76it/s]
2022-03-21 14:22:01,839 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0105, loss: 0.0753 ||: 100%|#########9| 7173/7188 [24:22<00:02,  6.70it/s]
2022-03-21 14:22:02,036 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0242, loss: 0.0753 ||: 100%|#########9| 7174/7188 [24:22<00:02,  6.12it/s]
2022-03-21 14:22:02,230 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0221, loss: 0.0753 ||: 100%|#########9| 7175/7188 [24:22<00:02,  5.79it/s]
2022-03-21 14:22:02,382 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0382, loss: 0.0753 ||: 100%|#########9| 7176/7188 [24:22<00:01,  6.01it/s]
2022-03-21 14:22:02,522 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0169, loss: 0.0753 ||: 100%|#########9| 7177/7188 [24:22<00:01,  6.30it/s]
2022-03-21 14:22:02,675 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0036, loss: 0.0752 ||: 100%|#########9| 7178/7188 [24:23<00:01,  6.38it/s]
2022-03-21 14:22:02,821 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0735, loss: 0.0752 ||: 100%|#########9| 7179/7188 [24:23<00:01,  6.51it/s]
2022-03-21 14:22:03,074 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0408, loss: 0.0752 ||: 100%|#########9| 7180/7188 [24:23<00:01,  5.46it/s]
2022-03-21 14:22:03,214 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0057, loss: 0.0752 ||: 100%|#########9| 7181/7188 [24:23<00:01,  5.87it/s]
2022-03-21 14:22:03,356 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0146, loss: 0.0752 ||: 100%|#########9| 7182/7188 [24:23<00:00,  6.18it/s]
2022-03-21 14:22:03,507 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0089, loss: 0.0752 ||: 100%|#########9| 7183/7188 [24:23<00:00,  6.31it/s]
2022-03-21 14:22:03,638 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0213, loss: 0.0752 ||: 100%|#########9| 7184/7188 [24:24<00:00,  6.65it/s]
2022-03-21 14:22:03,857 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0041, loss: 0.0752 ||: 100%|#########9| 7186/7188 [24:24<00:00,  7.60it/s]
2022-03-21 14:22:04,006 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0124, loss: 0.0752 ||: 100%|#########9| 7187/7188 [24:24<00:00,  7.36it/s]
2022-03-21 14:22:04,110 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0043, loss: 0.0752 ||: 100%|##########| 7188/7188 [24:24<00:00,  7.85it/s]
2022-03-21 14:22:04,159 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0043, loss: 0.0752 ||: 100%|##########| 7188/7188 [24:24<00:00,  4.91it/s]
2022-03-21 14:22:04,191 - INFO - allennlp.training.trainer - Validating
2022-03-21 14:22:04,201 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 14:22:14,263 - INFO - tqdm - f1: 0.9345, accuracy: 0.9335, batch_loss: 0.0057, loss: 0.2872 ||:  55%|#####5    | 173/313 [00:10<00:07, 18.43it/s]
2022-03-21 14:22:24,528 - INFO - tqdm - f1: 0.9375, accuracy: 0.9372, batch_loss: 0.8923, loss: 0.2780 ||:  97%|#########7| 305/313 [00:20<00:00, 10.15it/s]
2022-03-21 14:22:25,514 - INFO - tqdm - f1: 0.9379, accuracy: 0.9376, batch_loss: 0.0264, loss: 0.2760 ||: 100%|##########| 313/313 [00:21<00:00,  9.94it/s]
2022-03-21 14:22:25,519 - INFO - tqdm - f1: 0.9379, accuracy: 0.9376, batch_loss: 0.0264, loss: 0.2760 ||: 100%|##########| 313/313 [00:21<00:00, 14.69it/s]
2022-03-21 14:22:25,592 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-21 14:22:25,593 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-21 14:22:26,220 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-21 14:22:26,224 - INFO - allennlp.training.util - Iterating over dataset
2022-03-21 14:22:26,229 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-21 14:22:26,244 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 14:22:26,248 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 14:22:36,265 - INFO - tqdm - f1: 0.94, accuracy: 0.94, loss: 0.18 ||: : 83it [00:10,  7.48it/s]
2022-03-21 14:22:46,351 - INFO - tqdm - f1: 0.94, accuracy: 0.94, loss: 0.18 ||: : 169it [00:20,  8.70it/s]
2022-03-21 14:22:56,401 - INFO - tqdm - f1: 0.94, accuracy: 0.94, loss: 0.19 ||: : 252it [00:30,  8.79it/s]
2022-03-21 14:23:06,469 - INFO - tqdm - f1: 0.94, accuracy: 0.94, loss: 0.20 ||: : 336it [00:40,  8.72it/s]
2022-03-21 14:23:16,607 - INFO - tqdm - f1: 0.94, accuracy: 0.94, loss: 0.20 ||: : 419it [00:50,  8.79it/s]
2022-03-21 14:23:23,369 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 2,
  "peak_worker_0_memory_MB": 7584.36328125,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "1:08:37.277431",
  "training_start_epoch": 0,
  "training_epochs": 4,
  "epoch": 4,
  "training_f1": 0.9698567986488342,
  "training_accuracy": 0.9698347826086956,
  "training_loss": 0.08965558586016664,
  "training_worker_0_memory_MB": 7584.36328125,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.9354003369808197,
  "validation_accuracy": 0.9352,
  "validation_loss": 0.24421423487086297,
  "best_validation_f1": 0.9415311962366104,
  "best_validation_accuracy": 0.9414,
  "best_validation_loss": 0.19101928998254977,
  "test_f1": 0.9378728866577148,
  "test_accuracy": 0.9377631578947369,
  "test_loss": 0.19997945868998374
}
2022-03-21 14:23:23,442 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/ag_base_hyper_small_seed_177/model.tar.gz
