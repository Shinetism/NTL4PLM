2022-03-19 23:38:41,665 - INFO - allennlp.common.params - random_seed = 2322624587
2022-03-19 23:38:41,667 - INFO - allennlp.common.params - numpy_seed = 2322624587
2022-03-19 23:38:41,669 - INFO - allennlp.common.params - pytorch_seed = 2322624587
2022-03-19 23:38:41,671 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-19 23:38:41,673 - INFO - allennlp.common.params - type = default
2022-03-19 23:38:41,676 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-19 23:38:41,677 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-19 23:38:41,679 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-19 23:38:41,683 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-19 23:38:41,684 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-19 23:38:41,686 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-19 23:38:41,687 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-19 23:38:56,480 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-19 23:38:56,482 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-19 23:38:56,483 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-19 23:38:56,485 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-19 23:38:56,486 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-19 23:38:56,488 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-19 23:38:56,490 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-19 23:38:56,491 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-19 23:38:56,493 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-19 23:38:56,495 - INFO - allennlp.common.params - train_data_path = datasets/rct-20k/train.jsonl
2022-03-19 23:38:56,498 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7fec17fa9190>
2022-03-19 23:38:56,499 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-19 23:38:56,501 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-19 23:38:56,503 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-19 23:38:56,505 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-19 23:38:56,507 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-19 23:38:56,508 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-19 23:38:56,510 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-19 23:38:56,512 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-19 23:38:56,514 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-19 23:38:56,516 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-19 23:38:56,518 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-19 23:38:56,520 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-19 23:38:56,521 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-19 23:38:56,523 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-19 23:38:56,525 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-19 23:38:56,527 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-19 23:38:56,529 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-19 23:38:56,531 - INFO - allennlp.common.params - validation_data_path = datasets/rct-20k/dev.jsonl
2022-03-19 23:38:56,532 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-19 23:38:56,534 - INFO - allennlp.common.params - test_data_path = datasets/rct-20k/test.jsonl
2022-03-19 23:38:56,535 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-19 23:38:56,537 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-19 23:38:56,538 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-19 23:38:56,540 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-19 23:38:56,541 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-19 23:38:56,543 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-19 23:38:56,544 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-19 23:38:56,546 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-19 23:38:56,547 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-19 23:38:56,548 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-19 23:38:56,550 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-19 23:38:56,551 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-19 23:38:56,552 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-19 23:38:56,554 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-19 23:38:56,556 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-19 23:38:56,560 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-19 23:38:56,564 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-19 23:39:06,605 - INFO - tqdm - loading instances: 36038it [00:10, 4278.82it/s]
2022-03-19 23:39:16,672 - INFO - tqdm - loading instances: 72146it [00:20, 3951.99it/s]
2022-03-19 23:39:26,698 - INFO - tqdm - loading instances: 106238it [00:30, 3721.04it/s]
2022-03-19 23:39:36,754 - INFO - tqdm - loading instances: 142846it [00:40, 4211.00it/s]
2022-03-19 23:39:46,758 - INFO - tqdm - loading instances: 178320it [00:50, 4275.14it/s]
2022-03-19 23:39:47,164 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-19 23:39:47,170 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-19 23:39:47,172 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-19 23:39:47,173 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-19 23:39:47,175 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-19 23:39:47,177 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-19 23:39:47,178 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-19 23:39:47,180 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-19 23:39:47,181 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-19 23:39:47,183 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-19 23:39:47,185 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-19 23:39:47,186 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-19 23:39:47,187 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-19 23:39:47,189 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-19 23:39:47,190 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-19 23:39:56,757 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-19 23:39:56,764 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-19 23:39:56,766 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-19 23:39:56,767 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-19 23:39:56,769 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-19 23:39:56,771 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-19 23:39:56,773 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-19 23:39:56,774 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-19 23:39:56,776 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-19 23:39:56,778 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-19 23:39:56,779 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-19 23:39:56,781 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-19 23:39:56,783 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-19 23:39:56,784 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-19 23:39:56,786 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-19 23:40:03,907 - INFO - allennlp.common.params - type = from_instances
2022-03-19 23:40:03,913 - INFO - allennlp.common.params - min_count = None
2022-03-19 23:40:03,914 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-19 23:40:03,916 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-19 23:40:03,917 - INFO - allennlp.common.params - pretrained_files = None
2022-03-19 23:40:03,919 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-19 23:40:03,920 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-19 23:40:03,922 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-19 23:40:03,924 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-19 23:40:03,925 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-19 23:40:03,927 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-19 23:40:03,928 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-19 23:40:05,143 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-19 23:40:05,150 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-19 23:40:05,152 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-19 23:40:05,154 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-19 23:40:05,156 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-19 23:40:05,157 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-19 23:40:05,159 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-19 23:40:05,161 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-19 23:40:05,162 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-19 23:40:05,163 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-19 23:40:05,165 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-19 23:40:05,166 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-19 23:40:05,168 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-19 23:40:11,156 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-19 23:40:11,163 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-19 23:40:11,166 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-19 23:40:11,168 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-19 23:40:11,169 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-19 23:40:11,171 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-19 23:40:11,173 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-19 23:40:11,174 - INFO - allennlp.common.params - type = tanh
2022-03-19 23:40:11,176 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-19 23:40:11,184 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-19 23:40:11,185 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-19 23:40:11,187 - INFO - allennlp.common.params - model.num_labels = None
2022-03-19 23:40:11,188 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-19 23:40:11,190 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fec17fdccd0>
2022-03-19 23:40:11,191 - INFO - allennlp.common.params - model.regularizer = None
2022-03-19 23:40:11,193 - INFO - allennlp.common.params - model.track_weights = False
2022-03-19 23:40:11,194 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-19 23:40:11,196 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-19 23:40:11,199 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-19 23:40:11,200 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-19 23:40:11,201 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-19 23:40:11,203 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-19 23:40:11,204 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-19 23:40:11,206 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-19 23:40:11,207 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-19 23:40:11,209 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-19 23:40:11,210 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-19 23:40:11,211 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-19 23:40:11,213 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-19 23:40:11,214 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-19 23:40:11,215 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-19 23:40:11,216 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-19 23:40:11,218 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-19 23:40:11,219 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-19 23:40:11,220 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-19 23:40:11,222 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-19 23:40:11,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-19 23:40:11,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-19 23:40:11,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-19 23:40:11,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-19 23:40:11,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-19 23:40:11,232 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-19 23:40:11,233 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-19 23:40:11,234 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-19 23:40:11,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-19 23:40:11,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-19 23:40:11,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-19 23:40:11,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-19 23:40:11,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-19 23:40:11,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-19 23:40:11,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-19 23:40:11,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-19 23:40:11,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-19 23:40:11,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-19 23:40:11,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-19 23:40:11,250 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-19 23:40:11,251 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-19 23:40:11,252 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-19 23:40:11,253 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-19 23:40:11,255 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-19 23:40:11,257 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-19 23:40:11,258 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-19 23:40:11,259 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-19 23:40:11,261 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-19 23:40:11,262 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-19 23:40:11,263 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-19 23:40:11,264 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-19 23:40:11,266 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-19 23:40:11,267 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-19 23:40:11,268 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-19 23:40:11,270 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-19 23:40:11,271 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-19 23:40:11,272 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-19 23:40:11,273 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-19 23:40:11,275 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-19 23:40:11,276 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-19 23:40:11,277 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-19 23:40:11,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-19 23:40:11,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-19 23:40:11,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-19 23:40:11,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-19 23:40:11,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-19 23:40:11,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-19 23:40:11,286 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-19 23:40:11,287 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-19 23:40:11,289 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-19 23:40:11,290 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-19 23:40:11,291 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-19 23:40:11,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-19 23:40:11,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-19 23:40:11,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-19 23:40:11,296 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-19 23:40:11,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-19 23:40:11,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-19 23:40:11,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-19 23:40:11,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-19 23:40:11,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-19 23:40:11,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-19 23:40:11,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-19 23:40:11,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-19 23:40:11,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-19 23:40:11,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-19 23:40:11,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-19 23:40:11,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-19 23:40:11,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-19 23:40:11,313 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-19 23:40:11,314 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-19 23:40:11,315 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-19 23:40:11,317 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-19 23:40:11,318 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-19 23:40:11,320 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-19 23:40:11,321 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-19 23:40:11,322 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-19 23:40:11,323 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-19 23:40:11,324 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-19 23:40:11,326 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-19 23:40:11,327 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-19 23:40:11,328 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-19 23:40:11,329 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-19 23:40:11,331 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-19 23:40:11,332 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-19 23:40:11,333 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-19 23:40:11,334 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-19 23:40:11,335 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-19 23:40:11,337 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-19 23:40:11,338 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-19 23:40:11,339 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-19 23:40:11,340 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-19 23:40:11,341 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-19 23:40:11,343 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-19 23:40:11,344 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-19 23:40:11,345 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-19 23:40:11,346 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-19 23:40:11,347 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-19 23:40:11,349 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-19 23:40:11,351 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-19 23:40:11,352 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-19 23:40:11,353 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-19 23:40:11,357 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-19 23:40:11,359 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-19 23:40:11,360 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-19 23:40:11,361 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-19 23:40:11,363 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-19 23:40:11,364 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-19 23:40:11,365 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-19 23:40:11,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-19 23:40:11,367 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-19 23:40:11,369 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-19 23:40:11,370 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-19 23:40:11,371 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-19 23:40:11,372 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-19 23:40:11,373 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-19 23:40:11,375 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-19 23:40:11,376 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-19 23:40:11,377 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-19 23:40:11,378 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-19 23:40:11,380 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-19 23:40:11,381 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-19 23:40:11,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-19 23:40:11,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-19 23:40:11,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-19 23:40:11,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-19 23:40:11,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-19 23:40:11,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-19 23:40:11,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-19 23:40:11,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-19 23:40:11,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-19 23:40:11,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-19 23:40:11,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-19 23:40:11,396 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-19 23:40:11,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-19 23:40:11,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-19 23:40:11,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-19 23:40:11,401 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-19 23:40:11,402 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-19 23:40:11,404 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-19 23:40:11,405 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-19 23:40:11,406 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-19 23:40:11,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-19 23:40:11,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-19 23:40:11,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-19 23:40:11,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-19 23:40:11,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-19 23:40:11,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-19 23:40:11,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-19 23:40:11,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-19 23:40:11,418 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-19 23:40:11,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-19 23:40:11,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-19 23:40:11,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-19 23:40:11,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-19 23:40:11,424 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-19 23:40:11,426 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-19 23:40:11,428 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-19 23:40:11,429 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-19 23:40:11,430 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-19 23:40:11,431 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-19 23:40:11,432 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-19 23:40:11,434 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-19 23:40:11,435 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-19 23:40:11,436 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-19 23:40:11,437 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-19 23:40:11,439 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-19 23:40:11,440 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-19 23:40:11,441 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-19 23:40:11,443 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-19 23:40:11,444 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-19 23:40:11,445 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-19 23:40:11,447 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-19 23:40:11,449 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-19 23:40:11,450 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-19 23:40:11,451 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-19 23:40:11,452 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-19 23:40:11,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-19 23:40:11,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-19 23:40:11,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-19 23:40:11,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-19 23:40:11,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-19 23:40:11,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-19 23:40:11,461 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-19 23:40:11,463 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-19 23:40:11,464 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-19 23:40:21,095 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-19 23:40:21,102 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-19 23:40:21,103 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-19 23:40:21,105 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-19 23:40:21,107 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-19 23:40:21,109 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-19 23:40:21,111 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-19 23:40:21,112 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-19 23:40:21,114 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-19 23:40:21,115 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-19 23:40:21,117 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-19 23:40:21,118 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-19 23:40:21,121 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-19 23:40:21,122 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-19 23:40:21,124 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-19 23:40:21,125 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-19 23:40:21,129 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-19 23:40:28,121 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-19 23:40:28,127 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-19 23:40:28,129 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-19 23:40:28,131 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-19 23:40:28,133 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-19 23:40:28,134 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-19 23:40:28,138 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-19 23:40:28,140 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias'], {'weight_decay': 0}
2022-03-19 23:40:28,143 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight'], {}
2022-03-19 23:40:28,145 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-19 23:40:28,147 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125240069
2022-03-19 23:40:28,149 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-19 23:40:28,152 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-19 23:40:28,153 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-19 23:40:28,155 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-19 23:40:28,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-19 23:40:28,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-19 23:40:28,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-19 23:40:28,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-19 23:40:28,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-19 23:40:28,164 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-19 23:40:28,166 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-19 23:40:28,168 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-19 23:40:28,169 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-19 23:40:28,171 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-19 23:40:28,172 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-19 23:40:28,174 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-19 23:40:28,175 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-19 23:40:28,178 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-19 23:40:28,179 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-19 23:40:28,181 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-19 23:40:28,182 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-19 23:40:28,183 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-19 23:40:28,185 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-19 23:40:28,186 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-19 23:40:28,188 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-19 23:40:28,189 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-19 23:40:28,190 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-19 23:40:28,192 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-19 23:40:28,193 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-19 23:40:28,194 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-19 23:40:28,195 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-19 23:40:28,197 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-19 23:40:28,198 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-19 23:40:28,199 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-19 23:40:28,201 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-19 23:40:28,202 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-19 23:40:28,203 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-19 23:40:28,204 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-19 23:40:28,206 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-19 23:40:28,207 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-19 23:40:28,208 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-19 23:40:28,209 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-19 23:40:28,211 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-19 23:40:28,213 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-19 23:40:28,214 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-19 23:40:28,220 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-19 23:40:28,222 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-19 23:40:28,223 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-19 23:40:28,224 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-19 23:40:28,226 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-19 23:40:28,227 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-19 23:40:28,228 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-19 23:40:28,229 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-19 23:40:28,231 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-19 23:40:28,232 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-19 23:40:28,233 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-19 23:40:28,234 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-19 23:40:28,236 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-19 23:40:28,237 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-19 23:40:28,238 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-19 23:40:28,239 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-19 23:40:28,241 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-19 23:40:28,242 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-19 23:40:28,243 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-19 23:40:28,244 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-19 23:40:28,246 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-19 23:40:28,247 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-19 23:40:28,248 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-19 23:40:28,249 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-19 23:40:28,251 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-19 23:40:28,253 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-19 23:40:28,254 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-19 23:40:28,255 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-19 23:40:28,256 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-19 23:40:28,258 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-19 23:40:28,259 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-19 23:40:28,261 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-19 23:40:28,262 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-19 23:40:28,263 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-19 23:40:28,264 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-19 23:40:28,265 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-19 23:40:28,267 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-19 23:40:28,268 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-19 23:40:28,269 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-19 23:40:28,270 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-19 23:40:28,272 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-19 23:40:28,273 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-19 23:40:28,274 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-19 23:40:28,277 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-19 23:40:28,278 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-19 23:40:28,279 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-19 23:40:28,281 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-19 23:40:28,282 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-19 23:40:28,283 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-19 23:40:28,284 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-19 23:40:28,286 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-19 23:40:28,288 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-19 23:40:28,289 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-19 23:40:28,290 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-19 23:40:28,291 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-19 23:40:28,293 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-19 23:40:28,294 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-19 23:40:28,295 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-19 23:40:28,296 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-19 23:40:28,297 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-19 23:40:28,299 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-19 23:40:28,300 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-19 23:40:28,301 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-19 23:40:28,302 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-19 23:40:28,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-19 23:40:28,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-19 23:40:28,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-19 23:40:28,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-19 23:40:28,309 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-19 23:40:28,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-19 23:40:28,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-19 23:40:28,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-19 23:40:28,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-19 23:40:28,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-19 23:40:28,317 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-19 23:40:28,319 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-19 23:40:28,320 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-19 23:40:28,322 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-19 23:40:28,323 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-19 23:40:28,324 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-19 23:40:28,325 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-19 23:40:28,327 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-19 23:40:28,328 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-19 23:40:28,329 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-19 23:40:28,331 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-19 23:40:28,332 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-19 23:40:28,333 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-19 23:40:28,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-19 23:40:28,336 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-19 23:40:28,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-19 23:40:28,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-19 23:40:28,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-19 23:40:28,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-19 23:40:28,342 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-19 23:40:28,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-19 23:40:28,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-19 23:40:28,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-19 23:40:28,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-19 23:40:28,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-19 23:40:28,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-19 23:40:28,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-19 23:40:28,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-19 23:40:28,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-19 23:40:28,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-19 23:40:28,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-19 23:40:28,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-19 23:40:28,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-19 23:40:28,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-19 23:40:28,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-19 23:40:28,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-19 23:40:28,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-19 23:40:28,366 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-19 23:40:28,367 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-19 23:40:28,368 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-19 23:40:28,369 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-19 23:40:28,371 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-19 23:40:28,372 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-19 23:40:28,373 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-19 23:40:28,374 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-19 23:40:28,376 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-19 23:40:28,377 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-19 23:40:28,378 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-19 23:40:28,379 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-19 23:40:28,381 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-19 23:40:28,382 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-19 23:40:28,383 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-19 23:40:28,384 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-19 23:40:28,387 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-19 23:40:28,388 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-19 23:40:28,389 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-19 23:40:28,391 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-19 23:40:28,392 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-19 23:40:28,393 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-19 23:40:28,395 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-19 23:40:28,396 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-19 23:40:28,397 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-19 23:40:28,398 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-19 23:40:28,399 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-19 23:40:28,401 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-19 23:40:28,402 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-19 23:40:28,403 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-19 23:40:28,405 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-19 23:40:28,406 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-19 23:40:28,408 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-19 23:40:28,409 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-19 23:40:28,411 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-19 23:40:28,412 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-19 23:40:28,413 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-19 23:40:28,415 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-19 23:40:28,416 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-19 23:40:28,417 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-19 23:40:28,418 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-19 23:40:28,420 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-19 23:40:28,421 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-19 23:40:28,423 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-19 23:40:28,424 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-19 23:40:28,425 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-19 23:40:28,426 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-19 23:40:28,428 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-19 23:40:28,429 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-19 23:40:28,430 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-19 23:40:28,432 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-19 23:40:28,433 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-19 23:40:28,435 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-19 23:40:28,436 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-19 23:40:28,438 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-19 23:40:28,442 - INFO - allennlp.training.trainer - Beginning training.
2022-03-19 23:40:28,444 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-19 23:40:28,445 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.3G
2022-03-19 23:40:28,446 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-19 23:40:28,448 - INFO - allennlp.training.trainer - Training
2022-03-19 23:40:28,450 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-19 23:40:28,616 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-19 23:40:28,618 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-19 23:40:38,586 - INFO - tqdm - f1: 0.4175, accuracy: 0.5949, batch_loss: 0.1885, loss: 1.0361 ||:   1%|          | 81/11253 [00:10<19:06,  9.74it/s]
2022-03-19 23:40:48,601 - INFO - tqdm - f1: 0.5955, accuracy: 0.6983, batch_loss: 0.3830, loss: 0.7987 ||:   2%|1         | 179/11253 [00:20<13:53, 13.28it/s]
2022-03-19 23:40:58,748 - INFO - tqdm - f1: 0.6485, accuracy: 0.7376, batch_loss: 0.8116, loss: 0.7041 ||:   3%|2         | 283/11253 [00:30<12:58, 14.09it/s]
2022-03-19 23:41:08,776 - INFO - tqdm - f1: 0.6815, accuracy: 0.7569, batch_loss: 0.3149, loss: 0.6563 ||:   3%|3         | 383/11253 [00:40<13:46, 13.15it/s]
2022-03-19 23:41:18,782 - INFO - tqdm - f1: 0.6972, accuracy: 0.7692, batch_loss: 0.3982, loss: 0.6246 ||:   4%|4         | 485/11253 [00:50<15:55, 11.27it/s]
2022-03-19 23:41:28,882 - INFO - tqdm - f1: 0.7053, accuracy: 0.7764, batch_loss: 0.2286, loss: 0.6010 ||:   5%|5         | 587/11253 [01:00<14:45, 12.05it/s]
2022-03-19 23:41:38,906 - INFO - tqdm - f1: 0.7116, accuracy: 0.7825, batch_loss: 0.1983, loss: 0.5841 ||:   6%|6         | 689/11253 [01:10<22:15,  7.91it/s]
2022-03-19 23:41:48,973 - INFO - tqdm - f1: 0.7216, accuracy: 0.7904, batch_loss: 0.3349, loss: 0.5653 ||:   7%|7         | 793/11253 [01:20<30:11,  5.77it/s]
2022-03-19 23:41:59,200 - INFO - tqdm - f1: 0.7277, accuracy: 0.7966, batch_loss: 0.2034, loss: 0.5518 ||:   8%|7         | 897/11253 [01:30<37:40,  4.58it/s]
2022-03-19 23:42:09,524 - INFO - tqdm - f1: 0.7321, accuracy: 0.7997, batch_loss: 0.1601, loss: 0.5447 ||:   9%|8         | 1003/11253 [01:41<37:48,  4.52it/s]
2022-03-19 23:42:19,798 - INFO - tqdm - f1: 0.7358, accuracy: 0.8027, batch_loss: 0.4789, loss: 0.5373 ||:  10%|9         | 1107/11253 [01:51<38:19,  4.41it/s]
2022-03-19 23:42:30,388 - INFO - tqdm - f1: 0.7367, accuracy: 0.8040, batch_loss: 0.3666, loss: 0.5341 ||:  11%|#         | 1219/11253 [02:01<36:40,  4.56it/s]
2022-03-19 23:42:40,874 - INFO - tqdm - f1: 0.7407, accuracy: 0.8078, batch_loss: 0.3976, loss: 0.5237 ||:  12%|#1        | 1329/11253 [02:12<36:16,  4.56it/s]
2022-03-19 23:42:51,483 - INFO - tqdm - f1: 0.7431, accuracy: 0.8113, batch_loss: 0.2500, loss: 0.5149 ||:  13%|#2        | 1435/11253 [02:23<37:01,  4.42it/s]
2022-03-19 23:43:01,815 - INFO - tqdm - f1: 0.7448, accuracy: 0.8130, batch_loss: 0.4276, loss: 0.5108 ||:  14%|#3        | 1543/11253 [02:33<34:52,  4.64it/s]
2022-03-19 23:43:12,562 - INFO - tqdm - f1: 0.7472, accuracy: 0.8150, batch_loss: 0.2115, loss: 0.5055 ||:  15%|#4        | 1657/11253 [02:44<36:19,  4.40it/s]
2022-03-19 23:43:23,057 - INFO - tqdm - f1: 0.7488, accuracy: 0.8164, batch_loss: 0.3278, loss: 0.5012 ||:  16%|#5        | 1765/11253 [02:54<35:15,  4.49it/s]
2022-03-19 23:43:34,219 - INFO - tqdm - f1: 0.7503, accuracy: 0.8179, batch_loss: 0.4323, loss: 0.4974 ||:  17%|#6        | 1879/11253 [03:05<36:13,  4.31it/s]
2022-03-19 23:43:44,307 - INFO - tqdm - f1: 0.7532, accuracy: 0.8194, batch_loss: 0.4308, loss: 0.4944 ||:  18%|#7        | 1993/11253 [03:15<11:19, 13.62it/s]
2022-03-19 23:43:54,327 - INFO - tqdm - f1: 0.7552, accuracy: 0.8210, batch_loss: 0.0776, loss: 0.4906 ||:  19%|#8        | 2091/11253 [03:25<10:32, 14.49it/s]
2022-03-19 23:44:04,380 - INFO - tqdm - f1: 0.7569, accuracy: 0.8226, batch_loss: 0.3766, loss: 0.4877 ||:  19%|#9        | 2193/11253 [03:35<10:55, 13.81it/s]
2022-03-19 23:44:14,504 - INFO - tqdm - f1: 0.7576, accuracy: 0.8236, batch_loss: 0.3514, loss: 0.4845 ||:  20%|##        | 2297/11253 [03:46<10:43, 13.93it/s]
2022-03-19 23:44:24,593 - INFO - tqdm - f1: 0.7593, accuracy: 0.8246, batch_loss: 0.3619, loss: 0.4820 ||:  21%|##1       | 2397/11253 [03:56<13:16, 11.12it/s]
2022-03-19 23:44:34,674 - INFO - tqdm - f1: 0.7595, accuracy: 0.8252, batch_loss: 0.1730, loss: 0.4788 ||:  22%|##2       | 2499/11253 [04:06<17:43,  8.23it/s]
2022-03-19 23:44:44,698 - INFO - tqdm - f1: 0.7609, accuracy: 0.8263, batch_loss: 0.1575, loss: 0.4767 ||:  23%|##3       | 2601/11253 [04:16<31:43,  4.55it/s]
2022-03-19 23:44:54,994 - INFO - tqdm - f1: 0.7614, accuracy: 0.8266, batch_loss: 0.3535, loss: 0.4762 ||:  24%|##4       | 2705/11253 [04:26<31:25,  4.53it/s]
2022-03-19 23:45:05,762 - INFO - tqdm - f1: 0.7620, accuracy: 0.8276, batch_loss: 0.1864, loss: 0.4737 ||:  25%|##4       | 2811/11253 [04:37<31:49,  4.42it/s]
2022-03-19 23:45:16,234 - INFO - tqdm - f1: 0.7638, accuracy: 0.8289, batch_loss: 0.2286, loss: 0.4703 ||:  26%|##5       | 2915/11253 [04:47<31:21,  4.43it/s]
2022-03-19 23:45:27,042 - INFO - tqdm - f1: 0.7641, accuracy: 0.8294, batch_loss: 0.5902, loss: 0.4692 ||:  27%|##6       | 3023/11253 [04:58<30:45,  4.46it/s]
2022-03-19 23:45:37,437 - INFO - tqdm - f1: 0.7652, accuracy: 0.8303, batch_loss: 0.1806, loss: 0.4677 ||:  28%|##7       | 3129/11253 [05:08<29:42,  4.56it/s]
2022-03-19 23:45:47,816 - INFO - tqdm - f1: 0.7658, accuracy: 0.8306, batch_loss: 0.2409, loss: 0.4669 ||:  29%|##8       | 3233/11253 [05:19<30:04,  4.44it/s]
2022-03-19 23:45:58,237 - INFO - tqdm - f1: 0.7663, accuracy: 0.8312, batch_loss: 0.4696, loss: 0.4649 ||:  30%|##9       | 3337/11253 [05:29<29:09,  4.53it/s]
2022-03-19 23:46:09,030 - INFO - tqdm - f1: 0.7669, accuracy: 0.8319, batch_loss: 0.5190, loss: 0.4629 ||:  31%|###       | 3449/11253 [05:40<28:39,  4.54it/s]
2022-03-19 23:46:19,691 - INFO - tqdm - f1: 0.7680, accuracy: 0.8330, batch_loss: 0.3404, loss: 0.4597 ||:  32%|###1      | 3559/11253 [05:51<28:46,  4.46it/s]
2022-03-19 23:46:30,019 - INFO - tqdm - f1: 0.7686, accuracy: 0.8337, batch_loss: 0.1703, loss: 0.4579 ||:  33%|###2      | 3665/11253 [06:01<27:36,  4.58it/s]
2022-03-19 23:46:40,767 - INFO - tqdm - f1: 0.7693, accuracy: 0.8344, batch_loss: 0.3278, loss: 0.4564 ||:  34%|###3      | 3777/11253 [06:12<27:53,  4.47it/s]
2022-03-19 23:46:51,346 - INFO - tqdm - f1: 0.7695, accuracy: 0.8350, batch_loss: 0.3208, loss: 0.4552 ||:  35%|###4      | 3887/11253 [06:22<26:51,  4.57it/s]
2022-03-19 23:47:01,821 - INFO - tqdm - f1: 0.7706, accuracy: 0.8360, batch_loss: 0.2493, loss: 0.4530 ||:  36%|###5      | 3995/11253 [06:33<27:17,  4.43it/s]
2022-03-19 23:47:12,471 - INFO - tqdm - f1: 0.7709, accuracy: 0.8363, batch_loss: 0.1858, loss: 0.4519 ||:  36%|###6      | 4105/11253 [06:44<26:10,  4.55it/s]
2022-03-19 23:47:22,872 - INFO - tqdm - f1: 0.7707, accuracy: 0.8363, batch_loss: 0.1384, loss: 0.4516 ||:  37%|###7      | 4211/11253 [06:54<26:01,  4.51it/s]
2022-03-19 23:47:33,387 - INFO - tqdm - f1: 0.7712, accuracy: 0.8369, batch_loss: 0.4854, loss: 0.4501 ||:  38%|###8      | 4319/11253 [07:04<25:50,  4.47it/s]
2022-03-19 23:47:43,734 - INFO - tqdm - f1: 0.7716, accuracy: 0.8374, batch_loss: 0.1660, loss: 0.4487 ||:  39%|###9      | 4425/11253 [07:15<24:57,  4.56it/s]
2022-03-19 23:47:53,937 - INFO - tqdm - f1: 0.7725, accuracy: 0.8379, batch_loss: 0.2489, loss: 0.4479 ||:  40%|####      | 4529/11253 [07:25<25:11,  4.45it/s]
2022-03-19 23:48:04,322 - INFO - tqdm - f1: 0.7726, accuracy: 0.8382, batch_loss: 0.1463, loss: 0.4468 ||:  41%|####1     | 4635/11253 [07:35<24:47,  4.45it/s]
2022-03-19 23:48:14,632 - INFO - tqdm - f1: 0.7734, accuracy: 0.8389, batch_loss: 0.4167, loss: 0.4453 ||:  42%|####2     | 4741/11253 [07:46<24:16,  4.47it/s]
2022-03-19 23:48:25,185 - INFO - tqdm - f1: 0.7739, accuracy: 0.8392, batch_loss: 0.4218, loss: 0.4447 ||:  43%|####3     | 4847/11253 [07:56<24:22,  4.38it/s]
2022-03-19 23:48:35,577 - INFO - tqdm - f1: 0.7743, accuracy: 0.8394, batch_loss: 0.2929, loss: 0.4436 ||:  44%|####4     | 4953/11253 [08:07<21:48,  4.81it/s]
2022-03-19 23:48:46,300 - INFO - tqdm - f1: 0.7747, accuracy: 0.8396, batch_loss: 0.4186, loss: 0.4432 ||:  45%|####4     | 5063/11253 [08:17<23:05,  4.47it/s]
2022-03-19 23:48:56,689 - INFO - tqdm - f1: 0.7754, accuracy: 0.8402, batch_loss: 0.6071, loss: 0.4415 ||:  46%|####5     | 5169/11253 [08:28<22:24,  4.53it/s]
2022-03-19 23:49:07,217 - INFO - tqdm - f1: 0.7758, accuracy: 0.8406, batch_loss: 0.7272, loss: 0.4408 ||:  47%|####6     | 5277/11253 [08:38<22:42,  4.39it/s]
2022-03-19 23:49:17,684 - INFO - tqdm - f1: 0.7762, accuracy: 0.8407, batch_loss: 0.4099, loss: 0.4403 ||:  48%|####7     | 5385/11253 [08:49<21:20,  4.58it/s]
2022-03-19 23:49:28,393 - INFO - tqdm - f1: 0.7769, accuracy: 0.8411, batch_loss: 0.7538, loss: 0.4388 ||:  49%|####8     | 5501/11253 [08:59<20:28,  4.68it/s]
2022-03-19 23:49:39,001 - INFO - tqdm - f1: 0.7770, accuracy: 0.8411, batch_loss: 0.5079, loss: 0.4390 ||:  50%|####9     | 5609/11253 [09:10<20:32,  4.58it/s]
2022-03-19 23:49:49,707 - INFO - tqdm - f1: 0.7777, accuracy: 0.8416, batch_loss: 0.0576, loss: 0.4380 ||:  51%|#####     | 5721/11253 [09:21<20:44,  4.44it/s]
2022-03-19 23:50:00,207 - INFO - tqdm - f1: 0.7784, accuracy: 0.8420, batch_loss: 0.3334, loss: 0.4371 ||:  52%|#####1    | 5831/11253 [09:31<19:52,  4.55it/s]
2022-03-19 23:50:11,102 - INFO - tqdm - f1: 0.7788, accuracy: 0.8421, batch_loss: 0.2603, loss: 0.4366 ||:  53%|#####2    | 5941/11253 [09:42<20:22,  4.34it/s]
2022-03-19 23:50:21,703 - INFO - tqdm - f1: 0.7791, accuracy: 0.8423, batch_loss: 0.4485, loss: 0.4359 ||:  54%|#####3    | 6049/11253 [09:53<18:48,  4.61it/s]
2022-03-19 23:50:32,458 - INFO - tqdm - f1: 0.7791, accuracy: 0.8424, batch_loss: 0.6380, loss: 0.4357 ||:  55%|#####4    | 6159/11253 [10:04<19:14,  4.41it/s]
2022-03-19 23:50:43,030 - INFO - tqdm - f1: 0.7799, accuracy: 0.8430, batch_loss: 0.1131, loss: 0.4340 ||:  56%|#####5    | 6267/11253 [10:14<18:45,  4.43it/s]
2022-03-19 23:50:53,405 - INFO - tqdm - f1: 0.7804, accuracy: 0.8433, batch_loss: 0.1421, loss: 0.4333 ||:  57%|#####6    | 6373/11253 [10:24<18:39,  4.36it/s]
2022-03-19 23:51:04,141 - INFO - tqdm - f1: 0.7807, accuracy: 0.8436, batch_loss: 0.7236, loss: 0.4324 ||:  58%|#####7    | 6483/11253 [10:35<17:49,  4.46it/s]
2022-03-19 23:51:14,510 - INFO - tqdm - f1: 0.7814, accuracy: 0.8440, batch_loss: 0.4187, loss: 0.4315 ||:  59%|#####8    | 6591/11253 [10:46<17:25,  4.46it/s]
2022-03-19 23:51:24,989 - INFO - tqdm - f1: 0.7816, accuracy: 0.8441, batch_loss: 0.3194, loss: 0.4311 ||:  60%|#####9    | 6699/11253 [10:56<16:39,  4.55it/s]
2022-03-19 23:51:35,405 - INFO - tqdm - f1: 0.7817, accuracy: 0.8442, batch_loss: 0.2553, loss: 0.4304 ||:  60%|######    | 6805/11253 [11:06<16:13,  4.57it/s]
2022-03-19 23:51:46,002 - INFO - tqdm - f1: 0.7818, accuracy: 0.8444, batch_loss: 0.3908, loss: 0.4298 ||:  61%|######1   | 6913/11253 [11:17<16:29,  4.39it/s]
2022-03-19 23:51:56,489 - INFO - tqdm - f1: 0.7820, accuracy: 0.8446, batch_loss: 0.1010, loss: 0.4289 ||:  62%|######2   | 7019/11253 [11:28<15:36,  4.52it/s]
2022-03-19 23:52:07,069 - INFO - tqdm - f1: 0.7818, accuracy: 0.8447, batch_loss: 0.5851, loss: 0.4286 ||:  63%|######3   | 7129/11253 [11:38<15:19,  4.48it/s]
2022-03-19 23:52:17,374 - INFO - tqdm - f1: 0.7819, accuracy: 0.8450, batch_loss: 0.2812, loss: 0.4278 ||:  64%|######4   | 7233/11253 [11:48<15:10,  4.42it/s]
2022-03-19 23:52:27,912 - INFO - tqdm - f1: 0.7824, accuracy: 0.8453, batch_loss: 0.3812, loss: 0.4270 ||:  65%|######5   | 7341/11253 [11:59<14:50,  4.39it/s]
2022-03-19 23:52:38,359 - INFO - tqdm - f1: 0.7824, accuracy: 0.8454, batch_loss: 0.2987, loss: 0.4268 ||:  66%|######6   | 7449/11253 [12:09<14:01,  4.52it/s]
2022-03-19 23:52:48,799 - INFO - tqdm - f1: 0.7827, accuracy: 0.8456, batch_loss: 0.4142, loss: 0.4256 ||:  67%|######7   | 7555/11253 [12:20<13:58,  4.41it/s]
2022-03-19 23:52:59,409 - INFO - tqdm - f1: 0.7825, accuracy: 0.8455, batch_loss: 0.1923, loss: 0.4256 ||:  68%|######8   | 7663/11253 [12:30<13:24,  4.46it/s]
2022-03-19 23:53:10,175 - INFO - tqdm - f1: 0.7826, accuracy: 0.8457, batch_loss: 0.2853, loss: 0.4253 ||:  69%|######9   | 7775/11253 [12:41<12:39,  4.58it/s]
2022-03-19 23:53:20,705 - INFO - tqdm - f1: 0.7828, accuracy: 0.8458, batch_loss: 0.5930, loss: 0.4248 ||:  70%|#######   | 7885/11253 [12:52<12:21,  4.54it/s]
2022-03-19 23:53:31,269 - INFO - tqdm - f1: 0.7833, accuracy: 0.8461, batch_loss: 0.4217, loss: 0.4242 ||:  71%|#######1  | 7995/11253 [13:02<12:16,  4.42it/s]
2022-03-19 23:53:41,824 - INFO - tqdm - f1: 0.7836, accuracy: 0.8464, batch_loss: 0.2649, loss: 0.4233 ||:  72%|#######2  | 8105/11253 [13:13<11:29,  4.56it/s]
2022-03-19 23:53:52,378 - INFO - tqdm - f1: 0.7840, accuracy: 0.8465, batch_loss: 0.2824, loss: 0.4228 ||:  73%|#######3  | 8215/11253 [13:23<10:42,  4.73it/s]
2022-03-19 23:54:02,998 - INFO - tqdm - f1: 0.7841, accuracy: 0.8468, batch_loss: 0.1099, loss: 0.4219 ||:  74%|#######3  | 8325/11253 [13:34<11:03,  4.41it/s]
2022-03-19 23:54:13,562 - INFO - tqdm - f1: 0.7842, accuracy: 0.8468, batch_loss: 0.3178, loss: 0.4216 ||:  75%|#######4  | 8433/11253 [13:45<10:12,  4.61it/s]
2022-03-19 23:54:24,236 - INFO - tqdm - f1: 0.7845, accuracy: 0.8471, batch_loss: 0.3339, loss: 0.4212 ||:  76%|#######5  | 8543/11253 [13:55<10:10,  4.44it/s]
2022-03-19 23:54:34,774 - INFO - tqdm - f1: 0.7844, accuracy: 0.8471, batch_loss: 0.3061, loss: 0.4214 ||:  77%|#######6  | 8651/11253 [14:06<09:40,  4.48it/s]
2022-03-19 23:54:45,276 - INFO - tqdm - f1: 0.7849, accuracy: 0.8474, batch_loss: 0.2482, loss: 0.4208 ||:  78%|#######7  | 8757/11253 [14:16<09:26,  4.41it/s]
2022-03-19 23:54:55,666 - INFO - tqdm - f1: 0.7854, accuracy: 0.8477, batch_loss: 0.2718, loss: 0.4202 ||:  79%|#######8  | 8861/11253 [14:27<08:53,  4.48it/s]
2022-03-19 23:55:06,400 - INFO - tqdm - f1: 0.7857, accuracy: 0.8478, batch_loss: 0.2652, loss: 0.4196 ||:  80%|#######9  | 8971/11253 [14:37<08:37,  4.41it/s]
2022-03-19 23:55:16,943 - INFO - tqdm - f1: 0.7857, accuracy: 0.8479, batch_loss: 0.2794, loss: 0.4191 ||:  81%|########  | 9077/11253 [14:48<08:13,  4.41it/s]
2022-03-19 23:55:27,664 - INFO - tqdm - f1: 0.7858, accuracy: 0.8481, batch_loss: 0.4857, loss: 0.4186 ||:  82%|########1 | 9183/11253 [14:59<07:40,  4.50it/s]
2022-03-19 23:55:38,439 - INFO - tqdm - f1: 0.7860, accuracy: 0.8482, batch_loss: 0.5892, loss: 0.4181 ||:  83%|########2 | 9293/11253 [15:09<07:22,  4.42it/s]
2022-03-19 23:55:48,936 - INFO - tqdm - f1: 0.7863, accuracy: 0.8484, batch_loss: 0.2138, loss: 0.4177 ||:  84%|########3 | 9401/11253 [15:20<06:52,  4.49it/s]
2022-03-19 23:55:59,697 - INFO - tqdm - f1: 0.7864, accuracy: 0.8484, batch_loss: 0.2772, loss: 0.4176 ||:  85%|########4 | 9513/11253 [15:31<06:25,  4.52it/s]
2022-03-19 23:56:10,064 - INFO - tqdm - f1: 0.7867, accuracy: 0.8486, batch_loss: 0.2249, loss: 0.4171 ||:  85%|########5 | 9621/11253 [15:41<05:52,  4.63it/s]
2022-03-19 23:56:20,545 - INFO - tqdm - f1: 0.7871, accuracy: 0.8488, batch_loss: 0.2156, loss: 0.4168 ||:  86%|########6 | 9731/11253 [15:52<05:29,  4.61it/s]
2022-03-19 23:56:31,279 - INFO - tqdm - f1: 0.7873, accuracy: 0.8489, batch_loss: 0.1175, loss: 0.4166 ||:  87%|########7 | 9845/11253 [16:02<05:07,  4.58it/s]
2022-03-19 23:56:41,391 - INFO - tqdm - f1: 0.7875, accuracy: 0.8491, batch_loss: 0.5931, loss: 0.4160 ||:  88%|########8 | 9951/11253 [16:12<04:40,  4.64it/s]
2022-03-19 23:56:51,848 - INFO - tqdm - f1: 0.7875, accuracy: 0.8492, batch_loss: 0.3838, loss: 0.4159 ||:  89%|########9 | 10057/11253 [16:23<04:32,  4.39it/s]
2022-03-19 23:57:02,533 - INFO - tqdm - f1: 0.7877, accuracy: 0.8494, batch_loss: 0.1803, loss: 0.4154 ||:  90%|######### | 10165/11253 [16:34<03:58,  4.56it/s]
2022-03-19 23:57:13,032 - INFO - tqdm - f1: 0.7880, accuracy: 0.8496, batch_loss: 0.4102, loss: 0.4150 ||:  91%|#########1| 10271/11253 [16:44<03:40,  4.46it/s]
2022-03-19 23:57:23,437 - INFO - tqdm - f1: 0.7882, accuracy: 0.8497, batch_loss: 0.1570, loss: 0.4145 ||:  92%|#########2| 10375/11253 [16:54<03:01,  4.84it/s]
2022-03-19 23:57:33,873 - INFO - tqdm - f1: 0.7881, accuracy: 0.8498, batch_loss: 0.3892, loss: 0.4143 ||:  93%|#########3| 10479/11253 [17:05<02:56,  4.39it/s]
2022-03-19 23:57:44,583 - INFO - tqdm - f1: 0.7882, accuracy: 0.8499, batch_loss: 0.2478, loss: 0.4140 ||:  94%|#########4| 10591/11253 [17:16<02:26,  4.53it/s]
2022-03-19 23:57:55,171 - INFO - tqdm - f1: 0.7882, accuracy: 0.8499, batch_loss: 0.1636, loss: 0.4143 ||:  95%|#########5| 10703/11253 [17:26<02:00,  4.57it/s]
2022-03-19 23:58:06,040 - INFO - tqdm - f1: 0.7887, accuracy: 0.8501, batch_loss: 0.5122, loss: 0.4136 ||:  96%|#########6| 10813/11253 [17:37<01:40,  4.40it/s]
2022-03-19 23:58:16,618 - INFO - tqdm - f1: 0.7888, accuracy: 0.8503, batch_loss: 0.5310, loss: 0.4131 ||:  97%|#########7| 10923/11253 [17:48<01:12,  4.52it/s]
2022-03-19 23:58:27,797 - INFO - tqdm - f1: 0.7889, accuracy: 0.8504, batch_loss: 0.1813, loss: 0.4127 ||:  98%|#########8| 11031/11253 [17:59<00:51,  4.28it/s]
2022-03-19 23:58:38,117 - INFO - tqdm - f1: 0.7891, accuracy: 0.8506, batch_loss: 0.1771, loss: 0.4123 ||:  99%|#########8| 11135/11253 [18:09<00:27,  4.33it/s]
2022-03-19 23:58:43,567 - INFO - tqdm - f1: 0.7893, accuracy: 0.8507, batch_loss: 0.2259, loss: 0.4120 ||: 100%|#########9| 11197/11253 [18:15<00:04, 13.86it/s]
2022-03-19 23:58:43,699 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.4690, loss: 0.4120 ||: 100%|#########9| 11199/11253 [18:15<00:03, 14.24it/s]
2022-03-19 23:58:43,853 - INFO - tqdm - f1: 0.7894, accuracy: 0.8507, batch_loss: 0.6888, loss: 0.4120 ||: 100%|#########9| 11201/11253 [18:15<00:03, 13.84it/s]
2022-03-19 23:58:43,993 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.1522, loss: 0.4120 ||: 100%|#########9| 11203/11253 [18:15<00:03, 13.97it/s]
2022-03-19 23:58:45,177 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.2036, loss: 0.4120 ||: 100%|#########9| 11205/11253 [18:16<00:10,  4.39it/s]
2022-03-19 23:58:45,319 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.1790, loss: 0.4120 ||: 100%|#########9| 11207/11253 [18:16<00:08,  5.53it/s]
2022-03-19 23:58:45,452 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.2553, loss: 0.4119 ||: 100%|#########9| 11209/11253 [18:17<00:06,  6.83it/s]
2022-03-19 23:58:45,589 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.3998, loss: 0.4119 ||: 100%|#########9| 11211/11253 [18:17<00:05,  8.13it/s]
2022-03-19 23:58:45,726 - INFO - tqdm - f1: 0.7893, accuracy: 0.8507, batch_loss: 0.6672, loss: 0.4120 ||: 100%|#########9| 11213/11253 [18:17<00:04,  9.37it/s]
2022-03-19 23:58:45,874 - INFO - tqdm - f1: 0.7893, accuracy: 0.8507, batch_loss: 0.5312, loss: 0.4120 ||: 100%|#########9| 11215/11253 [18:17<00:03, 10.32it/s]
2022-03-19 23:58:46,036 - INFO - tqdm - f1: 0.7893, accuracy: 0.8507, batch_loss: 0.4516, loss: 0.4120 ||: 100%|#########9| 11217/11253 [18:17<00:03, 10.86it/s]
2022-03-19 23:58:46,168 - INFO - tqdm - f1: 0.7893, accuracy: 0.8507, batch_loss: 0.2787, loss: 0.4120 ||: 100%|#########9| 11219/11253 [18:17<00:02, 11.86it/s]
2022-03-19 23:58:46,305 - INFO - tqdm - f1: 0.7893, accuracy: 0.8507, batch_loss: 0.3730, loss: 0.4120 ||: 100%|#########9| 11221/11253 [18:17<00:02, 12.58it/s]
2022-03-19 23:58:46,438 - INFO - tqdm - f1: 0.7893, accuracy: 0.8507, batch_loss: 0.3501, loss: 0.4120 ||: 100%|#########9| 11223/11253 [18:17<00:02, 13.21it/s]
2022-03-19 23:58:46,572 - INFO - tqdm - f1: 0.7893, accuracy: 0.8508, batch_loss: 0.1622, loss: 0.4119 ||: 100%|#########9| 11225/11253 [18:18<00:02, 13.69it/s]
2022-03-19 23:58:46,706 - INFO - tqdm - f1: 0.7893, accuracy: 0.8508, batch_loss: 0.1051, loss: 0.4119 ||: 100%|#########9| 11227/11253 [18:18<00:01, 14.04it/s]
2022-03-19 23:58:46,860 - INFO - tqdm - f1: 0.7893, accuracy: 0.8508, batch_loss: 0.2688, loss: 0.4120 ||: 100%|#########9| 11229/11253 [18:18<00:01, 13.71it/s]
2022-03-19 23:58:47,012 - INFO - tqdm - f1: 0.7893, accuracy: 0.8508, batch_loss: 0.4655, loss: 0.4120 ||: 100%|#########9| 11231/11253 [18:18<00:01, 13.54it/s]
2022-03-19 23:58:47,155 - INFO - tqdm - f1: 0.7893, accuracy: 0.8508, batch_loss: 0.2305, loss: 0.4119 ||: 100%|#########9| 11233/11253 [18:18<00:01, 13.66it/s]
2022-03-19 23:58:47,289 - INFO - tqdm - f1: 0.7893, accuracy: 0.8508, batch_loss: 0.2498, loss: 0.4119 ||: 100%|#########9| 11235/11253 [18:18<00:01, 14.03it/s]
2022-03-19 23:58:47,416 - INFO - tqdm - f1: 0.7893, accuracy: 0.8508, batch_loss: 0.0950, loss: 0.4119 ||: 100%|#########9| 11237/11253 [18:18<00:01, 14.49it/s]
2022-03-19 23:58:47,551 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.4524, loss: 0.4119 ||: 100%|#########9| 11239/11253 [18:19<00:00, 14.58it/s]
2022-03-19 23:58:48,678 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.5946, loss: 0.4119 ||: 100%|#########9| 11241/11253 [18:20<00:02,  4.61it/s]
2022-03-19 23:58:48,818 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.2814, loss: 0.4118 ||: 100%|#########9| 11243/11253 [18:20<00:01,  5.78it/s]
2022-03-19 23:58:48,956 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.1469, loss: 0.4118 ||: 100%|#########9| 11245/11253 [18:20<00:01,  7.06it/s]
2022-03-19 23:58:49,089 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.5093, loss: 0.4118 ||: 100%|#########9| 11247/11253 [18:20<00:00,  8.39it/s]
2022-03-19 23:58:49,233 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.7933, loss: 0.4118 ||: 100%|#########9| 11249/11253 [18:20<00:00,  9.52it/s]
2022-03-19 23:58:49,370 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.2704, loss: 0.4118 ||: 100%|#########9| 11251/11253 [18:20<00:00, 10.63it/s]
2022-03-19 23:58:49,509 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.0890, loss: 0.4118 ||: 100%|##########| 11253/11253 [18:21<00:00, 11.54it/s]
2022-03-19 23:58:49,572 - INFO - tqdm - f1: 0.7894, accuracy: 0.8508, batch_loss: 0.0890, loss: 0.4118 ||: 100%|##########| 11253/11253 [18:21<00:00, 10.22it/s]
2022-03-19 23:58:49,578 - INFO - allennlp.training.trainer - Validating
2022-03-19 23:58:49,580 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-19 23:58:49,622 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-19 23:58:49,623 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-19 23:58:59,690 - INFO - tqdm - f1: 0.8255, accuracy: 0.8783, batch_loss: 0.4737, loss: 0.3499 ||:  14%|#3        | 262/1889 [00:10<02:00, 13.52it/s]
2022-03-19 23:59:10,275 - INFO - tqdm - f1: 0.8244, accuracy: 0.8791, batch_loss: 0.5076, loss: 0.3494 ||:  29%|##8       | 546/1889 [00:20<01:55, 11.62it/s]
2022-03-19 23:59:21,043 - INFO - tqdm - f1: 0.8243, accuracy: 0.8795, batch_loss: 0.2835, loss: 0.3424 ||:  45%|####4     | 842/1889 [00:31<01:29, 11.76it/s]
2022-03-19 23:59:31,416 - INFO - tqdm - f1: 0.8240, accuracy: 0.8796, batch_loss: 0.3154, loss: 0.3438 ||:  60%|#####9    | 1131/1889 [00:41<01:06, 11.47it/s]
2022-03-19 23:59:41,742 - INFO - tqdm - f1: 0.8201, accuracy: 0.8770, batch_loss: 0.2319, loss: 0.3478 ||:  75%|#######5  | 1420/1889 [00:52<00:37, 12.45it/s]
2022-03-19 23:59:52,486 - INFO - tqdm - f1: 0.8172, accuracy: 0.8747, batch_loss: 0.6001, loss: 0.3511 ||:  91%|#########1| 1721/1889 [01:02<00:14, 11.43it/s]
2022-03-19 23:59:57,632 - INFO - tqdm - f1: 0.8168, accuracy: 0.8744, batch_loss: 0.2190, loss: 0.3517 ||: 100%|#########9| 1881/1889 [01:08<00:00, 35.63it/s]
2022-03-19 23:59:57,738 - INFO - tqdm - f1: 0.8169, accuracy: 0.8745, batch_loss: 0.3025, loss: 0.3515 ||: 100%|#########9| 1885/1889 [01:08<00:00, 36.13it/s]
2022-03-19 23:59:57,846 - INFO - tqdm - f1: 0.8169, accuracy: 0.8744, batch_loss: 0.3755, loss: 0.3514 ||: 100%|##########| 1889/1889 [01:08<00:00, 27.67it/s]
2022-03-19 23:59:57,860 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct-20k_base/best.th'.
2022-03-20 00:00:00,202 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 00:00:00,204 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.851  |     0.874
2022-03-20 00:00:00,205 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.789  |     0.817
2022-03-20 00:00:00,207 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 00:00:00,212 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.412  |     0.351
2022-03-20 00:00:00,213 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8464.277  |       N/A
2022-03-20 00:00:00,214 - INFO - allennlp.training.trainer - Epoch duration: 0:19:31.770788
2022-03-20 00:00:00,217 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:55:45
2022-03-20 00:00:00,218 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-20 00:00:00,219 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-20 00:00:00,221 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 00:00:00,223 - INFO - allennlp.training.trainer - Training
2022-03-20 00:00:00,225 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-20 00:00:10,280 - INFO - tqdm - f1: 0.8210, accuracy: 0.8919, batch_loss: 0.4677, loss: 0.3089 ||:   1%|          | 85/11253 [00:10<27:05,  6.87it/s]
2022-03-20 00:00:20,375 - INFO - tqdm - f1: 0.8226, accuracy: 0.8793, batch_loss: 0.4063, loss: 0.3368 ||:   2%|1         | 187/11253 [00:20<32:58,  5.59it/s]
2022-03-20 00:00:30,603 - INFO - tqdm - f1: 0.8252, accuracy: 0.8786, batch_loss: 0.0988, loss: 0.3438 ||:   3%|2         | 293/11253 [00:30<40:20,  4.53it/s]
2022-03-20 00:00:41,100 - INFO - tqdm - f1: 0.8281, accuracy: 0.8798, batch_loss: 0.2784, loss: 0.3444 ||:   4%|3         | 401/11253 [00:40<41:27,  4.36it/s]
2022-03-20 00:00:51,604 - INFO - tqdm - f1: 0.8250, accuracy: 0.8775, batch_loss: 0.1488, loss: 0.3469 ||:   5%|4         | 509/11253 [00:51<39:46,  4.50it/s]
2022-03-20 00:01:02,217 - INFO - tqdm - f1: 0.8253, accuracy: 0.8784, batch_loss: 0.7727, loss: 0.3425 ||:   5%|5         | 617/11253 [01:01<40:23,  4.39it/s]
2022-03-20 00:01:12,708 - INFO - tqdm - f1: 0.8238, accuracy: 0.8778, batch_loss: 0.1504, loss: 0.3445 ||:   6%|6         | 721/11253 [01:12<39:27,  4.45it/s]
2022-03-20 00:01:23,057 - INFO - tqdm - f1: 0.8224, accuracy: 0.8766, batch_loss: 0.1138, loss: 0.3456 ||:   7%|7         | 823/11253 [01:22<40:05,  4.34it/s]
2022-03-20 00:01:33,461 - INFO - tqdm - f1: 0.8220, accuracy: 0.8761, batch_loss: 0.2777, loss: 0.3458 ||:   8%|8         | 925/11253 [01:33<38:58,  4.42it/s]
2022-03-20 00:01:43,818 - INFO - tqdm - f1: 0.8217, accuracy: 0.8764, batch_loss: 0.1109, loss: 0.3450 ||:   9%|9         | 1027/11253 [01:43<37:56,  4.49it/s]
2022-03-20 00:01:54,209 - INFO - tqdm - f1: 0.8216, accuracy: 0.8773, batch_loss: 0.4351, loss: 0.3432 ||:  10%|#         | 1129/11253 [01:53<38:08,  4.42it/s]
2022-03-20 00:02:05,155 - INFO - tqdm - f1: 0.8189, accuracy: 0.8760, batch_loss: 0.1121, loss: 0.3446 ||:  11%|#1        | 1239/11253 [02:04<36:32,  4.57it/s]
2022-03-20 00:02:15,193 - INFO - tqdm - f1: 0.8199, accuracy: 0.8763, batch_loss: 0.0909, loss: 0.3436 ||:  12%|#1        | 1347/11253 [02:14<12:08, 13.60it/s]
2022-03-20 00:02:25,455 - INFO - tqdm - f1: 0.8192, accuracy: 0.8761, batch_loss: 0.3637, loss: 0.3431 ||:  13%|#2        | 1439/11253 [02:25<36:10,  4.52it/s]
2022-03-20 00:02:35,748 - INFO - tqdm - f1: 0.8196, accuracy: 0.8767, batch_loss: 0.1938, loss: 0.3411 ||:  14%|#3        | 1545/11253 [02:35<35:50,  4.51it/s]
2022-03-20 00:02:46,154 - INFO - tqdm - f1: 0.8205, accuracy: 0.8774, batch_loss: 0.2116, loss: 0.3394 ||:  15%|#4        | 1649/11253 [02:45<35:20,  4.53it/s]
2022-03-20 00:02:56,621 - INFO - tqdm - f1: 0.8200, accuracy: 0.8776, batch_loss: 0.2136, loss: 0.3394 ||:  16%|#5        | 1757/11253 [02:56<35:20,  4.48it/s]
2022-03-20 00:03:07,538 - INFO - tqdm - f1: 0.8213, accuracy: 0.8781, batch_loss: 0.6787, loss: 0.3388 ||:  17%|#6        | 1871/11253 [03:07<35:13,  4.44it/s]
2022-03-20 00:03:17,905 - INFO - tqdm - f1: 0.8214, accuracy: 0.8780, batch_loss: 0.3461, loss: 0.3393 ||:  18%|#7        | 1977/11253 [03:17<33:35,  4.60it/s]
2022-03-20 00:03:28,494 - INFO - tqdm - f1: 0.8218, accuracy: 0.8782, batch_loss: 0.3153, loss: 0.3393 ||:  19%|#8        | 2085/11253 [03:28<35:00,  4.36it/s]
2022-03-20 00:03:38,616 - INFO - tqdm - f1: 0.8206, accuracy: 0.8769, batch_loss: 0.2257, loss: 0.3419 ||:  20%|#9        | 2203/11253 [03:38<10:14, 14.72it/s]
2022-03-20 00:03:48,755 - INFO - tqdm - f1: 0.8215, accuracy: 0.8772, batch_loss: 0.0710, loss: 0.3412 ||:  20%|##        | 2305/11253 [03:48<11:01, 13.52it/s]
2022-03-20 00:03:58,769 - INFO - tqdm - f1: 0.8217, accuracy: 0.8772, batch_loss: 0.1906, loss: 0.3410 ||:  21%|##1       | 2407/11253 [03:58<13:47, 10.69it/s]
2022-03-20 00:04:08,776 - INFO - tqdm - f1: 0.8215, accuracy: 0.8770, batch_loss: 0.0871, loss: 0.3415 ||:  22%|##2       | 2507/11253 [04:08<21:11,  6.88it/s]
2022-03-20 00:04:19,109 - INFO - tqdm - f1: 0.8213, accuracy: 0.8768, batch_loss: 0.5334, loss: 0.3418 ||:  23%|##3       | 2613/11253 [04:18<31:54,  4.51it/s]
2022-03-20 00:04:29,646 - INFO - tqdm - f1: 0.8212, accuracy: 0.8767, batch_loss: 0.6309, loss: 0.3419 ||:  24%|##4       | 2723/11253 [04:29<31:19,  4.54it/s]
2022-03-20 00:04:39,687 - INFO - tqdm - f1: 0.8206, accuracy: 0.8764, batch_loss: 0.2429, loss: 0.3429 ||:  25%|##5       | 2835/11253 [04:39<09:08, 15.35it/s]
2022-03-20 00:04:49,742 - INFO - tqdm - f1: 0.8208, accuracy: 0.8765, batch_loss: 0.1644, loss: 0.3431 ||:  26%|##6       | 2937/11253 [04:49<10:05, 13.74it/s]
2022-03-20 00:04:59,797 - INFO - tqdm - f1: 0.8208, accuracy: 0.8763, batch_loss: 0.3348, loss: 0.3433 ||:  27%|##7       | 3041/11253 [04:59<09:15, 14.78it/s]
2022-03-20 00:05:09,847 - INFO - tqdm - f1: 0.8203, accuracy: 0.8761, batch_loss: 0.7539, loss: 0.3438 ||:  28%|##7       | 3145/11253 [05:09<09:22, 14.40it/s]
2022-03-20 00:05:19,913 - INFO - tqdm - f1: 0.8201, accuracy: 0.8761, batch_loss: 0.3584, loss: 0.3438 ||:  29%|##8       | 3249/11253 [05:19<09:51, 13.54it/s]
2022-03-20 00:05:29,978 - INFO - tqdm - f1: 0.8197, accuracy: 0.8761, batch_loss: 0.1662, loss: 0.3442 ||:  30%|##9       | 3351/11253 [05:29<11:02, 11.92it/s]
2022-03-20 00:05:40,037 - INFO - tqdm - f1: 0.8198, accuracy: 0.8762, batch_loss: 0.2555, loss: 0.3437 ||:  31%|###       | 3455/11253 [05:39<18:36,  6.98it/s]
2022-03-20 00:05:50,406 - INFO - tqdm - f1: 0.8200, accuracy: 0.8764, batch_loss: 0.2038, loss: 0.3427 ||:  32%|###1      | 3561/11253 [05:50<28:50,  4.44it/s]
2022-03-20 00:06:01,028 - INFO - tqdm - f1: 0.8198, accuracy: 0.8760, batch_loss: 0.3418, loss: 0.3437 ||:  33%|###2      | 3671/11253 [06:00<28:28,  4.44it/s]
2022-03-20 00:06:11,458 - INFO - tqdm - f1: 0.8198, accuracy: 0.8761, batch_loss: 0.7740, loss: 0.3434 ||:  34%|###3      | 3779/11253 [06:11<27:22,  4.55it/s]
2022-03-20 00:06:22,301 - INFO - tqdm - f1: 0.8193, accuracy: 0.8762, batch_loss: 0.0836, loss: 0.3428 ||:  35%|###4      | 3889/11253 [06:22<27:35,  4.45it/s]
2022-03-20 00:06:33,423 - INFO - tqdm - f1: 0.8197, accuracy: 0.8765, batch_loss: 0.4266, loss: 0.3420 ||:  36%|###5      | 4003/11253 [06:33<26:20,  4.59it/s]
2022-03-20 00:06:43,441 - INFO - tqdm - f1: 0.8197, accuracy: 0.8765, batch_loss: 0.1924, loss: 0.3422 ||:  37%|###6      | 4115/11253 [06:43<08:27, 14.07it/s]
2022-03-20 00:06:53,484 - INFO - tqdm - f1: 0.8191, accuracy: 0.8761, batch_loss: 0.0224, loss: 0.3432 ||:  37%|###7      | 4217/11253 [06:53<08:13, 14.24it/s]
2022-03-20 00:07:03,554 - INFO - tqdm - f1: 0.8195, accuracy: 0.8764, batch_loss: 0.6162, loss: 0.3424 ||:  38%|###8      | 4319/11253 [07:03<09:30, 12.14it/s]
2022-03-20 00:07:13,638 - INFO - tqdm - f1: 0.8194, accuracy: 0.8765, batch_loss: 0.3204, loss: 0.3423 ||:  39%|###9      | 4419/11253 [07:13<20:10,  5.65it/s]
2022-03-20 00:07:24,183 - INFO - tqdm - f1: 0.8197, accuracy: 0.8767, batch_loss: 0.3792, loss: 0.3418 ||:  40%|####      | 4527/11253 [07:23<25:11,  4.45it/s]
2022-03-20 00:07:34,834 - INFO - tqdm - f1: 0.8193, accuracy: 0.8764, batch_loss: 0.1209, loss: 0.3425 ||:  41%|####1     | 4635/11253 [07:34<23:53,  4.62it/s]
2022-03-20 00:07:45,490 - INFO - tqdm - f1: 0.8194, accuracy: 0.8764, batch_loss: 0.2168, loss: 0.3423 ||:  42%|####2     | 4743/11253 [07:45<23:26,  4.63it/s]
2022-03-20 00:07:56,471 - INFO - tqdm - f1: 0.8193, accuracy: 0.8765, batch_loss: 0.2345, loss: 0.3421 ||:  43%|####3     | 4855/11253 [07:56<24:02,  4.43it/s]
2022-03-20 00:08:06,945 - INFO - tqdm - f1: 0.8192, accuracy: 0.8764, batch_loss: 1.1919, loss: 0.3423 ||:  44%|####4     | 4963/11253 [08:06<22:46,  4.60it/s]
2022-03-20 00:08:17,570 - INFO - tqdm - f1: 0.8190, accuracy: 0.8763, batch_loss: 0.0965, loss: 0.3422 ||:  45%|####5     | 5073/11253 [08:17<23:01,  4.47it/s]
2022-03-20 00:08:28,052 - INFO - tqdm - f1: 0.8191, accuracy: 0.8764, batch_loss: 0.3381, loss: 0.3418 ||:  46%|####6     | 5183/11253 [08:27<21:38,  4.67it/s]
2022-03-20 00:08:38,298 - INFO - tqdm - f1: 0.8187, accuracy: 0.8762, batch_loss: 0.1801, loss: 0.3425 ||:  47%|####7     | 5289/11253 [08:38<21:55,  4.53it/s]
2022-03-20 00:08:49,112 - INFO - tqdm - f1: 0.8188, accuracy: 0.8762, batch_loss: 0.3828, loss: 0.3428 ||:  48%|####8     | 5403/11253 [08:48<21:14,  4.59it/s]
2022-03-20 00:08:59,718 - INFO - tqdm - f1: 0.8187, accuracy: 0.8762, batch_loss: 0.4761, loss: 0.3425 ||:  49%|####8     | 5511/11253 [08:59<21:17,  4.50it/s]
2022-03-20 00:09:10,294 - INFO - tqdm - f1: 0.8186, accuracy: 0.8761, batch_loss: 0.4127, loss: 0.3426 ||:  50%|####9     | 5619/11253 [09:10<21:07,  4.44it/s]
2022-03-20 00:09:20,762 - INFO - tqdm - f1: 0.8187, accuracy: 0.8762, batch_loss: 0.4932, loss: 0.3425 ||:  51%|#####     | 5725/11253 [09:20<20:39,  4.46it/s]
2022-03-20 00:09:31,279 - INFO - tqdm - f1: 0.8187, accuracy: 0.8762, batch_loss: 0.1733, loss: 0.3428 ||:  52%|#####1    | 5831/11253 [09:31<19:36,  4.61it/s]
2022-03-20 00:09:41,747 - INFO - tqdm - f1: 0.8183, accuracy: 0.8757, batch_loss: 0.5986, loss: 0.3436 ||:  53%|#####2    | 5937/11253 [09:41<19:52,  4.46it/s]
2022-03-20 00:09:52,225 - INFO - tqdm - f1: 0.8177, accuracy: 0.8755, batch_loss: 0.3008, loss: 0.3439 ||:  54%|#####3    | 6047/11253 [09:51<18:58,  4.57it/s]
2022-03-20 00:10:02,974 - INFO - tqdm - f1: 0.8181, accuracy: 0.8758, batch_loss: 0.3990, loss: 0.3435 ||:  55%|#####4    | 6159/11253 [10:02<18:43,  4.53it/s]
2022-03-20 00:10:13,335 - INFO - tqdm - f1: 0.8181, accuracy: 0.8759, batch_loss: 0.1059, loss: 0.3431 ||:  56%|#####5    | 6267/11253 [10:13<16:49,  4.94it/s]
2022-03-20 00:10:24,025 - INFO - tqdm - f1: 0.8181, accuracy: 0.8759, batch_loss: 0.2583, loss: 0.3431 ||:  57%|#####6    | 6377/11253 [10:23<17:39,  4.60it/s]
2022-03-20 00:10:34,103 - INFO - tqdm - f1: 0.8181, accuracy: 0.8758, batch_loss: 0.4270, loss: 0.3431 ||:  58%|#####7    | 6473/11253 [10:33<07:41, 10.35it/s]
2022-03-20 00:10:44,242 - INFO - tqdm - f1: 0.8178, accuracy: 0.8757, batch_loss: 0.3188, loss: 0.3433 ||:  58%|#####8    | 6573/11253 [10:44<17:46,  4.39it/s]
2022-03-20 00:10:54,338 - INFO - tqdm - f1: 0.8184, accuracy: 0.8759, batch_loss: 0.2609, loss: 0.3430 ||:  59%|#####9    | 6685/11253 [10:54<05:15, 14.50it/s]
2022-03-20 00:11:04,415 - INFO - tqdm - f1: 0.8182, accuracy: 0.8758, batch_loss: 0.1414, loss: 0.3431 ||:  60%|######    | 6785/11253 [11:04<10:10,  7.31it/s]
2022-03-20 00:11:14,878 - INFO - tqdm - f1: 0.8181, accuracy: 0.8757, batch_loss: 0.1755, loss: 0.3433 ||:  61%|######1   | 6893/11253 [11:14<15:42,  4.63it/s]
2022-03-20 00:11:25,956 - INFO - tqdm - f1: 0.8181, accuracy: 0.8758, batch_loss: 0.5113, loss: 0.3430 ||:  62%|######2   | 7011/11253 [11:25<15:20,  4.61it/s]
2022-03-20 00:11:35,995 - INFO - tqdm - f1: 0.8179, accuracy: 0.8758, batch_loss: 0.2562, loss: 0.3429 ||:  63%|######3   | 7119/11253 [11:35<07:16,  9.46it/s]
2022-03-20 00:11:46,015 - INFO - tqdm - f1: 0.8178, accuracy: 0.8758, batch_loss: 0.4821, loss: 0.3429 ||:  64%|######4   | 7221/11253 [11:45<04:55, 13.65it/s]
2022-03-20 00:11:56,148 - INFO - tqdm - f1: 0.8178, accuracy: 0.8757, batch_loss: 0.3307, loss: 0.3434 ||:  65%|######5   | 7321/11253 [11:55<06:06, 10.72it/s]
2022-03-20 00:12:06,219 - INFO - tqdm - f1: 0.8181, accuracy: 0.8757, batch_loss: 0.7205, loss: 0.3433 ||:  66%|######5   | 7419/11253 [12:05<14:15,  4.48it/s]
2022-03-20 00:12:16,296 - INFO - tqdm - f1: 0.8180, accuracy: 0.8757, batch_loss: 0.4581, loss: 0.3439 ||:  67%|######6   | 7531/11253 [12:16<04:31, 13.73it/s]
2022-03-20 00:12:26,424 - INFO - tqdm - f1: 0.8181, accuracy: 0.8757, batch_loss: 0.3202, loss: 0.3441 ||:  68%|######7   | 7647/11253 [12:26<04:05, 14.68it/s]
2022-03-20 00:12:36,503 - INFO - tqdm - f1: 0.8178, accuracy: 0.8754, batch_loss: 0.3732, loss: 0.3446 ||:  69%|######8   | 7741/11253 [12:36<04:50, 12.08it/s]
2022-03-20 00:12:46,519 - INFO - tqdm - f1: 0.8178, accuracy: 0.8754, batch_loss: 0.2751, loss: 0.3448 ||:  70%|######9   | 7845/11253 [12:46<06:48,  8.34it/s]
2022-03-20 00:12:56,679 - INFO - tqdm - f1: 0.8179, accuracy: 0.8756, batch_loss: 0.1886, loss: 0.3448 ||:  71%|#######   | 7949/11253 [12:56<10:37,  5.18it/s]
2022-03-20 00:13:07,237 - INFO - tqdm - f1: 0.8179, accuracy: 0.8756, batch_loss: 0.9002, loss: 0.3448 ||:  72%|#######1  | 8057/11253 [13:07<12:00,  4.43it/s]
2022-03-20 00:13:17,888 - INFO - tqdm - f1: 0.8175, accuracy: 0.8756, batch_loss: 0.1378, loss: 0.3445 ||:  73%|#######2  | 8165/11253 [13:17<11:36,  4.43it/s]
2022-03-20 00:13:28,130 - INFO - tqdm - f1: 0.8173, accuracy: 0.8755, batch_loss: 0.7476, loss: 0.3447 ||:  74%|#######3  | 8273/11253 [13:27<09:05,  5.46it/s]
2022-03-20 00:13:39,226 - INFO - tqdm - f1: 0.8173, accuracy: 0.8755, batch_loss: 0.1455, loss: 0.3449 ||:  75%|#######4  | 8385/11253 [13:38<10:20,  4.62it/s]
2022-03-20 00:13:50,000 - INFO - tqdm - f1: 0.8175, accuracy: 0.8757, batch_loss: 0.0589, loss: 0.3444 ||:  76%|#######5  | 8497/11253 [13:49<09:59,  4.60it/s]
2022-03-20 00:14:00,664 - INFO - tqdm - f1: 0.8175, accuracy: 0.8757, batch_loss: 0.4459, loss: 0.3443 ||:  76%|#######6  | 8605/11253 [14:00<09:30,  4.64it/s]
2022-03-20 00:14:11,285 - INFO - tqdm - f1: 0.8174, accuracy: 0.8756, batch_loss: 0.2003, loss: 0.3443 ||:  77%|#######7  | 8715/11253 [14:11<08:47,  4.81it/s]
2022-03-20 00:14:22,052 - INFO - tqdm - f1: 0.8175, accuracy: 0.8757, batch_loss: 0.3033, loss: 0.3446 ||:  78%|#######8  | 8825/11253 [14:21<08:55,  4.53it/s]
2022-03-20 00:14:32,973 - INFO - tqdm - f1: 0.8175, accuracy: 0.8755, batch_loss: 0.0433, loss: 0.3451 ||:  79%|#######9  | 8937/11253 [14:32<08:28,  4.56it/s]
2022-03-20 00:14:43,606 - INFO - tqdm - f1: 0.8173, accuracy: 0.8754, batch_loss: 0.2114, loss: 0.3451 ||:  80%|########  | 9045/11253 [14:43<08:18,  4.43it/s]
2022-03-20 00:14:54,285 - INFO - tqdm - f1: 0.8171, accuracy: 0.8754, batch_loss: 0.5433, loss: 0.3448 ||:  81%|########1 | 9151/11253 [14:54<07:59,  4.38it/s]
2022-03-20 00:15:05,141 - INFO - tqdm - f1: 0.8172, accuracy: 0.8755, batch_loss: 0.1929, loss: 0.3449 ||:  82%|########2 | 9265/11253 [15:04<06:07,  5.41it/s]
2022-03-20 00:15:16,213 - INFO - tqdm - f1: 0.8171, accuracy: 0.8754, batch_loss: 0.1648, loss: 0.3447 ||:  83%|########3 | 9373/11253 [15:15<07:03,  4.44it/s]
2022-03-20 00:15:27,013 - INFO - tqdm - f1: 0.8172, accuracy: 0.8754, batch_loss: 0.3435, loss: 0.3451 ||:  84%|########4 | 9483/11253 [15:26<06:36,  4.46it/s]
2022-03-20 00:15:37,456 - INFO - tqdm - f1: 0.8172, accuracy: 0.8755, batch_loss: 0.1341, loss: 0.3450 ||:  85%|########5 | 9593/11253 [15:37<05:06,  5.41it/s]
2022-03-20 00:15:48,463 - INFO - tqdm - f1: 0.8175, accuracy: 0.8755, batch_loss: 0.1170, loss: 0.3451 ||:  86%|########6 | 9703/11253 [15:48<05:43,  4.51it/s]
2022-03-20 00:15:59,162 - INFO - tqdm - f1: 0.8175, accuracy: 0.8755, batch_loss: 0.4303, loss: 0.3449 ||:  87%|########7 | 9811/11253 [15:58<04:58,  4.83it/s]
2022-03-20 00:16:09,855 - INFO - tqdm - f1: 0.8175, accuracy: 0.8755, batch_loss: 0.3127, loss: 0.3449 ||:  88%|########8 | 9913/11253 [16:09<04:55,  4.53it/s]
2022-03-20 00:16:20,760 - INFO - tqdm - f1: 0.8174, accuracy: 0.8754, batch_loss: 0.2697, loss: 0.3452 ||:  89%|########9 | 10023/11253 [16:20<04:31,  4.53it/s]
2022-03-20 00:16:31,528 - INFO - tqdm - f1: 0.8175, accuracy: 0.8754, batch_loss: 0.1675, loss: 0.3453 ||:  90%|######### | 10133/11253 [16:31<04:10,  4.47it/s]
2022-03-20 00:16:42,204 - INFO - tqdm - f1: 0.8175, accuracy: 0.8753, batch_loss: 0.2564, loss: 0.3452 ||:  91%|#########1| 10243/11253 [16:41<03:39,  4.59it/s]
2022-03-20 00:16:52,267 - INFO - tqdm - f1: 0.8172, accuracy: 0.8752, batch_loss: 0.4006, loss: 0.3452 ||:  92%|#########1| 10351/11253 [16:52<01:04, 13.88it/s]
2022-03-20 00:17:02,357 - INFO - tqdm - f1: 0.8171, accuracy: 0.8752, batch_loss: 0.0690, loss: 0.3452 ||:  93%|#########2| 10453/11253 [17:02<00:56, 14.13it/s]
2022-03-20 00:17:12,430 - INFO - tqdm - f1: 0.8172, accuracy: 0.8752, batch_loss: 0.0980, loss: 0.3453 ||:  94%|#########3| 10555/11253 [17:12<00:51, 13.47it/s]
2022-03-20 00:17:22,450 - INFO - tqdm - f1: 0.8171, accuracy: 0.8752, batch_loss: 0.3235, loss: 0.3451 ||:  95%|#########4| 10657/11253 [17:22<00:46, 12.69it/s]
2022-03-20 00:17:32,544 - INFO - tqdm - f1: 0.8172, accuracy: 0.8753, batch_loss: 0.1579, loss: 0.3451 ||:  96%|#########5| 10761/11253 [17:32<00:46, 10.49it/s]
2022-03-20 00:17:42,567 - INFO - tqdm - f1: 0.8173, accuracy: 0.8753, batch_loss: 0.4273, loss: 0.3451 ||:  97%|#########6| 10861/11253 [17:42<00:48,  8.08it/s]
2022-03-20 00:17:52,702 - INFO - tqdm - f1: 0.8171, accuracy: 0.8752, batch_loss: 0.5482, loss: 0.3453 ||:  97%|#########7| 10965/11253 [17:52<00:34,  8.27it/s]
2022-03-20 00:18:02,814 - INFO - tqdm - f1: 0.8172, accuracy: 0.8751, batch_loss: 0.3813, loss: 0.3454 ||:  98%|#########8| 11069/11253 [18:02<00:40,  4.49it/s]
2022-03-20 00:18:13,261 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.0167, loss: 0.3451 ||:  99%|#########9| 11177/11253 [18:13<00:15,  4.83it/s]
2022-03-20 00:18:14,676 - INFO - tqdm - f1: 0.8173, accuracy: 0.8752, batch_loss: 0.1243, loss: 0.3451 ||: 100%|#########9| 11197/11253 [18:14<00:04, 13.36it/s]
2022-03-20 00:18:14,836 - INFO - tqdm - f1: 0.8173, accuracy: 0.8752, batch_loss: 0.2885, loss: 0.3452 ||: 100%|#########9| 11199/11253 [18:14<00:04, 13.09it/s]
2022-03-20 00:18:14,975 - INFO - tqdm - f1: 0.8173, accuracy: 0.8752, batch_loss: 0.0922, loss: 0.3451 ||: 100%|#########9| 11201/11253 [18:14<00:03, 13.43it/s]
2022-03-20 00:18:15,106 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.1845, loss: 0.3451 ||: 100%|#########9| 11203/11253 [18:14<00:03, 13.94it/s]
2022-03-20 00:18:15,240 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.3992, loss: 0.3451 ||: 100%|#########9| 11205/11253 [18:15<00:03, 14.23it/s]
2022-03-20 00:18:15,353 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.3941, loss: 0.3451 ||: 100%|#########9| 11207/11253 [18:15<00:03, 15.13it/s]
2022-03-20 00:18:16,273 - INFO - tqdm - f1: 0.8173, accuracy: 0.8752, batch_loss: 0.5390, loss: 0.3452 ||: 100%|#########9| 11209/11253 [18:16<00:08,  5.43it/s]
2022-03-20 00:18:16,622 - INFO - tqdm - f1: 0.8173, accuracy: 0.8752, batch_loss: 0.2820, loss: 0.3452 ||: 100%|#########9| 11211/11253 [18:16<00:07,  5.51it/s]
2022-03-20 00:18:16,775 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.3139, loss: 0.3452 ||: 100%|#########9| 11213/11253 [18:16<00:05,  6.67it/s]
2022-03-20 00:18:16,911 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.1372, loss: 0.3451 ||: 100%|#########9| 11215/11253 [18:16<00:04,  7.98it/s]
2022-03-20 00:18:17,042 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.7400, loss: 0.3452 ||: 100%|#########9| 11217/11253 [18:16<00:03,  9.31it/s]
2022-03-20 00:18:17,191 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.8975, loss: 0.3452 ||: 100%|#########9| 11219/11253 [18:16<00:03, 10.25it/s]
2022-03-20 00:18:17,317 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.2824, loss: 0.3452 ||: 100%|#########9| 11221/11253 [18:17<00:02, 11.47it/s]
2022-03-20 00:18:17,449 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.3804, loss: 0.3452 ||: 100%|#########9| 11223/11253 [18:17<00:02, 12.38it/s]
2022-03-20 00:18:17,581 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.2291, loss: 0.3452 ||: 100%|#########9| 11225/11253 [18:17<00:02, 13.09it/s]
2022-03-20 00:18:17,714 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.3234, loss: 0.3452 ||: 100%|#########9| 11227/11253 [18:17<00:01, 13.63it/s]
2022-03-20 00:18:17,851 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.2706, loss: 0.3452 ||: 100%|#########9| 11229/11253 [18:17<00:01, 13.90it/s]
2022-03-20 00:18:18,016 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.0383, loss: 0.3452 ||: 100%|#########9| 11231/11253 [18:17<00:01, 13.33it/s]
2022-03-20 00:18:18,180 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.3721, loss: 0.3452 ||: 100%|#########9| 11233/11253 [18:17<00:01, 12.96it/s]
2022-03-20 00:18:18,335 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.1830, loss: 0.3451 ||: 100%|#########9| 11235/11253 [18:18<00:01, 12.96it/s]
2022-03-20 00:18:18,465 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.5283, loss: 0.3451 ||: 100%|#########9| 11237/11253 [18:18<00:01, 13.59it/s]
2022-03-20 00:18:18,603 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.2841, loss: 0.3451 ||: 100%|#########9| 11239/11253 [18:18<00:01, 13.85it/s]
2022-03-20 00:18:18,729 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.2313, loss: 0.3451 ||: 100%|#########9| 11241/11253 [18:18<00:00, 14.38it/s]
2022-03-20 00:18:18,862 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.1455, loss: 0.3451 ||: 100%|#########9| 11243/11253 [18:18<00:00, 14.58it/s]
2022-03-20 00:18:19,017 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.0568, loss: 0.3451 ||: 100%|#########9| 11245/11253 [18:18<00:00, 14.03it/s]
2022-03-20 00:18:20,166 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.3333, loss: 0.3451 ||: 100%|#########9| 11247/11253 [18:19<00:01,  4.50it/s]
2022-03-20 00:18:20,312 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.4546, loss: 0.3451 ||: 100%|#########9| 11249/11253 [18:20<00:00,  5.64it/s]
2022-03-20 00:18:20,453 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.2399, loss: 0.3451 ||: 100%|#########9| 11251/11253 [18:20<00:00,  6.88it/s]
2022-03-20 00:18:20,586 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.3809, loss: 0.3451 ||: 100%|##########| 11253/11253 [18:20<00:00,  8.22it/s]
2022-03-20 00:18:20,651 - INFO - tqdm - f1: 0.8174, accuracy: 0.8752, batch_loss: 0.3809, loss: 0.3451 ||: 100%|##########| 11253/11253 [18:20<00:00, 10.23it/s]
2022-03-20 00:18:20,657 - INFO - allennlp.training.trainer - Validating
2022-03-20 00:18:20,659 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-20 00:18:30,713 - INFO - tqdm - f1: 0.8338, accuracy: 0.8864, batch_loss: 0.8403, loss: 0.3391 ||:  14%|#4        | 269/1889 [00:10<01:54, 14.15it/s]
2022-03-20 00:18:41,295 - INFO - tqdm - f1: 0.8285, accuracy: 0.8816, batch_loss: 0.1385, loss: 0.3458 ||:  30%|##9       | 562/1889 [00:20<01:57, 11.29it/s]
2022-03-20 00:18:52,060 - INFO - tqdm - f1: 0.8236, accuracy: 0.8770, batch_loss: 0.3314, loss: 0.3544 ||:  46%|####5     | 863/1889 [00:31<01:32, 11.10it/s]
2022-03-20 00:19:02,726 - INFO - tqdm - f1: 0.8242, accuracy: 0.8783, batch_loss: 0.1497, loss: 0.3533 ||:  62%|######1   | 1164/1889 [00:42<00:59, 12.22it/s]
2022-03-20 00:19:13,233 - INFO - tqdm - f1: 0.8215, accuracy: 0.8776, batch_loss: 0.2510, loss: 0.3503 ||:  78%|#######7  | 1464/1889 [00:52<00:36, 11.76it/s]
2022-03-20 00:19:23,711 - INFO - tqdm - f1: 0.8222, accuracy: 0.8779, batch_loss: 0.3989, loss: 0.3489 ||:  93%|#########2| 1751/1889 [01:03<00:10, 12.74it/s]
2022-03-20 00:19:28,116 - INFO - tqdm - f1: 0.8222, accuracy: 0.8777, batch_loss: 0.2539, loss: 0.3491 ||: 100%|#########9| 1880/1889 [01:07<00:00, 28.41it/s]
2022-03-20 00:19:28,285 - INFO - tqdm - f1: 0.8221, accuracy: 0.8776, batch_loss: 0.4645, loss: 0.3493 ||: 100%|#########9| 1885/1889 [01:07<00:00, 28.77it/s]
2022-03-20 00:19:28,404 - INFO - tqdm - f1: 0.8220, accuracy: 0.8775, batch_loss: 0.1528, loss: 0.3493 ||: 100%|##########| 1889/1889 [01:07<00:00, 29.87it/s]
2022-03-20 00:19:28,415 - INFO - tqdm - f1: 0.8220, accuracy: 0.8775, batch_loss: 0.1528, loss: 0.3493 ||: 100%|##########| 1889/1889 [01:07<00:00, 27.88it/s]
2022-03-20 00:19:28,428 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct-20k_base/best.th'.
2022-03-20 00:19:30,965 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 00:19:30,967 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.875  |     0.878
2022-03-20 00:19:30,969 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.817  |     0.822
2022-03-20 00:19:30,970 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 00:19:30,971 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.345  |     0.349
2022-03-20 00:19:30,973 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8640.777  |       N/A
2022-03-20 00:19:30,974 - INFO - allennlp.training.trainer - Epoch duration: 0:19:30.756322
2022-03-20 00:19:30,976 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:36:10
2022-03-20 00:19:30,977 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-20 00:19:30,979 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-20 00:19:30,980 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 00:19:30,983 - INFO - allennlp.training.trainer - Training
2022-03-20 00:19:30,985 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-20 00:19:41,609 - INFO - tqdm - f1: 0.8174, accuracy: 0.8792, batch_loss: 0.1769, loss: 0.3394 ||:   0%|          | 45/11253 [00:10<41:41,  4.48it/s]
2022-03-20 00:19:52,061 - INFO - tqdm - f1: 0.8384, accuracy: 0.8940, batch_loss: 0.1582, loss: 0.2946 ||:   1%|1         | 151/11253 [00:21<41:59,  4.41it/s]
2022-03-20 00:20:02,752 - INFO - tqdm - f1: 0.8393, accuracy: 0.8961, batch_loss: 0.0186, loss: 0.2978 ||:   2%|2         | 261/11253 [00:31<41:18,  4.43it/s]
2022-03-20 00:20:13,023 - INFO - tqdm - f1: 0.8386, accuracy: 0.8946, batch_loss: 0.7817, loss: 0.2971 ||:   3%|3         | 367/11253 [00:42<33:46,  5.37it/s]
2022-03-20 00:20:23,171 - INFO - tqdm - f1: 0.8317, accuracy: 0.8899, batch_loss: 0.0733, loss: 0.2990 ||:   4%|4         | 479/11253 [00:52<12:41, 14.14it/s]
2022-03-20 00:20:33,266 - INFO - tqdm - f1: 0.8302, accuracy: 0.8893, batch_loss: 0.3432, loss: 0.3004 ||:   5%|5         | 581/11253 [01:02<12:35, 14.13it/s]
2022-03-20 00:20:43,381 - INFO - tqdm - f1: 0.8311, accuracy: 0.8899, batch_loss: 0.0910, loss: 0.3016 ||:   6%|6         | 681/11253 [01:12<13:19, 13.22it/s]
2022-03-20 00:20:53,412 - INFO - tqdm - f1: 0.8314, accuracy: 0.8904, batch_loss: 0.1602, loss: 0.3005 ||:   7%|6         | 781/11253 [01:22<12:54, 13.52it/s]
2022-03-20 00:21:03,537 - INFO - tqdm - f1: 0.8333, accuracy: 0.8904, batch_loss: 0.0778, loss: 0.3016 ||:   8%|7         | 885/11253 [01:32<16:23, 10.55it/s]
2022-03-20 00:21:13,653 - INFO - tqdm - f1: 0.8342, accuracy: 0.8905, batch_loss: 0.1608, loss: 0.3019 ||:   9%|8         | 987/11253 [01:42<20:35,  8.31it/s]
2022-03-20 00:21:23,781 - INFO - tqdm - f1: 0.8353, accuracy: 0.8915, batch_loss: 0.2058, loss: 0.3001 ||:  10%|9         | 1089/11253 [01:52<24:22,  6.95it/s]
2022-03-20 00:21:33,825 - INFO - tqdm - f1: 0.8333, accuracy: 0.8907, batch_loss: 0.4261, loss: 0.3013 ||:  11%|#         | 1191/11253 [02:02<29:13,  5.74it/s]
2022-03-20 00:21:44,357 - INFO - tqdm - f1: 0.8325, accuracy: 0.8905, batch_loss: 0.2673, loss: 0.3002 ||:  12%|#1        | 1299/11253 [02:13<37:51,  4.38it/s]
2022-03-20 00:21:55,126 - INFO - tqdm - f1: 0.8327, accuracy: 0.8909, batch_loss: 0.2877, loss: 0.2977 ||:  13%|#2        | 1411/11253 [02:24<37:12,  4.41it/s]
2022-03-20 00:22:05,690 - INFO - tqdm - f1: 0.8334, accuracy: 0.8912, batch_loss: 0.4314, loss: 0.2961 ||:  14%|#3        | 1523/11253 [02:34<35:01,  4.63it/s]
2022-03-20 00:22:16,350 - INFO - tqdm - f1: 0.8331, accuracy: 0.8908, batch_loss: 0.7400, loss: 0.2977 ||:  15%|#4        | 1633/11253 [02:45<35:32,  4.51it/s]
2022-03-20 00:22:26,406 - INFO - tqdm - f1: 0.8327, accuracy: 0.8901, batch_loss: 0.3535, loss: 0.3000 ||:  15%|#5        | 1735/11253 [02:55<34:43,  4.57it/s]
2022-03-20 00:22:36,977 - INFO - tqdm - f1: 0.8323, accuracy: 0.8900, batch_loss: 0.0969, loss: 0.3004 ||:  16%|#6        | 1843/11253 [03:05<34:37,  4.53it/s]
2022-03-20 00:22:47,547 - INFO - tqdm - f1: 0.8322, accuracy: 0.8895, batch_loss: 0.3346, loss: 0.3020 ||:  17%|#7        | 1949/11253 [03:16<34:19,  4.52it/s]
2022-03-20 00:22:58,088 - INFO - tqdm - f1: 0.8321, accuracy: 0.8892, batch_loss: 0.2345, loss: 0.3030 ||:  18%|#8        | 2055/11253 [03:27<34:52,  4.40it/s]
2022-03-20 00:23:08,251 - INFO - tqdm - f1: 0.8320, accuracy: 0.8893, batch_loss: 0.0465, loss: 0.3028 ||:  19%|#9        | 2157/11253 [03:37<31:40,  4.79it/s]
2022-03-20 00:23:18,976 - INFO - tqdm - f1: 0.8317, accuracy: 0.8890, batch_loss: 0.6114, loss: 0.3047 ||:  20%|##        | 2267/11253 [03:47<33:49,  4.43it/s]
2022-03-20 00:23:29,681 - INFO - tqdm - f1: 0.8322, accuracy: 0.8889, batch_loss: 0.4128, loss: 0.3045 ||:  21%|##1       | 2377/11253 [03:58<32:32,  4.55it/s]
2022-03-20 00:23:40,204 - INFO - tqdm - f1: 0.8324, accuracy: 0.8892, batch_loss: 0.1192, loss: 0.3036 ||:  22%|##2       | 2485/11253 [04:09<33:11,  4.40it/s]
2022-03-20 00:23:50,434 - INFO - tqdm - f1: 0.8319, accuracy: 0.8889, batch_loss: 0.1323, loss: 0.3042 ||:  23%|##3       | 2589/11253 [04:19<32:17,  4.47it/s]
2022-03-20 00:24:00,867 - INFO - tqdm - f1: 0.8322, accuracy: 0.8889, batch_loss: 0.1307, loss: 0.3051 ||:  24%|##3       | 2695/11253 [04:29<32:21,  4.41it/s]
2022-03-20 00:24:11,249 - INFO - tqdm - f1: 0.8326, accuracy: 0.8892, batch_loss: 0.1369, loss: 0.3037 ||:  25%|##4       | 2801/11253 [04:40<32:23,  4.35it/s]
2022-03-20 00:24:21,763 - INFO - tqdm - f1: 0.8328, accuracy: 0.8890, batch_loss: 0.0677, loss: 0.3040 ||:  26%|##5       | 2909/11253 [04:50<30:47,  4.52it/s]
2022-03-20 00:24:32,329 - INFO - tqdm - f1: 0.8323, accuracy: 0.8886, batch_loss: 0.1554, loss: 0.3055 ||:  27%|##6       | 3017/11253 [05:01<30:09,  4.55it/s]
2022-03-20 00:24:43,014 - INFO - tqdm - f1: 0.8322, accuracy: 0.8882, batch_loss: 0.5089, loss: 0.3063 ||:  28%|##7       | 3129/11253 [05:12<29:56,  4.52it/s]
2022-03-20 00:24:53,222 - INFO - tqdm - f1: 0.8320, accuracy: 0.8883, batch_loss: 0.1494, loss: 0.3065 ||:  29%|##8       | 3231/11253 [05:22<29:42,  4.50it/s]
2022-03-20 00:25:03,619 - INFO - tqdm - f1: 0.8329, accuracy: 0.8887, batch_loss: 0.4825, loss: 0.3062 ||:  30%|##9       | 3339/11253 [05:32<28:34,  4.62it/s]
2022-03-20 00:25:13,761 - INFO - tqdm - f1: 0.8330, accuracy: 0.8888, batch_loss: 0.2167, loss: 0.3059 ||:  31%|###       | 3443/11253 [05:42<28:28,  4.57it/s]
2022-03-20 00:25:24,236 - INFO - tqdm - f1: 0.8334, accuracy: 0.8892, batch_loss: 0.2726, loss: 0.3049 ||:  32%|###1      | 3549/11253 [05:53<28:56,  4.44it/s]
2022-03-20 00:25:34,657 - INFO - tqdm - f1: 0.8335, accuracy: 0.8891, batch_loss: 0.1001, loss: 0.3057 ||:  32%|###2      | 3655/11253 [06:03<28:18,  4.47it/s]
2022-03-20 00:25:45,144 - INFO - tqdm - f1: 0.8337, accuracy: 0.8891, batch_loss: 0.1993, loss: 0.3059 ||:  33%|###3      | 3763/11253 [06:14<27:35,  4.52it/s]
2022-03-20 00:25:55,673 - INFO - tqdm - f1: 0.8338, accuracy: 0.8894, batch_loss: 0.2762, loss: 0.3058 ||:  34%|###4      | 3871/11253 [06:24<25:09,  4.89it/s]
2022-03-20 00:26:06,283 - INFO - tqdm - f1: 0.8336, accuracy: 0.8893, batch_loss: 0.5662, loss: 0.3059 ||:  35%|###5      | 3979/11253 [06:35<27:43,  4.37it/s]
2022-03-20 00:26:16,512 - INFO - tqdm - f1: 0.8332, accuracy: 0.8889, batch_loss: 0.3110, loss: 0.3062 ||:  36%|###6      | 4083/11253 [06:45<26:43,  4.47it/s]
2022-03-20 00:26:27,284 - INFO - tqdm - f1: 0.8332, accuracy: 0.8888, batch_loss: 0.3959, loss: 0.3062 ||:  37%|###7      | 4193/11253 [06:56<26:09,  4.50it/s]
2022-03-20 00:26:38,094 - INFO - tqdm - f1: 0.8334, accuracy: 0.8890, batch_loss: 0.2104, loss: 0.3063 ||:  38%|###8      | 4303/11253 [07:07<26:17,  4.41it/s]
2022-03-20 00:26:48,113 - INFO - tqdm - f1: 0.8332, accuracy: 0.8887, batch_loss: 0.4580, loss: 0.3066 ||:  39%|###9      | 4417/11253 [07:17<07:49, 14.56it/s]
2022-03-20 00:26:58,218 - INFO - tqdm - f1: 0.8327, accuracy: 0.8885, batch_loss: 0.1391, loss: 0.3071 ||:  40%|####      | 4519/11253 [07:27<07:56, 14.14it/s]
2022-03-20 00:27:08,305 - INFO - tqdm - f1: 0.8328, accuracy: 0.8883, batch_loss: 0.2834, loss: 0.3072 ||:  41%|####1     | 4615/11253 [07:37<12:16,  9.02it/s]
2022-03-20 00:27:18,326 - INFO - tqdm - f1: 0.8328, accuracy: 0.8883, batch_loss: 0.1271, loss: 0.3075 ||:  42%|####1     | 4715/11253 [07:47<18:57,  5.75it/s]
2022-03-20 00:27:28,638 - INFO - tqdm - f1: 0.8328, accuracy: 0.8882, batch_loss: 0.5625, loss: 0.3077 ||:  43%|####2     | 4819/11253 [07:57<24:22,  4.40it/s]
2022-03-20 00:27:39,225 - INFO - tqdm - f1: 0.8328, accuracy: 0.8882, batch_loss: 0.3402, loss: 0.3079 ||:  44%|####3     | 4929/11253 [08:08<23:48,  4.43it/s]
2022-03-20 00:27:49,802 - INFO - tqdm - f1: 0.8325, accuracy: 0.8880, batch_loss: 0.1616, loss: 0.3077 ||:  45%|####4     | 5037/11253 [08:18<23:31,  4.40it/s]
2022-03-20 00:28:00,205 - INFO - tqdm - f1: 0.8327, accuracy: 0.8880, batch_loss: 0.0751, loss: 0.3081 ||:  46%|####5     | 5143/11253 [08:29<23:13,  4.38it/s]
2022-03-20 00:28:10,602 - INFO - tqdm - f1: 0.8331, accuracy: 0.8882, batch_loss: 0.5836, loss: 0.3077 ||:  47%|####6     | 5247/11253 [08:39<21:51,  4.58it/s]
2022-03-20 00:28:21,314 - INFO - tqdm - f1: 0.8330, accuracy: 0.8880, batch_loss: 0.0084, loss: 0.3079 ||:  48%|####7     | 5351/11253 [08:50<23:14,  4.23it/s]
2022-03-20 00:28:31,705 - INFO - tqdm - f1: 0.8330, accuracy: 0.8882, batch_loss: 0.3922, loss: 0.3078 ||:  48%|####8     | 5455/11253 [09:00<21:35,  4.48it/s]
2022-03-20 00:28:42,276 - INFO - tqdm - f1: 0.8335, accuracy: 0.8885, batch_loss: 0.2698, loss: 0.3071 ||:  49%|####9     | 5561/11253 [09:11<21:03,  4.51it/s]
2022-03-20 00:28:53,008 - INFO - tqdm - f1: 0.8336, accuracy: 0.8886, batch_loss: 0.6110, loss: 0.3065 ||:  50%|#####     | 5669/11253 [09:22<21:04,  4.42it/s]
2022-03-20 00:29:03,470 - INFO - tqdm - f1: 0.8335, accuracy: 0.8886, batch_loss: 0.0650, loss: 0.3066 ||:  51%|#####1    | 5775/11253 [09:32<20:23,  4.48it/s]
2022-03-20 00:29:13,842 - INFO - tqdm - f1: 0.8334, accuracy: 0.8886, batch_loss: 0.0803, loss: 0.3064 ||:  52%|#####2    | 5879/11253 [09:42<19:59,  4.48it/s]
2022-03-20 00:29:24,050 - INFO - tqdm - f1: 0.8330, accuracy: 0.8883, batch_loss: 0.4054, loss: 0.3071 ||:  53%|#####3    | 5983/11253 [09:53<19:52,  4.42it/s]
2022-03-20 00:29:34,562 - INFO - tqdm - f1: 0.8329, accuracy: 0.8883, batch_loss: 0.4481, loss: 0.3071 ||:  54%|#####4    | 6089/11253 [10:03<19:11,  4.49it/s]
2022-03-20 00:29:44,965 - INFO - tqdm - f1: 0.8327, accuracy: 0.8882, batch_loss: 0.5202, loss: 0.3071 ||:  55%|#####5    | 6193/11253 [10:13<19:19,  4.36it/s]
2022-03-20 00:29:55,541 - INFO - tqdm - f1: 0.8326, accuracy: 0.8881, batch_loss: 0.4686, loss: 0.3076 ||:  56%|#####5    | 6301/11253 [10:24<18:31,  4.45it/s]
2022-03-20 00:30:06,674 - INFO - tqdm - f1: 0.8326, accuracy: 0.8882, batch_loss: 0.1949, loss: 0.3072 ||:  57%|#####7    | 6417/11253 [10:35<17:54,  4.50it/s]
2022-03-20 00:30:17,792 - INFO - tqdm - f1: 0.8328, accuracy: 0.8882, batch_loss: 0.1735, loss: 0.3075 ||:  58%|#####8    | 6527/11253 [10:46<18:01,  4.37it/s]
2022-03-20 00:30:28,352 - INFO - tqdm - f1: 0.8329, accuracy: 0.8882, batch_loss: 0.0717, loss: 0.3077 ||:  59%|#####8    | 6633/11253 [10:57<17:14,  4.46it/s]
2022-03-20 00:30:38,822 - INFO - tqdm - f1: 0.8331, accuracy: 0.8884, batch_loss: 0.2656, loss: 0.3074 ||:  60%|#####9    | 6739/11253 [11:07<16:24,  4.59it/s]
2022-03-20 00:30:48,879 - INFO - tqdm - f1: 0.8334, accuracy: 0.8885, batch_loss: 0.0514, loss: 0.3075 ||:  61%|######    | 6849/11253 [11:17<05:05, 14.41it/s]
2022-03-20 00:30:58,923 - INFO - tqdm - f1: 0.8330, accuracy: 0.8883, batch_loss: 0.6599, loss: 0.3078 ||:  62%|######1   | 6949/11253 [11:27<05:03, 14.17it/s]
2022-03-20 00:31:09,031 - INFO - tqdm - f1: 0.8331, accuracy: 0.8883, batch_loss: 0.4770, loss: 0.3079 ||:  63%|######2   | 7051/11253 [11:38<05:18, 13.21it/s]
2022-03-20 00:31:19,121 - INFO - tqdm - f1: 0.8334, accuracy: 0.8884, batch_loss: 0.3349, loss: 0.3077 ||:  64%|######3   | 7153/11253 [11:48<05:38, 12.13it/s]
2022-03-20 00:31:29,196 - INFO - tqdm - f1: 0.8332, accuracy: 0.8884, batch_loss: 0.0100, loss: 0.3079 ||:  64%|######4   | 7253/11253 [11:58<06:25, 10.37it/s]
2022-03-20 00:31:39,226 - INFO - tqdm - f1: 0.8333, accuracy: 0.8884, batch_loss: 0.0192, loss: 0.3078 ||:  65%|######5   | 7353/11253 [12:08<14:53,  4.37it/s]
2022-03-20 00:31:49,531 - INFO - tqdm - f1: 0.8331, accuracy: 0.8884, batch_loss: 0.2606, loss: 0.3074 ||:  66%|######6   | 7457/11253 [12:18<14:03,  4.50it/s]
2022-03-20 00:32:00,001 - INFO - tqdm - f1: 0.8332, accuracy: 0.8884, batch_loss: 0.2090, loss: 0.3075 ||:  67%|######7   | 7565/11253 [12:29<13:45,  4.47it/s]
2022-03-20 00:32:10,451 - INFO - tqdm - f1: 0.8332, accuracy: 0.8883, batch_loss: 0.2418, loss: 0.3077 ||:  68%|######8   | 7671/11253 [12:39<13:27,  4.44it/s]
2022-03-20 00:32:20,597 - INFO - tqdm - f1: 0.8333, accuracy: 0.8883, batch_loss: 0.0733, loss: 0.3075 ||:  69%|######9   | 7773/11253 [12:49<12:57,  4.48it/s]
2022-03-20 00:32:31,162 - INFO - tqdm - f1: 0.8333, accuracy: 0.8884, batch_loss: 0.2812, loss: 0.3073 ||:  70%|#######   | 7881/11253 [13:00<12:38,  4.45it/s]
2022-03-20 00:32:41,545 - INFO - tqdm - f1: 0.8330, accuracy: 0.8882, batch_loss: 0.3164, loss: 0.3075 ||:  71%|#######   | 7985/11253 [13:10<12:23,  4.39it/s]
2022-03-20 00:32:52,016 - INFO - tqdm - f1: 0.8330, accuracy: 0.8882, batch_loss: 0.4541, loss: 0.3075 ||:  72%|#######1  | 8091/11253 [13:21<11:45,  4.48it/s]
2022-03-20 00:33:02,577 - INFO - tqdm - f1: 0.8328, accuracy: 0.8883, batch_loss: 0.1200, loss: 0.3073 ||:  73%|#######2  | 8199/11253 [13:31<11:15,  4.52it/s]
2022-03-20 00:33:12,985 - INFO - tqdm - f1: 0.8330, accuracy: 0.8884, batch_loss: 0.3858, loss: 0.3069 ||:  74%|#######3  | 8305/11253 [13:41<10:52,  4.52it/s]
2022-03-20 00:33:23,446 - INFO - tqdm - f1: 0.8333, accuracy: 0.8885, batch_loss: 0.0445, loss: 0.3066 ||:  75%|#######4  | 8411/11253 [13:52<10:49,  4.38it/s]
2022-03-20 00:33:33,707 - INFO - tqdm - f1: 0.8331, accuracy: 0.8884, batch_loss: 0.1939, loss: 0.3068 ||:  76%|#######5  | 8515/11253 [14:02<10:16,  4.44it/s]
2022-03-20 00:33:44,022 - INFO - tqdm - f1: 0.8328, accuracy: 0.8882, batch_loss: 0.5279, loss: 0.3071 ||:  77%|#######6  | 8619/11253 [14:13<09:43,  4.51it/s]
2022-03-20 00:33:54,624 - INFO - tqdm - f1: 0.8329, accuracy: 0.8883, batch_loss: 0.5166, loss: 0.3073 ||:  78%|#######7  | 8725/11253 [14:23<09:39,  4.37it/s]
2022-03-20 00:34:05,058 - INFO - tqdm - f1: 0.8328, accuracy: 0.8882, batch_loss: 0.4382, loss: 0.3075 ||:  78%|#######8  | 8833/11253 [14:34<08:51,  4.55it/s]
2022-03-20 00:34:15,386 - INFO - tqdm - f1: 0.8327, accuracy: 0.8881, batch_loss: 0.3534, loss: 0.3079 ||:  79%|#######9  | 8939/11253 [14:44<08:26,  4.56it/s]
2022-03-20 00:34:25,925 - INFO - tqdm - f1: 0.8328, accuracy: 0.8881, batch_loss: 0.1516, loss: 0.3079 ||:  80%|########  | 9047/11253 [14:54<08:12,  4.48it/s]
2022-03-20 00:34:36,401 - INFO - tqdm - f1: 0.8330, accuracy: 0.8882, batch_loss: 0.3460, loss: 0.3077 ||:  81%|########1 | 9155/11253 [15:05<07:44,  4.52it/s]
2022-03-20 00:34:46,736 - INFO - tqdm - f1: 0.8329, accuracy: 0.8881, batch_loss: 0.3709, loss: 0.3080 ||:  82%|########2 | 9263/11253 [15:15<07:22,  4.50it/s]
2022-03-20 00:34:57,100 - INFO - tqdm - f1: 0.8328, accuracy: 0.8882, batch_loss: 0.4194, loss: 0.3079 ||:  83%|########3 | 9369/11253 [15:26<06:28,  4.85it/s]
2022-03-20 00:35:07,516 - INFO - tqdm - f1: 0.8327, accuracy: 0.8881, batch_loss: 0.3853, loss: 0.3081 ||:  84%|########4 | 9475/11253 [15:36<06:30,  4.55it/s]
2022-03-20 00:35:18,021 - INFO - tqdm - f1: 0.8330, accuracy: 0.8882, batch_loss: 0.0153, loss: 0.3078 ||:  85%|########5 | 9581/11253 [15:47<06:07,  4.55it/s]
2022-03-20 00:35:28,332 - INFO - tqdm - f1: 0.8327, accuracy: 0.8879, batch_loss: 0.3884, loss: 0.3086 ||:  86%|########6 | 9685/11253 [15:57<05:41,  4.59it/s]
2022-03-20 00:35:38,939 - INFO - tqdm - f1: 0.8324, accuracy: 0.8878, batch_loss: 0.7533, loss: 0.3089 ||:  87%|########7 | 9793/11253 [16:07<05:23,  4.52it/s]
2022-03-20 00:35:49,287 - INFO - tqdm - f1: 0.8323, accuracy: 0.8876, batch_loss: 0.2467, loss: 0.3091 ||:  88%|########7 | 9899/11253 [16:18<05:06,  4.42it/s]
2022-03-20 00:35:59,745 - INFO - tqdm - f1: 0.8324, accuracy: 0.8876, batch_loss: 0.3685, loss: 0.3090 ||:  89%|########8 | 10007/11253 [16:28<04:34,  4.53it/s]
2022-03-20 00:36:10,354 - INFO - tqdm - f1: 0.8323, accuracy: 0.8876, batch_loss: 0.0866, loss: 0.3091 ||:  90%|########9 | 10117/11253 [16:39<04:10,  4.53it/s]
2022-03-20 00:36:20,465 - INFO - tqdm - f1: 0.8321, accuracy: 0.8875, batch_loss: 0.1787, loss: 0.3095 ||:  91%|######### | 10219/11253 [16:49<03:48,  4.52it/s]
2022-03-20 00:36:31,210 - INFO - tqdm - f1: 0.8322, accuracy: 0.8876, batch_loss: 0.0593, loss: 0.3091 ||:  92%|#########1| 10329/11253 [17:00<03:31,  4.36it/s]
2022-03-20 00:36:41,891 - INFO - tqdm - f1: 0.8321, accuracy: 0.8875, batch_loss: 0.8616, loss: 0.3092 ||:  93%|#########2| 10437/11253 [17:10<03:03,  4.44it/s]
2022-03-20 00:36:52,855 - INFO - tqdm - f1: 0.8320, accuracy: 0.8874, batch_loss: 0.1863, loss: 0.3096 ||:  94%|#########3| 10549/11253 [17:21<02:39,  4.42it/s]
2022-03-20 00:37:03,653 - INFO - tqdm - f1: 0.8319, accuracy: 0.8873, batch_loss: 0.3012, loss: 0.3097 ||:  95%|#########4| 10661/11253 [17:32<02:11,  4.49it/s]
2022-03-20 00:37:14,245 - INFO - tqdm - f1: 0.8318, accuracy: 0.8872, batch_loss: 0.5535, loss: 0.3100 ||:  96%|#########5| 10771/11253 [17:43<01:34,  5.08it/s]
2022-03-20 00:37:24,497 - INFO - tqdm - f1: 0.8317, accuracy: 0.8871, batch_loss: 0.3103, loss: 0.3101 ||:  97%|#########6| 10877/11253 [17:53<01:24,  4.47it/s]
2022-03-20 00:37:35,227 - INFO - tqdm - f1: 0.8316, accuracy: 0.8870, batch_loss: 0.2736, loss: 0.3104 ||:  98%|#########7| 10985/11253 [18:04<00:59,  4.48it/s]
2022-03-20 00:37:45,918 - INFO - tqdm - f1: 0.8312, accuracy: 0.8868, batch_loss: 0.2759, loss: 0.3108 ||:  99%|#########8| 11095/11253 [18:14<00:34,  4.53it/s]
2022-03-20 00:37:55,210 - INFO - tqdm - f1: 0.8312, accuracy: 0.8868, batch_loss: 0.6137, loss: 0.3107 ||: 100%|#########9| 11197/11253 [18:24<00:04, 13.49it/s]
2022-03-20 00:37:55,365 - INFO - tqdm - f1: 0.8312, accuracy: 0.8868, batch_loss: 0.2639, loss: 0.3107 ||: 100%|#########9| 11199/11253 [18:24<00:04, 13.30it/s]
2022-03-20 00:37:55,505 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.1680, loss: 0.3106 ||: 100%|#########9| 11201/11253 [18:24<00:03, 13.58it/s]
2022-03-20 00:37:55,646 - INFO - tqdm - f1: 0.8312, accuracy: 0.8868, batch_loss: 0.5905, loss: 0.3107 ||: 100%|#########9| 11203/11253 [18:24<00:03, 13.76it/s]
2022-03-20 00:37:55,783 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.1593, loss: 0.3106 ||: 100%|#########9| 11205/11253 [18:24<00:03, 14.00it/s]
2022-03-20 00:37:55,922 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.2146, loss: 0.3106 ||: 100%|#########9| 11207/11253 [18:24<00:03, 14.13it/s]
2022-03-20 00:37:56,060 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.3866, loss: 0.3106 ||: 100%|#########9| 11209/11253 [18:25<00:03, 14.24it/s]
2022-03-20 00:37:56,191 - INFO - tqdm - f1: 0.8313, accuracy: 0.8869, batch_loss: 0.0976, loss: 0.3106 ||: 100%|#########9| 11211/11253 [18:25<00:02, 14.51it/s]
2022-03-20 00:37:56,345 - INFO - tqdm - f1: 0.8313, accuracy: 0.8869, batch_loss: 0.2198, loss: 0.3105 ||: 100%|#########9| 11213/11253 [18:25<00:02, 14.04it/s]
2022-03-20 00:37:57,475 - INFO - tqdm - f1: 0.8313, accuracy: 0.8869, batch_loss: 0.0235, loss: 0.3105 ||: 100%|#########9| 11215/11253 [18:26<00:08,  4.56it/s]
2022-03-20 00:37:57,621 - INFO - tqdm - f1: 0.8313, accuracy: 0.8869, batch_loss: 0.1431, loss: 0.3105 ||: 100%|#########9| 11217/11253 [18:26<00:06,  5.70it/s]
2022-03-20 00:37:57,758 - INFO - tqdm - f1: 0.8313, accuracy: 0.8869, batch_loss: 0.0345, loss: 0.3105 ||: 100%|#########9| 11219/11253 [18:26<00:04,  6.97it/s]
2022-03-20 00:37:57,895 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.5108, loss: 0.3105 ||: 100%|#########9| 11221/11253 [18:26<00:03,  8.27it/s]
2022-03-20 00:37:58,036 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.0655, loss: 0.3105 ||: 100%|#########9| 11223/11253 [18:27<00:03,  9.45it/s]
2022-03-20 00:37:58,188 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.2866, loss: 0.3105 ||: 100%|#########9| 11225/11253 [18:27<00:02, 10.33it/s]
2022-03-20 00:37:58,320 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.0660, loss: 0.3105 ||: 100%|#########9| 11227/11253 [18:27<00:02, 11.40it/s]
2022-03-20 00:37:58,453 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.2994, loss: 0.3105 ||: 100%|#########9| 11229/11253 [18:27<00:01, 12.30it/s]
2022-03-20 00:37:58,586 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.2921, loss: 0.3105 ||: 100%|#########9| 11231/11253 [18:27<00:01, 13.01it/s]
2022-03-20 00:37:58,718 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.4396, loss: 0.3105 ||: 100%|#########9| 11233/11253 [18:27<00:01, 13.58it/s]
2022-03-20 00:37:58,857 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.0866, loss: 0.3105 ||: 100%|#########9| 11235/11253 [18:27<00:01, 13.82it/s]
2022-03-20 00:37:59,010 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.3546, loss: 0.3105 ||: 100%|#########9| 11237/11253 [18:28<00:01, 13.60it/s]
2022-03-20 00:37:59,153 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.4309, loss: 0.3105 ||: 100%|#########9| 11239/11253 [18:28<00:01, 13.69it/s]
2022-03-20 00:37:59,294 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.2127, loss: 0.3105 ||: 100%|#########9| 11241/11253 [18:28<00:00, 13.84it/s]
2022-03-20 00:37:59,430 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.4578, loss: 0.3105 ||: 100%|#########9| 11243/11253 [18:28<00:00, 14.10it/s]
2022-03-20 00:37:59,560 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.4888, loss: 0.3105 ||: 100%|#########9| 11245/11253 [18:28<00:00, 14.46it/s]
2022-03-20 00:37:59,678 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.2485, loss: 0.3105 ||: 100%|#########9| 11247/11253 [18:28<00:00, 15.14it/s]
2022-03-20 00:37:59,821 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.1017, loss: 0.3105 ||: 100%|#########9| 11249/11253 [18:28<00:00, 14.76it/s]
2022-03-20 00:38:00,983 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.0936, loss: 0.3104 ||: 100%|#########9| 11251/11253 [18:29<00:00,  4.51it/s]
2022-03-20 00:38:01,120 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.3803, loss: 0.3104 ||: 100%|##########| 11253/11253 [18:30<00:00,  5.69it/s]
2022-03-20 00:38:01,187 - INFO - tqdm - f1: 0.8312, accuracy: 0.8869, batch_loss: 0.3803, loss: 0.3104 ||: 100%|##########| 11253/11253 [18:30<00:00, 10.14it/s]
2022-03-20 00:38:01,202 - INFO - allennlp.training.trainer - Validating
2022-03-20 00:38:01,204 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-20 00:38:11,823 - INFO - tqdm - f1: 0.8232, accuracy: 0.8823, batch_loss: 0.0287, loss: 0.3422 ||:  16%|#5        | 296/1889 [00:10<02:13, 11.93it/s]
2022-03-20 00:38:22,728 - INFO - tqdm - f1: 0.8147, accuracy: 0.8770, batch_loss: 0.1806, loss: 0.3522 ||:  32%|###1      | 602/1889 [00:21<01:54, 11.20it/s]
2022-03-20 00:38:33,474 - INFO - tqdm - f1: 0.8132, accuracy: 0.8755, batch_loss: 0.2066, loss: 0.3672 ||:  48%|####7     | 902/1889 [00:32<01:20, 12.26it/s]
2022-03-20 00:38:44,428 - INFO - tqdm - f1: 0.8128, accuracy: 0.8757, batch_loss: 0.3168, loss: 0.3648 ||:  64%|######3   | 1206/1889 [00:43<00:59, 11.52it/s]
2022-03-20 00:38:55,306 - INFO - tqdm - f1: 0.8091, accuracy: 0.8739, batch_loss: 0.2025, loss: 0.3643 ||:  80%|########  | 1513/1889 [00:54<00:30, 12.42it/s]
2022-03-20 00:39:06,068 - INFO - tqdm - f1: 0.8119, accuracy: 0.8750, batch_loss: 0.3421, loss: 0.3632 ||:  96%|#########6| 1817/1889 [01:04<00:05, 12.25it/s]
2022-03-20 00:39:07,892 - INFO - tqdm - f1: 0.8124, accuracy: 0.8757, batch_loss: 0.0512, loss: 0.3609 ||: 100%|#########9| 1883/1889 [01:06<00:00, 33.74it/s]
2022-03-20 00:39:07,998 - INFO - tqdm - f1: 0.8125, accuracy: 0.8757, batch_loss: 0.4207, loss: 0.3609 ||: 100%|#########9| 1887/1889 [01:06<00:00, 34.84it/s]
2022-03-20 00:39:08,054 - INFO - tqdm - f1: 0.8127, accuracy: 0.8758, batch_loss: 0.2331, loss: 0.3606 ||: 100%|##########| 1889/1889 [01:06<00:00, 28.26it/s]
2022-03-20 00:39:08,062 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 00:39:08,063 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.887  |     0.876
2022-03-20 00:39:08,065 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.831  |     0.813
2022-03-20 00:39:08,066 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 00:39:08,067 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.310  |     0.361
2022-03-20 00:39:08,068 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8640.777  |       N/A
2022-03-20 00:39:08,069 - INFO - allennlp.training.trainer - Epoch duration: 0:19:37.092275
2022-03-20 00:39:08,071 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:16:52
2022-03-20 00:39:08,073 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-20 00:39:08,074 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-20 00:39:08,076 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 00:39:08,078 - INFO - allennlp.training.trainer - Training
2022-03-20 00:39:08,080 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-20 00:39:18,173 - INFO - tqdm - f1: 0.8563, accuracy: 0.9059, batch_loss: 0.2297, loss: 0.2915 ||:   1%|          | 95/11253 [00:10<13:27, 13.82it/s]
2022-03-20 00:39:28,215 - INFO - tqdm - f1: 0.8402, accuracy: 0.9029, batch_loss: 0.2288, loss: 0.2787 ||:   2%|1         | 195/11253 [00:20<26:56,  6.84it/s]
2022-03-20 00:39:38,569 - INFO - tqdm - f1: 0.8462, accuracy: 0.9051, batch_loss: 0.1487, loss: 0.2714 ||:   3%|2         | 301/11253 [00:30<39:42,  4.60it/s]
2022-03-20 00:39:49,198 - INFO - tqdm - f1: 0.8439, accuracy: 0.9033, batch_loss: 0.0870, loss: 0.2731 ||:   4%|3         | 411/11253 [00:41<39:53,  4.53it/s]
2022-03-20 00:40:00,121 - INFO - tqdm - f1: 0.8484, accuracy: 0.9046, batch_loss: 0.0278, loss: 0.2668 ||:   5%|4         | 527/11253 [00:52<38:45,  4.61it/s]
2022-03-20 00:40:10,793 - INFO - tqdm - f1: 0.8460, accuracy: 0.9024, batch_loss: 0.2900, loss: 0.2684 ||:   6%|5         | 637/11253 [01:02<39:23,  4.49it/s]
2022-03-20 00:40:21,410 - INFO - tqdm - f1: 0.8430, accuracy: 0.9009, batch_loss: 0.1385, loss: 0.2717 ||:   7%|6         | 747/11253 [01:13<38:08,  4.59it/s]
2022-03-20 00:40:32,097 - INFO - tqdm - f1: 0.8427, accuracy: 0.9004, batch_loss: 0.1563, loss: 0.2724 ||:   8%|7         | 857/11253 [01:24<37:29,  4.62it/s]
2022-03-20 00:40:42,782 - INFO - tqdm - f1: 0.8440, accuracy: 0.9009, batch_loss: 0.6485, loss: 0.2712 ||:   9%|8         | 969/11253 [01:34<38:12,  4.49it/s]
2022-03-20 00:40:53,517 - INFO - tqdm - f1: 0.8462, accuracy: 0.9014, batch_loss: 0.3595, loss: 0.2713 ||:  10%|9         | 1081/11253 [01:45<37:34,  4.51it/s]
2022-03-20 00:41:03,942 - INFO - tqdm - f1: 0.8464, accuracy: 0.9020, batch_loss: 0.8298, loss: 0.2693 ||:  11%|#         | 1187/11253 [01:55<37:54,  4.43it/s]
2022-03-20 00:41:14,577 - INFO - tqdm - f1: 0.8473, accuracy: 0.9026, batch_loss: 0.3181, loss: 0.2676 ||:  12%|#1        | 1297/11253 [02:06<36:19,  4.57it/s]
2022-03-20 00:41:25,253 - INFO - tqdm - f1: 0.8476, accuracy: 0.9025, batch_loss: 0.3912, loss: 0.2683 ||:  13%|#2        | 1407/11253 [02:17<35:57,  4.56it/s]
2022-03-20 00:41:36,025 - INFO - tqdm - f1: 0.8474, accuracy: 0.9022, batch_loss: 0.3379, loss: 0.2676 ||:  13%|#3        | 1517/11253 [02:27<36:45,  4.42it/s]
2022-03-20 00:41:46,635 - INFO - tqdm - f1: 0.8483, accuracy: 0.9024, batch_loss: 0.3167, loss: 0.2666 ||:  14%|#4        | 1625/11253 [02:38<32:10,  4.99it/s]
2022-03-20 00:41:57,513 - INFO - tqdm - f1: 0.8477, accuracy: 0.9019, batch_loss: 0.3353, loss: 0.2675 ||:  15%|#5        | 1737/11253 [02:49<35:28,  4.47it/s]
2022-03-20 00:42:08,123 - INFO - tqdm - f1: 0.8472, accuracy: 0.9015, batch_loss: 0.2468, loss: 0.2692 ||:  16%|#6        | 1847/11253 [03:00<34:45,  4.51it/s]
2022-03-20 00:42:18,591 - INFO - tqdm - f1: 0.8464, accuracy: 0.9006, batch_loss: 0.2813, loss: 0.2711 ||:  17%|#7        | 1953/11253 [03:10<34:28,  4.50it/s]
2022-03-20 00:42:29,443 - INFO - tqdm - f1: 0.8474, accuracy: 0.9012, batch_loss: 0.2305, loss: 0.2703 ||:  18%|#8        | 2067/11253 [03:21<33:57,  4.51it/s]
2022-03-20 00:42:40,403 - INFO - tqdm - f1: 0.8475, accuracy: 0.9010, batch_loss: 0.1408, loss: 0.2706 ||:  19%|#9        | 2183/11253 [03:32<32:42,  4.62it/s]
2022-03-20 00:42:50,980 - INFO - tqdm - f1: 0.8477, accuracy: 0.9009, batch_loss: 0.0408, loss: 0.2704 ||:  20%|##        | 2293/11253 [03:42<33:01,  4.52it/s]
2022-03-20 00:43:01,845 - INFO - tqdm - f1: 0.8471, accuracy: 0.9007, batch_loss: 0.1950, loss: 0.2700 ||:  21%|##1       | 2407/11253 [03:53<31:57,  4.61it/s]
2022-03-20 00:43:11,967 - INFO - tqdm - f1: 0.8472, accuracy: 0.9007, batch_loss: 0.0732, loss: 0.2699 ||:  22%|##2       | 2523/11253 [04:03<09:50, 14.78it/s]
2022-03-20 00:43:22,058 - INFO - tqdm - f1: 0.8472, accuracy: 0.9006, batch_loss: 0.1516, loss: 0.2706 ||:  23%|##3       | 2621/11253 [04:13<12:57, 11.11it/s]
2022-03-20 00:43:32,153 - INFO - tqdm - f1: 0.8462, accuracy: 0.9002, batch_loss: 0.0725, loss: 0.2711 ||:  24%|##4       | 2723/11253 [04:24<25:13,  5.64it/s]
2022-03-20 00:43:42,178 - INFO - tqdm - f1: 0.8463, accuracy: 0.9003, batch_loss: 0.1924, loss: 0.2705 ||:  25%|##5       | 2833/11253 [04:34<09:59, 14.06it/s]
2022-03-20 00:43:52,253 - INFO - tqdm - f1: 0.8472, accuracy: 0.9007, batch_loss: 0.1014, loss: 0.2700 ||:  26%|##6       | 2935/11253 [04:44<10:42, 12.94it/s]
2022-03-20 00:44:02,343 - INFO - tqdm - f1: 0.8472, accuracy: 0.9007, batch_loss: 0.2627, loss: 0.2700 ||:  27%|##6       | 3035/11253 [04:54<15:05,  9.07it/s]
2022-03-20 00:44:12,482 - INFO - tqdm - f1: 0.8475, accuracy: 0.9008, batch_loss: 0.2944, loss: 0.2704 ||:  28%|##7       | 3137/11253 [05:04<30:10,  4.48it/s]
2022-03-20 00:44:23,488 - INFO - tqdm - f1: 0.8473, accuracy: 0.9005, batch_loss: 0.3361, loss: 0.2711 ||:  29%|##8       | 3251/11253 [05:15<29:14,  4.56it/s]
2022-03-20 00:44:33,865 - INFO - tqdm - f1: 0.8473, accuracy: 0.9006, batch_loss: 0.6773, loss: 0.2711 ||:  30%|##9       | 3359/11253 [05:25<24:18,  5.41it/s]
2022-03-20 00:44:43,902 - INFO - tqdm - f1: 0.8476, accuracy: 0.9009, batch_loss: 0.0533, loss: 0.2711 ||:  31%|###       | 3469/11253 [05:35<09:01, 14.37it/s]
2022-03-20 00:44:53,924 - INFO - tqdm - f1: 0.8470, accuracy: 0.9006, batch_loss: 0.0440, loss: 0.2711 ||:  32%|###1      | 3571/11253 [05:45<09:12, 13.91it/s]
2022-03-20 00:45:03,964 - INFO - tqdm - f1: 0.8469, accuracy: 0.9007, batch_loss: 0.3696, loss: 0.2714 ||:  33%|###2      | 3675/11253 [05:55<08:44, 14.44it/s]
2022-03-20 00:45:14,087 - INFO - tqdm - f1: 0.8469, accuracy: 0.9004, batch_loss: 0.1458, loss: 0.2724 ||:  34%|###3      | 3779/11253 [06:06<17:55,  6.95it/s]
2022-03-20 00:45:24,530 - INFO - tqdm - f1: 0.8470, accuracy: 0.9002, batch_loss: 0.3334, loss: 0.2729 ||:  35%|###4      | 3885/11253 [06:16<27:18,  4.50it/s]
2022-03-20 00:45:35,553 - INFO - tqdm - f1: 0.8467, accuracy: 0.9001, batch_loss: 0.4596, loss: 0.2734 ||:  36%|###5      | 3999/11253 [06:27<26:22,  4.59it/s]
2022-03-20 00:45:46,155 - INFO - tqdm - f1: 0.8472, accuracy: 0.9004, batch_loss: 0.2369, loss: 0.2727 ||:  37%|###6      | 4111/11253 [06:38<21:34,  5.52it/s]
2022-03-20 00:45:56,210 - INFO - tqdm - f1: 0.8469, accuracy: 0.9003, batch_loss: 0.2831, loss: 0.2729 ||:  38%|###7      | 4221/11253 [06:48<08:10, 14.34it/s]
2022-03-20 00:46:06,210 - INFO - tqdm - f1: 0.8471, accuracy: 0.9003, batch_loss: 0.0538, loss: 0.2731 ||:  38%|###8      | 4319/11253 [06:58<13:19,  8.67it/s]
2022-03-20 00:46:17,186 - INFO - tqdm - f1: 0.8468, accuracy: 0.9001, batch_loss: 0.0498, loss: 0.2730 ||:  39%|###9      | 4431/11253 [07:09<24:42,  4.60it/s]
2022-03-20 00:46:27,834 - INFO - tqdm - f1: 0.8469, accuracy: 0.9001, batch_loss: 0.2098, loss: 0.2732 ||:  40%|####      | 4541/11253 [07:19<24:35,  4.55it/s]
2022-03-20 00:46:38,393 - INFO - tqdm - f1: 0.8468, accuracy: 0.9002, batch_loss: 0.1849, loss: 0.2728 ||:  41%|####1     | 4651/11253 [07:30<23:46,  4.63it/s]
2022-03-20 00:46:48,409 - INFO - tqdm - f1: 0.8469, accuracy: 0.9002, batch_loss: 0.1558, loss: 0.2730 ||:  42%|####2     | 4765/11253 [07:40<07:38, 14.16it/s]
2022-03-20 00:46:58,563 - INFO - tqdm - f1: 0.8469, accuracy: 0.9001, batch_loss: 0.0694, loss: 0.2732 ||:  43%|####3     | 4867/11253 [07:50<08:01, 13.27it/s]
2022-03-20 00:47:08,603 - INFO - tqdm - f1: 0.8465, accuracy: 0.8999, batch_loss: 0.2761, loss: 0.2733 ||:  44%|####4     | 4967/11253 [08:00<07:25, 14.12it/s]
2022-03-20 00:47:18,852 - INFO - tqdm - f1: 0.8468, accuracy: 0.9002, batch_loss: 0.3431, loss: 0.2730 ||:  45%|####5     | 5065/11253 [08:10<23:49,  4.33it/s]
2022-03-20 00:47:28,975 - INFO - tqdm - f1: 0.8470, accuracy: 0.9003, batch_loss: 0.7114, loss: 0.2730 ||:  46%|####6     | 5177/11253 [08:20<07:04, 14.32it/s]
2022-03-20 00:47:39,023 - INFO - tqdm - f1: 0.8472, accuracy: 0.9003, batch_loss: 0.2314, loss: 0.2729 ||:  47%|####6     | 5277/11253 [08:30<07:11, 13.84it/s]
2022-03-20 00:47:49,059 - INFO - tqdm - f1: 0.8471, accuracy: 0.9004, batch_loss: 0.1675, loss: 0.2727 ||:  48%|####7     | 5377/11253 [08:40<09:25, 10.40it/s]
2022-03-20 00:47:59,142 - INFO - tqdm - f1: 0.8472, accuracy: 0.9003, batch_loss: 0.1172, loss: 0.2729 ||:  49%|####8     | 5477/11253 [08:51<16:50,  5.72it/s]
2022-03-20 00:48:09,174 - INFO - tqdm - f1: 0.8472, accuracy: 0.9003, batch_loss: 0.4130, loss: 0.2730 ||:  50%|####9     | 5589/11253 [09:01<06:36, 14.28it/s]
2022-03-20 00:48:19,215 - INFO - tqdm - f1: 0.8472, accuracy: 0.9005, batch_loss: 0.2391, loss: 0.2729 ||:  51%|#####     | 5687/11253 [09:11<09:09, 10.13it/s]
2022-03-20 00:48:29,289 - INFO - tqdm - f1: 0.8472, accuracy: 0.9005, batch_loss: 0.6211, loss: 0.2729 ||:  51%|#####1    | 5789/11253 [09:21<19:59,  4.56it/s]
2022-03-20 00:48:40,344 - INFO - tqdm - f1: 0.8472, accuracy: 0.9004, batch_loss: 0.1737, loss: 0.2731 ||:  52%|#####2    | 5903/11253 [09:32<19:41,  4.53it/s]
2022-03-20 00:48:50,473 - INFO - tqdm - f1: 0.8470, accuracy: 0.9003, batch_loss: 0.6857, loss: 0.2733 ||:  53%|#####3    | 6013/11253 [09:42<10:44,  8.13it/s]
2022-03-20 00:49:00,504 - INFO - tqdm - f1: 0.8467, accuracy: 0.9001, batch_loss: 0.3009, loss: 0.2739 ||:  54%|#####4    | 6119/11253 [09:52<06:04, 14.08it/s]
2022-03-20 00:49:10,633 - INFO - tqdm - f1: 0.8468, accuracy: 0.9001, batch_loss: 0.1247, loss: 0.2733 ||:  55%|#####5    | 6221/11253 [10:02<06:39, 12.60it/s]
2022-03-20 00:49:20,742 - INFO - tqdm - f1: 0.8465, accuracy: 0.9000, batch_loss: 0.6563, loss: 0.2737 ||:  56%|#####6    | 6321/11253 [10:12<10:03,  8.18it/s]
2022-03-20 00:49:31,464 - INFO - tqdm - f1: 0.8470, accuracy: 0.9003, batch_loss: 0.2518, loss: 0.2734 ||:  57%|#####7    | 6431/11253 [10:23<17:30,  4.59it/s]
2022-03-20 00:49:41,609 - INFO - tqdm - f1: 0.8468, accuracy: 0.9002, batch_loss: 0.5815, loss: 0.2734 ||:  58%|#####8    | 6543/11253 [10:33<05:51, 13.39it/s]
2022-03-20 00:49:51,766 - INFO - tqdm - f1: 0.8472, accuracy: 0.9003, batch_loss: 0.3596, loss: 0.2734 ||:  59%|#####9    | 6645/11253 [10:43<05:40, 13.53it/s]
2022-03-20 00:50:01,907 - INFO - tqdm - f1: 0.8470, accuracy: 0.9003, batch_loss: 0.1483, loss: 0.2734 ||:  60%|#####9    | 6749/11253 [10:53<06:57, 10.79it/s]
2022-03-20 00:50:11,990 - INFO - tqdm - f1: 0.8471, accuracy: 0.9003, batch_loss: 0.0448, loss: 0.2736 ||:  61%|######    | 6853/11253 [11:03<13:17,  5.52it/s]
2022-03-20 00:50:22,425 - INFO - tqdm - f1: 0.8473, accuracy: 0.9004, batch_loss: 0.3187, loss: 0.2733 ||:  62%|######1   | 6965/11253 [11:14<10:17,  6.94it/s]
2022-03-20 00:50:32,517 - INFO - tqdm - f1: 0.8469, accuracy: 0.9003, batch_loss: 0.0741, loss: 0.2732 ||:  63%|######2   | 7073/11253 [11:24<04:58, 14.00it/s]
2022-03-20 00:50:42,524 - INFO - tqdm - f1: 0.8466, accuracy: 0.9001, batch_loss: 0.3346, loss: 0.2738 ||:  64%|######3   | 7173/11253 [11:34<05:02, 13.49it/s]
2022-03-20 00:50:52,570 - INFO - tqdm - f1: 0.8465, accuracy: 0.9001, batch_loss: 0.0865, loss: 0.2735 ||:  65%|######4   | 7277/11253 [11:44<06:49,  9.70it/s]
2022-03-20 00:51:02,597 - INFO - tqdm - f1: 0.8466, accuracy: 0.9001, batch_loss: 0.2731, loss: 0.2736 ||:  66%|######5   | 7379/11253 [11:54<14:19,  4.51it/s]
2022-03-20 00:51:13,299 - INFO - tqdm - f1: 0.8467, accuracy: 0.9002, batch_loss: 0.1371, loss: 0.2736 ||:  67%|######6   | 7491/11253 [12:05<13:35,  4.61it/s]
2022-03-20 00:51:24,181 - INFO - tqdm - f1: 0.8467, accuracy: 0.9002, batch_loss: 0.1221, loss: 0.2737 ||:  68%|######7   | 7605/11253 [12:16<13:35,  4.47it/s]
2022-03-20 00:51:34,948 - INFO - tqdm - f1: 0.8464, accuracy: 0.9001, batch_loss: 0.1904, loss: 0.2741 ||:  69%|######8   | 7717/11253 [12:26<13:22,  4.41it/s]
2022-03-20 00:51:45,793 - INFO - tqdm - f1: 0.8464, accuracy: 0.8999, batch_loss: 0.1357, loss: 0.2744 ||:  70%|######9   | 7831/11253 [12:37<12:42,  4.49it/s]
2022-03-20 00:51:56,546 - INFO - tqdm - f1: 0.8463, accuracy: 0.8998, batch_loss: 0.2011, loss: 0.2747 ||:  71%|#######   | 7941/11253 [12:48<12:01,  4.59it/s]
2022-03-20 00:52:07,670 - INFO - tqdm - f1: 0.8466, accuracy: 0.9000, batch_loss: 0.0755, loss: 0.2741 ||:  72%|#######1  | 8057/11253 [12:59<11:54,  4.47it/s]
2022-03-20 00:52:18,362 - INFO - tqdm - f1: 0.8466, accuracy: 0.9000, batch_loss: 0.2835, loss: 0.2742 ||:  73%|#######2  | 8167/11253 [13:10<11:19,  4.54it/s]
2022-03-20 00:52:29,373 - INFO - tqdm - f1: 0.8467, accuracy: 0.8999, batch_loss: 0.0204, loss: 0.2743 ||:  74%|#######3  | 8281/11253 [13:21<11:10,  4.43it/s]
2022-03-20 00:52:40,079 - INFO - tqdm - f1: 0.8467, accuracy: 0.9000, batch_loss: 0.5939, loss: 0.2742 ||:  75%|#######4  | 8391/11253 [13:31<10:44,  4.44it/s]
2022-03-20 00:52:50,936 - INFO - tqdm - f1: 0.8465, accuracy: 0.8998, batch_loss: 0.2255, loss: 0.2745 ||:  76%|#######5  | 8503/11253 [13:42<09:57,  4.60it/s]
2022-03-20 00:53:01,843 - INFO - tqdm - f1: 0.8465, accuracy: 0.8999, batch_loss: 0.3196, loss: 0.2745 ||:  77%|#######6  | 8617/11253 [13:53<09:36,  4.57it/s]
2022-03-20 00:53:12,535 - INFO - tqdm - f1: 0.8466, accuracy: 0.8999, batch_loss: 0.3154, loss: 0.2746 ||:  78%|#######7  | 8727/11253 [14:04<09:24,  4.47it/s]
2022-03-20 00:53:23,257 - INFO - tqdm - f1: 0.8467, accuracy: 0.8999, batch_loss: 0.1738, loss: 0.2746 ||:  79%|#######8  | 8837/11253 [14:15<09:00,  4.47it/s]
2022-03-20 00:53:34,216 - INFO - tqdm - f1: 0.8467, accuracy: 0.8999, batch_loss: 0.2557, loss: 0.2749 ||:  80%|#######9  | 8951/11253 [14:26<08:36,  4.46it/s]
2022-03-20 00:53:44,893 - INFO - tqdm - f1: 0.8465, accuracy: 0.8997, batch_loss: 0.1739, loss: 0.2752 ||:  81%|########  | 9061/11253 [14:36<07:52,  4.64it/s]
2022-03-20 00:53:55,799 - INFO - tqdm - f1: 0.8466, accuracy: 0.8996, batch_loss: 0.1577, loss: 0.2753 ||:  82%|########1 | 9173/11253 [14:47<07:35,  4.57it/s]
2022-03-20 00:54:06,471 - INFO - tqdm - f1: 0.8464, accuracy: 0.8995, batch_loss: 0.2527, loss: 0.2758 ||:  83%|########2 | 9287/11253 [14:58<07:01,  4.66it/s]
2022-03-20 00:54:17,291 - INFO - tqdm - f1: 0.8465, accuracy: 0.8994, batch_loss: 0.9487, loss: 0.2761 ||:  84%|########3 | 9401/11253 [15:09<06:45,  4.57it/s]
2022-03-20 00:54:28,112 - INFO - tqdm - f1: 0.8463, accuracy: 0.8992, batch_loss: 0.0773, loss: 0.2766 ||:  85%|########4 | 9515/11253 [15:20<06:31,  4.44it/s]
2022-03-20 00:54:39,170 - INFO - tqdm - f1: 0.8464, accuracy: 0.8992, batch_loss: 0.2141, loss: 0.2765 ||:  86%|########5 | 9631/11253 [15:31<05:52,  4.60it/s]
2022-03-20 00:54:49,276 - INFO - tqdm - f1: 0.8465, accuracy: 0.8993, batch_loss: 0.1524, loss: 0.2766 ||:  87%|########6 | 9739/11253 [15:41<01:55, 13.11it/s]
2022-03-20 00:54:59,299 - INFO - tqdm - f1: 0.8464, accuracy: 0.8992, batch_loss: 0.0616, loss: 0.2766 ||:  87%|########7 | 9835/11253 [15:51<02:05, 11.29it/s]
2022-03-20 00:55:09,324 - INFO - tqdm - f1: 0.8463, accuracy: 0.8992, batch_loss: 0.1374, loss: 0.2766 ||:  88%|########8 | 9933/11253 [16:01<03:35,  6.13it/s]
2022-03-20 00:55:19,828 - INFO - tqdm - f1: 0.8462, accuracy: 0.8992, batch_loss: 0.4485, loss: 0.2767 ||:  89%|########9 | 10039/11253 [16:11<04:34,  4.42it/s]
2022-03-20 00:55:30,625 - INFO - tqdm - f1: 0.8463, accuracy: 0.8992, batch_loss: 0.2788, loss: 0.2766 ||:  90%|######### | 10149/11253 [16:22<04:10,  4.42it/s]
2022-03-20 00:55:40,774 - INFO - tqdm - f1: 0.8461, accuracy: 0.8991, batch_loss: 0.1013, loss: 0.2767 ||:  91%|#########1| 10265/11253 [16:32<01:10, 13.98it/s]
2022-03-20 00:55:50,844 - INFO - tqdm - f1: 0.8462, accuracy: 0.8991, batch_loss: 0.4316, loss: 0.2767 ||:  92%|#########2| 10365/11253 [16:42<01:14, 11.84it/s]
2022-03-20 00:56:00,988 - INFO - tqdm - f1: 0.8463, accuracy: 0.8991, batch_loss: 0.0323, loss: 0.2768 ||:  93%|#########3| 10467/11253 [16:52<02:20,  5.59it/s]
2022-03-20 00:56:11,608 - INFO - tqdm - f1: 0.8460, accuracy: 0.8990, batch_loss: 0.1508, loss: 0.2771 ||:  94%|#########3| 10577/11253 [17:03<02:32,  4.42it/s]
2022-03-20 00:56:22,097 - INFO - tqdm - f1: 0.8458, accuracy: 0.8989, batch_loss: 0.6151, loss: 0.2773 ||:  95%|#########4| 10687/11253 [17:14<02:01,  4.68it/s]
2022-03-20 00:56:32,286 - INFO - tqdm - f1: 0.8459, accuracy: 0.8990, batch_loss: 0.5414, loss: 0.2772 ||:  96%|#########5| 10799/11253 [17:24<00:56,  8.00it/s]
2022-03-20 00:56:42,344 - INFO - tqdm - f1: 0.8458, accuracy: 0.8989, batch_loss: 0.2260, loss: 0.2772 ||:  97%|#########6| 10907/11253 [17:34<00:23, 14.52it/s]
2022-03-20 00:56:52,481 - INFO - tqdm - f1: 0.8458, accuracy: 0.8989, batch_loss: 0.4575, loss: 0.2770 ||:  98%|#########7| 11013/11253 [17:44<00:17, 13.89it/s]
2022-03-20 00:57:02,550 - INFO - tqdm - f1: 0.8458, accuracy: 0.8988, batch_loss: 0.1988, loss: 0.2772 ||:  99%|#########8| 11117/11253 [17:54<00:10, 13.33it/s]
2022-03-20 00:57:09,935 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.5013, loss: 0.2772 ||: 100%|#########9| 11197/11253 [18:01<00:03, 14.03it/s]
2022-03-20 00:57:10,063 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.1269, loss: 0.2772 ||: 100%|#########9| 11199/11253 [18:01<00:03, 14.45it/s]
2022-03-20 00:57:10,212 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.4981, loss: 0.2772 ||: 100%|#########9| 11201/11253 [18:02<00:03, 14.16it/s]
2022-03-20 00:57:10,367 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.1106, loss: 0.2772 ||: 100%|#########9| 11203/11253 [18:02<00:03, 13.75it/s]
2022-03-20 00:57:10,513 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.4045, loss: 0.2772 ||: 100%|#########9| 11205/11253 [18:02<00:03, 13.74it/s]
2022-03-20 00:57:10,646 - INFO - tqdm - f1: 0.8460, accuracy: 0.8988, batch_loss: 0.8052, loss: 0.2773 ||: 100%|#########9| 11207/11253 [18:02<00:03, 14.11it/s]
2022-03-20 00:57:10,783 - INFO - tqdm - f1: 0.8460, accuracy: 0.8988, batch_loss: 0.3299, loss: 0.2773 ||: 100%|#########9| 11209/11253 [18:02<00:03, 14.24it/s]
2022-03-20 00:57:10,923 - INFO - tqdm - f1: 0.8460, accuracy: 0.8988, batch_loss: 0.0823, loss: 0.2773 ||: 100%|#########9| 11211/11253 [18:02<00:02, 14.24it/s]
2022-03-20 00:57:11,052 - INFO - tqdm - f1: 0.8460, accuracy: 0.8988, batch_loss: 0.2975, loss: 0.2773 ||: 100%|#########9| 11213/11253 [18:02<00:02, 14.60it/s]
2022-03-20 00:57:11,200 - INFO - tqdm - f1: 0.8460, accuracy: 0.8988, batch_loss: 0.4736, loss: 0.2773 ||: 100%|#########9| 11215/11253 [18:03<00:02, 14.27it/s]
2022-03-20 00:57:11,352 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.0227, loss: 0.2773 ||: 100%|#########9| 11217/11253 [18:03<00:02, 13.92it/s]
2022-03-20 00:57:12,506 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.1802, loss: 0.2772 ||: 100%|#########9| 11219/11253 [18:04<00:07,  4.48it/s]
2022-03-20 00:57:12,670 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.0526, loss: 0.2772 ||: 100%|#########9| 11221/11253 [18:04<00:05,  5.52it/s]
2022-03-20 00:57:12,827 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.5876, loss: 0.2772 ||: 100%|#########9| 11223/11253 [18:04<00:04,  6.66it/s]
2022-03-20 00:57:12,969 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.1819, loss: 0.2772 ||: 100%|#########9| 11225/11253 [18:04<00:03,  7.90it/s]
2022-03-20 00:57:13,132 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.2261, loss: 0.2772 ||: 100%|#########9| 11227/11253 [18:05<00:02,  8.85it/s]
2022-03-20 00:57:13,298 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.1716, loss: 0.2772 ||: 100%|#########9| 11229/11253 [18:05<00:02,  9.62it/s]
2022-03-20 00:57:13,456 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.1654, loss: 0.2772 ||: 100%|#########9| 11231/11253 [18:05<00:02, 10.36it/s]
2022-03-20 00:57:13,596 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.4352, loss: 0.2772 ||: 100%|#########9| 11233/11253 [18:05<00:01, 11.29it/s]
2022-03-20 00:57:13,731 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.0107, loss: 0.2771 ||: 100%|#########9| 11235/11253 [18:05<00:01, 12.15it/s]
2022-03-20 00:57:13,869 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.1106, loss: 0.2771 ||: 100%|#########9| 11237/11253 [18:05<00:01, 12.78it/s]
2022-03-20 00:57:14,011 - INFO - tqdm - f1: 0.8461, accuracy: 0.8989, batch_loss: 0.0746, loss: 0.2771 ||: 100%|#########9| 11239/11253 [18:05<00:01, 13.16it/s]
2022-03-20 00:57:14,163 - INFO - tqdm - f1: 0.8461, accuracy: 0.8989, batch_loss: 0.2540, loss: 0.2771 ||: 100%|#########9| 11241/11253 [18:06<00:00, 13.13it/s]
2022-03-20 00:57:14,324 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.2307, loss: 0.2771 ||: 100%|#########9| 11243/11253 [18:06<00:00, 12.93it/s]
2022-03-20 00:57:14,485 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.1220, loss: 0.2771 ||: 100%|#########9| 11245/11253 [18:06<00:00, 12.76it/s]
2022-03-20 00:57:14,622 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.5660, loss: 0.2771 ||: 100%|#########9| 11247/11253 [18:06<00:00, 13.27it/s]
2022-03-20 00:57:14,770 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.1410, loss: 0.2771 ||: 100%|#########9| 11249/11253 [18:06<00:00, 13.35it/s]
2022-03-20 00:57:14,898 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.2291, loss: 0.2771 ||: 100%|#########9| 11251/11253 [18:06<00:00, 13.95it/s]
2022-03-20 00:57:16,036 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.0348, loss: 0.2771 ||: 100%|##########| 11253/11253 [18:07<00:00,  4.53it/s]
2022-03-20 00:57:16,105 - INFO - tqdm - f1: 0.8460, accuracy: 0.8989, batch_loss: 0.0348, loss: 0.2771 ||: 100%|##########| 11253/11253 [18:08<00:00, 10.34it/s]
2022-03-20 00:57:16,114 - INFO - allennlp.training.trainer - Validating
2022-03-20 00:57:16,119 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-20 00:57:27,197 - INFO - tqdm - f1: 0.8155, accuracy: 0.8811, batch_loss: 0.5442, loss: 0.3511 ||:  16%|#5        | 294/1889 [00:11<02:26, 10.92it/s]
2022-03-20 00:57:37,953 - INFO - tqdm - f1: 0.8043, accuracy: 0.8698, batch_loss: 0.6937, loss: 0.3799 ||:  31%|###1      | 595/1889 [00:21<01:47, 12.06it/s]
2022-03-20 00:57:49,075 - INFO - tqdm - f1: 0.8045, accuracy: 0.8704, batch_loss: 1.1664, loss: 0.3839 ||:  48%|####7     | 904/1889 [00:32<01:22, 11.91it/s]
2022-03-20 00:58:00,012 - INFO - tqdm - f1: 0.8044, accuracy: 0.8693, batch_loss: 0.2892, loss: 0.3889 ||:  64%|######3   | 1208/1889 [00:43<00:56, 11.96it/s]
2022-03-20 00:58:10,073 - INFO - tqdm - f1: 0.8039, accuracy: 0.8694, batch_loss: 0.6332, loss: 0.3921 ||:  80%|#######9  | 1507/1889 [00:53<00:10, 38.14it/s]
2022-03-20 00:58:20,116 - INFO - tqdm - f1: 0.8050, accuracy: 0.8708, batch_loss: 0.7624, loss: 0.3898 ||:  93%|#########3| 1763/1889 [01:03<00:03, 37.25it/s]
2022-03-20 00:58:24,282 - INFO - tqdm - f1: 0.8050, accuracy: 0.8708, batch_loss: 0.0536, loss: 0.3881 ||: 100%|#########9| 1881/1889 [01:08<00:00, 38.12it/s]
2022-03-20 00:58:24,397 - INFO - tqdm - f1: 0.8053, accuracy: 0.8710, batch_loss: 0.1328, loss: 0.3878 ||: 100%|#########9| 1887/1889 [01:08<00:00, 42.36it/s]
2022-03-20 00:58:24,470 - INFO - tqdm - f1: 0.8053, accuracy: 0.8710, batch_loss: 0.3330, loss: 0.3876 ||: 100%|##########| 1889/1889 [01:08<00:00, 27.64it/s]
2022-03-20 00:58:24,484 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-20 00:58:24,486 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.899  |     0.871
2022-03-20 00:58:24,489 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.846  |     0.805
2022-03-20 00:58:24,491 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-20 00:58:24,493 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.277  |     0.388
2022-03-20 00:58:24,496 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  8640.777  |       N/A
2022-03-20 00:58:24,498 - INFO - allennlp.training.trainer - Epoch duration: 0:19:16.424915
2022-03-20 00:58:24,500 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:56:54
2022-03-20 00:58:24,503 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-20 00:58:24,505 - INFO - allennlp.training.trainer - Worker 0 memory usage: 8.4G
2022-03-20 00:58:24,508 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-20 00:58:24,511 - INFO - allennlp.training.trainer - Training
2022-03-20 00:58:24,514 - INFO - tqdm - 0%|          | 0/11253 [00:00<?, ?it/s]
2022-03-20 00:58:34,514 - INFO - tqdm - f1: 0.8690, accuracy: 0.9156, batch_loss: 0.0148, loss: 0.2461 ||:   1%|          | 97/11253 [00:09<13:19, 13.96it/s]
2022-03-20 00:58:44,619 - INFO - tqdm - f1: 0.8709, accuracy: 0.9165, batch_loss: 0.5312, loss: 0.2397 ||:   2%|1         | 199/11253 [00:20<15:19, 12.03it/s]
2022-03-20 00:58:54,699 - INFO - tqdm - f1: 0.8729, accuracy: 0.9208, batch_loss: 0.2438, loss: 0.2241 ||:   3%|2         | 299/11253 [00:30<26:13,  6.96it/s]
2022-03-20 00:59:05,370 - INFO - tqdm - f1: 0.8680, accuracy: 0.9173, batch_loss: 0.0662, loss: 0.2270 ||:   4%|3         | 409/11253 [00:40<40:15,  4.49it/s]
2022-03-20 00:59:15,764 - INFO - tqdm - f1: 0.8645, accuracy: 0.9150, batch_loss: 0.1715, loss: 0.2297 ||:   5%|4         | 519/11253 [00:51<32:33,  5.49it/s]
2022-03-20 00:59:26,841 - INFO - tqdm - f1: 0.8643, accuracy: 0.9154, batch_loss: 0.4224, loss: 0.2291 ||:   6%|5         | 631/11253 [01:02<39:37,  4.47it/s]
2022-03-20 00:59:37,421 - INFO - tqdm - f1: 0.8649, accuracy: 0.9157, batch_loss: 0.1911, loss: 0.2287 ||:   7%|6         | 739/11253 [01:12<37:52,  4.63it/s]
2022-03-20 00:59:48,450 - INFO - tqdm - f1: 0.8650, accuracy: 0.9156, batch_loss: 0.4986, loss: 0.2313 ||:   8%|7         | 853/11253 [01:23<38:07,  4.55it/s]
2022-03-20 00:59:59,050 - INFO - tqdm - f1: 0.8645, accuracy: 0.9145, batch_loss: 0.1878, loss: 0.2338 ||:   9%|8         | 963/11253 [01:34<37:45,  4.54it/s]
2022-03-20 01:00:09,781 - INFO - tqdm - f1: 0.8629, accuracy: 0.9134, batch_loss: 0.1274, loss: 0.2351 ||:  10%|9         | 1073/11253 [01:45<37:42,  4.50it/s]
2022-03-20 01:00:20,339 - INFO - tqdm - f1: 0.8628, accuracy: 0.9134, batch_loss: 0.1067, loss: 0.2350 ||:  11%|#         | 1183/11253 [01:55<36:41,  4.57it/s]
2022-03-20 01:00:31,001 - INFO - tqdm - f1: 0.8638, accuracy: 0.9142, batch_loss: 0.1081, loss: 0.2329 ||:  11%|#1        | 1293/11253 [02:06<37:03,  4.48it/s]
2022-03-20 01:00:41,449 - INFO - tqdm - f1: 0.8635, accuracy: 0.9142, batch_loss: 0.2359, loss: 0.2323 ||:  12%|#2        | 1403/11253 [02:16<29:35,  5.55it/s]
2022-03-20 01:00:52,581 - INFO - tqdm - f1: 0.8639, accuracy: 0.9147, batch_loss: 0.4585, loss: 0.2313 ||:  13%|#3        | 1519/11253 [02:28<35:21,  4.59it/s]
2022-03-20 01:01:03,104 - INFO - tqdm - f1: 0.8643, accuracy: 0.9149, batch_loss: 0.2981, loss: 0.2312 ||:  14%|#4        | 1631/11253 [02:38<29:23,  5.46it/s]
2022-03-20 01:01:13,200 - INFO - tqdm - f1: 0.8637, accuracy: 0.9145, batch_loss: 0.3035, loss: 0.2310 ||:  16%|#5        | 1745/11253 [02:48<10:46, 14.70it/s]
2022-03-20 01:01:23,342 - INFO - tqdm - f1: 0.8636, accuracy: 0.9146, batch_loss: 0.1720, loss: 0.2304 ||:  16%|#6        | 1845/11253 [02:58<11:37, 13.49it/s]
2022-03-20 01:01:33,432 - INFO - tqdm - f1: 0.8634, accuracy: 0.9142, batch_loss: 0.6893, loss: 0.2315 ||:  17%|#7        | 1947/11253 [03:08<12:06, 12.81it/s]
2022-03-20 01:01:43,446 - INFO - tqdm - f1: 0.8630, accuracy: 0.9145, batch_loss: 0.3195, loss: 0.2305 ||:  18%|#8        | 2045/11253 [03:18<16:24,  9.35it/s]
2022-03-20 01:01:53,834 - INFO - tqdm - f1: 0.8622, accuracy: 0.9138, batch_loss: 0.1046, loss: 0.2319 ||:  19%|#9        | 2151/11253 [03:29<33:30,  4.53it/s]
2022-03-20 01:02:04,652 - INFO - tqdm - f1: 0.8619, accuracy: 0.9137, batch_loss: 0.0902, loss: 0.2314 ||:  20%|##        | 2265/11253 [03:40<32:31,  4.60it/s]
2022-03-20 01:02:15,580 - INFO - tqdm - f1: 0.8615, accuracy: 0.9136, batch_loss: 0.2276, loss: 0.2308 ||:  21%|##1       | 2381/11253 [03:51<32:40,  4.53it/s]
2022-03-20 01:02:26,363 - INFO - tqdm - f1: 0.8608, accuracy: 0.9129, batch_loss: 0.4016, loss: 0.2327 ||:  22%|##2       | 2497/11253 [04:01<30:50,  4.73it/s]
2022-03-20 01:02:37,234 - INFO - tqdm - f1: 0.8608, accuracy: 0.9129, batch_loss: 0.0746, loss: 0.2332 ||:  23%|##3       | 2613/11253 [04:12<31:13,  4.61it/s]
2022-03-20 01:02:48,113 - INFO - tqdm - f1: 0.8603, accuracy: 0.9127, batch_loss: 0.3349, loss: 0.2346 ||:  24%|##4       | 2727/11253 [04:23<31:12,  4.55it/s]
2022-03-20 01:02:58,118 - INFO - tqdm - f1: 0.8603, accuracy: 0.9128, batch_loss: 0.0413, loss: 0.2348 ||:  25%|##5       | 2841/11253 [04:33<09:31, 14.72it/s]
2022-03-20 01:03:08,175 - INFO - tqdm - f1: 0.8607, accuracy: 0.9129, batch_loss: 0.2411, loss: 0.2348 ||:  26%|##6       | 2941/11253 [04:43<10:10, 13.62it/s]
2022-03-20 01:03:18,253 - INFO - tqdm - f1: 0.8609, accuracy: 0.9130, batch_loss: 0.0761, loss: 0.2347 ||:  27%|##7       | 3043/11253 [04:53<10:27, 13.09it/s]
2022-03-20 01:03:28,270 - INFO - tqdm - f1: 0.8613, accuracy: 0.9130, batch_loss: 0.1843, loss: 0.2347 ||:  28%|##7       | 3145/11253 [05:03<12:23, 10.91it/s]
2022-03-20 01:03:38,338 - INFO - tqdm - f1: 0.8613, accuracy: 0.9129, batch_loss: 0.2281, loss: 0.2350 ||:  29%|##8       | 3247/11253 [05:13<19:10,  6.96it/s]
2022-03-20 01:03:48,699 - INFO - tqdm - f1: 0.8618, accuracy: 0.9129, batch_loss: 0.3498, loss: 0.2355 ||:  30%|##9       | 3353/11253 [05:24<29:03,  4.53it/s]
2022-03-20 01:03:59,584 - INFO - tqdm - f1: 0.8614, accuracy: 0.9126, batch_loss: 0.2467, loss: 0.2366 ||:  31%|###       | 3467/11253 [05:35<29:15,  4.44it/s]
2022-03-20 01:04:09,687 - INFO - tqdm - f1: 0.8617, accuracy: 0.9128, batch_loss: 0.2477, loss: 0.2364 ||:  32%|###1      | 3579/11253 [05:45<15:47,  8.10it/s]
2022-03-20 01:04:19,714 - INFO - tqdm - f1: 0.8622, accuracy: 0.9130, batch_loss: 0.0418, loss: 0.2362 ||:  33%|###2      | 3685/11253 [05:55<08:49, 14.29it/s]
2022-03-20 01:04:29,814 - INFO - tqdm - f1: 0.8618, accuracy: 0.9130, batch_loss: 0.3128, loss: 0.2363 ||:  34%|###3      | 3787/11253 [06:05<09:32, 13.04it/s]
2022-03-20 01:04:39,941 - INFO - tqdm - f1: 0.8613, accuracy: 0.9127, batch_loss: 0.4733, loss: 0.2369 ||:  35%|###4      | 3891/11253 [06:15<12:43,  9.65it/s]
2022-03-20 01:04:50,066 - INFO - tqdm - f1: 0.8613, accuracy: 0.9128, batch_loss: 0.1614, loss: 0.2375 ||:  35%|###5      | 3993/11253 [06:25<20:56,  5.78it/s]
2022-03-20 01:05:00,805 - INFO - tqdm - f1: 0.8614, accuracy: 0.9128, batch_loss: 0.2284, loss: 0.2375 ||:  36%|###6      | 4105/11253 [06:36<25:54,  4.60it/s]
2022-03-20 01:05:11,868 - INFO - tqdm - f1: 0.8619, accuracy: 0.9129, batch_loss: 0.3924, loss: 0.2375 ||:  38%|###7      | 4221/11253 [06:47<26:14,  4.47it/s]
2022-03-20 01:05:22,674 - INFO - tqdm - f1: 0.8619, accuracy: 0.9130, batch_loss: 0.3367, loss: 0.2380 ||:  39%|###8      | 4333/11253 [06:58<25:27,  4.53it/s]
2022-03-20 01:05:33,204 - INFO - tqdm - f1: 0.8621, accuracy: 0.9132, batch_loss: 0.2763, loss: 0.2376 ||:  39%|###9      | 4441/11253 [07:08<25:08,  4.51it/s]
2022-03-20 01:05:43,794 - INFO - tqdm - f1: 0.8617, accuracy: 0.9129, batch_loss: 0.5443, loss: 0.2385 ||:  40%|####      | 4551/11253 [07:19<24:15,  4.61it/s]
2022-03-20 01:05:54,571 - INFO - tqdm - f1: 0.8616, accuracy: 0.9126, batch_loss: 0.1726, loss: 0.2390 ||:  41%|####1     | 4663/11253 [07:30<24:03,  4.57it/s]
2022-03-20 01:06:05,588 - INFO - tqdm - f1: 0.8613, accuracy: 0.9124, batch_loss: 0.0871, loss: 0.2395 ||:  42%|####2     | 4777/11253 [07:41<23:49,  4.53it/s]
2022-03-20 01:06:15,589 - INFO - tqdm - f1: 0.8615, accuracy: 0.9126, batch_loss: 0.5010, loss: 0.2392 ||:  43%|####3     | 4893/11253 [07:51<07:04, 14.99it/s]
2022-03-20 01:06:26,703 - INFO - tqdm - f1: 0.8617, accuracy: 0.9126, batch_loss: 0.5635, loss: 0.2392 ||:  45%|####4     | 5011/11253 [08:02<22:29,  4.62it/s]
2022-03-20 01:06:37,510 - INFO - tqdm - f1: 0.8613, accuracy: 0.9124, batch_loss: 0.0175, loss: 0.2398 ||:  46%|####5     | 5123/11253 [08:12<22:20,  4.57it/s]
2022-03-20 01:06:48,374 - INFO - tqdm - f1: 0.8614, accuracy: 0.9123, batch_loss: 0.3912, loss: 0.2398 ||:  47%|####6     | 5235/11253 [08:23<21:35,  4.64it/s]
2022-03-20 01:06:59,465 - INFO - tqdm - f1: 0.8615, accuracy: 0.9123, batch_loss: 0.2100, loss: 0.2400 ||:  48%|####7     | 5351/11253 [08:34<22:05,  4.45it/s]
2022-03-20 01:07:10,372 - INFO - tqdm - f1: 0.8617, accuracy: 0.9123, batch_loss: 0.0509, loss: 0.2402 ||:  49%|####8     | 5465/11253 [08:45<21:26,  4.50it/s]
2022-03-20 01:07:21,492 - INFO - tqdm - f1: 0.8615, accuracy: 0.9122, batch_loss: 0.3879, loss: 0.2403 ||:  50%|####9     | 5581/11253 [08:56<20:43,  4.56it/s]
2022-03-20 01:07:32,323 - INFO - tqdm - f1: 0.8614, accuracy: 0.9121, batch_loss: 0.3908, loss: 0.2409 ||:  51%|#####     | 5693/11253 [09:07<20:02,  4.62it/s]
2022-03-20 01:07:43,357 - INFO - tqdm - f1: 0.8617, accuracy: 0.9121, batch_loss: 0.1270, loss: 0.2409 ||:  52%|#####1    | 5803/11253 [09:18<19:45,  4.60it/s]
2022-03-20 01:07:54,157 - INFO - tqdm - f1: 0.8617, accuracy: 0.9121, batch_loss: 0.0914, loss: 0.2409 ||:  53%|#####2    | 5915/11253 [09:29<19:36,  4.54it/s]
2022-03-20 01:08:05,242 - INFO - tqdm - f1: 0.8616, accuracy: 0.9120, batch_loss: 0.3184, loss: 0.2412 ||:  54%|#####3    | 6029/11253 [09:40<19:40,  4.42it/s]
2022-03-20 01:08:16,136 - INFO - tqdm - f1: 0.8615, accuracy: 0.9118, batch_loss: 0.1519, loss: 0.2415 ||:  55%|#####4    | 6139/11253 [09:51<19:18,  4.41it/s]
2022-03-20 01:08:27,120 - INFO - tqdm - f1: 0.8615, accuracy: 0.9118, batch_loss: 0.1110, loss: 0.2414 ||:  56%|#####5    | 6253/11253 [10:02<17:51,  4.67it/s]
2022-03-20 01:08:37,988 - INFO - tqdm - f1: 0.8616, accuracy: 0.9117, batch_loss: 0.2307, loss: 0.2414 ||:  57%|#####6    | 6365/11253 [10:13<17:36,  4.63it/s]
2022-03-20 01:08:49,048 - INFO - tqdm - f1: 0.8612, accuracy: 0.9116, batch_loss: 0.0880, loss: 0.2416 ||:  58%|#####7    | 6481/11253 [10:24<17:21,  4.58it/s]
2022-03-20 01:08:59,919 - INFO - tqdm - f1: 0.8611, accuracy: 0.9115, batch_loss: 0.4086, loss: 0.2417 ||:  59%|#####8    | 6593/11253 [10:35<16:53,  4.60it/s]
2022-03-20 01:09:10,514 - INFO - tqdm - f1: 0.8613, accuracy: 0.9116, batch_loss: 0.6147, loss: 0.2418 ||:  60%|#####9    | 6705/11253 [10:45<16:27,  4.60it/s]
2022-03-20 01:09:21,470 - INFO - tqdm - f1: 0.8609, accuracy: 0.9113, batch_loss: 0.6708, loss: 0.2426 ||:  61%|######    | 6819/11253 [10:56<16:02,  4.61it/s]
2022-03-20 01:09:32,257 - INFO - tqdm - f1: 0.8607, accuracy: 0.9112, batch_loss: 0.1496, loss: 0.2429 ||:  62%|######1   | 6931/11253 [11:07<15:47,  4.56it/s]
2022-03-20 01:09:43,096 - INFO - tqdm - f1: 0.8608, accuracy: 0.9113, batch_loss: 0.1919, loss: 0.2427 ||:  63%|######2   | 7043/11253 [11:18<15:28,  4.53it/s]
2022-03-20 01:09:53,955 - INFO - tqdm - f1: 0.8609, accuracy: 0.9114, batch_loss: 0.2928, loss: 0.2429 ||:  64%|######3   | 7157/11253 [11:29<14:55,  4.57it/s]
2022-03-20 01:10:04,712 - INFO - tqdm - f1: 0.8610, accuracy: 0.9114, batch_loss: 0.0219, loss: 0.2431 ||:  65%|######4   | 7271/11253 [11:40<14:24,  4.61it/s]
2022-03-20 01:10:15,143 - INFO - tqdm - f1: 0.8607, accuracy: 0.9113, batch_loss: 0.1277, loss: 0.2433 ||:  66%|######5   | 7379/11253 [11:50<14:05,  4.58it/s]
2022-03-20 01:10:26,115 - INFO - tqdm - f1: 0.8606, accuracy: 0.9112, batch_loss: 0.6060, loss: 0.2433 ||:  67%|######6   | 7495/11253 [12:01<13:41,  4.57it/s]
2022-03-20 01:10:36,872 - INFO - tqdm - f1: 0.8607, accuracy: 0.9113, batch_loss: 0.4377, loss: 0.2433 ||:  68%|######7   | 7607/11253 [12:12<13:00,  4.67it/s]
2022-03-20 01:10:47,851 - INFO - tqdm - f1: 0.8605, accuracy: 0.9113, batch_loss: 0.3023, loss: 0.2433 ||:  69%|######8   | 7723/11253 [12:23<12:44,  4.62it/s]
2022-03-20 01:10:58,339 - INFO - tqdm - f1: 0.8604, accuracy: 0.9112, batch_loss: 0.4702, loss: 0.2435 ||:  70%|######9   | 7833/11253 [12:33<12:25,  4.59it/s]
2022-03-20 01:11:09,094 - INFO - tqdm - f1: 0.8604, accuracy: 0.9111, batch_loss: 0.3104, loss: 0.2436 ||:  71%|#######   | 7947/11253 [12:44<12:11,  4.52it/s]
2022-03-20 01:11:19,765 - INFO - tqdm - f1: 0.8603, accuracy: 0.9111, batch_loss: 0.5342, loss: 0.2438 ||:  72%|#######1  | 8057/11253 [12:55<11:37,  4.58it/s]
2022-03-20 01:11:30,174 - INFO - tqdm - f1: 0.8604, accuracy: 0.9111, batch_loss: 0.1628, loss: 0.2438 ||:  73%|#######2  | 8165/11253 [13:05<11:16,  4.57it/s]
2022-03-20 01:11:41,198 - INFO - tqdm - f1: 0.8603, accuracy: 0.9110, batch_loss: 0.2270, loss: 0.2439 ||:  74%|#######3  | 8281/11253 [13:16<10:57,  4.52it/s]
2022-03-20 01:11:51,451 - INFO - tqdm - f1: 0.8604, accuracy: 0.9111, batch_loss: 0.6847, loss: 0.2439 ||:  75%|#######4  | 8391/11253 [13:26<08:39,  5.51it/s]
2022-03-20 01:12:01,510 - INFO - tqdm - f1: 0.8603, accuracy: 0.9110, batch_loss: 0.1997, loss: 0.2442 ||:  76%|#######5  | 8503/11253 [13:36<03:22, 13.55it/s]
2022-03-20 01:12:11,518 - INFO - tqdm - f1: 0.8603, accuracy: 0.9110, batch_loss: 0.1498, loss: 0.2442 ||:  76%|#######6  | 8605/11253 [13:47<03:04, 14.31it/s]
2022-03-20 01:12:21,575 - INFO - tqdm - f1: 0.8602, accuracy: 0.9110, batch_loss: 0.1294, loss: 0.2443 ||:  77%|#######7  | 8709/11253 [13:57<04:02, 10.51it/s]
2022-03-20 01:12:31,765 - INFO - tqdm - f1: 0.8600, accuracy: 0.9108, batch_loss: 0.1813, loss: 0.2445 ||:  78%|#######8  | 8811/11253 [14:07<08:58,  4.54it/s]
2022-03-20 01:12:42,500 - INFO - tqdm - f1: 0.8599, accuracy: 0.9108, batch_loss: 0.1629, loss: 0.2446 ||:  79%|#######9  | 8923/11253 [14:17<08:25,  4.61it/s]
2022-03-20 01:12:53,245 - INFO - tqdm - f1: 0.8597, accuracy: 0.9107, batch_loss: 0.1487, loss: 0.2447 ||:  80%|########  | 9035/11253 [14:28<08:25,  4.39it/s]
2022-03-20 01:13:04,146 - INFO - tqdm - f1: 0.8595, accuracy: 0.9106, batch_loss: 0.5119, loss: 0.2450 ||:  81%|########1 | 9147/11253 [14:39<07:34,  4.63it/s]
2022-03-20 01:13:14,835 - INFO - tqdm - f1: 0.8595, accuracy: 0.9106, batch_loss: 0.1644, loss: 0.2451 ||:  82%|########2 | 9257/11253 [14:50<07:26,  4.47it/s]
2022-03-20 01:13:25,518 - INFO - tqdm - f1: 0.8593, accuracy: 0.9104, batch_loss: 0.0178, loss: 0.2454 ||:  83%|########3 | 9367/11253 [15:01<06:55,  4.53it/s]
2022-03-20 01:13:35,598 - INFO - tqdm - f1: 0.8592, accuracy: 0.9103, batch_loss: 0.5108, loss: 0.2459 ||:  84%|########4 | 9483/11253 [15:11<01:56, 15.19it/s]
2022-03-20 01:13:45,640 - INFO - tqdm - f1: 0.8591, accuracy: 0.9102, batch_loss: 0.4955, loss: 0.2460 ||:  85%|########5 | 9601/11253 [15:21<01:52, 14.68it/s]
2022-03-20 01:13:55,658 - INFO - tqdm - f1: 0.8589, accuracy: 0.9100, batch_loss: 0.2735, loss: 0.2464 ||:  86%|########6 | 9697/11253 [15:31<02:07, 12.23it/s]
2022-03-20 01:14:05,833 - INFO - tqdm - f1: 0.8588, accuracy: 0.9099, batch_loss: 0.1192, loss: 0.2467 ||:  87%|########7 | 9795/11253 [15:41<04:25,  5.49it/s]
2022-03-20 01:14:16,562 - INFO - tqdm - f1: 0.8588, accuracy: 0.9098, batch_loss: 0.5645, loss: 0.2468 ||:  88%|########8 | 9907/11253 [15:52<04:49,  4.65it/s]
2022-03-20 01:14:27,397 - INFO - tqdm - f1: 0.8590, accuracy: 0.9099, batch_loss: 0.2466, loss: 0.2467 ||:  89%|########9 | 10019/11253 [16:02<04:34,  4.50it/s]
2022-03-20 01:14:37,465 - INFO - tqdm - f1: 0.8589, accuracy: 0.9099, batch_loss: 0.6553, loss: 0.2468 ||:  90%|######### | 10133/11253 [16:12<01:22, 13.59it/s]
2022-03-20 01:14:47,466 - INFO - tqdm - f1: 0.8588, accuracy: 0.9098, batch_loss: 0.1496, loss: 0.2469 ||:  91%|#########1| 10279/11253 [16:22<01:00, 16.06it/s]
2022-03-20 01:14:57,497 - INFO - tqdm - f1: 0.8587, accuracy: 0.9097, batch_loss: 0.5174, loss: 0.2470 ||:  93%|#########2| 10427/11253 [16:32<00:57, 14.27it/s]
2022-03-20 01:15:07,623 - INFO - tqdm - f1: 0.8585, accuracy: 0.9095, batch_loss: 0.7302, loss: 0.2474 ||:  94%|#########4| 10579/11253 [16:43<00:46, 14.65it/s]
2022-03-20 01:15:17,644 - INFO - tqdm - f1: 0.8585, accuracy: 0.9095, batch_loss: 0.1452, loss: 0.2479 ||:  95%|#########5| 10729/11253 [16:53<00:34, 15.09it/s]
2022-03-20 01:15:27,764 - INFO - tqdm - f1: 0.8584, accuracy: 0.9093, batch_loss: 0.0458, loss: 0.2483 ||:  97%|#########6| 10883/11253 [17:03<00:25, 14.76it/s]
2022-03-20 01:15:37,877 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.1549, loss: 0.2482 ||:  98%|#########8| 11035/11253 [17:13<00:13, 15.68it/s]
2022-03-20 01:15:48,006 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.3938, loss: 0.2482 ||:  99%|#########9| 11187/11253 [17:23<00:04, 14.73it/s]
2022-03-20 01:15:48,693 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.7662, loss: 0.2483 ||: 100%|#########9| 11197/11253 [17:24<00:03, 15.06it/s]
2022-03-20 01:15:48,842 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.1702, loss: 0.2483 ||: 100%|#########9| 11199/11253 [17:24<00:03, 14.55it/s]
2022-03-20 01:15:48,978 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.3746, loss: 0.2483 ||: 100%|#########9| 11201/11253 [17:24<00:03, 14.57it/s]
2022-03-20 01:15:49,111 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.1017, loss: 0.2483 ||: 100%|#########9| 11203/11253 [17:24<00:03, 14.72it/s]
2022-03-20 01:15:49,250 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.1874, loss: 0.2483 ||: 100%|#########9| 11205/11253 [17:24<00:03, 14.62it/s]
2022-03-20 01:15:49,408 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.3205, loss: 0.2483 ||: 100%|#########9| 11207/11253 [17:24<00:03, 13.95it/s]
2022-03-20 01:15:49,545 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.2875, loss: 0.2483 ||: 100%|#########9| 11209/11253 [17:25<00:03, 14.15it/s]
2022-03-20 01:15:49,675 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.2789, loss: 0.2484 ||: 100%|#########9| 11211/11253 [17:25<00:02, 14.50it/s]
2022-03-20 01:15:49,802 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.3911, loss: 0.2484 ||: 100%|#########9| 11213/11253 [17:25<00:02, 14.87it/s]
2022-03-20 01:15:49,938 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.3768, loss: 0.2484 ||: 100%|#########9| 11215/11253 [17:25<00:02, 14.82it/s]
2022-03-20 01:15:50,076 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.1789, loss: 0.2484 ||: 100%|#########9| 11217/11253 [17:25<00:02, 14.69it/s]
2022-03-20 01:15:50,240 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.3571, loss: 0.2484 ||: 100%|#########9| 11219/11253 [17:25<00:02, 13.84it/s]
2022-03-20 01:15:50,390 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.1216, loss: 0.2484 ||: 100%|#########9| 11221/11253 [17:25<00:02, 13.70it/s]
2022-03-20 01:15:50,522 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.5902, loss: 0.2484 ||: 100%|#########9| 11223/11253 [17:26<00:02, 14.10it/s]
2022-03-20 01:15:50,652 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.1077, loss: 0.2484 ||: 100%|#########9| 11225/11253 [17:26<00:01, 14.45it/s]
2022-03-20 01:15:50,795 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.3268, loss: 0.2484 ||: 100%|#########9| 11227/11253 [17:26<00:01, 14.33it/s]
2022-03-20 01:15:50,950 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.3468, loss: 0.2484 ||: 100%|#########9| 11229/11253 [17:26<00:01, 13.87it/s]
2022-03-20 01:15:51,078 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.4742, loss: 0.2484 ||: 100%|#########9| 11231/11253 [17:26<00:01, 14.36it/s]
2022-03-20 01:15:51,226 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.1682, loss: 0.2484 ||: 100%|#########9| 11233/11253 [17:26<00:01, 14.07it/s]
2022-03-20 01:15:51,361 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.1820, loss: 0.2484 ||: 100%|#########9| 11235/11253 [17:26<00:01, 14.28it/s]
2022-03-20 01:15:51,491 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.3920, loss: 0.2484 ||: 100%|#########9| 11237/11253 [17:26<00:01, 14.61it/s]
2022-03-20 01:15:51,625 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.1284, loss: 0.2484 ||: 100%|#########9| 11239/11253 [17:27<00:00, 14.72it/s]
2022-03-20 01:15:51,749 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.5863, loss: 0.2484 ||: 100%|#########9| 11241/11253 [17:27<00:00, 15.10it/s]
2022-03-20 01:15:51,885 - INFO - tqdm - f1: 0.8585, accuracy: 0.9094, batch_loss: 0.0089, loss: 0.2484 ||: 100%|#########9| 11243/11253 [17:27<00:00, 14.97it/s]
2022-03-20 01:15:52,011 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.6754, loss: 0.2484 ||: 100%|#########9| 11245/11253 [17:27<00:00, 15.25it/s]
2022-03-20 01:15:52,159 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.4883, loss: 0.2485 ||: 100%|#########9| 11247/11253 [17:27<00:00, 14.66it/s]
2022-03-20 01:15:52,325 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.5307, loss: 0.2485 ||: 100%|#########9| 11249/11253 [17:27<00:00, 13.78it/s]
2022-03-20 01:15:52,475 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.6146, loss: 0.2485 ||: 100%|#########9| 11251/11253 [17:27<00:00, 13.63it/s]
2022-03-20 01:15:52,615 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.0609, loss: 0.2485 ||: 100%|##########| 11253/11253 [17:28<00:00, 13.84it/s]
2022-03-20 01:15:52,680 - INFO - tqdm - f1: 0.8585, accuracy: 0.9093, batch_loss: 0.0609, loss: 0.2485 ||: 100%|##########| 11253/11253 [17:28<00:00, 10.74it/s]
2022-03-20 01:15:52,687 - INFO - allennlp.training.trainer - Validating
2022-03-20 01:15:52,691 - INFO - tqdm - 0%|          | 0/1889 [00:00<?, ?it/s]
2022-03-20 01:16:02,729 - INFO - tqdm - f1: 0.8098, accuracy: 0.8711, batch_loss: 0.3099, loss: 0.3909 ||:  23%|##2       | 431/1889 [00:10<00:33, 43.37it/s]
2022-03-20 01:16:12,797 - INFO - tqdm - f1: 0.8106, accuracy: 0.8732, batch_loss: 0.4595, loss: 0.3821 ||:  46%|####6     | 878/1889 [00:20<00:23, 43.81it/s]
2022-03-20 01:16:22,810 - INFO - tqdm - f1: 0.8147, accuracy: 0.8737, batch_loss: 0.0663, loss: 0.3891 ||:  70%|######9   | 1316/1889 [00:30<00:13, 42.10it/s]
2022-03-20 01:16:32,895 - INFO - tqdm - f1: 0.8168, accuracy: 0.8737, batch_loss: 0.2079, loss: 0.3897 ||:  86%|########5 | 1618/1889 [00:40<00:13, 20.19it/s]
2022-03-20 01:16:42,009 - INFO - tqdm - f1: 0.8168, accuracy: 0.8737, batch_loss: 1.2541, loss: 0.3893 ||: 100%|#########9| 1884/1889 [00:49<00:00, 36.17it/s]
2022-03-20 01:16:42,135 - INFO - tqdm - f1: 0.8168, accuracy: 0.8738, batch_loss: 0.5314, loss: 0.3893 ||: 100%|##########| 1889/1889 [00:49<00:00, 37.28it/s]
2022-03-20 01:16:42,151 - INFO - tqdm - f1: 0.8168, accuracy: 0.8738, batch_loss: 0.5314, loss: 0.3893 ||: 100%|##########| 1889/1889 [00:49<00:00, 38.19it/s]
2022-03-20 01:16:42,157 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-20 01:16:42,160 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-20 01:16:42,476 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-20 01:16:42,480 - INFO - allennlp.training.util - Iterating over dataset
2022-03-20 01:16:42,482 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-20 01:16:42,517 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-20 01:16:42,520 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-20 01:16:52,496 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.37 ||: : 266it [00:10, 36.17it/s]
2022-03-20 01:17:02,585 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.38 ||: : 534it [00:20, 29.16it/s]
2022-03-20 01:17:12,764 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.37 ||: : 807it [00:30, 12.09it/s]
2022-03-20 01:17:23,175 - INFO - tqdm - f1: 0.82, accuracy: 0.87, loss: 0.37 ||: : 1113it [00:40, 19.87it/s]
2022-03-20 01:17:33,181 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.37 ||: : 1388it [00:50, 33.74it/s]
2022-03-20 01:17:43,266 - INFO - tqdm - f1: 0.81, accuracy: 0.87, loss: 0.37 ||: : 1649it [01:00, 37.21it/s]
2022-03-20 01:17:51,615 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 1,
  "peak_worker_0_memory_MB": 8640.77734375,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "1:17:56.031645",
  "training_start_epoch": 0,
  "training_epochs": 3,
  "epoch": 3,
  "training_f1": 0.8460006594657898,
  "training_accuracy": 0.8989002443901355,
  "training_loss": 0.27708104092662195,
  "training_worker_0_memory_MB": 8640.77734375,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.8052799105644226,
  "validation_accuracy": 0.8710115186018801,
  "validation_loss": 0.3876093068949448,
  "best_validation_f1": 0.8220285773277283,
  "best_validation_accuracy": 0.8775321064477691,
  "best_validation_loss": 0.3493192914021416,
  "test_f1": 0.8129465222358704,
  "test_accuracy": 0.8692218350754937,
  "test_loss": 0.37443572805943304
}
2022-03-20 01:17:51,820 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/rct-20k_base/model.tar.gz
