2022-03-22 11:32:12,199 - INFO - allennlp.common.params - random_seed = 13
2022-03-22 11:32:12,217 - INFO - allennlp.common.params - numpy_seed = 13
2022-03-22 11:32:12,217 - INFO - allennlp.common.params - pytorch_seed = 13
2022-03-22 11:32:12,230 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-22 11:32:12,238 - INFO - allennlp.common.params - type = default
2022-03-22 11:32:12,238 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-22 11:32:12,262 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-22 11:32:12,285 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-22 11:32:12,285 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-22 11:32:12,286 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-22 11:32:12,286 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-22 11:32:12,305 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-22 11:32:27,887 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-22 11:32:27,889 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-22 11:32:27,889 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-22 11:32:27,889 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-22 11:32:27,889 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-22 11:32:27,889 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-22 11:32:27,889 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-22 11:32:27,908 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-22 11:32:27,909 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-22 11:32:27,909 - INFO - allennlp.common.params - train_data_path = datasets/imdb/train.jsonl
2022-03-22 11:32:27,930 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f02170c31d0>
2022-03-22 11:32:27,949 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-22 11:32:27,949 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-22 11:32:27,969 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-22 11:32:27,992 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-22 11:32:27,993 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-22 11:32:27,993 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-22 11:32:27,993 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-22 11:32:27,993 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-22 11:32:28,013 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-22 11:32:28,033 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-22 11:32:28,033 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-22 11:32:28,033 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-22 11:32:28,053 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-22 11:32:28,053 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-22 11:32:28,053 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-22 11:32:28,053 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-22 11:32:28,073 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-22 11:32:28,073 - INFO - allennlp.common.params - validation_data_path = datasets/imdb/dev.jsonl
2022-03-22 11:32:28,073 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-22 11:32:28,073 - INFO - allennlp.common.params - test_data_path = datasets/imdb/test.jsonl
2022-03-22 11:32:28,073 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-22 11:32:28,073 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-22 11:32:28,073 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-22 11:32:28,074 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-22 11:32:28,074 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-22 11:32:28,074 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-22 11:32:28,074 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-22 11:32:28,094 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-22 11:32:28,094 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-22 11:32:28,094 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-22 11:32:28,094 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-22 11:32:28,094 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-22 11:32:28,113 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-22 11:32:28,114 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-22 11:32:28,114 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-22 11:32:28,114 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-22 11:32:28,115 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-22 11:32:38,139 - INFO - tqdm - loading instances: 6023it [00:10, 463.43it/s]
2022-03-22 11:32:48,487 - INFO - tqdm - loading instances: 12456it [00:20, 249.49it/s]
2022-03-22 11:32:58,509 - INFO - tqdm - loading instances: 19104it [00:30, 723.33it/s]
2022-03-22 11:32:59,707 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-22 11:32:59,721 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-22 11:32:59,721 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-22 11:32:59,721 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-22 11:32:59,721 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-22 11:32:59,721 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-22 11:32:59,741 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-22 11:32:59,741 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-22 11:32:59,741 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-22 11:32:59,742 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-22 11:32:59,742 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-22 11:32:59,762 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-22 11:32:59,762 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-22 11:32:59,762 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-22 11:32:59,762 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-22 11:33:07,947 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-22 11:33:07,952 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-22 11:33:07,952 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-22 11:33:07,952 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-22 11:33:07,972 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-22 11:33:07,972 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-22 11:33:07,992 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-22 11:33:07,993 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-22 11:33:07,993 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-22 11:33:08,013 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-22 11:33:08,013 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-22 11:33:08,013 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-22 11:33:08,033 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-22 11:33:08,033 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-22 11:33:08,034 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-22 11:33:18,127 - INFO - tqdm - loading instances: 6315it [00:10, 737.87it/s]
2022-03-22 11:33:28,224 - INFO - tqdm - loading instances: 12452it [00:20, 703.27it/s]
2022-03-22 11:33:38,225 - INFO - tqdm - loading instances: 18245it [00:30, 756.10it/s]
2022-03-22 11:33:47,842 - INFO - allennlp.common.params - type = from_instances
2022-03-22 11:33:47,850 - INFO - allennlp.common.params - min_count = None
2022-03-22 11:33:47,850 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-22 11:33:47,850 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-22 11:33:47,850 - INFO - allennlp.common.params - pretrained_files = None
2022-03-22 11:33:47,871 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-22 11:33:47,871 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-22 11:33:47,871 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-22 11:33:47,871 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-22 11:33:47,871 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-22 11:33:47,892 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-22 11:33:47,892 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-22 11:33:49,198 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-22 11:33:49,209 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-22 11:33:49,209 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-22 11:33:49,229 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-22 11:33:49,229 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-22 11:33:49,229 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-22 11:33:49,229 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-22 11:33:49,229 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-22 11:33:49,229 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-22 11:33:49,230 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-22 11:33:49,230 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-22 11:33:49,230 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-22 11:33:49,230 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-22 11:33:56,212 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-22 11:33:56,212 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-22 11:33:56,212 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-22 11:33:56,212 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-22 11:33:56,212 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-22 11:33:56,213 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-22 11:33:56,213 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-22 11:33:56,213 - INFO - allennlp.common.params - type = tanh
2022-03-22 11:33:56,213 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-22 11:33:56,217 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-22 11:33:56,234 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-22 11:33:56,234 - INFO - allennlp.common.params - model.num_labels = None
2022-03-22 11:33:56,234 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-22 11:33:56,235 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f02170cf9d0>
2022-03-22 11:33:56,235 - INFO - allennlp.common.params - model.regularizer = None
2022-03-22 11:33:56,235 - INFO - allennlp.common.params - model.track_weights = False
2022-03-22 11:33:56,235 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-22 11:33:56,236 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-22 11:33:56,238 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-22 11:33:56,238 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-22 11:33:56,238 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-22 11:33:56,238 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-22 11:33:56,238 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-22 11:33:56,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-22 11:33:56,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-22 11:33:56,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-22 11:33:56,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-22 11:33:56,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-22 11:33:56,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-22 11:33:56,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-22 11:33:56,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-22 11:33:56,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-22 11:33:56,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-22 11:33:56,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-22 11:33:56,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-22 11:33:56,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-22 11:33:56,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-22 11:33:56,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-22 11:33:56,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-22 11:33:56,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-22 11:33:56,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-22 11:33:56,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-22 11:33:56,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-22 11:33:56,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-22 11:33:56,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-22 11:33:56,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-22 11:33:56,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-22 11:33:56,264 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-22 11:33:56,264 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-22 11:33:56,264 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-22 11:33:56,264 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-22 11:33:56,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-22 11:33:56,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-22 11:33:56,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-22 11:33:56,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-22 11:33:56,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-22 11:33:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-22 11:33:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-22 11:33:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-22 11:33:56,325 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-22 11:33:56,325 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-22 11:33:56,325 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-22 11:33:56,325 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-22 11:33:56,346 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-22 11:33:56,346 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-22 11:33:56,346 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-22 11:33:56,346 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-22 11:33:56,346 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-22 11:33:56,346 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-22 11:33:56,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-22 11:33:56,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-22 11:33:56,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-22 11:33:56,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-22 11:33:56,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-22 11:33:56,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-22 11:33:56,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-22 11:33:56,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-22 11:33:56,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-22 11:33:56,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-22 11:33:56,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-22 11:33:56,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-22 11:33:56,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-22 11:33:56,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-22 11:33:56,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-22 11:33:56,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-22 11:33:56,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-22 11:33:56,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-22 11:33:56,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-22 11:33:56,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-22 11:33:56,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-22 11:33:56,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-22 11:33:56,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-22 11:33:56,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-22 11:33:56,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-22 11:33:56,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-22 11:33:56,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-22 11:33:56,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-22 11:33:56,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-22 11:33:56,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-22 11:33:56,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-22 11:33:56,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-22 11:33:56,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-22 11:33:56,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-22 11:33:56,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-22 11:33:56,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-22 11:33:56,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-22 11:33:56,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-22 11:33:56,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-22 11:33:56,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-22 11:33:56,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-22 11:33:56,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-22 11:33:56,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-22 11:33:56,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-22 11:33:56,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-22 11:33:56,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-22 11:33:56,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-22 11:33:56,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-22 11:33:56,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-22 11:33:56,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-22 11:33:56,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-22 11:33:56,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-22 11:33:56,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-22 11:33:56,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-22 11:33:56,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-22 11:33:56,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-22 11:33:56,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-22 11:33:56,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-22 11:33:56,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-22 11:33:56,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-22 11:33:56,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-22 11:33:56,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-22 11:33:56,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-22 11:33:56,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-22 11:33:56,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-22 11:33:56,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-22 11:33:56,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-22 11:33:56,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-22 11:33:56,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-22 11:33:56,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-22 11:33:56,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-22 11:33:56,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-22 11:33:56,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-22 11:33:56,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-22 11:33:56,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-22 11:33:56,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-22 11:33:56,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-22 11:33:56,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-22 11:33:56,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-22 11:33:56,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-22 11:33:56,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-22 11:33:56,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-22 11:33:56,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-22 11:33:56,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-22 11:33:56,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-22 11:33:56,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-22 11:33:56,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-22 11:33:56,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-22 11:33:56,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-22 11:33:56,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-22 11:33:56,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-22 11:33:56,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-22 11:33:56,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-22 11:33:56,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-22 11:33:56,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-22 11:33:56,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-22 11:33:56,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-22 11:33:56,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-22 11:33:56,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-22 11:33:56,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-22 11:33:56,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-22 11:33:56,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-22 11:33:56,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-22 11:33:56,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-22 11:33:56,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-22 11:33:56,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-22 11:33:56,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-22 11:33:56,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-22 11:33:56,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-22 11:33:56,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-22 11:33:56,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-22 11:33:56,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-22 11:33:56,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-22 11:33:56,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-22 11:33:56,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-22 11:33:56,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-22 11:33:56,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-22 11:33:56,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-22 11:33:56,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-22 11:33:56,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-22 11:33:56,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-22 11:33:56,416 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-22 11:33:56,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-22 11:34:05,014 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-22 11:34:05,027 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-22 11:34:05,047 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-22 11:34:05,047 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-22 11:34:05,047 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-22 11:34:05,047 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-22 11:34:05,068 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-22 11:34:05,068 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-22 11:34:05,068 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-22 11:34:05,068 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-22 11:34:05,068 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-22 11:34:05,068 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-22 11:34:05,088 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-22 11:34:05,088 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-22 11:34:05,088 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-22 11:34:05,088 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-22 11:34:05,108 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-22 11:34:13,216 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-22 11:34:13,217 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-22 11:34:13,217 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-22 11:34:13,217 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-22 11:34:13,237 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-22 11:34:13,258 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-22 11:34:13,259 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-22 11:34:13,278 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias'], {'weight_decay': 0}
2022-03-22 11:34:13,279 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight'], {}
2022-03-22 11:34:13,279 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-22 11:34:13,280 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125237762
2022-03-22 11:34:13,282 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-22 11:34:13,283 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-22 11:34:13,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-22 11:34:13,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-22 11:34:13,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-22 11:34:13,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-22 11:34:13,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-22 11:34:13,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-22 11:34:13,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-22 11:34:13,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-22 11:34:13,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-22 11:34:13,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-22 11:34:13,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-22 11:34:13,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-22 11:34:13,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-22 11:34:13,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-22 11:34:13,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-22 11:34:13,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-22 11:34:13,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-22 11:34:13,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-22 11:34:13,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-22 11:34:13,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-22 11:34:13,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-22 11:34:13,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-22 11:34:13,305 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-22 11:34:13,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-22 11:34:13,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-22 11:34:13,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-22 11:34:13,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-22 11:34:13,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-22 11:34:13,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-22 11:34:13,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-22 11:34:13,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-22 11:34:13,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-22 11:34:13,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-22 11:34:13,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-22 11:34:13,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-22 11:34:13,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-22 11:34:13,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-22 11:34:13,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-22 11:34:13,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-22 11:34:13,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-22 11:34:13,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-22 11:34:13,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-22 11:34:13,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-22 11:34:13,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-22 11:34:13,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-22 11:34:13,308 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-22 11:34:13,308 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-22 11:34:13,308 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-22 11:34:13,308 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-22 11:34:13,308 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-22 11:34:13,308 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-22 11:34:13,308 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-22 11:34:13,308 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-22 11:34:13,308 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-22 11:34:13,308 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-22 11:34:13,308 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-22 11:34:13,309 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-22 11:34:13,309 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-22 11:34:13,309 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-22 11:34:13,309 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-22 11:34:13,309 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-22 11:34:13,309 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-22 11:34:13,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-22 11:34:13,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-22 11:34:13,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-22 11:34:13,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-22 11:34:13,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-22 11:34:13,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-22 11:34:13,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-22 11:34:13,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-22 11:34:13,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-22 11:34:13,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-22 11:34:13,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-22 11:34:13,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-22 11:34:13,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-22 11:34:13,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-22 11:34:13,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-22 11:34:13,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-22 11:34:13,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-22 11:34:13,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-22 11:34:13,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-22 11:34:13,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-22 11:34:13,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-22 11:34:13,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-22 11:34:13,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-22 11:34:13,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-22 11:34:13,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-22 11:34:13,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-22 11:34:13,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-22 11:34:13,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-22 11:34:13,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-22 11:34:13,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-22 11:34:13,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-22 11:34:13,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-22 11:34:13,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-22 11:34:13,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-22 11:34:13,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-22 11:34:13,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-22 11:34:13,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-22 11:34:13,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-22 11:34:13,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-22 11:34:13,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-22 11:34:13,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-22 11:34:13,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-22 11:34:13,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-22 11:34:13,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-22 11:34:13,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-22 11:34:13,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-22 11:34:13,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-22 11:34:13,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-22 11:34:13,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-22 11:34:13,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-22 11:34:13,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-22 11:34:13,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-22 11:34:13,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-22 11:34:13,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-22 11:34:13,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-22 11:34:13,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-22 11:34:13,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-22 11:34:13,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-22 11:34:13,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-22 11:34:13,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-22 11:34:13,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-22 11:34:13,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-22 11:34:13,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-22 11:34:13,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-22 11:34:13,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-22 11:34:13,361 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-22 11:34:13,361 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-22 11:34:13,382 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-22 11:34:13,382 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-22 11:34:13,382 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-22 11:34:13,406 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-22 11:34:13,423 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-22 11:34:13,423 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-22 11:34:13,423 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-22 11:34:13,423 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-22 11:34:13,426 - INFO - allennlp.training.trainer - Beginning training.
2022-03-22 11:34:13,444 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-22 11:34:13,444 - INFO - allennlp.training.trainer - Worker 0 memory usage: 9.6G
2022-03-22 11:34:13,444 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-22 11:34:13,465 - INFO - allennlp.training.trainer - Training
2022-03-22 11:34:13,485 - INFO - tqdm - 0%|          | 0/1250 [00:00<?, ?it/s]
2022-03-22 11:34:13,534 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-22 11:34:13,550 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-22 11:34:23,628 - INFO - tqdm - f1: 0.5108, accuracy: 0.5280, batch_loss: 0.6260, loss: 0.6928 ||:   2%|2         | 29/1250 [00:10<05:40,  3.58it/s]
2022-03-22 11:34:33,906 - INFO - tqdm - f1: 0.7003, accuracy: 0.7029, batch_loss: 0.2297, loss: 0.5453 ||:   5%|5         | 65/1250 [00:20<05:46,  3.42it/s]
2022-03-22 11:34:43,919 - INFO - tqdm - f1: 0.7756, accuracy: 0.7763, batch_loss: 0.2157, loss: 0.4507 ||:   8%|8         | 102/1250 [00:30<06:14,  3.07it/s]
2022-03-22 11:34:54,107 - INFO - tqdm - f1: 0.8114, accuracy: 0.8116, batch_loss: 0.1671, loss: 0.3962 ||:  11%|#1        | 139/1250 [00:40<05:09,  3.58it/s]
2022-03-22 11:35:04,136 - INFO - tqdm - f1: 0.8375, accuracy: 0.8376, batch_loss: 0.2902, loss: 0.3526 ||:  14%|#4        | 177/1250 [00:50<04:30,  3.96it/s]
2022-03-22 11:35:14,297 - INFO - tqdm - f1: 0.8516, accuracy: 0.8516, batch_loss: 0.4480, loss: 0.3288 ||:  17%|#7        | 216/1250 [01:00<05:26,  3.16it/s]
2022-03-22 11:35:24,341 - INFO - tqdm - f1: 0.8636, accuracy: 0.8636, batch_loss: 0.0829, loss: 0.3123 ||:  20%|##        | 253/1250 [01:10<05:02,  3.29it/s]
2022-03-22 11:35:34,606 - INFO - tqdm - f1: 0.8722, accuracy: 0.8722, batch_loss: 0.0399, loss: 0.2957 ||:  23%|##3       | 291/1250 [01:21<05:04,  3.15it/s]
2022-03-22 11:35:44,799 - INFO - tqdm - f1: 0.8804, accuracy: 0.8804, batch_loss: 0.0732, loss: 0.2804 ||:  26%|##6       | 327/1250 [01:31<04:52,  3.16it/s]
2022-03-22 11:35:54,830 - INFO - tqdm - f1: 0.8839, accuracy: 0.8839, batch_loss: 0.4954, loss: 0.2740 ||:  29%|##9       | 367/1250 [01:41<04:00,  3.67it/s]
2022-03-22 11:36:04,893 - INFO - tqdm - f1: 0.8873, accuracy: 0.8873, batch_loss: 0.3035, loss: 0.2679 ||:  32%|###2      | 403/1250 [01:51<03:52,  3.64it/s]
2022-03-22 11:36:14,963 - INFO - tqdm - f1: 0.8883, accuracy: 0.8883, batch_loss: 0.3901, loss: 0.2661 ||:  35%|###5      | 441/1250 [02:01<03:18,  4.08it/s]
2022-03-22 11:36:25,203 - INFO - tqdm - f1: 0.8926, accuracy: 0.8926, batch_loss: 0.0807, loss: 0.2599 ||:  38%|###8      | 480/1250 [02:11<03:47,  3.38it/s]
2022-03-22 11:36:35,476 - INFO - tqdm - f1: 0.8965, accuracy: 0.8965, batch_loss: 0.1039, loss: 0.2539 ||:  41%|####1     | 517/1250 [02:21<03:26,  3.55it/s]
2022-03-22 11:36:45,546 - INFO - tqdm - f1: 0.8975, accuracy: 0.8975, batch_loss: 0.4375, loss: 0.2524 ||:  44%|####4     | 551/1250 [02:32<03:47,  3.08it/s]
2022-03-22 11:36:55,802 - INFO - tqdm - f1: 0.8992, accuracy: 0.8993, batch_loss: 0.2013, loss: 0.2491 ||:  47%|####6     | 585/1250 [02:42<03:20,  3.31it/s]
2022-03-22 11:37:06,012 - INFO - tqdm - f1: 0.9016, accuracy: 0.9016, batch_loss: 0.0209, loss: 0.2448 ||:  50%|####9     | 621/1250 [02:52<03:02,  3.45it/s]
2022-03-22 11:37:16,112 - INFO - tqdm - f1: 0.9027, accuracy: 0.9027, batch_loss: 0.3924, loss: 0.2421 ||:  53%|#####2    | 661/1250 [03:02<01:14,  7.93it/s]
2022-03-22 11:37:26,187 - INFO - tqdm - f1: 0.9050, accuracy: 0.9050, batch_loss: 0.2160, loss: 0.2366 ||:  58%|#####8    | 731/1250 [03:12<01:58,  4.39it/s]
2022-03-22 11:37:36,263 - INFO - tqdm - f1: 0.9079, accuracy: 0.9079, batch_loss: 0.1677, loss: 0.2317 ||:  62%|######2   | 778/1250 [03:22<02:02,  3.85it/s]
2022-03-22 11:37:46,286 - INFO - tqdm - f1: 0.9090, accuracy: 0.9090, batch_loss: 0.0853, loss: 0.2287 ||:  66%|######5   | 822/1250 [03:32<01:41,  4.23it/s]
2022-03-22 11:37:56,390 - INFO - tqdm - f1: 0.9111, accuracy: 0.9111, batch_loss: 0.0462, loss: 0.2254 ||:  69%|######9   | 868/1250 [03:42<01:42,  3.72it/s]
2022-03-22 11:38:06,521 - INFO - tqdm - f1: 0.9125, accuracy: 0.9126, batch_loss: 0.0566, loss: 0.2232 ||:  73%|#######2  | 907/1250 [03:53<01:29,  3.82it/s]
2022-03-22 11:38:16,537 - INFO - tqdm - f1: 0.9143, accuracy: 0.9144, batch_loss: 0.0855, loss: 0.2197 ||:  76%|#######5  | 945/1250 [04:03<01:27,  3.48it/s]
2022-03-22 11:38:26,598 - INFO - tqdm - f1: 0.9154, accuracy: 0.9154, batch_loss: 0.2319, loss: 0.2183 ||:  79%|#######8  | 983/1250 [04:13<01:13,  3.63it/s]
2022-03-22 11:38:36,735 - INFO - tqdm - f1: 0.9158, accuracy: 0.9158, batch_loss: 0.1923, loss: 0.2170 ||:  82%|########1 | 1019/1250 [04:23<01:02,  3.73it/s]
2022-03-22 11:38:46,984 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.2643, loss: 0.2160 ||:  84%|########4 | 1054/1250 [04:33<01:00,  3.23it/s]
2022-03-22 11:38:57,176 - INFO - tqdm - f1: 0.9172, accuracy: 0.9172, batch_loss: 0.2305, loss: 0.2146 ||:  87%|########7 | 1089/1250 [04:43<00:42,  3.82it/s]
2022-03-22 11:39:07,262 - INFO - tqdm - f1: 0.9174, accuracy: 0.9174, batch_loss: 0.1580, loss: 0.2143 ||:  90%|########9 | 1124/1250 [04:53<00:38,  3.29it/s]
2022-03-22 11:39:17,530 - INFO - tqdm - f1: 0.9173, accuracy: 0.9173, batch_loss: 0.2908, loss: 0.2143 ||:  93%|#########3| 1163/1250 [05:04<00:24,  3.57it/s]
2022-03-22 11:39:27,740 - INFO - tqdm - f1: 0.9178, accuracy: 0.9178, batch_loss: 0.0760, loss: 0.2132 ||:  96%|#########5| 1198/1250 [05:14<00:16,  3.10it/s]
2022-03-22 11:39:37,983 - INFO - tqdm - f1: 0.9183, accuracy: 0.9183, batch_loss: 0.1218, loss: 0.2118 ||:  99%|#########8| 1235/1250 [05:24<00:04,  3.18it/s]
2022-03-22 11:39:40,412 - INFO - tqdm - f1: 0.9185, accuracy: 0.9185, batch_loss: 0.0640, loss: 0.2113 ||: 100%|#########9| 1244/1250 [05:26<00:01,  3.73it/s]
2022-03-22 11:39:40,549 - INFO - tqdm - f1: 0.9184, accuracy: 0.9184, batch_loss: 0.2031, loss: 0.2113 ||: 100%|#########9| 1245/1250 [05:27<00:01,  4.37it/s]
2022-03-22 11:39:40,992 - INFO - tqdm - f1: 0.9184, accuracy: 0.9184, batch_loss: 0.2264, loss: 0.2113 ||: 100%|#########9| 1246/1250 [05:27<00:01,  3.41it/s]
2022-03-22 11:39:41,211 - INFO - tqdm - f1: 0.9184, accuracy: 0.9184, batch_loss: 0.3717, loss: 0.2114 ||: 100%|#########9| 1247/1250 [05:27<00:00,  3.69it/s]
2022-03-22 11:39:41,538 - INFO - tqdm - f1: 0.9184, accuracy: 0.9184, batch_loss: 0.0195, loss: 0.2113 ||: 100%|#########9| 1248/1250 [05:28<00:00,  3.48it/s]
2022-03-22 11:39:41,789 - INFO - tqdm - f1: 0.9185, accuracy: 0.9185, batch_loss: 0.0571, loss: 0.2111 ||: 100%|#########9| 1249/1250 [05:28<00:00,  3.62it/s]
2022-03-22 11:39:42,038 - INFO - tqdm - f1: 0.9185, accuracy: 0.9185, batch_loss: 0.0331, loss: 0.2110 ||: 100%|##########| 1250/1250 [05:28<00:00,  3.73it/s]
2022-03-22 11:39:42,063 - INFO - tqdm - f1: 0.9185, accuracy: 0.9185, batch_loss: 0.0331, loss: 0.2110 ||: 100%|##########| 1250/1250 [05:28<00:00,  3.80it/s]
2022-03-22 11:39:42,112 - INFO - allennlp.training.trainer - Validating
2022-03-22 11:39:42,121 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-22 11:39:42,132 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-22 11:39:42,143 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-22 11:39:52,172 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.4266, loss: 0.1626 ||:  27%|##6       | 84/313 [00:10<00:25,  9.13it/s]
2022-03-22 11:40:02,184 - INFO - tqdm - f1: 0.9388, accuracy: 0.9390, batch_loss: 0.0817, loss: 0.1604 ||:  52%|#####2    | 163/313 [00:20<00:17,  8.57it/s]
2022-03-22 11:40:12,198 - INFO - tqdm - f1: 0.9348, accuracy: 0.9350, batch_loss: 0.1213, loss: 0.1679 ||:  79%|#######8  | 246/313 [00:30<00:08,  8.28it/s]
2022-03-22 11:40:19,933 - INFO - tqdm - f1: 0.9328, accuracy: 0.9330, batch_loss: 0.0469, loss: 0.1746 ||: 100%|#########9| 312/313 [00:37<00:00,  8.17it/s]
2022-03-22 11:40:19,956 - INFO - tqdm - f1: 0.9329, accuracy: 0.9330, batch_loss: 0.0874, loss: 0.1743 ||: 100%|##########| 313/313 [00:37<00:00,  8.27it/s]
2022-03-22 11:40:19,960 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/imdb_base_hyper_small_seed_13/best.th'.
2022-03-22 11:40:20,549 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-22 11:40:20,549 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.919  |     0.933
2022-03-22 11:40:20,549 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.919  |     0.933
2022-03-22 11:40:20,549 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-22 11:40:20,549 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.211  |     0.174
2022-03-22 11:40:20,549 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  9845.758  |       N/A
2022-03-22 11:40:20,549 - INFO - allennlp.training.trainer - Epoch duration: 0:06:07.105314
2022-03-22 11:40:20,549 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:55:03
2022-03-22 11:40:20,549 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-22 11:40:20,550 - INFO - allennlp.training.trainer - Worker 0 memory usage: 9.8G
2022-03-22 11:40:20,550 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-22 11:40:20,551 - INFO - allennlp.training.trainer - Training
2022-03-22 11:40:20,551 - INFO - tqdm - 0%|          | 0/1250 [00:00<?, ?it/s]
2022-03-22 11:40:30,778 - INFO - tqdm - f1: 0.9535, accuracy: 0.9535, batch_loss: 0.0215, loss: 0.1165 ||:   3%|3         | 39/1250 [00:10<05:33,  3.63it/s]
2022-03-22 11:40:40,854 - INFO - tqdm - f1: 0.9586, accuracy: 0.9586, batch_loss: 0.0291, loss: 0.1173 ||:   6%|5         | 74/1250 [00:20<05:40,  3.45it/s]
2022-03-22 11:40:51,125 - INFO - tqdm - f1: 0.9604, accuracy: 0.9604, batch_loss: 0.3441, loss: 0.1189 ||:   9%|8         | 109/1250 [00:30<06:21,  2.99it/s]
2022-03-22 11:41:01,320 - INFO - tqdm - f1: 0.9640, accuracy: 0.9640, batch_loss: 0.0500, loss: 0.1073 ||:  12%|#1        | 146/1250 [00:40<06:04,  3.03it/s]
2022-03-22 11:41:11,544 - INFO - tqdm - f1: 0.9631, accuracy: 0.9631, batch_loss: 0.0695, loss: 0.1050 ||:  15%|#4        | 183/1250 [00:50<04:50,  3.67it/s]
2022-03-22 11:41:21,643 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0231, loss: 0.1046 ||:  17%|#7        | 217/1250 [01:01<04:23,  3.92it/s]
2022-03-22 11:41:31,646 - INFO - tqdm - f1: 0.9604, accuracy: 0.9604, batch_loss: 0.0085, loss: 0.1062 ||:  20%|##        | 254/1250 [01:11<04:41,  3.54it/s]
2022-03-22 11:41:41,902 - INFO - tqdm - f1: 0.9603, accuracy: 0.9603, batch_loss: 0.0819, loss: 0.1096 ||:  23%|##3       | 293/1250 [01:21<04:04,  3.92it/s]
2022-03-22 11:41:52,123 - INFO - tqdm - f1: 0.9597, accuracy: 0.9597, batch_loss: 0.1178, loss: 0.1123 ||:  27%|##6       | 332/1250 [01:31<04:26,  3.44it/s]
2022-03-22 11:42:02,237 - INFO - tqdm - f1: 0.9585, accuracy: 0.9585, batch_loss: 0.2528, loss: 0.1161 ||:  29%|##9       | 366/1250 [01:41<05:15,  2.80it/s]
2022-03-22 11:42:12,320 - INFO - tqdm - f1: 0.9583, accuracy: 0.9583, batch_loss: 0.2791, loss: 0.1180 ||:  32%|###2      | 402/1250 [01:51<04:22,  3.23it/s]
2022-03-22 11:42:22,409 - INFO - tqdm - f1: 0.9584, accuracy: 0.9584, batch_loss: 0.1043, loss: 0.1186 ||:  35%|###5      | 439/1250 [02:01<03:28,  3.89it/s]
2022-03-22 11:42:32,642 - INFO - tqdm - f1: 0.9587, accuracy: 0.9587, batch_loss: 0.0495, loss: 0.1193 ||:  38%|###7      | 474/1250 [02:12<03:31,  3.67it/s]
2022-03-22 11:42:42,970 - INFO - tqdm - f1: 0.9583, accuracy: 0.9583, batch_loss: 0.1899, loss: 0.1202 ||:  41%|####      | 510/1250 [02:22<03:28,  3.55it/s]
2022-03-22 11:42:53,074 - INFO - tqdm - f1: 0.9586, accuracy: 0.9586, batch_loss: 0.1050, loss: 0.1199 ||:  44%|####3     | 547/1250 [02:32<03:03,  3.83it/s]
2022-03-22 11:43:03,275 - INFO - tqdm - f1: 0.9597, accuracy: 0.9597, batch_loss: 0.4817, loss: 0.1176 ||:  47%|####6     | 585/1250 [02:42<03:05,  3.58it/s]
2022-03-22 11:43:13,303 - INFO - tqdm - f1: 0.9601, accuracy: 0.9601, batch_loss: 0.1092, loss: 0.1186 ||:  50%|####9     | 623/1250 [02:52<03:15,  3.21it/s]
2022-03-22 11:43:23,463 - INFO - tqdm - f1: 0.9598, accuracy: 0.9598, batch_loss: 0.0149, loss: 0.1191 ||:  53%|#####2    | 660/1250 [03:02<02:43,  3.61it/s]
2022-03-22 11:43:33,716 - INFO - tqdm - f1: 0.9594, accuracy: 0.9594, batch_loss: 0.0737, loss: 0.1197 ||:  56%|#####5    | 697/1250 [03:13<02:38,  3.50it/s]
2022-03-22 11:43:43,819 - INFO - tqdm - f1: 0.9593, accuracy: 0.9593, batch_loss: 0.1029, loss: 0.1191 ||:  59%|#####8    | 732/1250 [03:23<02:27,  3.50it/s]
2022-03-22 11:43:54,078 - INFO - tqdm - f1: 0.9590, accuracy: 0.9590, batch_loss: 0.2157, loss: 0.1195 ||:  62%|######1   | 769/1250 [03:33<02:13,  3.61it/s]
2022-03-22 11:44:04,303 - INFO - tqdm - f1: 0.9588, accuracy: 0.9588, batch_loss: 0.0727, loss: 0.1191 ||:  64%|######4   | 805/1250 [03:43<02:02,  3.63it/s]
2022-03-22 11:44:14,478 - INFO - tqdm - f1: 0.9577, accuracy: 0.9577, batch_loss: 0.0358, loss: 0.1210 ||:  67%|######7   | 841/1250 [03:53<01:52,  3.63it/s]
2022-03-22 11:44:24,643 - INFO - tqdm - f1: 0.9585, accuracy: 0.9585, batch_loss: 0.3006, loss: 0.1198 ||:  70%|#######   | 878/1250 [04:04<01:32,  4.04it/s]
2022-03-22 11:44:34,749 - INFO - tqdm - f1: 0.9585, accuracy: 0.9585, batch_loss: 0.2008, loss: 0.1191 ||:  74%|#######3  | 919/1250 [04:14<01:21,  4.09it/s]
2022-03-22 11:44:44,953 - INFO - tqdm - f1: 0.9584, accuracy: 0.9584, batch_loss: 0.3127, loss: 0.1199 ||:  76%|#######6  | 955/1250 [04:24<01:14,  3.96it/s]
2022-03-22 11:44:55,097 - INFO - tqdm - f1: 0.9585, accuracy: 0.9585, batch_loss: 0.0883, loss: 0.1207 ||:  79%|#######9  | 992/1250 [04:34<01:07,  3.81it/s]
2022-03-22 11:45:05,172 - INFO - tqdm - f1: 0.9586, accuracy: 0.9586, batch_loss: 0.2563, loss: 0.1209 ||:  82%|########2 | 1028/1250 [04:44<00:59,  3.74it/s]
2022-03-22 11:45:15,283 - INFO - tqdm - f1: 0.9588, accuracy: 0.9588, batch_loss: 0.0897, loss: 0.1204 ||:  85%|########5 | 1067/1250 [04:54<00:43,  4.24it/s]
2022-03-22 11:45:25,369 - INFO - tqdm - f1: 0.9586, accuracy: 0.9586, batch_loss: 0.2536, loss: 0.1210 ||:  88%|########8 | 1102/1250 [05:04<00:38,  3.83it/s]
2022-03-22 11:45:35,431 - INFO - tqdm - f1: 0.9587, accuracy: 0.9587, batch_loss: 0.3110, loss: 0.1208 ||:  91%|######### | 1137/1250 [05:14<00:26,  4.33it/s]
2022-03-22 11:45:45,586 - INFO - tqdm - f1: 0.9588, accuracy: 0.9588, batch_loss: 0.0476, loss: 0.1211 ||:  94%|#########3| 1173/1250 [05:25<00:24,  3.15it/s]
2022-03-22 11:45:55,905 - INFO - tqdm - f1: 0.9589, accuracy: 0.9589, batch_loss: 0.0764, loss: 0.1206 ||:  97%|#########6| 1208/1250 [05:35<00:12,  3.48it/s]
2022-03-22 11:46:05,747 - INFO - tqdm - f1: 0.9588, accuracy: 0.9588, batch_loss: 0.0491, loss: 0.1206 ||: 100%|#########9| 1244/1250 [05:45<00:01,  3.55it/s]
2022-03-22 11:46:05,899 - INFO - tqdm - f1: 0.9587, accuracy: 0.9587, batch_loss: 0.1498, loss: 0.1206 ||: 100%|#########9| 1245/1250 [05:45<00:01,  4.12it/s]
2022-03-22 11:46:06,339 - INFO - tqdm - f1: 0.9587, accuracy: 0.9587, batch_loss: 0.1647, loss: 0.1207 ||: 100%|#########9| 1246/1250 [05:45<00:01,  3.31it/s]
2022-03-22 11:46:06,530 - INFO - tqdm - f1: 0.9587, accuracy: 0.9587, batch_loss: 0.0796, loss: 0.1206 ||: 100%|#########9| 1247/1250 [05:45<00:00,  3.72it/s]
2022-03-22 11:46:06,913 - INFO - tqdm - f1: 0.9587, accuracy: 0.9587, batch_loss: 0.0462, loss: 0.1206 ||: 100%|#########9| 1248/1250 [05:46<00:00,  3.30it/s]
2022-03-22 11:46:07,191 - INFO - tqdm - f1: 0.9587, accuracy: 0.9587, batch_loss: 0.1093, loss: 0.1206 ||: 100%|#########9| 1249/1250 [05:46<00:00,  3.38it/s]
2022-03-22 11:46:07,336 - INFO - tqdm - f1: 0.9588, accuracy: 0.9587, batch_loss: 0.0366, loss: 0.1205 ||: 100%|##########| 1250/1250 [05:46<00:00,  3.99it/s]
2022-03-22 11:46:07,346 - INFO - tqdm - f1: 0.9588, accuracy: 0.9587, batch_loss: 0.0366, loss: 0.1205 ||: 100%|##########| 1250/1250 [05:46<00:00,  3.60it/s]
2022-03-22 11:46:07,381 - INFO - allennlp.training.trainer - Validating
2022-03-22 11:46:07,382 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-22 11:46:17,491 - INFO - tqdm - f1: 0.9629, accuracy: 0.9630, batch_loss: 0.0594, loss: 0.1193 ||:  26%|##5       | 81/313 [00:10<00:37,  6.21it/s]
2022-03-22 11:46:27,714 - INFO - tqdm - f1: 0.9553, accuracy: 0.9553, batch_loss: 0.2372, loss: 0.1269 ||:  50%|#####     | 158/313 [00:20<00:15,  9.74it/s]
2022-03-22 11:46:37,968 - INFO - tqdm - f1: 0.9524, accuracy: 0.9524, batch_loss: 0.3208, loss: 0.1337 ||:  77%|#######6  | 241/313 [00:30<00:08,  8.24it/s]
2022-03-22 11:46:46,575 - INFO - tqdm - f1: 0.9524, accuracy: 0.9524, batch_loss: 0.2515, loss: 0.1373 ||: 100%|#########9| 312/313 [00:39<00:00,  8.64it/s]
2022-03-22 11:46:46,698 - INFO - tqdm - f1: 0.9524, accuracy: 0.9524, batch_loss: 0.0818, loss: 0.1372 ||: 100%|##########| 313/313 [00:39<00:00,  8.54it/s]
2022-03-22 11:46:46,701 - INFO - tqdm - f1: 0.9524, accuracy: 0.9524, batch_loss: 0.0818, loss: 0.1372 ||: 100%|##########| 313/313 [00:39<00:00,  7.96it/s]
2022-03-22 11:46:46,729 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/imdb_base_hyper_small_seed_13/best.th'.
2022-03-22 11:46:47,337 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-22 11:46:47,339 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.959  |     0.952
2022-03-22 11:46:47,339 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.959  |     0.952
2022-03-22 11:46:47,339 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-22 11:46:47,339 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.120  |     0.137
2022-03-22 11:46:47,339 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  10043.898  |       N/A
2022-03-22 11:46:47,339 - INFO - allennlp.training.trainer - Epoch duration: 0:06:26.789341
2022-03-22 11:46:47,340 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:50:15
2022-03-22 11:46:47,340 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-22 11:46:47,340 - INFO - allennlp.training.trainer - Worker 0 memory usage: 9.8G
2022-03-22 11:46:47,342 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-22 11:46:47,344 - INFO - allennlp.training.trainer - Training
2022-03-22 11:46:47,345 - INFO - tqdm - 0%|          | 0/1250 [00:00<?, ?it/s]
2022-03-22 11:46:57,513 - INFO - tqdm - f1: 0.9821, accuracy: 0.9821, batch_loss: 0.5195, loss: 0.0560 ||:   3%|2         | 35/1250 [00:10<05:15,  3.85it/s]
2022-03-22 11:47:07,712 - INFO - tqdm - f1: 0.9788, accuracy: 0.9789, batch_loss: 0.0073, loss: 0.0693 ||:   6%|5         | 74/1250 [00:20<05:00,  3.91it/s]
2022-03-22 11:47:17,793 - INFO - tqdm - f1: 0.9799, accuracy: 0.9799, batch_loss: 0.0142, loss: 0.0637 ||:   9%|8         | 109/1250 [00:30<05:48,  3.28it/s]
2022-03-22 11:47:28,021 - INFO - tqdm - f1: 0.9794, accuracy: 0.9795, batch_loss: 0.0024, loss: 0.0629 ||:  11%|#1        | 143/1250 [00:40<04:49,  3.83it/s]
2022-03-22 11:47:38,061 - INFO - tqdm - f1: 0.9786, accuracy: 0.9786, batch_loss: 0.0323, loss: 0.0653 ||:  14%|#4        | 181/1250 [00:50<03:50,  4.64it/s]
2022-03-22 11:47:48,168 - INFO - tqdm - f1: 0.9787, accuracy: 0.9787, batch_loss: 0.0117, loss: 0.0660 ||:  18%|#7        | 220/1250 [01:00<03:33,  4.83it/s]
2022-03-22 11:47:58,261 - INFO - tqdm - f1: 0.9787, accuracy: 0.9787, batch_loss: 0.0324, loss: 0.0670 ||:  21%|##        | 258/1250 [01:10<04:16,  3.86it/s]
2022-03-22 11:48:08,277 - INFO - tqdm - f1: 0.9787, accuracy: 0.9787, batch_loss: 0.0659, loss: 0.0674 ||:  24%|##3       | 296/1250 [01:20<03:42,  4.28it/s]
2022-03-22 11:48:18,591 - INFO - tqdm - f1: 0.9781, accuracy: 0.9781, batch_loss: 0.0149, loss: 0.0706 ||:  27%|##6       | 334/1250 [01:31<04:37,  3.30it/s]
2022-03-22 11:48:28,988 - INFO - tqdm - f1: 0.9788, accuracy: 0.9788, batch_loss: 0.2397, loss: 0.0685 ||:  30%|##9       | 372/1250 [01:41<04:52,  3.00it/s]
2022-03-22 11:48:39,031 - INFO - tqdm - f1: 0.9780, accuracy: 0.9780, batch_loss: 0.0046, loss: 0.0689 ||:  33%|###2      | 410/1250 [01:51<03:42,  3.78it/s]
2022-03-22 11:48:49,312 - INFO - tqdm - f1: 0.9779, accuracy: 0.9779, batch_loss: 0.0440, loss: 0.0697 ||:  36%|###5      | 449/1250 [02:01<04:04,  3.28it/s]
2022-03-22 11:48:59,382 - INFO - tqdm - f1: 0.9776, accuracy: 0.9776, batch_loss: 0.0688, loss: 0.0711 ||:  39%|###8      | 483/1250 [02:12<04:04,  3.13it/s]
2022-03-22 11:49:09,512 - INFO - tqdm - f1: 0.9778, accuracy: 0.9778, batch_loss: 0.1239, loss: 0.0711 ||:  41%|####1     | 518/1250 [02:22<03:11,  3.83it/s]
2022-03-22 11:49:19,651 - INFO - tqdm - f1: 0.9777, accuracy: 0.9777, batch_loss: 0.0643, loss: 0.0700 ||:  44%|####4     | 553/1250 [02:32<03:03,  3.80it/s]
2022-03-22 11:49:29,803 - INFO - tqdm - f1: 0.9773, accuracy: 0.9773, batch_loss: 0.0890, loss: 0.0705 ||:  47%|####7     | 589/1250 [02:42<02:49,  3.89it/s]
2022-03-22 11:49:39,833 - INFO - tqdm - f1: 0.9776, accuracy: 0.9776, batch_loss: 0.0961, loss: 0.0708 ||:  50%|#####     | 626/1250 [02:52<02:26,  4.25it/s]
2022-03-22 11:49:50,010 - INFO - tqdm - f1: 0.9774, accuracy: 0.9774, batch_loss: 0.0223, loss: 0.0704 ||:  53%|#####3    | 666/1250 [03:02<02:20,  4.17it/s]
2022-03-22 11:50:00,261 - INFO - tqdm - f1: 0.9772, accuracy: 0.9772, batch_loss: 0.0777, loss: 0.0708 ||:  56%|#####6    | 704/1250 [03:12<02:27,  3.70it/s]
2022-03-22 11:50:10,294 - INFO - tqdm - f1: 0.9772, accuracy: 0.9772, batch_loss: 0.0058, loss: 0.0710 ||:  59%|#####9    | 742/1250 [03:22<01:45,  4.80it/s]
2022-03-22 11:50:20,302 - INFO - tqdm - f1: 0.9772, accuracy: 0.9772, batch_loss: 0.0056, loss: 0.0718 ||:  62%|######2   | 777/1250 [03:32<02:10,  3.63it/s]
2022-03-22 11:50:30,322 - INFO - tqdm - f1: 0.9773, accuracy: 0.9773, batch_loss: 0.0174, loss: 0.0718 ||:  65%|######4   | 810/1250 [03:42<02:03,  3.56it/s]
2022-03-22 11:50:40,402 - INFO - tqdm - f1: 0.9767, accuracy: 0.9767, batch_loss: 0.2287, loss: 0.0726 ||:  68%|######7   | 845/1250 [03:53<02:19,  2.91it/s]
2022-03-22 11:50:50,615 - INFO - tqdm - f1: 0.9765, accuracy: 0.9765, batch_loss: 0.0863, loss: 0.0727 ||:  70%|#######   | 880/1250 [04:03<01:48,  3.41it/s]
2022-03-22 11:51:00,852 - INFO - tqdm - f1: 0.9761, accuracy: 0.9761, batch_loss: 0.2186, loss: 0.0743 ||:  73%|#######3  | 917/1250 [04:13<01:24,  3.96it/s]
2022-03-22 11:51:10,936 - INFO - tqdm - f1: 0.9760, accuracy: 0.9760, batch_loss: 0.0703, loss: 0.0743 ||:  76%|#######6  | 955/1250 [04:23<01:06,  4.47it/s]
2022-03-22 11:51:21,071 - INFO - tqdm - f1: 0.9756, accuracy: 0.9756, batch_loss: 0.0275, loss: 0.0747 ||:  79%|#######9  | 991/1250 [04:33<01:21,  3.18it/s]
2022-03-22 11:51:31,252 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.0141, loss: 0.0754 ||:  82%|########2 | 1025/1250 [04:43<01:10,  3.21it/s]
2022-03-22 11:51:41,340 - INFO - tqdm - f1: 0.9751, accuracy: 0.9751, batch_loss: 0.0185, loss: 0.0757 ||:  85%|########5 | 1063/1250 [04:53<00:53,  3.51it/s]
2022-03-22 11:51:51,697 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.4342, loss: 0.0748 ||:  88%|########7 | 1098/1250 [05:04<00:49,  3.05it/s]
2022-03-22 11:52:02,008 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.0038, loss: 0.0743 ||:  91%|######### | 1135/1250 [05:14<00:33,  3.40it/s]
2022-03-22 11:52:12,084 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.2149, loss: 0.0744 ||:  94%|#########3| 1170/1250 [05:24<00:20,  3.98it/s]
2022-03-22 11:52:22,443 - INFO - tqdm - f1: 0.9755, accuracy: 0.9755, batch_loss: 0.3991, loss: 0.0742 ||:  97%|#########6| 1209/1250 [05:35<00:12,  3.17it/s]
2022-03-22 11:52:31,427 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.1399, loss: 0.0749 ||: 100%|#########9| 1244/1250 [05:44<00:01,  3.83it/s]
2022-03-22 11:52:31,577 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0116, loss: 0.0748 ||: 100%|#########9| 1245/1250 [05:44<00:01,  4.38it/s]
2022-03-22 11:52:31,826 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0067, loss: 0.0748 ||: 100%|#########9| 1246/1250 [05:44<00:00,  4.27it/s]
2022-03-22 11:52:32,099 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0067, loss: 0.0747 ||: 100%|#########9| 1247/1250 [05:44<00:00,  4.07it/s]
2022-03-22 11:52:32,303 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.0700, loss: 0.0747 ||: 100%|#########9| 1248/1250 [05:44<00:00,  4.29it/s]
2022-03-22 11:52:32,579 - INFO - tqdm - f1: 0.9751, accuracy: 0.9751, batch_loss: 0.5188, loss: 0.0751 ||: 100%|#########9| 1249/1250 [05:45<00:00,  4.06it/s]
2022-03-22 11:52:32,961 - INFO - tqdm - f1: 0.9750, accuracy: 0.9750, batch_loss: 0.3335, loss: 0.0753 ||: 100%|##########| 1250/1250 [05:45<00:00,  3.49it/s]
2022-03-22 11:52:32,971 - INFO - tqdm - f1: 0.9750, accuracy: 0.9750, batch_loss: 0.3335, loss: 0.0753 ||: 100%|##########| 1250/1250 [05:45<00:00,  3.62it/s]
2022-03-22 11:52:33,032 - INFO - allennlp.training.trainer - Validating
2022-03-22 11:52:33,047 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-22 11:52:43,092 - INFO - tqdm - f1: 0.9382, accuracy: 0.9382, batch_loss: 0.2743, loss: 0.1851 ||:  28%|##8       | 89/313 [00:10<00:26,  8.49it/s]
2022-03-22 11:52:53,199 - INFO - tqdm - f1: 0.9364, accuracy: 0.9364, batch_loss: 0.2401, loss: 0.1948 ||:  55%|#####5    | 173/313 [00:20<00:18,  7.40it/s]
2022-03-22 11:53:03,321 - INFO - tqdm - f1: 0.9420, accuracy: 0.9420, batch_loss: 0.0045, loss: 0.1834 ||:  82%|########2 | 258/313 [00:30<00:06,  8.59it/s]
2022-03-22 11:53:09,881 - INFO - tqdm - f1: 0.9446, accuracy: 0.9446, batch_loss: 0.2797, loss: 0.1764 ||: 100%|#########9| 312/313 [00:36<00:00,  8.16it/s]
2022-03-22 11:53:10,023 - INFO - tqdm - f1: 0.9448, accuracy: 0.9448, batch_loss: 0.0023, loss: 0.1758 ||: 100%|##########| 313/313 [00:36<00:00,  7.85it/s]
2022-03-22 11:53:10,026 - INFO - tqdm - f1: 0.9448, accuracy: 0.9448, batch_loss: 0.0023, loss: 0.1758 ||: 100%|##########| 313/313 [00:36<00:00,  8.47it/s]
2022-03-22 11:53:10,078 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-22 11:53:10,084 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.975  |     0.945
2022-03-22 11:53:10,084 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.975  |     0.945
2022-03-22 11:53:10,084 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-22 11:53:10,084 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.075  |     0.176
2022-03-22 11:53:10,084 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  10044.324  |       N/A
2022-03-22 11:53:10,084 - INFO - allennlp.training.trainer - Epoch duration: 0:06:22.744161
2022-03-22 11:53:10,084 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:44:12
2022-03-22 11:53:10,085 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-22 11:53:10,085 - INFO - allennlp.training.trainer - Worker 0 memory usage: 9.8G
2022-03-22 11:53:10,085 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-22 11:53:10,092 - INFO - allennlp.training.trainer - Training
2022-03-22 11:53:10,099 - INFO - tqdm - 0%|          | 0/1250 [00:00<?, ?it/s]
2022-03-22 11:53:20,334 - INFO - tqdm - f1: 0.9948, accuracy: 0.9948, batch_loss: 0.0017, loss: 0.0230 ||:   3%|2         | 36/1250 [00:10<07:15,  2.79it/s]
2022-03-22 11:53:30,386 - INFO - tqdm - f1: 0.9905, accuracy: 0.9905, batch_loss: 0.1059, loss: 0.0411 ||:   6%|5         | 72/1250 [00:20<05:08,  3.82it/s]
2022-03-22 11:53:40,790 - INFO - tqdm - f1: 0.9870, accuracy: 0.9870, batch_loss: 0.0327, loss: 0.0478 ||:   9%|8         | 111/1250 [00:30<05:20,  3.55it/s]
2022-03-22 11:53:50,993 - INFO - tqdm - f1: 0.9866, accuracy: 0.9866, batch_loss: 0.0389, loss: 0.0466 ||:  12%|#1        | 145/1250 [00:40<05:49,  3.16it/s]
2022-03-22 11:54:01,170 - INFO - tqdm - f1: 0.9835, accuracy: 0.9835, batch_loss: 0.1394, loss: 0.0566 ||:  15%|#4        | 182/1250 [00:51<04:53,  3.64it/s]
2022-03-22 11:54:11,203 - INFO - tqdm - f1: 0.9840, accuracy: 0.9840, batch_loss: 0.0036, loss: 0.0551 ||:  18%|#7        | 222/1250 [01:01<03:15,  5.27it/s]
2022-03-22 11:54:21,253 - INFO - tqdm - f1: 0.9832, accuracy: 0.9832, batch_loss: 0.2760, loss: 0.0581 ||:  20%|##        | 256/1250 [01:11<03:51,  4.29it/s]
2022-03-22 11:54:31,424 - INFO - tqdm - f1: 0.9819, accuracy: 0.9819, batch_loss: 0.2052, loss: 0.0595 ||:  24%|##3       | 294/1250 [01:21<04:20,  3.67it/s]
2022-03-22 11:54:41,560 - INFO - tqdm - f1: 0.9828, accuracy: 0.9828, batch_loss: 0.0050, loss: 0.0566 ||:  26%|##6       | 331/1250 [01:31<04:31,  3.39it/s]
2022-03-22 11:54:51,718 - INFO - tqdm - f1: 0.9829, accuracy: 0.9829, batch_loss: 0.0020, loss: 0.0560 ||:  29%|##9       | 366/1250 [01:41<04:16,  3.45it/s]
2022-03-22 11:55:01,882 - INFO - tqdm - f1: 0.9829, accuracy: 0.9829, batch_loss: 0.0092, loss: 0.0553 ||:  32%|###2      | 403/1250 [01:51<03:40,  3.83it/s]
2022-03-22 11:55:12,097 - INFO - tqdm - f1: 0.9836, accuracy: 0.9836, batch_loss: 0.0194, loss: 0.0528 ||:  35%|###5      | 439/1250 [02:01<04:18,  3.13it/s]
2022-03-22 11:55:22,437 - INFO - tqdm - f1: 0.9834, accuracy: 0.9834, batch_loss: 0.2808, loss: 0.0525 ||:  38%|###8      | 478/1250 [02:12<04:18,  2.99it/s]
2022-03-22 11:55:32,769 - INFO - tqdm - f1: 0.9836, accuracy: 0.9836, batch_loss: 0.0029, loss: 0.0515 ||:  41%|####      | 512/1250 [02:22<03:38,  3.37it/s]
2022-03-22 11:55:42,800 - INFO - tqdm - f1: 0.9839, accuracy: 0.9839, batch_loss: 0.0019, loss: 0.0508 ||:  44%|####3     | 548/1250 [02:32<02:57,  3.96it/s]
2022-03-22 11:55:52,809 - INFO - tqdm - f1: 0.9837, accuracy: 0.9837, batch_loss: 0.2675, loss: 0.0522 ||:  47%|####6     | 585/1250 [02:42<02:39,  4.16it/s]
2022-03-22 11:56:03,043 - INFO - tqdm - f1: 0.9838, accuracy: 0.9838, batch_loss: 0.0795, loss: 0.0519 ||:  50%|####9     | 623/1250 [02:52<03:02,  3.43it/s]
2022-03-22 11:56:13,074 - INFO - tqdm - f1: 0.9842, accuracy: 0.9842, batch_loss: 0.0082, loss: 0.0513 ||:  56%|#####5    | 695/1250 [03:02<02:10,  4.26it/s]
2022-03-22 11:56:23,101 - INFO - tqdm - f1: 0.9845, accuracy: 0.9845, batch_loss: 0.1723, loss: 0.0499 ||:  60%|#####9    | 744/1250 [03:13<01:35,  5.30it/s]
2022-03-22 11:56:33,310 - INFO - tqdm - f1: 0.9841, accuracy: 0.9841, batch_loss: 0.0160, loss: 0.0515 ||:  64%|######3   | 795/1250 [03:23<01:27,  5.19it/s]
2022-03-22 11:56:43,316 - INFO - tqdm - f1: 0.9843, accuracy: 0.9843, batch_loss: 0.0571, loss: 0.0517 ||:  68%|######7   | 844/1250 [03:33<01:42,  3.97it/s]
2022-03-22 11:56:53,543 - INFO - tqdm - f1: 0.9841, accuracy: 0.9841, batch_loss: 0.0053, loss: 0.0523 ||:  71%|#######   | 885/1250 [03:43<01:44,  3.49it/s]
2022-03-22 11:57:03,796 - INFO - tqdm - f1: 0.9839, accuracy: 0.9839, batch_loss: 0.0973, loss: 0.0523 ||:  74%|#######3  | 924/1250 [03:53<01:30,  3.62it/s]
2022-03-22 11:57:13,928 - INFO - tqdm - f1: 0.9838, accuracy: 0.9838, batch_loss: 0.0174, loss: 0.0526 ||:  77%|#######6  | 959/1250 [04:03<01:27,  3.34it/s]
2022-03-22 11:57:24,190 - INFO - tqdm - f1: 0.9839, accuracy: 0.9839, batch_loss: 0.3566, loss: 0.0526 ||:  80%|#######9  | 996/1250 [04:14<01:19,  3.21it/s]
2022-03-22 11:57:34,220 - INFO - tqdm - f1: 0.9840, accuracy: 0.9840, batch_loss: 0.0069, loss: 0.0526 ||:  83%|########2 | 1033/1250 [04:24<00:55,  3.89it/s]
2022-03-22 11:57:44,332 - INFO - tqdm - f1: 0.9841, accuracy: 0.9841, batch_loss: 0.0321, loss: 0.0521 ||:  85%|########5 | 1067/1250 [04:34<01:03,  2.90it/s]
2022-03-22 11:57:54,476 - INFO - tqdm - f1: 0.9839, accuracy: 0.9839, batch_loss: 0.0378, loss: 0.0530 ||:  88%|########8 | 1103/1250 [04:44<00:50,  2.93it/s]
2022-03-22 11:58:04,620 - INFO - tqdm - f1: 0.9838, accuracy: 0.9838, batch_loss: 0.0634, loss: 0.0534 ||:  91%|#########1| 1143/1250 [04:54<00:24,  4.38it/s]
2022-03-22 11:58:14,706 - INFO - tqdm - f1: 0.9838, accuracy: 0.9838, batch_loss: 0.0047, loss: 0.0531 ||:  94%|#########4| 1178/1250 [05:04<00:20,  3.58it/s]
2022-03-22 11:58:24,715 - INFO - tqdm - f1: 0.9838, accuracy: 0.9838, batch_loss: 0.0072, loss: 0.0526 ||:  97%|#########7| 1214/1250 [05:14<00:09,  3.72it/s]
2022-03-22 11:58:33,011 - INFO - tqdm - f1: 0.9840, accuracy: 0.9840, batch_loss: 0.0137, loss: 0.0519 ||: 100%|#########9| 1244/1250 [05:22<00:01,  3.06it/s]
2022-03-22 11:58:33,175 - INFO - tqdm - f1: 0.9840, accuracy: 0.9840, batch_loss: 0.0157, loss: 0.0519 ||: 100%|#########9| 1245/1250 [05:23<00:01,  3.59it/s]
2022-03-22 11:58:33,604 - INFO - tqdm - f1: 0.9840, accuracy: 0.9840, batch_loss: 0.0032, loss: 0.0519 ||: 100%|#########9| 1246/1250 [05:23<00:01,  3.09it/s]
2022-03-22 11:58:33,856 - INFO - tqdm - f1: 0.9841, accuracy: 0.9841, batch_loss: 0.0024, loss: 0.0518 ||: 100%|#########9| 1247/1250 [05:23<00:00,  3.31it/s]
2022-03-22 11:58:33,975 - INFO - tqdm - f1: 0.9840, accuracy: 0.9840, batch_loss: 0.1493, loss: 0.0519 ||: 100%|#########9| 1248/1250 [05:23<00:00,  4.05it/s]
2022-03-22 11:58:34,219 - INFO - tqdm - f1: 0.9840, accuracy: 0.9840, batch_loss: 0.0011, loss: 0.0519 ||: 100%|#########9| 1249/1250 [05:24<00:00,  4.06it/s]
2022-03-22 11:58:34,516 - INFO - tqdm - f1: 0.9840, accuracy: 0.9840, batch_loss: 0.0013, loss: 0.0518 ||: 100%|##########| 1250/1250 [05:24<00:00,  3.83it/s]
2022-03-22 11:58:34,533 - INFO - tqdm - f1: 0.9840, accuracy: 0.9840, batch_loss: 0.0013, loss: 0.0518 ||: 100%|##########| 1250/1250 [05:24<00:00,  3.85it/s]
2022-03-22 11:58:34,548 - INFO - allennlp.training.trainer - Validating
2022-03-22 11:58:34,554 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-22 11:58:44,619 - INFO - tqdm - f1: 0.9452, accuracy: 0.9452, batch_loss: 0.2409, loss: 0.2226 ||:  26%|##5       | 81/313 [00:10<00:33,  6.96it/s]
2022-03-22 11:58:54,666 - INFO - tqdm - f1: 0.9443, accuracy: 0.9443, batch_loss: 0.0004, loss: 0.2353 ||:  53%|#####3    | 166/313 [00:20<00:12, 11.87it/s]
2022-03-22 11:59:04,715 - INFO - tqdm - f1: 0.9425, accuracy: 0.9425, batch_loss: 0.0006, loss: 0.2441 ||:  79%|#######9  | 248/313 [00:30<00:08,  7.70it/s]
2022-03-22 11:59:13,068 - INFO - tqdm - f1: 0.9446, accuracy: 0.9446, batch_loss: 0.2587, loss: 0.2407 ||: 100%|#########9| 312/313 [00:38<00:00,  7.26it/s]
2022-03-22 11:59:13,107 - INFO - tqdm - f1: 0.9446, accuracy: 0.9446, batch_loss: 0.3501, loss: 0.2410 ||: 100%|##########| 313/313 [00:38<00:00,  8.12it/s]
2022-03-22 11:59:13,160 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-22 11:59:13,169 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.984  |     0.945
2022-03-22 11:59:13,169 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.984  |     0.945
2022-03-22 11:59:13,169 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-22 11:59:13,169 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.052  |     0.241
2022-03-22 11:59:13,169 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  10044.324  |       N/A
2022-03-22 11:59:13,169 - INFO - allennlp.training.trainer - Epoch duration: 0:06:03.084241
2022-03-22 11:59:13,178 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:37:29
2022-03-22 11:59:13,178 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-22 11:59:13,179 - INFO - allennlp.training.trainer - Worker 0 memory usage: 9.8G
2022-03-22 11:59:13,179 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-22 11:59:13,189 - INFO - allennlp.training.trainer - Training
2022-03-22 11:59:13,190 - INFO - tqdm - 0%|          | 0/1250 [00:00<?, ?it/s]
2022-03-22 11:59:23,504 - INFO - tqdm - f1: 0.9865, accuracy: 0.9865, batch_loss: 0.0016, loss: 0.0349 ||:   3%|2         | 37/1250 [00:10<05:54,  3.42it/s]
2022-03-22 11:59:33,731 - INFO - tqdm - f1: 0.9904, accuracy: 0.9905, batch_loss: 0.0036, loss: 0.0289 ||:   6%|5         | 72/1250 [00:20<06:07,  3.21it/s]
2022-03-22 11:59:43,731 - INFO - tqdm - f1: 0.9903, accuracy: 0.9903, batch_loss: 0.0058, loss: 0.0307 ||:   9%|8         | 110/1250 [00:30<04:39,  4.07it/s]
2022-03-22 11:59:53,835 - INFO - tqdm - f1: 0.9907, accuracy: 0.9907, batch_loss: 0.0009, loss: 0.0299 ||:  12%|#1        | 148/1250 [00:40<04:46,  3.84it/s]
2022-03-22 12:00:03,936 - INFO - tqdm - f1: 0.9910, accuracy: 0.9910, batch_loss: 0.0561, loss: 0.0272 ||:  15%|#5        | 188/1250 [00:50<03:39,  4.85it/s]
2022-03-22 12:00:14,280 - INFO - tqdm - f1: 0.9900, accuracy: 0.9900, batch_loss: 0.0179, loss: 0.0301 ||:  18%|#8        | 225/1250 [01:01<05:44,  2.98it/s]
2022-03-22 12:00:24,544 - INFO - tqdm - f1: 0.9897, accuracy: 0.9897, batch_loss: 0.0032, loss: 0.0304 ||:  21%|##        | 260/1250 [01:11<05:00,  3.29it/s]
2022-03-22 12:00:34,563 - INFO - tqdm - f1: 0.9897, accuracy: 0.9897, batch_loss: 0.0661, loss: 0.0319 ||:  24%|##3       | 298/1250 [01:21<04:45,  3.34it/s]
2022-03-22 12:00:44,800 - INFO - tqdm - f1: 0.9903, accuracy: 0.9903, batch_loss: 0.0008, loss: 0.0301 ||:  27%|##6       | 335/1250 [01:31<03:39,  4.18it/s]
2022-03-22 12:00:55,122 - INFO - tqdm - f1: 0.9896, accuracy: 0.9896, batch_loss: 0.0024, loss: 0.0316 ||:  30%|##9       | 372/1250 [01:41<04:44,  3.09it/s]
2022-03-22 12:01:05,237 - INFO - tqdm - f1: 0.9900, accuracy: 0.9900, batch_loss: 0.0093, loss: 0.0305 ||:  33%|###3      | 414/1250 [01:52<03:09,  4.40it/s]
2022-03-22 12:01:15,267 - INFO - tqdm - f1: 0.9894, accuracy: 0.9894, batch_loss: 0.0011, loss: 0.0326 ||:  36%|###5      | 448/1250 [02:02<03:20,  4.01it/s]
2022-03-22 12:01:25,328 - INFO - tqdm - f1: 0.9902, accuracy: 0.9902, batch_loss: 0.0066, loss: 0.0309 ||:  39%|###8      | 483/1250 [02:12<03:56,  3.24it/s]
2022-03-22 12:01:35,359 - INFO - tqdm - f1: 0.9901, accuracy: 0.9901, batch_loss: 0.1131, loss: 0.0312 ||:  42%|####1     | 520/1250 [02:22<03:35,  3.39it/s]
2022-03-22 12:01:45,676 - INFO - tqdm - f1: 0.9905, accuracy: 0.9905, batch_loss: 0.1133, loss: 0.0303 ||:  45%|####4     | 557/1250 [02:32<03:29,  3.31it/s]
2022-03-22 12:01:55,774 - INFO - tqdm - f1: 0.9896, accuracy: 0.9896, batch_loss: 0.0428, loss: 0.0338 ||:  48%|####7     | 594/1250 [02:42<02:28,  4.42it/s]
2022-03-22 12:02:05,984 - INFO - tqdm - f1: 0.9895, accuracy: 0.9895, batch_loss: 0.0084, loss: 0.0350 ||:  50%|#####     | 630/1250 [02:52<02:45,  3.74it/s]
2022-03-22 12:02:16,100 - INFO - tqdm - f1: 0.9898, accuracy: 0.9898, batch_loss: 0.0021, loss: 0.0346 ||:  53%|#####3    | 665/1250 [03:02<03:06,  3.14it/s]
2022-03-22 12:02:26,109 - INFO - tqdm - f1: 0.9903, accuracy: 0.9903, batch_loss: 0.0007, loss: 0.0333 ||:  56%|#####5    | 699/1250 [03:12<03:06,  2.95it/s]
2022-03-22 12:02:36,305 - INFO - tqdm - f1: 0.9900, accuracy: 0.9900, batch_loss: 0.0110, loss: 0.0345 ||:  59%|#####8    | 734/1250 [03:23<03:06,  2.76it/s]
2022-03-22 12:02:46,346 - INFO - tqdm - f1: 0.9899, accuracy: 0.9899, batch_loss: 0.0047, loss: 0.0345 ||:  62%|######1   | 771/1250 [03:33<01:56,  4.12it/s]
2022-03-22 12:02:56,358 - INFO - tqdm - f1: 0.9897, accuracy: 0.9897, batch_loss: 0.0030, loss: 0.0349 ||:  64%|######4   | 806/1250 [03:43<02:09,  3.42it/s]
2022-03-22 12:03:06,385 - INFO - tqdm - f1: 0.9893, accuracy: 0.9893, batch_loss: 0.0337, loss: 0.0362 ||:  68%|######7   | 844/1250 [03:53<01:39,  4.10it/s]
2022-03-22 12:03:16,652 - INFO - tqdm - f1: 0.9897, accuracy: 0.9897, batch_loss: 0.0084, loss: 0.0353 ||:  70%|#######   | 880/1250 [04:03<01:59,  3.11it/s]
2022-03-22 12:03:26,687 - INFO - tqdm - f1: 0.9896, accuracy: 0.9896, batch_loss: 0.0015, loss: 0.0360 ||:  73%|#######3  | 916/1250 [04:13<01:23,  3.98it/s]
2022-03-22 12:03:37,056 - INFO - tqdm - f1: 0.9896, accuracy: 0.9896, batch_loss: 0.0085, loss: 0.0358 ||:  76%|#######6  | 952/1250 [04:23<01:32,  3.21it/s]
2022-03-22 12:03:47,369 - INFO - tqdm - f1: 0.9893, accuracy: 0.9893, batch_loss: 0.2693, loss: 0.0368 ||:  79%|#######9  | 990/1250 [04:34<01:24,  3.07it/s]
2022-03-22 12:03:57,377 - INFO - tqdm - f1: 0.9894, accuracy: 0.9894, batch_loss: 0.0014, loss: 0.0364 ||:  82%|########2 | 1025/1250 [04:44<01:09,  3.22it/s]
2022-03-22 12:04:07,437 - INFO - tqdm - f1: 0.9893, accuracy: 0.9893, batch_loss: 0.0151, loss: 0.0366 ||:  85%|########5 | 1064/1250 [04:54<00:46,  4.00it/s]
2022-03-22 12:04:17,698 - INFO - tqdm - f1: 0.9891, accuracy: 0.9891, batch_loss: 0.0039, loss: 0.0374 ||:  88%|########8 | 1102/1250 [05:04<00:42,  3.44it/s]
2022-03-22 12:04:27,921 - INFO - tqdm - f1: 0.9890, accuracy: 0.9890, batch_loss: 0.0064, loss: 0.0375 ||:  91%|#########1| 1140/1250 [05:14<00:29,  3.71it/s]
2022-03-22 12:04:38,034 - INFO - tqdm - f1: 0.9890, accuracy: 0.9890, batch_loss: 0.0014, loss: 0.0372 ||:  94%|#########3| 1175/1250 [05:24<00:22,  3.35it/s]
2022-03-22 12:04:48,140 - INFO - tqdm - f1: 0.9887, accuracy: 0.9887, batch_loss: 0.0078, loss: 0.0382 ||:  97%|#########7| 1213/1250 [05:34<00:09,  3.79it/s]
2022-03-22 12:04:56,242 - INFO - tqdm - f1: 0.9886, accuracy: 0.9886, batch_loss: 0.0039, loss: 0.0382 ||: 100%|#########9| 1244/1250 [05:43<00:01,  4.24it/s]
2022-03-22 12:04:56,529 - INFO - tqdm - f1: 0.9887, accuracy: 0.9887, batch_loss: 0.0288, loss: 0.0382 ||: 100%|#########9| 1245/1250 [05:43<00:01,  3.98it/s]
2022-03-22 12:04:56,820 - INFO - tqdm - f1: 0.9887, accuracy: 0.9887, batch_loss: 0.0059, loss: 0.0382 ||: 100%|#########9| 1246/1250 [05:43<00:01,  3.80it/s]
2022-03-22 12:04:57,210 - INFO - tqdm - f1: 0.9886, accuracy: 0.9886, batch_loss: 0.0881, loss: 0.0382 ||: 100%|#########9| 1247/1250 [05:44<00:00,  3.32it/s]
2022-03-22 12:04:57,487 - INFO - tqdm - f1: 0.9886, accuracy: 0.9886, batch_loss: 0.0422, loss: 0.0382 ||: 100%|#########9| 1248/1250 [05:44<00:00,  3.40it/s]
2022-03-22 12:04:57,885 - INFO - tqdm - f1: 0.9886, accuracy: 0.9886, batch_loss: 0.0107, loss: 0.0382 ||: 100%|#########9| 1249/1250 [05:44<00:00,  3.07it/s]
2022-03-22 12:04:58,268 - INFO - tqdm - f1: 0.9887, accuracy: 0.9887, batch_loss: 0.0759, loss: 0.0382 ||: 100%|##########| 1250/1250 [05:45<00:00,  2.92it/s]
2022-03-22 12:04:58,282 - INFO - tqdm - f1: 0.9887, accuracy: 0.9887, batch_loss: 0.0759, loss: 0.0382 ||: 100%|##########| 1250/1250 [05:45<00:00,  3.62it/s]
2022-03-22 12:04:58,286 - INFO - allennlp.training.trainer - Validating
2022-03-22 12:04:58,287 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-22 12:05:08,354 - INFO - tqdm - f1: 0.9502, accuracy: 0.9502, batch_loss: 0.0234, loss: 0.2163 ||:  25%|##5       | 79/313 [00:10<00:29,  7.97it/s]
2022-03-22 12:05:18,436 - INFO - tqdm - f1: 0.9483, accuracy: 0.9483, batch_loss: 0.0027, loss: 0.2137 ||:  53%|#####2    | 165/313 [00:20<00:18,  8.01it/s]
2022-03-22 12:05:28,643 - INFO - tqdm - f1: 0.9475, accuracy: 0.9475, batch_loss: 0.4439, loss: 0.2012 ||:  79%|#######8  | 247/313 [00:30<00:07,  8.43it/s]
2022-03-22 12:05:36,271 - INFO - tqdm - f1: 0.9452, accuracy: 0.9452, batch_loss: 0.1568, loss: 0.2039 ||: 100%|#########9| 312/313 [00:37<00:00,  8.73it/s]
2022-03-22 12:05:36,310 - INFO - tqdm - f1: 0.9448, accuracy: 0.9448, batch_loss: 0.5757, loss: 0.2051 ||: 100%|##########| 313/313 [00:38<00:00,  8.23it/s]
2022-03-22 12:05:36,317 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-22 12:05:36,328 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-22 12:05:36,789 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-22 12:05:36,800 - INFO - allennlp.training.util - Iterating over dataset
2022-03-22 12:05:36,811 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-22 12:05:36,844 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-22 12:05:36,848 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-22 12:05:46,865 - INFO - tqdm - f1: 0.94, accuracy: 0.94, loss: 0.15 ||: : 80it [00:10,  9.72it/s]
2022-03-22 12:05:57,016 - INFO - tqdm - f1: 0.94, accuracy: 0.94, loss: 0.14 ||: : 168it [00:20,  8.98it/s]
2022-03-22 12:06:07,143 - INFO - tqdm - f1: 0.94, accuracy: 0.94, loss: 0.15 ||: : 257it [00:30,  8.92it/s]
2022-03-22 12:06:17,145 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.13 ||: : 337it [00:40,  9.64it/s]
2022-03-22 12:06:27,257 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.14 ||: : 420it [00:50,  7.69it/s]
2022-03-22 12:06:37,302 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.14 ||: : 505it [01:00,  8.34it/s]
2022-03-22 12:06:47,376 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.14 ||: : 588it [01:10,  8.70it/s]
2022-03-22 12:06:57,389 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.14 ||: : 671it [01:20,  7.13it/s]
2022-03-22 12:07:07,488 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.14 ||: : 757it [01:30, 10.36it/s]
2022-03-22 12:07:17,581 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.13 ||: : 841it [01:40,  7.79it/s]
2022-03-22 12:07:27,754 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.13 ||: : 923it [01:50,  9.28it/s]
2022-03-22 12:07:37,765 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.13 ||: : 1002it [02:00,  7.96it/s]
2022-03-22 12:07:47,796 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.13 ||: : 1083it [02:10,  7.28it/s]
2022-03-22 12:07:57,842 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.13 ||: : 1167it [02:21,  7.65it/s]
2022-03-22 12:08:07,932 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.13 ||: : 1251it [02:31,  9.07it/s]
2022-03-22 12:08:17,996 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.13 ||: : 1337it [02:41,  9.06it/s]
2022-03-22 12:08:28,033 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.13 ||: : 1421it [02:51,  7.97it/s]
2022-03-22 12:08:38,233 - INFO - tqdm - f1: 0.95, accuracy: 0.95, loss: 0.13 ||: : 1507it [03:01,  6.84it/s]
2022-03-22 12:08:45,231 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 1,
  "peak_worker_0_memory_MB": 10044.32421875,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "0:24:59.703299",
  "training_start_epoch": 0,
  "training_epochs": 3,
  "epoch": 3,
  "training_f1": 0.9839999973773956,
  "training_accuracy": 0.984,
  "training_loss": 0.05181553372717462,
  "training_worker_0_memory_MB": 10044.32421875,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.944582462310791,
  "validation_accuracy": 0.9446,
  "validation_loss": 0.2410220213649317,
  "best_validation_f1": 0.952399879693985,
  "best_validation_accuracy": 0.9524,
  "best_validation_loss": 0.13717162492536247,
  "test_f1": 0.9524797201156616,
  "test_accuracy": 0.95248,
  "test_loss": 0.13210763952677554
}
2022-03-22 12:08:46,256 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/imdb_base_hyper_small_seed_13/model.tar.gz
