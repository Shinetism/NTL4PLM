2022-03-21 07:49:58,971 - INFO - allennlp.common.params - random_seed = 314
2022-03-21 07:49:58,986 - INFO - allennlp.common.params - numpy_seed = 314
2022-03-21 07:49:58,997 - INFO - allennlp.common.params - pytorch_seed = 314
2022-03-21 07:49:59,012 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-21 07:49:59,014 - INFO - allennlp.common.params - type = default
2022-03-21 07:49:59,028 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-21 07:49:59,047 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 07:49:59,067 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 07:49:59,075 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 07:49:59,077 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 07:49:59,091 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 07:49:59,094 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 07:50:12,141 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 07:50:12,178 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 07:50:12,182 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 07:50:12,214 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-21 07:50:12,252 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-21 07:50:12,256 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 07:50:12,288 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-21 07:50:12,313 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-21 07:50:12,329 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-21 07:50:12,356 - INFO - allennlp.common.params - train_data_path = datasets/sciie/train.jsonl
2022-03-21 07:50:12,361 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7ff122829250>
2022-03-21 07:50:12,393 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-21 07:50:12,403 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-21 07:50:12,405 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 07:50:12,419 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 07:50:12,432 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 07:50:12,465 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 07:50:12,472 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 07:50:12,500 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 07:50:12,503 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 07:50:12,505 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 07:50:12,506 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 07:50:12,508 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-21 07:50:12,509 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-21 07:50:12,523 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 07:50:12,537 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-21 07:50:12,557 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-21 07:50:12,575 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-21 07:50:12,577 - INFO - allennlp.common.params - validation_data_path = datasets/sciie/dev.jsonl
2022-03-21 07:50:12,593 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-21 07:50:12,619 - INFO - allennlp.common.params - test_data_path = datasets/sciie/test.jsonl
2022-03-21 07:50:12,643 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-21 07:50:12,684 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-21 07:50:12,685 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 07:50:12,700 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 07:50:12,733 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 07:50:12,736 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 07:50:12,738 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 07:50:12,754 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 07:50:12,798 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 07:50:12,812 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 07:50:12,830 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 07:50:12,868 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 07:50:12,880 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 07:50:12,907 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 07:50:12,925 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 07:50:12,955 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 07:50:12,970 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 07:50:16,041 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 07:50:16,059 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 07:50:16,085 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 07:50:16,116 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 07:50:16,118 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 07:50:16,133 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 07:50:16,153 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 07:50:16,180 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 07:50:16,193 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 07:50:16,206 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 07:50:16,221 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 07:50:16,250 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 07:50:16,278 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 07:50:16,291 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 07:50:16,293 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 07:50:16,597 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 07:50:16,615 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 07:50:16,625 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 07:50:16,635 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 07:50:16,642 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 07:50:16,652 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 07:50:16,665 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 07:50:16,680 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 07:50:16,692 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 07:50:16,706 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 07:50:16,719 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 07:50:16,733 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 07:50:16,746 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 07:50:16,760 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 07:50:16,762 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 07:50:17,192 - INFO - allennlp.common.params - type = from_instances
2022-03-21 07:50:17,209 - INFO - allennlp.common.params - min_count = None
2022-03-21 07:50:17,218 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-21 07:50:17,246 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-21 07:50:17,259 - INFO - allennlp.common.params - pretrained_files = None
2022-03-21 07:50:17,277 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-21 07:50:17,286 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-21 07:50:17,313 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-21 07:50:17,341 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-21 07:50:17,354 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-21 07:50:17,369 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-21 07:50:17,380 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-21 07:50:17,418 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-21 07:50:17,421 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-21 07:50:17,443 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-21 07:50:17,447 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-21 07:50:17,460 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-21 07:50:17,473 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-21 07:50:17,487 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-21 07:50:17,500 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-21 07:50:17,513 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-21 07:50:17,537 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-21 07:50:17,540 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-21 07:50:17,556 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-21 07:50:17,568 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-21 07:50:23,367 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-21 07:50:23,374 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-21 07:50:23,387 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-21 07:50:23,400 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-21 07:50:23,413 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-21 07:50:23,426 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-21 07:50:23,429 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-21 07:50:23,430 - INFO - allennlp.common.params - type = tanh
2022-03-21 07:50:23,432 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-21 07:50:23,440 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-21 07:50:23,450 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-21 07:50:23,463 - INFO - allennlp.common.params - model.num_labels = None
2022-03-21 07:50:23,477 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-21 07:50:23,490 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7ff1227bb190>
2022-03-21 07:50:23,503 - INFO - allennlp.common.params - model.regularizer = None
2022-03-21 07:50:23,520 - INFO - allennlp.common.params - model.track_weights = False
2022-03-21 07:50:23,530 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-21 07:50:23,544 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-21 07:50:23,546 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-21 07:50:23,547 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-21 07:50:23,548 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-21 07:50:23,549 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-21 07:50:23,550 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-21 07:50:23,552 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 07:50:23,553 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 07:50:23,570 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 07:50:23,584 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 07:50:23,586 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 07:50:23,587 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 07:50:23,588 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 07:50:23,590 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 07:50:23,591 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 07:50:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 07:50:23,618 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 07:50:23,632 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 07:50:23,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 07:50:23,659 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 07:50:23,673 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 07:50:23,675 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 07:50:23,677 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 07:50:23,678 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 07:50:23,692 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 07:50:23,709 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 07:50:23,720 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 07:50:23,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 07:50:23,747 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 07:50:23,761 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 07:50:23,774 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 07:50:23,787 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 07:50:23,801 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 07:50:23,814 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 07:50:23,828 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 07:50:23,841 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 07:50:23,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 07:50:23,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 07:50:23,882 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 07:50:23,895 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 07:50:23,909 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 07:50:23,923 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 07:50:23,937 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 07:50:23,952 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 07:50:23,966 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 07:50:23,979 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 07:50:23,981 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 07:50:23,983 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 07:50:23,984 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 07:50:23,986 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 07:50:23,987 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 07:50:24,002 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 07:50:24,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 07:50:24,031 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 07:50:24,044 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 07:50:24,058 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 07:50:24,072 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 07:50:24,089 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 07:50:24,100 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 07:50:24,114 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 07:50:24,115 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 07:50:24,117 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 07:50:24,118 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 07:50:24,120 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 07:50:24,122 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 07:50:24,123 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 07:50:24,125 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 07:50:24,126 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 07:50:24,128 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 07:50:24,129 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 07:50:24,131 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 07:50:24,132 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 07:50:24,134 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 07:50:24,135 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 07:50:24,136 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 07:50:24,138 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 07:50:24,139 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 07:50:24,140 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 07:50:24,142 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 07:50:24,143 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 07:50:24,145 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 07:50:24,147 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 07:50:24,149 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 07:50:24,150 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 07:50:24,151 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 07:50:24,153 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 07:50:24,154 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 07:50:24,158 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 07:50:24,160 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 07:50:24,161 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 07:50:24,162 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 07:50:24,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 07:50:24,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 07:50:24,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 07:50:24,168 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 07:50:24,170 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 07:50:24,171 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 07:50:24,173 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 07:50:24,174 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 07:50:24,175 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 07:50:24,177 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 07:50:24,194 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 07:50:24,213 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 07:50:24,221 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 07:50:24,234 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 07:50:24,235 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 07:50:24,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 07:50:24,251 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 07:50:24,265 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 07:50:24,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 07:50:24,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 07:50:24,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 07:50:24,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 07:50:24,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 07:50:24,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 07:50:24,313 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 07:50:24,315 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 07:50:24,316 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 07:50:24,318 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 07:50:24,319 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 07:50:24,321 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 07:50:24,337 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 07:50:24,351 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 07:50:24,365 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 07:50:24,379 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 07:50:24,381 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 07:50:24,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 07:50:24,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 07:50:24,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 07:50:24,425 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 07:50:24,427 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 07:50:24,442 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 07:50:24,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 07:50:24,468 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 07:50:24,482 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 07:50:24,495 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 07:50:24,509 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 07:50:24,510 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 07:50:24,511 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 07:50:24,513 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 07:50:24,527 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 07:50:24,541 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 07:50:24,554 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 07:50:24,567 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 07:50:24,582 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 07:50:24,595 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 07:50:24,611 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 07:50:24,623 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 07:50:24,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 07:50:24,651 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 07:50:24,653 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 07:50:24,654 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 07:50:24,669 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 07:50:24,683 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 07:50:24,696 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 07:50:24,710 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 07:50:24,724 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 07:50:24,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 07:50:24,751 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 07:50:24,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 07:50:24,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 07:50:24,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 07:50:24,770 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 07:50:24,772 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 07:50:24,774 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 07:50:24,776 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 07:50:24,778 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 07:50:24,780 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 07:50:24,782 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 07:50:24,784 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 07:50:24,786 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 07:50:24,787 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 07:50:24,789 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 07:50:24,791 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 07:50:24,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 07:50:24,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 07:50:24,798 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 07:50:24,800 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 07:50:24,801 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 07:50:24,803 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 07:50:24,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 07:50:24,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 07:50:24,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 07:50:24,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 07:50:24,812 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 07:50:24,813 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 07:50:24,814 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 07:50:24,816 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 07:50:24,817 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 07:50:24,818 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 07:50:24,820 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 07:50:24,821 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 07:50:24,822 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 07:50:24,824 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 07:50:24,826 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 07:50:24,827 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 07:50:24,829 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 07:50:24,830 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 07:50:24,831 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 07:50:24,832 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 07:50:24,834 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 07:50:24,835 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 07:50:24,836 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 07:50:24,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 07:50:24,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 07:50:26,093 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-21 07:50:26,101 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-21 07:50:26,110 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-21 07:50:26,123 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-21 07:50:26,137 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-21 07:50:26,150 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-21 07:50:26,163 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-21 07:50:26,176 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-21 07:50:26,190 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-21 07:50:26,204 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-21 07:50:26,218 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-21 07:50:26,232 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-21 07:50:26,246 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-21 07:50:26,260 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-21 07:50:26,274 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-21 07:50:26,288 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-21 07:50:26,301 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-21 07:50:34,035 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-21 07:50:34,052 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-21 07:50:34,072 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-21 07:50:34,089 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-21 07:50:34,090 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-21 07:50:34,107 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-21 07:50:34,109 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-21 07:50:34,117 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight'], {'weight_decay': 0}
2022-03-21 07:50:34,130 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight'], {}
2022-03-21 07:50:34,166 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-21 07:50:34,173 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125241607
2022-03-21 07:50:34,187 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-21 07:50:34,200 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-21 07:50:34,213 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 07:50:34,226 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 07:50:34,239 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 07:50:34,252 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 07:50:34,268 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 07:50:34,281 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 07:50:34,282 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 07:50:34,328 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 07:50:34,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 07:50:34,374 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 07:50:34,376 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 07:50:34,377 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 07:50:34,378 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 07:50:34,391 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 07:50:34,405 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 07:50:34,418 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 07:50:34,457 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 07:50:34,490 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 07:50:34,503 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 07:50:34,516 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 07:50:34,529 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 07:50:34,560 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 07:50:34,576 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 07:50:34,608 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 07:50:34,612 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 07:50:34,623 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 07:50:34,636 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 07:50:34,650 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 07:50:34,663 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 07:50:34,665 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 07:50:34,666 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 07:50:34,681 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 07:50:34,696 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 07:50:34,711 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 07:50:34,713 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 07:50:34,715 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 07:50:34,730 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 07:50:34,732 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 07:50:34,733 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 07:50:34,747 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 07:50:34,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 07:50:34,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 07:50:34,765 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 07:50:34,767 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 07:50:34,790 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 07:50:34,798 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 07:50:34,802 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 07:50:34,820 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 07:50:34,821 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 07:50:34,823 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 07:50:34,824 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 07:50:34,837 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 07:50:34,839 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 07:50:34,840 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 07:50:34,878 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 07:50:34,891 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 07:50:34,892 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 07:50:34,908 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 07:50:34,925 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 07:50:34,934 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 07:50:34,936 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 07:50:34,937 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 07:50:34,966 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 07:50:34,985 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 07:50:35,029 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 07:50:35,035 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 07:50:35,049 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 07:50:35,050 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 07:50:35,063 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 07:50:35,076 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 07:50:35,091 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 07:50:35,121 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 07:50:35,130 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 07:50:35,151 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 07:50:35,171 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 07:50:35,184 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 07:50:35,185 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 07:50:35,186 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 07:50:35,200 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 07:50:35,213 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 07:50:35,227 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 07:50:35,228 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 07:50:35,230 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 07:50:35,234 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 07:50:35,271 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 07:50:35,285 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 07:50:35,286 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 07:50:35,301 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 07:50:35,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 07:50:35,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 07:50:35,329 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 07:50:35,330 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 07:50:35,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 07:50:35,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 07:50:35,378 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 07:50:35,412 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 07:50:35,425 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 07:50:35,438 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 07:50:35,451 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 07:50:35,464 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 07:50:35,477 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 07:50:35,513 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 07:50:35,515 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 07:50:35,516 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 07:50:35,517 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 07:50:35,518 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 07:50:35,520 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 07:50:35,521 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 07:50:35,522 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 07:50:35,524 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 07:50:35,525 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 07:50:35,533 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 07:50:35,579 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 07:50:35,589 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 07:50:35,602 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 07:50:35,614 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 07:50:35,628 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 07:50:35,641 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 07:50:35,654 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 07:50:35,655 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 07:50:35,657 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 07:50:35,659 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 07:50:35,696 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 07:50:35,697 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 07:50:35,698 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 07:50:35,714 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 07:50:35,724 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 07:50:35,754 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 07:50:35,767 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 07:50:35,780 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 07:50:35,782 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 07:50:35,783 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 07:50:35,784 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 07:50:35,786 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 07:50:35,787 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 07:50:35,788 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 07:50:35,790 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 07:50:35,791 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 07:50:35,841 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 07:50:35,847 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 07:50:35,849 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 07:50:35,850 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 07:50:35,863 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 07:50:35,909 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 07:50:35,917 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 07:50:35,930 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 07:50:35,933 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 07:50:35,935 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 07:50:35,937 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 07:50:35,938 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 07:50:35,953 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 07:50:35,967 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 07:50:35,980 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 07:50:35,993 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 07:50:36,026 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 07:50:36,069 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 07:50:36,071 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 07:50:36,072 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 07:50:36,109 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 07:50:36,123 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 07:50:36,136 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 07:50:36,149 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 07:50:36,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 07:50:36,175 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 07:50:36,189 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 07:50:36,190 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 07:50:36,191 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 07:50:36,193 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 07:50:36,195 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 07:50:36,197 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 07:50:36,198 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 07:50:36,203 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 07:50:36,205 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 07:50:36,208 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 07:50:36,209 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 07:50:36,211 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 07:50:36,213 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 07:50:36,214 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 07:50:36,216 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 07:50:36,217 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 07:50:36,219 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 07:50:36,220 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 07:50:36,221 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 07:50:36,223 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 07:50:36,225 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 07:50:36,226 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 07:50:36,227 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 07:50:36,229 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 07:50:36,230 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 07:50:36,232 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 07:50:36,233 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 07:50:36,245 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 07:50:36,249 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 07:50:36,251 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 07:50:36,252 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 07:50:36,253 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 07:50:36,254 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 07:50:36,255 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 07:50:36,256 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 07:50:36,258 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-21 07:50:36,263 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-21 07:50:36,264 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-21 07:50:36,265 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-21 07:50:36,266 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-21 07:50:36,268 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-21 07:50:36,269 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-21 07:50:36,270 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-21 07:50:36,271 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-21 07:50:36,273 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-21 07:50:36,276 - INFO - allennlp.training.trainer - Beginning training.
2022-03-21 07:50:36,277 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-21 07:50:36,279 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.2G
2022-03-21 07:50:36,280 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 07:50:36,282 - INFO - allennlp.training.trainer - Training
2022-03-21 07:50:36,284 - INFO - tqdm - 0%|          | 0/202 [00:00<?, ?it/s]
2022-03-21 07:50:36,290 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 07:50:36,298 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 07:50:46,384 - INFO - tqdm - f1: 0.1091, accuracy: 0.4309, batch_loss: 1.4181, loss: 1.7509 ||:   9%|9         | 19/202 [00:10<01:20,  2.27it/s]
2022-03-21 07:50:56,686 - INFO - tqdm - f1: 0.1084, accuracy: 0.4973, batch_loss: 1.4999, loss: 1.5721 ||:  23%|##2       | 46/202 [00:20<00:58,  2.68it/s]
2022-03-21 07:51:07,061 - INFO - tqdm - f1: 0.1046, accuracy: 0.5046, batch_loss: 1.7764, loss: 1.5419 ||:  37%|###7      | 75/202 [00:30<00:47,  2.66it/s]
2022-03-21 07:51:17,142 - INFO - tqdm - f1: 0.1316, accuracy: 0.5144, batch_loss: 1.2119, loss: 1.4784 ||:  51%|#####     | 103/202 [00:40<00:38,  2.55it/s]
2022-03-21 07:51:27,473 - INFO - tqdm - f1: 0.1675, accuracy: 0.5378, batch_loss: 0.7511, loss: 1.4096 ||:  66%|######6   | 134/202 [00:51<00:24,  2.78it/s]
2022-03-21 07:51:37,777 - INFO - tqdm - f1: 0.2129, accuracy: 0.5523, batch_loss: 1.0921, loss: 1.3613 ||:  78%|#######8  | 158/202 [01:01<00:16,  2.66it/s]
2022-03-21 07:51:47,893 - INFO - tqdm - f1: 0.2491, accuracy: 0.5727, batch_loss: 0.5463, loss: 1.3021 ||:  93%|#########2| 187/202 [01:11<00:04,  3.31it/s]
2022-03-21 07:51:52,803 - INFO - tqdm - f1: 0.2706, accuracy: 0.5838, batch_loss: 0.7249, loss: 1.2715 ||: 100%|#########9| 201/202 [01:16<00:00,  3.17it/s]
2022-03-21 07:51:53,294 - INFO - tqdm - f1: 0.2716, accuracy: 0.5843, batch_loss: 0.9126, loss: 1.2697 ||: 100%|##########| 202/202 [01:17<00:00,  2.72it/s]
2022-03-21 07:51:53,308 - INFO - tqdm - f1: 0.2716, accuracy: 0.5843, batch_loss: 0.9126, loss: 1.2697 ||: 100%|##########| 202/202 [01:17<00:00,  2.62it/s]
2022-03-21 07:51:53,325 - INFO - allennlp.training.trainer - Validating
2022-03-21 07:51:53,330 - INFO - tqdm - 0%|          | 0/29 [00:00<?, ?it/s]
2022-03-21 07:51:53,332 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 07:51:53,345 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 07:52:00,010 - INFO - tqdm - f1: 0.4803, accuracy: 0.7077, batch_loss: 0.5056, loss: 0.8438 ||: 100%|##########| 29/29 [00:06<00:00,  5.01it/s]
2022-03-21 07:52:00,025 - INFO - tqdm - f1: 0.4803, accuracy: 0.7077, batch_loss: 0.5056, loss: 0.8438 ||: 100%|##########| 29/29 [00:06<00:00,  4.33it/s]
2022-03-21 07:52:00,183 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/sciie_base_hyper_small_seed_314/best.th'.
2022-03-21 07:52:04,151 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 07:52:04,162 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.584  |     0.708
2022-03-21 07:52:04,179 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.272  |     0.480
2022-03-21 07:52:04,193 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 07:52:04,207 - INFO - allennlp.training.callbacks.console_logger - loss               |     1.270  |     0.844
2022-03-21 07:52:04,271 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  6354.719  |       N/A
2022-03-21 07:52:04,284 - INFO - allennlp.training.trainer - Epoch duration: 0:01:28.006245
2022-03-21 07:52:04,286 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:13:12
2022-03-21 07:52:04,300 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-21 07:52:04,314 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.3G
2022-03-21 07:52:04,328 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 07:52:04,342 - INFO - allennlp.training.trainer - Training
2022-03-21 07:52:04,355 - INFO - tqdm - 0%|          | 0/202 [00:00<?, ?it/s]
2022-03-21 07:52:14,425 - INFO - tqdm - f1: 0.4825, accuracy: 0.7112, batch_loss: 0.8260, loss: 0.9205 ||:  13%|#3        | 27/202 [00:10<01:03,  2.77it/s]
2022-03-21 07:52:24,886 - INFO - tqdm - f1: 0.4981, accuracy: 0.7309, batch_loss: 0.4276, loss: 0.8593 ||:  27%|##6       | 54/202 [00:20<01:04,  2.29it/s]
2022-03-21 07:52:35,010 - INFO - tqdm - f1: 0.5261, accuracy: 0.7405, batch_loss: 0.9764, loss: 0.8073 ||:  40%|####      | 81/202 [00:30<00:44,  2.74it/s]
2022-03-21 07:52:45,338 - INFO - tqdm - f1: 0.5336, accuracy: 0.7399, batch_loss: 0.5808, loss: 0.7918 ||:  53%|#####3    | 108/202 [00:40<00:36,  2.59it/s]
2022-03-21 07:52:55,356 - INFO - tqdm - f1: 0.5753, accuracy: 0.7596, batch_loss: 0.6809, loss: 0.7400 ||:  67%|######7   | 136/202 [00:50<00:23,  2.84it/s]
2022-03-21 07:53:05,481 - INFO - tqdm - f1: 0.6003, accuracy: 0.7761, batch_loss: 0.5090, loss: 0.6935 ||:  81%|########  | 163/202 [01:01<00:13,  2.87it/s]
2022-03-21 07:53:15,510 - INFO - tqdm - f1: 0.6348, accuracy: 0.7888, batch_loss: 0.5538, loss: 0.6628 ||:  95%|#########5| 192/202 [01:11<00:03,  3.12it/s]
2022-03-21 07:53:19,022 - INFO - tqdm - f1: 0.6380, accuracy: 0.7921, batch_loss: 0.4201, loss: 0.6531 ||: 100%|#########9| 201/202 [01:14<00:00,  2.67it/s]
2022-03-21 07:53:19,275 - INFO - tqdm - f1: 0.6393, accuracy: 0.7922, batch_loss: 0.8018, loss: 0.6539 ||: 100%|##########| 202/202 [01:14<00:00,  2.96it/s]
2022-03-21 07:53:19,286 - INFO - tqdm - f1: 0.6393, accuracy: 0.7922, batch_loss: 0.8018, loss: 0.6539 ||: 100%|##########| 202/202 [01:14<00:00,  2.70it/s]
2022-03-21 07:53:19,439 - INFO - allennlp.training.trainer - Validating
2022-03-21 07:53:19,479 - INFO - tqdm - 0%|          | 0/29 [00:00<?, ?it/s]
2022-03-21 07:53:26,881 - INFO - tqdm - f1: 0.7755, accuracy: 0.8418, batch_loss: 0.1823, loss: 0.5344 ||: 100%|##########| 29/29 [00:07<00:00,  3.63it/s]
2022-03-21 07:53:26,900 - INFO - tqdm - f1: 0.7755, accuracy: 0.8418, batch_loss: 0.1823, loss: 0.5344 ||: 100%|##########| 29/29 [00:07<00:00,  3.91it/s]
2022-03-21 07:53:26,939 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/sciie_base_hyper_small_seed_314/best.th'.
2022-03-21 07:53:31,419 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 07:53:31,434 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.792  |     0.842
2022-03-21 07:53:31,465 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.639  |     0.776
2022-03-21 07:53:31,499 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 07:53:31,533 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.654  |     0.534
2022-03-21 07:53:31,534 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  6400.285  |       N/A
2022-03-21 07:53:31,535 - INFO - allennlp.training.trainer - Epoch duration: 0:01:27.235660
2022-03-21 07:53:31,550 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:11:41
2022-03-21 07:53:31,564 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-21 07:53:31,579 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.3G
2022-03-21 07:53:31,594 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 07:53:31,611 - INFO - allennlp.training.trainer - Training
2022-03-21 07:53:31,623 - INFO - tqdm - 0%|          | 0/202 [00:00<?, ?it/s]
2022-03-21 07:53:41,744 - INFO - tqdm - f1: 0.8180, accuracy: 0.9038, batch_loss: 0.2568, loss: 0.3341 ||:  13%|#2        | 26/202 [00:10<01:10,  2.49it/s]
2022-03-21 07:53:51,785 - INFO - tqdm - f1: 0.8306, accuracy: 0.8909, batch_loss: 0.1956, loss: 0.3757 ||:  27%|##7       | 55/202 [00:20<00:46,  3.14it/s]
2022-03-21 07:54:01,888 - INFO - tqdm - f1: 0.8279, accuracy: 0.8863, batch_loss: 0.2069, loss: 0.3842 ||:  41%|####1     | 83/202 [00:30<00:41,  2.87it/s]
2022-03-21 07:54:12,044 - INFO - tqdm - f1: 0.8341, accuracy: 0.8923, batch_loss: 0.6218, loss: 0.3625 ||:  55%|#####5    | 112/202 [00:40<00:30,  2.93it/s]
2022-03-21 07:54:22,320 - INFO - tqdm - f1: 0.8359, accuracy: 0.8948, batch_loss: 0.3237, loss: 0.3541 ||:  69%|######8   | 139/202 [00:50<00:21,  2.92it/s]
2022-03-21 07:54:32,534 - INFO - tqdm - f1: 0.8376, accuracy: 0.8964, batch_loss: 0.0997, loss: 0.3507 ||:  83%|########3 | 168/202 [01:00<00:10,  3.19it/s]
2022-03-21 07:54:42,823 - INFO - tqdm - f1: 0.8399, accuracy: 0.8998, batch_loss: 0.4438, loss: 0.3377 ||:  97%|#########7| 196/202 [01:11<00:02,  2.70it/s]
2022-03-21 07:54:44,550 - INFO - tqdm - f1: 0.8390, accuracy: 0.8988, batch_loss: 0.2081, loss: 0.3399 ||: 100%|#########9| 201/202 [01:12<00:00,  2.84it/s]
2022-03-21 07:54:45,074 - INFO - tqdm - f1: 0.8394, accuracy: 0.8990, batch_loss: 0.3301, loss: 0.3398 ||: 100%|##########| 202/202 [01:13<00:00,  2.48it/s]
2022-03-21 07:54:45,094 - INFO - tqdm - f1: 0.8394, accuracy: 0.8990, batch_loss: 0.3301, loss: 0.3398 ||: 100%|##########| 202/202 [01:13<00:00,  2.75it/s]
2022-03-21 07:54:45,237 - INFO - allennlp.training.trainer - Validating
2022-03-21 07:54:45,277 - INFO - tqdm - 0%|          | 0/29 [00:00<?, ?it/s]
2022-03-21 07:54:52,579 - INFO - tqdm - f1: 0.8369, accuracy: 0.8659, batch_loss: 0.1374, loss: 0.4824 ||: 100%|##########| 29/29 [00:07<00:00,  4.44it/s]
2022-03-21 07:54:52,582 - INFO - tqdm - f1: 0.8369, accuracy: 0.8659, batch_loss: 0.1374, loss: 0.4824 ||: 100%|##########| 29/29 [00:07<00:00,  3.98it/s]
2022-03-21 07:54:52,722 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/sciie_base_hyper_small_seed_314/best.th'.
2022-03-21 07:54:57,178 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 07:54:57,191 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.899  |     0.866
2022-03-21 07:54:57,202 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.839  |     0.837
2022-03-21 07:54:57,215 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 07:54:57,263 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.340  |     0.482
2022-03-21 07:54:57,294 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  6400.379  |       N/A
2022-03-21 07:54:57,306 - INFO - allennlp.training.trainer - Epoch duration: 0:01:25.741379
2022-03-21 07:54:57,318 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:10:09
2022-03-21 07:54:57,330 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-21 07:54:57,341 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.3G
2022-03-21 07:54:57,353 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 07:54:57,368 - INFO - allennlp.training.trainer - Training
2022-03-21 07:54:57,377 - INFO - tqdm - 0%|          | 0/202 [00:00<?, ?it/s]
2022-03-21 07:55:07,639 - INFO - tqdm - f1: 0.8873, accuracy: 0.9259, batch_loss: 0.4205, loss: 0.2551 ||:  13%|#3        | 27/202 [00:10<01:09,  2.53it/s]
2022-03-21 07:55:17,905 - INFO - tqdm - f1: 0.8940, accuracy: 0.9329, batch_loss: 0.2599, loss: 0.2260 ||:  27%|##6       | 54/202 [00:20<00:55,  2.67it/s]
2022-03-21 07:55:28,195 - INFO - tqdm - f1: 0.9061, accuracy: 0.9352, batch_loss: 0.0699, loss: 0.2312 ||:  41%|####1     | 83/202 [00:30<00:39,  3.01it/s]
2022-03-21 07:55:38,303 - INFO - tqdm - f1: 0.8984, accuracy: 0.9331, batch_loss: 0.9171, loss: 0.2348 ||:  55%|#####4    | 111/202 [00:40<00:32,  2.81it/s]
2022-03-21 07:55:48,324 - INFO - tqdm - f1: 0.8857, accuracy: 0.9264, batch_loss: 0.8465, loss: 0.2455 ||:  70%|######9   | 141/202 [00:50<00:19,  3.09it/s]
2022-03-21 07:55:58,598 - INFO - tqdm - f1: 0.8809, accuracy: 0.9254, batch_loss: 0.0270, loss: 0.2441 ||:  84%|########4 | 170/202 [01:01<00:12,  2.57it/s]
2022-03-21 07:56:08,620 - INFO - tqdm - f1: 0.8869, accuracy: 0.9286, batch_loss: 0.2390, loss: 0.2411 ||:  98%|#########7| 197/202 [01:11<00:01,  2.81it/s]
2022-03-21 07:56:10,240 - INFO - tqdm - f1: 0.8862, accuracy: 0.9285, batch_loss: 0.0405, loss: 0.2428 ||: 100%|#########9| 201/202 [01:12<00:00,  2.44it/s]
2022-03-21 07:56:10,546 - INFO - tqdm - f1: 0.8870, accuracy: 0.9289, batch_loss: 0.0599, loss: 0.2419 ||: 100%|##########| 202/202 [01:13<00:00,  2.64it/s]
2022-03-21 07:56:10,608 - INFO - tqdm - f1: 0.8870, accuracy: 0.9289, batch_loss: 0.0599, loss: 0.2419 ||: 100%|##########| 202/202 [01:13<00:00,  2.76it/s]
2022-03-21 07:56:10,641 - INFO - allennlp.training.trainer - Validating
2022-03-21 07:56:10,655 - INFO - tqdm - 0%|          | 0/29 [00:00<?, ?it/s]
2022-03-21 07:56:17,978 - INFO - tqdm - f1: 0.8535, accuracy: 0.8791, batch_loss: 0.7537, loss: 0.4205 ||: 100%|##########| 29/29 [00:07<00:00,  4.14it/s]
2022-03-21 07:56:17,982 - INFO - tqdm - f1: 0.8535, accuracy: 0.8791, batch_loss: 0.7537, loss: 0.4205 ||: 100%|##########| 29/29 [00:07<00:00,  3.96it/s]
2022-03-21 07:56:18,126 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/sciie_base_hyper_small_seed_314/best.th'.
2022-03-21 07:56:20,719 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 07:56:20,727 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.929  |     0.879
2022-03-21 07:56:20,737 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.887  |     0.854
2022-03-21 07:56:20,748 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 07:56:20,751 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.242  |     0.421
2022-03-21 07:56:20,762 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  6400.391  |       N/A
2022-03-21 07:56:20,771 - INFO - allennlp.training.trainer - Epoch duration: 0:01:23.441008
2022-03-21 07:56:20,781 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:08:36
2022-03-21 07:56:20,791 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-21 07:56:20,801 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.3G
2022-03-21 07:56:20,812 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 07:56:20,826 - INFO - allennlp.training.trainer - Training
2022-03-21 07:56:20,845 - INFO - tqdm - 0%|          | 0/202 [00:00<?, ?it/s]
2022-03-21 07:56:31,148 - INFO - tqdm - f1: 0.9181, accuracy: 0.9442, batch_loss: 0.3751, loss: 0.1798 ||:  14%|#3        | 28/202 [00:10<01:09,  2.51it/s]
2022-03-21 07:56:41,234 - INFO - tqdm - f1: 0.9243, accuracy: 0.9475, batch_loss: 0.0252, loss: 0.1738 ||:  28%|##7       | 56/202 [00:20<00:53,  2.74it/s]
2022-03-21 07:56:51,368 - INFO - tqdm - f1: 0.9291, accuracy: 0.9539, batch_loss: 0.3286, loss: 0.1572 ||:  42%|####1     | 84/202 [00:30<00:43,  2.71it/s]
2022-03-21 07:57:01,571 - INFO - tqdm - f1: 0.9264, accuracy: 0.9535, batch_loss: 0.0753, loss: 0.1518 ||:  56%|#####5    | 113/202 [00:40<00:35,  2.51it/s]
2022-03-21 07:57:11,757 - INFO - tqdm - f1: 0.9241, accuracy: 0.9514, batch_loss: 0.0201, loss: 0.1568 ||:  70%|######9   | 141/202 [00:50<00:23,  2.56it/s]
2022-03-21 07:57:21,745 - INFO - tqdm - f1: 0.9303, accuracy: 0.9562, batch_loss: 0.5411, loss: 0.1489 ||: 100%|##########| 202/202 [01:00<00:00,  9.42it/s]
2022-03-21 07:57:21,763 - INFO - tqdm - f1: 0.9303, accuracy: 0.9562, batch_loss: 0.5411, loss: 0.1489 ||: 100%|##########| 202/202 [01:00<00:00,  3.32it/s]
2022-03-21 07:57:21,799 - INFO - allennlp.training.trainer - Validating
2022-03-21 07:57:21,806 - INFO - tqdm - 0%|          | 0/29 [00:00<?, ?it/s]
2022-03-21 07:57:24,063 - INFO - tqdm - f1: 0.7936, accuracy: 0.8615, batch_loss: 1.1431, loss: 0.5263 ||: 100%|##########| 29/29 [00:02<00:00, 13.03it/s]
2022-03-21 07:57:24,149 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 07:57:24,160 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.956  |     0.862
2022-03-21 07:57:24,169 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.930  |     0.794
2022-03-21 07:57:24,189 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 07:57:24,208 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.149  |     0.526
2022-03-21 07:57:24,218 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  6400.527  |       N/A
2022-03-21 07:57:24,227 - INFO - allennlp.training.trainer - Epoch duration: 0:01:03.436084
2022-03-21 07:57:24,228 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:06:47
2022-03-21 07:57:24,230 - INFO - allennlp.training.trainer - Epoch 5/9
2022-03-21 07:57:24,231 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.3G
2022-03-21 07:57:24,233 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 07:57:24,236 - INFO - allennlp.training.trainer - Training
2022-03-21 07:57:24,238 - INFO - tqdm - 0%|          | 0/202 [00:00<?, ?it/s]
2022-03-21 07:57:34,348 - INFO - tqdm - f1: 0.9528, accuracy: 0.9706, batch_loss: 0.0196, loss: 0.1031 ||:  25%|##5       | 51/202 [00:10<00:26,  5.67it/s]
2022-03-21 07:57:44,510 - INFO - tqdm - f1: 0.9479, accuracy: 0.9672, batch_loss: 0.0052, loss: 0.1035 ||:  50%|#####     | 101/202 [00:20<00:22,  4.53it/s]
2022-03-21 07:57:54,604 - INFO - tqdm - f1: 0.9424, accuracy: 0.9635, batch_loss: 0.0169, loss: 0.1112 ||:  74%|#######3  | 149/202 [00:30<00:18,  2.88it/s]
2022-03-21 07:58:04,718 - INFO - tqdm - f1: 0.9452, accuracy: 0.9652, batch_loss: 0.1244, loss: 0.1084 ||:  87%|########7 | 176/202 [00:40<00:08,  2.90it/s]
2022-03-21 07:58:13,293 - INFO - tqdm - f1: 0.9453, accuracy: 0.9644, batch_loss: 0.3737, loss: 0.1127 ||: 100%|#########9| 201/202 [00:49<00:00,  3.17it/s]
2022-03-21 07:58:13,800 - INFO - tqdm - f1: 0.9443, accuracy: 0.9637, batch_loss: 0.5932, loss: 0.1151 ||: 100%|##########| 202/202 [00:49<00:00,  2.68it/s]
2022-03-21 07:58:13,815 - INFO - tqdm - f1: 0.9443, accuracy: 0.9637, batch_loss: 0.5932, loss: 0.1151 ||: 100%|##########| 202/202 [00:49<00:00,  4.07it/s]
2022-03-21 07:58:14,001 - INFO - allennlp.training.trainer - Validating
2022-03-21 07:58:14,010 - INFO - tqdm - 0%|          | 0/29 [00:00<?, ?it/s]
2022-03-21 07:58:20,540 - INFO - tqdm - f1: 0.8313, accuracy: 0.8725, batch_loss: 0.5816, loss: 0.5292 ||: 100%|##########| 29/29 [00:06<00:00,  4.45it/s]
2022-03-21 07:58:20,725 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 07:58:20,728 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.964  |     0.873
2022-03-21 07:58:20,777 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.944  |     0.831
2022-03-21 07:58:20,791 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 07:58:20,801 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.115  |     0.529
2022-03-21 07:58:20,819 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  6400.527  |       N/A
2022-03-21 07:58:20,829 - INFO - allennlp.training.trainer - Epoch duration: 0:00:56.599492
2022-03-21 07:58:20,855 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:05:09
2022-03-21 07:58:20,873 - INFO - allennlp.training.trainer - Epoch 6/9
2022-03-21 07:58:20,885 - INFO - allennlp.training.trainer - Worker 0 memory usage: 6.3G
2022-03-21 07:58:20,889 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 07:58:20,900 - INFO - allennlp.training.trainer - Training
2022-03-21 07:58:20,918 - INFO - tqdm - 0%|          | 0/202 [00:00<?, ?it/s]
2022-03-21 07:58:31,312 - INFO - tqdm - f1: 0.9700, accuracy: 0.9792, batch_loss: 0.0086, loss: 0.0784 ||:  16%|#6        | 33/202 [00:10<00:58,  2.91it/s]
2022-03-21 07:58:41,529 - INFO - tqdm - f1: 0.9692, accuracy: 0.9792, batch_loss: 0.0767, loss: 0.0729 ||:  30%|##9       | 60/202 [00:20<00:49,  2.86it/s]
2022-03-21 07:58:51,768 - INFO - tqdm - f1: 0.9696, accuracy: 0.9797, batch_loss: 0.0690, loss: 0.0913 ||:  43%|####3     | 87/202 [00:30<00:44,  2.57it/s]
2022-03-21 07:59:01,978 - INFO - tqdm - f1: 0.9688, accuracy: 0.9783, batch_loss: 0.0121, loss: 0.0905 ||:  57%|#####7    | 116/202 [00:41<00:25,  3.42it/s]
2022-03-21 07:59:12,339 - INFO - tqdm - f1: 0.9691, accuracy: 0.9785, batch_loss: 0.0450, loss: 0.0881 ||:  72%|#######2  | 146/202 [00:51<00:23,  2.41it/s]
2022-03-21 07:59:22,586 - INFO - tqdm - f1: 0.9665, accuracy: 0.9779, batch_loss: 0.0076, loss: 0.0863 ||:  87%|########7 | 176/202 [01:01<00:09,  2.80it/s]
2022-03-21 07:59:31,577 - INFO - tqdm - f1: 0.9646, accuracy: 0.9766, batch_loss: 0.0218, loss: 0.0886 ||: 100%|#########9| 201/202 [01:10<00:00,  2.58it/s]
2022-03-21 07:59:32,087 - INFO - tqdm - f1: 0.9642, accuracy: 0.9764, batch_loss: 0.1740, loss: 0.0891 ||: 100%|##########| 202/202 [01:11<00:00,  2.36it/s]
2022-03-21 07:59:32,094 - INFO - tqdm - f1: 0.9642, accuracy: 0.9764, batch_loss: 0.1740, loss: 0.0891 ||: 100%|##########| 202/202 [01:11<00:00,  2.84it/s]
2022-03-21 07:59:32,107 - INFO - allennlp.training.trainer - Validating
2022-03-21 07:59:32,122 - INFO - tqdm - 0%|          | 0/29 [00:00<?, ?it/s]
2022-03-21 07:59:39,185 - INFO - tqdm - f1: 0.8302, accuracy: 0.8659, batch_loss: 0.2741, loss: 0.5813 ||: 100%|##########| 29/29 [00:07<00:00,  4.55it/s]
2022-03-21 07:59:39,202 - INFO - tqdm - f1: 0.8302, accuracy: 0.8659, batch_loss: 0.2741, loss: 0.5813 ||: 100%|##########| 29/29 [00:07<00:00,  4.10it/s]
2022-03-21 07:59:39,324 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-21 07:59:39,345 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-21 07:59:39,954 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-21 07:59:39,968 - INFO - allennlp.training.util - Iterating over dataset
2022-03-21 07:59:39,972 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-21 07:59:40,010 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 07:59:40,020 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 07:59:50,183 - INFO - tqdm - f1: 0.77, accuracy: 0.85, loss: 0.52 ||: : 41it [00:10,  4.48it/s]
2022-03-21 07:59:54,570 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 3,
  "peak_worker_0_memory_MB": 6400.52734375,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "0:07:44.404559",
  "training_start_epoch": 0,
  "training_epochs": 5,
  "epoch": 5,
  "training_f1": 0.9443422130175999,
  "training_accuracy": 0.9636533084808947,
  "training_loss": 0.11512701423598988,
  "training_worker_0_memory_MB": 6400.52734375,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.8313221676009042,
  "validation_accuracy": 0.8725274725274725,
  "validation_loss": 0.5291602440692228,
  "best_validation_f1": 0.8535458956445966,
  "best_validation_accuracy": 0.8791208791208791,
  "best_validation_loss": 0.4205336308684842,
  "test_f1": 0.7828150561877659,
  "test_accuracy": 0.8552361396303901,
  "test_loss": 0.4920162251982533
}
2022-03-21 07:59:54,589 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/sciie_base_hyper_small_seed_314/model.tar.gz
