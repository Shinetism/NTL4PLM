2022-03-21 21:54:29,995 - INFO - allennlp.common.params - random_seed = 47
2022-03-21 21:54:29,997 - INFO - allennlp.common.params - numpy_seed = 47
2022-03-21 21:54:29,999 - INFO - allennlp.common.params - pytorch_seed = 47
2022-03-21 21:54:30,002 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-21 21:54:30,004 - INFO - allennlp.common.params - type = default
2022-03-21 21:54:30,006 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-21 21:54:30,008 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 21:54:30,010 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 21:54:30,011 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 21:54:30,012 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 21:54:30,014 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 21:54:30,015 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 21:54:42,861 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 21:54:42,867 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 21:54:42,869 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 21:54:42,870 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-21 21:54:42,872 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-21 21:54:42,874 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 21:54:42,877 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-21 21:54:42,883 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-21 21:54:42,885 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-21 21:54:42,887 - INFO - allennlp.common.params - train_data_path = datasets/amazon/train.jsonl
2022-03-21 21:54:42,889 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f60e40e1190>
2022-03-21 21:54:42,891 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-21 21:54:42,893 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-21 21:54:42,895 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 21:54:42,897 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 21:54:42,898 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 21:54:42,900 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 21:54:42,901 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 21:54:42,903 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 21:54:42,906 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 21:54:42,908 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 21:54:42,910 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 21:54:42,913 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-21 21:54:42,914 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-21 21:54:42,916 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 21:54:42,918 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-21 21:54:42,920 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-21 21:54:42,922 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-21 21:54:42,923 - INFO - allennlp.common.params - validation_data_path = datasets/amazon/dev.jsonl
2022-03-21 21:54:42,925 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-21 21:54:42,926 - INFO - allennlp.common.params - test_data_path = datasets/amazon/test.jsonl
2022-03-21 21:54:42,928 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-21 21:54:42,930 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-21 21:54:42,931 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 21:54:42,933 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 21:54:42,935 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 21:54:42,936 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 21:54:42,938 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 21:54:42,940 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 21:54:42,941 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 21:54:42,943 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 21:54:42,944 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 21:54:42,945 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 21:54:42,947 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 21:54:42,948 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 21:54:42,950 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 21:54:42,951 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 21:54:42,954 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 21:54:53,034 - INFO - tqdm - loading instances: 9117it [00:10, 777.28it/s]
2022-03-21 21:55:03,357 - INFO - tqdm - loading instances: 18645it [00:20, 355.84it/s]
2022-03-21 21:55:13,451 - INFO - tqdm - loading instances: 28733it [00:30, 1053.93it/s]
2022-03-21 21:55:24,463 - INFO - tqdm - loading instances: 37775it [00:41, 189.55it/s]
2022-03-21 21:55:35,629 - INFO - tqdm - loading instances: 47610it [00:52, 159.72it/s]
2022-03-21 21:55:45,699 - INFO - tqdm - loading instances: 58418it [01:02, 1102.82it/s]
2022-03-21 21:55:55,703 - INFO - tqdm - loading instances: 66375it [01:12, 1016.42it/s]
2022-03-21 21:56:06,985 - INFO - tqdm - loading instances: 75058it [01:24, 112.12it/s]
2022-03-21 21:56:17,012 - INFO - tqdm - loading instances: 85537it [01:34, 1020.25it/s]
2022-03-21 21:56:28,777 - INFO - tqdm - loading instances: 94290it [01:45, 93.52it/s]
2022-03-21 21:56:38,855 - INFO - tqdm - loading instances: 104741it [01:55, 1031.54it/s]
2022-03-21 21:56:48,921 - INFO - tqdm - loading instances: 114960it [02:05, 929.21it/s]
2022-03-21 21:56:49,236 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 21:56:49,243 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 21:56:49,244 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 21:56:49,246 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 21:56:49,247 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 21:56:49,249 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 21:56:49,251 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 21:56:49,252 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 21:56:49,254 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 21:56:49,255 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 21:56:49,257 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 21:56:49,259 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 21:56:49,260 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 21:56:49,262 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 21:56:49,263 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 21:56:59,301 - INFO - tqdm - loading instances: 4587it [00:10, 935.13it/s]
2022-03-21 21:56:59,752 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 21:56:59,758 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 21:56:59,760 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 21:56:59,761 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 21:56:59,763 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 21:56:59,765 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 21:56:59,766 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 21:56:59,767 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 21:56:59,769 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 21:56:59,770 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 21:56:59,771 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 21:56:59,773 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 21:56:59,774 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 21:56:59,776 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 21:56:59,777 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 21:57:09,820 - INFO - tqdm - loading instances: 10038it [00:10, 1084.20it/s]
2022-03-21 21:57:19,843 - INFO - tqdm - loading instances: 20205it [00:20, 1002.48it/s]
2022-03-21 21:57:24,613 - INFO - allennlp.common.params - type = from_instances
2022-03-21 21:57:24,619 - INFO - allennlp.common.params - min_count = None
2022-03-21 21:57:24,621 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-21 21:57:24,622 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-21 21:57:24,624 - INFO - allennlp.common.params - pretrained_files = None
2022-03-21 21:57:24,626 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-21 21:57:24,627 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-21 21:57:24,629 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-21 21:57:24,631 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-21 21:57:24,633 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-21 21:57:24,635 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-21 21:57:24,636 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-21 21:57:27,766 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-21 21:57:27,775 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-21 21:57:27,778 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-21 21:57:27,779 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-21 21:57:27,781 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-21 21:57:27,783 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-21 21:57:27,784 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-21 21:57:27,786 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-21 21:57:27,789 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-21 21:57:27,790 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-21 21:57:27,792 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-21 21:57:27,793 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-21 21:57:27,795 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-21 21:57:33,841 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-21 21:57:33,848 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-21 21:57:33,849 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-21 21:57:33,851 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-21 21:57:33,853 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-21 21:57:33,854 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-21 21:57:33,856 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-21 21:57:33,857 - INFO - allennlp.common.params - type = tanh
2022-03-21 21:57:33,859 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-21 21:57:33,867 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-21 21:57:33,869 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-21 21:57:33,871 - INFO - allennlp.common.params - model.num_labels = None
2022-03-21 21:57:33,872 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-21 21:57:33,874 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f60e40f2350>
2022-03-21 21:57:33,875 - INFO - allennlp.common.params - model.regularizer = None
2022-03-21 21:57:33,877 - INFO - allennlp.common.params - model.track_weights = False
2022-03-21 21:57:33,878 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-21 21:57:33,880 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-21 21:57:33,883 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-21 21:57:33,884 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-21 21:57:33,887 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-21 21:57:33,888 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-21 21:57:33,890 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-21 21:57:33,891 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 21:57:33,893 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 21:57:33,894 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 21:57:33,895 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 21:57:33,897 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 21:57:33,898 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 21:57:33,900 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 21:57:33,902 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 21:57:33,903 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 21:57:33,905 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 21:57:33,906 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 21:57:33,907 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 21:57:33,909 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 21:57:33,910 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 21:57:33,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 21:57:33,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 21:57:33,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 21:57:33,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 21:57:33,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 21:57:33,918 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 21:57:33,919 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 21:57:33,921 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 21:57:33,922 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 21:57:33,924 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 21:57:33,925 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 21:57:33,927 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 21:57:33,928 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 21:57:33,930 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 21:57:33,931 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 21:57:33,933 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 21:57:33,934 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 21:57:33,935 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 21:57:33,938 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 21:57:33,939 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 21:57:33,941 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 21:57:33,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 21:57:33,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 21:57:33,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 21:57:33,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 21:57:33,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 21:57:33,949 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 21:57:33,950 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 21:57:33,952 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 21:57:33,953 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 21:57:33,955 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 21:57:33,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 21:57:33,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 21:57:33,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 21:57:33,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 21:57:33,962 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 21:57:33,964 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 21:57:33,965 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 21:57:33,967 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 21:57:33,968 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 21:57:33,970 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 21:57:33,971 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 21:57:33,972 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 21:57:33,975 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 21:57:33,976 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 21:57:33,977 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 21:57:33,979 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 21:57:33,980 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 21:57:33,982 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 21:57:33,983 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 21:57:33,987 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 21:57:33,988 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 21:57:33,990 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 21:57:33,991 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 21:57:33,993 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 21:57:33,994 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 21:57:33,995 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 21:57:33,997 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 21:57:33,998 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 21:57:34,000 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 21:57:34,001 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 21:57:34,003 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 21:57:34,004 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 21:57:34,006 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 21:57:34,007 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 21:57:34,009 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 21:57:34,010 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 21:57:34,012 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 21:57:34,013 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 21:57:34,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 21:57:34,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 21:57:34,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 21:57:34,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 21:57:34,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 21:57:34,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 21:57:34,023 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 21:57:34,024 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 21:57:34,025 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 21:57:34,027 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 21:57:34,028 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 21:57:34,030 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 21:57:34,031 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 21:57:34,032 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 21:57:34,034 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 21:57:34,035 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 21:57:34,037 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 21:57:34,038 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 21:57:34,039 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 21:57:34,041 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 21:57:34,042 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 21:57:34,043 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 21:57:34,045 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 21:57:34,047 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 21:57:34,049 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 21:57:34,050 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 21:57:34,051 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 21:57:34,053 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 21:57:34,054 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 21:57:34,056 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 21:57:34,057 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 21:57:34,058 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 21:57:34,060 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 21:57:34,062 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 21:57:34,063 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 21:57:34,065 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 21:57:34,067 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 21:57:34,068 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 21:57:34,070 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 21:57:34,071 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 21:57:34,073 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 21:57:34,074 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 21:57:34,076 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 21:57:34,077 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 21:57:34,079 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 21:57:34,080 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 21:57:34,082 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 21:57:34,084 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 21:57:34,085 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 21:57:34,087 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 21:57:34,088 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 21:57:34,092 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 21:57:34,101 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 21:57:34,102 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 21:57:34,104 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 21:57:34,105 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 21:57:34,107 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 21:57:34,108 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 21:57:34,110 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 21:57:34,111 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 21:57:34,112 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 21:57:34,114 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 21:57:34,116 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 21:57:34,117 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 21:57:34,118 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 21:57:34,120 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 21:57:34,121 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 21:57:34,122 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 21:57:34,124 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 21:57:34,126 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 21:57:34,128 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 21:57:34,129 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 21:57:34,131 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 21:57:34,133 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 21:57:34,136 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 21:57:34,138 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 21:57:34,139 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 21:57:34,140 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 21:57:34,142 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 21:57:34,143 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 21:57:34,145 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 21:57:34,149 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 21:57:34,151 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 21:57:34,152 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 21:57:34,154 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 21:57:34,155 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 21:57:34,157 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 21:57:34,158 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 21:57:34,159 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 21:57:34,161 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 21:57:34,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 21:57:34,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 21:57:34,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 21:57:34,168 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 21:57:34,170 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 21:57:34,171 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 21:57:34,173 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 21:57:34,175 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 21:57:34,176 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 21:57:34,178 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 21:57:34,179 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 21:57:34,181 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 21:57:34,182 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 21:57:34,184 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 21:57:34,185 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 21:57:34,187 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 21:57:34,188 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 21:57:34,190 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 21:57:34,191 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 21:57:34,192 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 21:57:34,194 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 21:57:34,195 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 21:57:34,197 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 21:57:34,198 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 21:57:34,200 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 21:57:34,201 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 21:57:50,506 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-21 21:57:50,513 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-21 21:57:50,514 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-21 21:57:50,516 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-21 21:57:50,517 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-21 21:57:50,519 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-21 21:57:50,520 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-21 21:57:50,522 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-21 21:57:50,523 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-21 21:57:50,525 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-21 21:57:50,527 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-21 21:57:50,529 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-21 21:57:50,531 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-21 21:57:50,533 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-21 21:57:50,534 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-21 21:57:50,536 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-21 21:57:50,538 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-21 21:57:59,855 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-21 21:57:59,861 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-21 21:57:59,863 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-21 21:57:59,865 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-21 21:57:59,867 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-21 21:57:59,869 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-21 21:57:59,873 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-21 21:57:59,874 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias'], {'weight_decay': 0}
2022-03-21 21:57:59,877 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight'], {}
2022-03-21 21:57:59,880 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-21 21:57:59,881 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125237762
2022-03-21 21:57:59,884 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-21 21:57:59,886 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-21 21:57:59,888 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 21:57:59,889 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 21:57:59,890 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 21:57:59,892 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 21:57:59,893 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 21:57:59,894 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 21:57:59,896 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 21:57:59,897 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 21:57:59,898 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 21:57:59,900 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 21:57:59,902 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 21:57:59,904 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 21:57:59,906 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 21:57:59,907 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 21:57:59,909 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 21:57:59,910 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 21:57:59,912 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 21:57:59,913 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 21:57:59,915 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 21:57:59,916 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 21:57:59,918 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 21:57:59,919 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 21:57:59,921 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 21:57:59,922 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 21:57:59,924 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 21:57:59,925 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 21:57:59,926 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 21:57:59,928 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 21:57:59,929 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 21:57:59,931 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 21:57:59,932 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 21:57:59,933 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 21:57:59,935 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 21:57:59,936 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 21:57:59,937 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 21:57:59,941 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 21:57:59,943 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 21:57:59,945 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 21:57:59,946 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 21:57:59,947 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 21:57:59,949 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 21:57:59,950 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 21:57:59,952 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 21:57:59,953 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 21:57:59,954 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 21:57:59,956 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 21:57:59,957 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 21:57:59,958 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 21:57:59,960 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 21:57:59,961 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 21:57:59,962 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 21:57:59,964 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 21:57:59,965 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 21:57:59,967 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 21:57:59,968 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 21:57:59,969 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 21:57:59,971 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 21:57:59,972 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 21:57:59,974 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 21:57:59,975 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 21:57:59,977 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 21:57:59,979 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 21:57:59,980 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 21:57:59,981 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 21:57:59,983 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 21:57:59,984 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 21:57:59,985 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 21:57:59,987 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 21:57:59,988 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 21:57:59,989 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 21:57:59,991 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 21:57:59,992 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 21:57:59,994 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 21:57:59,995 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 21:57:59,996 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 21:57:59,998 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 21:57:59,999 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 21:58:00,001 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 21:58:00,002 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 21:58:00,004 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 21:58:00,005 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 21:58:00,006 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 21:58:00,008 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 21:58:00,009 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 21:58:00,011 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 21:58:00,012 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 21:58:00,013 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 21:58:00,016 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 21:58:00,017 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 21:58:00,019 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 21:58:00,020 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 21:58:00,021 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 21:58:00,023 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 21:58:00,024 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 21:58:00,025 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 21:58:00,027 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 21:58:00,029 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 21:58:00,030 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 21:58:00,032 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 21:58:00,034 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 21:58:00,035 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 21:58:00,036 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 21:58:00,038 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 21:58:00,039 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 21:58:00,040 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 21:58:00,042 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 21:58:00,043 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 21:58:00,045 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 21:58:00,046 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 21:58:00,048 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 21:58:00,049 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 21:58:00,050 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 21:58:00,052 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 21:58:00,054 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 21:58:00,055 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 21:58:00,057 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 21:58:00,058 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 21:58:00,060 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 21:58:00,061 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 21:58:00,062 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 21:58:00,064 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 21:58:00,065 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 21:58:00,066 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 21:58:00,068 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 21:58:00,069 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 21:58:00,071 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 21:58:00,072 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 21:58:00,074 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 21:58:00,075 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 21:58:00,076 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 21:58:00,078 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 21:58:00,079 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 21:58:00,081 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 21:58:00,082 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 21:58:00,083 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 21:58:00,087 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 21:58:00,089 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 21:58:00,090 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 21:58:00,092 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 21:58:00,094 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 21:58:00,095 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 21:58:00,097 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 21:58:00,098 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 21:58:00,099 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 21:58:00,101 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 21:58:00,102 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 21:58:00,104 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 21:58:00,105 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 21:58:00,106 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 21:58:00,108 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 21:58:00,109 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 21:58:00,114 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 21:58:00,116 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 21:58:00,117 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 21:58:00,118 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 21:58:00,120 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 21:58:00,121 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 21:58:00,122 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 21:58:00,124 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 21:58:00,125 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 21:58:00,126 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 21:58:00,128 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 21:58:00,129 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 21:58:00,130 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 21:58:00,131 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 21:58:00,134 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 21:58:00,135 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 21:58:00,136 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 21:58:00,137 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 21:58:00,139 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 21:58:00,140 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 21:58:00,141 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 21:58:00,143 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 21:58:00,144 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 21:58:00,145 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 21:58:00,147 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 21:58:00,148 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 21:58:00,149 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 21:58:00,150 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 21:58:00,152 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 21:58:00,153 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 21:58:00,154 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 21:58:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 21:58:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 21:58:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 21:58:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 21:58:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 21:58:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 21:58:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 21:58:00,165 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 21:58:00,167 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 21:58:00,168 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 21:58:00,170 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 21:58:00,171 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 21:58:00,172 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 21:58:00,174 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 21:58:00,175 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 21:58:00,177 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 21:58:00,178 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 21:58:00,180 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-21 21:58:00,183 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-21 21:58:00,185 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-21 21:58:00,186 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-21 21:58:00,188 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-21 21:58:00,189 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-21 21:58:00,190 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-21 21:58:00,192 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-21 21:58:00,195 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-21 21:58:00,196 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-21 21:58:00,201 - INFO - allennlp.training.trainer - Beginning training.
2022-03-21 21:58:00,202 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-21 21:58:00,204 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-21 21:58:00,206 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 21:58:00,208 - INFO - allennlp.training.trainer - Training
2022-03-21 21:58:00,209 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-21 21:58:00,349 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 21:58:00,351 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 21:58:10,388 - INFO - tqdm - f1: 0.4583, accuracy: 0.8462, batch_loss: 0.4963, loss: 0.4760 ||:   0%|          | 26/7204 [00:10<25:05,  4.77it/s]
2022-03-21 21:58:20,516 - INFO - tqdm - f1: 0.4576, accuracy: 0.8438, batch_loss: 1.1257, loss: 0.4534 ||:   1%|          | 72/7204 [00:20<24:03,  4.94it/s]
2022-03-21 21:58:30,725 - INFO - tqdm - f1: 0.4666, accuracy: 0.8411, batch_loss: 0.4043, loss: 0.4310 ||:   2%|1         | 118/7204 [00:30<23:44,  4.97it/s]
2022-03-21 21:58:40,954 - INFO - tqdm - f1: 0.4644, accuracy: 0.8359, batch_loss: 0.3941, loss: 0.4207 ||:   2%|2         | 163/7204 [00:40<26:53,  4.36it/s]
2022-03-21 21:58:51,175 - INFO - tqdm - f1: 0.4679, accuracy: 0.8412, batch_loss: 0.1431, loss: 0.4070 ||:   3%|2         | 207/7204 [00:50<25:45,  4.53it/s]
2022-03-21 21:59:01,252 - INFO - tqdm - f1: 0.4722, accuracy: 0.8492, batch_loss: 0.2074, loss: 0.3893 ||:   3%|3         | 247/7204 [01:01<33:35,  3.45it/s]
2022-03-21 21:59:11,424 - INFO - tqdm - f1: 0.4723, accuracy: 0.8474, batch_loss: 0.3831, loss: 0.3836 ||:   4%|4         | 290/7204 [01:11<28:49,  4.00it/s]
2022-03-21 21:59:21,623 - INFO - tqdm - f1: 0.4719, accuracy: 0.8509, batch_loss: 0.1769, loss: 0.3767 ||:   5%|4         | 335/7204 [01:21<28:53,  3.96it/s]
2022-03-21 21:59:31,705 - INFO - tqdm - f1: 0.4698, accuracy: 0.8491, batch_loss: 0.5921, loss: 0.3781 ||:   5%|5         | 379/7204 [01:31<23:26,  4.85it/s]
2022-03-21 21:59:42,021 - INFO - tqdm - f1: 0.4773, accuracy: 0.8501, batch_loss: 0.2834, loss: 0.3718 ||:   6%|5         | 426/7204 [01:41<30:06,  3.75it/s]
2022-03-21 21:59:52,073 - INFO - tqdm - f1: 0.4765, accuracy: 0.8499, batch_loss: 0.2064, loss: 0.3693 ||:   7%|6         | 469/7204 [01:51<29:15,  3.84it/s]
2022-03-21 22:00:02,139 - INFO - tqdm - f1: 0.4747, accuracy: 0.8489, batch_loss: 0.5060, loss: 0.3689 ||:   7%|7         | 511/7204 [02:01<22:33,  4.94it/s]
2022-03-21 22:00:12,160 - INFO - tqdm - f1: 0.4741, accuracy: 0.8500, batch_loss: 0.5424, loss: 0.3662 ||:   8%|7         | 551/7204 [02:11<26:25,  4.20it/s]
2022-03-21 22:00:22,210 - INFO - tqdm - f1: 0.4783, accuracy: 0.8484, batch_loss: 0.3784, loss: 0.3681 ||:   8%|8         | 591/7204 [02:21<21:48,  5.05it/s]
2022-03-21 22:00:32,463 - INFO - tqdm - f1: 0.4806, accuracy: 0.8485, batch_loss: 0.6461, loss: 0.3681 ||:   9%|8         | 635/7204 [02:32<29:14,  3.74it/s]
2022-03-21 22:00:42,586 - INFO - tqdm - f1: 0.4804, accuracy: 0.8510, batch_loss: 0.4646, loss: 0.3625 ||:   9%|9         | 678/7204 [02:42<28:08,  3.86it/s]
2022-03-21 22:00:52,621 - INFO - tqdm - f1: 0.4855, accuracy: 0.8508, batch_loss: 0.5463, loss: 0.3615 ||:  10%|9         | 718/7204 [02:52<30:13,  3.58it/s]
2022-03-21 22:01:02,733 - INFO - tqdm - f1: 0.4850, accuracy: 0.8506, batch_loss: 0.3996, loss: 0.3621 ||:  11%|#         | 760/7204 [03:02<27:39,  3.88it/s]
2022-03-21 22:01:12,752 - INFO - tqdm - f1: 0.4855, accuracy: 0.8513, batch_loss: 0.2262, loss: 0.3601 ||:  11%|#1        | 803/7204 [03:12<22:07,  4.82it/s]
2022-03-21 22:01:22,782 - INFO - tqdm - f1: 0.4883, accuracy: 0.8516, batch_loss: 0.7311, loss: 0.3596 ||:  12%|#1        | 848/7204 [03:22<22:01,  4.81it/s]
2022-03-21 22:01:32,945 - INFO - tqdm - f1: 0.4886, accuracy: 0.8512, batch_loss: 0.1552, loss: 0.3596 ||:  12%|#2        | 888/7204 [03:32<22:39,  4.64it/s]
2022-03-21 22:01:43,015 - INFO - tqdm - f1: 0.4941, accuracy: 0.8512, batch_loss: 0.3084, loss: 0.3578 ||:  13%|#2        | 930/7204 [03:42<27:47,  3.76it/s]
2022-03-21 22:01:53,114 - INFO - tqdm - f1: 0.4935, accuracy: 0.8514, batch_loss: 0.1907, loss: 0.3574 ||:  14%|#3        | 973/7204 [03:52<25:22,  4.09it/s]
2022-03-21 22:02:03,275 - INFO - tqdm - f1: 0.5001, accuracy: 0.8517, batch_loss: 0.0596, loss: 0.3567 ||:  14%|#4        | 1016/7204 [04:03<26:43,  3.86it/s]
2022-03-21 22:02:13,398 - INFO - tqdm - f1: 0.5033, accuracy: 0.8523, batch_loss: 0.5514, loss: 0.3547 ||:  15%|#4        | 1058/7204 [04:13<25:30,  4.02it/s]
2022-03-21 22:02:23,465 - INFO - tqdm - f1: 0.5062, accuracy: 0.8532, batch_loss: 0.4187, loss: 0.3532 ||:  15%|#5        | 1099/7204 [04:23<26:15,  3.87it/s]
2022-03-21 22:02:33,638 - INFO - tqdm - f1: 0.5112, accuracy: 0.8538, batch_loss: 0.1527, loss: 0.3520 ||:  16%|#5        | 1143/7204 [04:33<21:55,  4.61it/s]
2022-03-21 22:02:43,816 - INFO - tqdm - f1: 0.5153, accuracy: 0.8535, batch_loss: 0.5525, loss: 0.3518 ||:  16%|#6        | 1188/7204 [04:43<19:52,  5.05it/s]
2022-03-21 22:02:53,979 - INFO - tqdm - f1: 0.5199, accuracy: 0.8541, batch_loss: 0.5333, loss: 0.3505 ||:  17%|#7        | 1228/7204 [04:53<22:29,  4.43it/s]
2022-03-21 22:03:04,185 - INFO - tqdm - f1: 0.5228, accuracy: 0.8543, batch_loss: 0.2555, loss: 0.3501 ||:  18%|#7        | 1273/7204 [05:03<19:30,  5.07it/s]
2022-03-21 22:03:14,364 - INFO - tqdm - f1: 0.5266, accuracy: 0.8542, batch_loss: 0.3623, loss: 0.3504 ||:  18%|#8        | 1321/7204 [05:14<20:28,  4.79it/s]
2022-03-21 22:03:24,373 - INFO - tqdm - f1: 0.5273, accuracy: 0.8546, batch_loss: 0.2482, loss: 0.3494 ||:  19%|#8        | 1362/7204 [05:24<23:51,  4.08it/s]
2022-03-21 22:03:34,387 - INFO - tqdm - f1: 0.5265, accuracy: 0.8551, batch_loss: 0.0918, loss: 0.3487 ||:  20%|#9        | 1405/7204 [05:34<21:42,  4.45it/s]
2022-03-21 22:03:44,390 - INFO - tqdm - f1: 0.5290, accuracy: 0.8555, batch_loss: 0.7329, loss: 0.3476 ||:  20%|##        | 1446/7204 [05:44<18:38,  5.15it/s]
2022-03-21 22:03:54,746 - INFO - tqdm - f1: 0.5287, accuracy: 0.8558, batch_loss: 0.1464, loss: 0.3471 ||:  21%|##        | 1485/7204 [05:54<23:49,  4.00it/s]
2022-03-21 22:04:04,866 - INFO - tqdm - f1: 0.5332, accuracy: 0.8564, batch_loss: 0.3079, loss: 0.3452 ||:  21%|##1       | 1528/7204 [06:04<19:12,  4.93it/s]
2022-03-21 22:04:15,008 - INFO - tqdm - f1: 0.5354, accuracy: 0.8572, batch_loss: 0.5413, loss: 0.3440 ||:  22%|##1       | 1570/7204 [06:14<21:54,  4.29it/s]
2022-03-21 22:04:25,126 - INFO - tqdm - f1: 0.5354, accuracy: 0.8571, batch_loss: 0.6351, loss: 0.3441 ||:  22%|##2       | 1611/7204 [06:24<19:13,  4.85it/s]
2022-03-21 22:04:35,483 - INFO - tqdm - f1: 0.5357, accuracy: 0.8575, batch_loss: 0.1566, loss: 0.3441 ||:  23%|##2       | 1655/7204 [06:35<24:46,  3.73it/s]
2022-03-21 22:04:45,603 - INFO - tqdm - f1: 0.5424, accuracy: 0.8576, batch_loss: 0.5482, loss: 0.3441 ||:  24%|##3       | 1698/7204 [06:45<19:45,  4.65it/s]
2022-03-21 22:04:55,679 - INFO - tqdm - f1: 0.5435, accuracy: 0.8572, batch_loss: 0.3279, loss: 0.3442 ||:  24%|##4       | 1745/7204 [06:55<22:47,  3.99it/s]
2022-03-21 22:05:05,769 - INFO - tqdm - f1: 0.5467, accuracy: 0.8571, batch_loss: 0.5008, loss: 0.3438 ||:  25%|##4       | 1791/7204 [07:05<20:18,  4.44it/s]
2022-03-21 22:05:15,833 - INFO - tqdm - f1: 0.5486, accuracy: 0.8572, batch_loss: 0.2562, loss: 0.3438 ||:  25%|##5       | 1837/7204 [07:15<20:48,  4.30it/s]
2022-03-21 22:05:26,155 - INFO - tqdm - f1: 0.5482, accuracy: 0.8568, batch_loss: 0.0411, loss: 0.3443 ||:  26%|##6       | 1883/7204 [07:25<26:52,  3.30it/s]
2022-03-21 22:05:36,362 - INFO - tqdm - f1: 0.5484, accuracy: 0.8564, batch_loss: 0.5547, loss: 0.3448 ||:  27%|##6       | 1927/7204 [07:36<22:18,  3.94it/s]
2022-03-21 22:05:46,543 - INFO - tqdm - f1: 0.5483, accuracy: 0.8570, batch_loss: 0.1466, loss: 0.3437 ||:  27%|##7       | 1971/7204 [07:46<23:05,  3.78it/s]
2022-03-21 22:05:56,587 - INFO - tqdm - f1: 0.5493, accuracy: 0.8567, batch_loss: 0.4089, loss: 0.3440 ||:  28%|##7       | 2014/7204 [07:56<19:17,  4.48it/s]
2022-03-21 22:06:06,651 - INFO - tqdm - f1: 0.5518, accuracy: 0.8572, batch_loss: 0.2431, loss: 0.3432 ||:  29%|##8       | 2056/7204 [08:06<18:01,  4.76it/s]
2022-03-21 22:06:16,686 - INFO - tqdm - f1: 0.5537, accuracy: 0.8575, batch_loss: 0.4300, loss: 0.3425 ||:  29%|##9       | 2096/7204 [08:16<22:34,  3.77it/s]
2022-03-21 22:06:26,865 - INFO - tqdm - f1: 0.5546, accuracy: 0.8579, batch_loss: 0.4048, loss: 0.3417 ||:  30%|##9       | 2137/7204 [08:26<27:26,  3.08it/s]
2022-03-21 22:06:37,041 - INFO - tqdm - f1: 0.5562, accuracy: 0.8580, batch_loss: 0.2840, loss: 0.3419 ||:  30%|###       | 2180/7204 [08:36<18:12,  4.60it/s]
2022-03-21 22:06:47,131 - INFO - tqdm - f1: 0.5596, accuracy: 0.8586, batch_loss: 0.4070, loss: 0.3407 ||:  31%|###       | 2223/7204 [08:46<23:08,  3.59it/s]
2022-03-21 22:06:57,220 - INFO - tqdm - f1: 0.5609, accuracy: 0.8589, batch_loss: 0.4166, loss: 0.3404 ||:  31%|###1      | 2266/7204 [08:57<17:29,  4.70it/s]
2022-03-21 22:07:07,346 - INFO - tqdm - f1: 0.5626, accuracy: 0.8593, batch_loss: 0.1641, loss: 0.3393 ||:  32%|###2      | 2307/7204 [09:07<19:02,  4.29it/s]
2022-03-21 22:07:17,598 - INFO - tqdm - f1: 0.5640, accuracy: 0.8595, batch_loss: 0.2292, loss: 0.3391 ||:  33%|###2      | 2349/7204 [09:17<19:10,  4.22it/s]
2022-03-21 22:07:27,871 - INFO - tqdm - f1: 0.5639, accuracy: 0.8595, batch_loss: 0.2674, loss: 0.3392 ||:  33%|###3      | 2392/7204 [09:27<19:55,  4.02it/s]
2022-03-21 22:07:37,914 - INFO - tqdm - f1: 0.5646, accuracy: 0.8595, batch_loss: 0.0647, loss: 0.3390 ||:  34%|###3      | 2433/7204 [09:37<24:16,  3.28it/s]
2022-03-21 22:07:48,010 - INFO - tqdm - f1: 0.5658, accuracy: 0.8598, batch_loss: 0.3100, loss: 0.3385 ||:  34%|###4      | 2475/7204 [09:47<19:47,  3.98it/s]
2022-03-21 22:07:58,021 - INFO - tqdm - f1: 0.5664, accuracy: 0.8599, batch_loss: 0.3463, loss: 0.3383 ||:  35%|###4      | 2510/7204 [09:57<16:50,  4.64it/s]
2022-03-21 22:08:08,023 - INFO - tqdm - f1: 0.5668, accuracy: 0.8599, batch_loss: 0.4908, loss: 0.3381 ||:  35%|###5      | 2550/7204 [10:07<24:06,  3.22it/s]
2022-03-21 22:08:18,180 - INFO - tqdm - f1: 0.5696, accuracy: 0.8600, batch_loss: 0.3730, loss: 0.3381 ||:  36%|###6      | 2624/7204 [10:17<07:19, 10.43it/s]
2022-03-21 22:08:28,290 - INFO - tqdm - f1: 0.5701, accuracy: 0.8602, batch_loss: 0.1309, loss: 0.3374 ||:  37%|###7      | 2688/7204 [10:28<15:23,  4.89it/s]
2022-03-21 22:08:38,327 - INFO - tqdm - f1: 0.5725, accuracy: 0.8606, batch_loss: 0.2029, loss: 0.3365 ||:  38%|###8      | 2750/7204 [10:38<09:50,  7.54it/s]
2022-03-21 22:08:48,394 - INFO - tqdm - f1: 0.5725, accuracy: 0.8607, batch_loss: 0.3086, loss: 0.3360 ||:  39%|###8      | 2807/7204 [10:48<10:45,  6.81it/s]
2022-03-21 22:08:58,594 - INFO - tqdm - f1: 0.5715, accuracy: 0.8610, batch_loss: 0.1425, loss: 0.3356 ||:  40%|###9      | 2855/7204 [10:58<20:06,  3.60it/s]
2022-03-21 22:09:08,665 - INFO - tqdm - f1: 0.5729, accuracy: 0.8607, batch_loss: 0.3561, loss: 0.3358 ||:  40%|####      | 2899/7204 [11:08<16:30,  4.35it/s]
2022-03-21 22:09:18,688 - INFO - tqdm - f1: 0.5740, accuracy: 0.8610, batch_loss: 0.3252, loss: 0.3354 ||:  41%|####      | 2935/7204 [11:18<18:09,  3.92it/s]
2022-03-21 22:09:28,735 - INFO - tqdm - f1: 0.5763, accuracy: 0.8612, batch_loss: 0.1685, loss: 0.3350 ||:  41%|####1     | 2978/7204 [11:28<14:27,  4.87it/s]
2022-03-21 22:09:38,803 - INFO - tqdm - f1: 0.5769, accuracy: 0.8612, batch_loss: 0.6171, loss: 0.3345 ||:  42%|####1     | 3022/7204 [11:38<13:37,  5.12it/s]
2022-03-21 22:09:48,943 - INFO - tqdm - f1: 0.5768, accuracy: 0.8612, batch_loss: 0.2430, loss: 0.3343 ||:  43%|####2     | 3065/7204 [11:48<15:45,  4.38it/s]
2022-03-21 22:09:59,185 - INFO - tqdm - f1: 0.5773, accuracy: 0.8610, batch_loss: 0.2981, loss: 0.3348 ||:  43%|####3     | 3108/7204 [11:58<18:28,  3.69it/s]
2022-03-21 22:10:09,270 - INFO - tqdm - f1: 0.5770, accuracy: 0.8611, batch_loss: 0.2877, loss: 0.3344 ||:  44%|####3     | 3152/7204 [12:09<14:25,  4.68it/s]
2022-03-21 22:10:19,401 - INFO - tqdm - f1: 0.5768, accuracy: 0.8611, batch_loss: 0.2301, loss: 0.3346 ||:  44%|####4     | 3196/7204 [12:19<17:52,  3.74it/s]
2022-03-21 22:10:29,430 - INFO - tqdm - f1: 0.5786, accuracy: 0.8610, batch_loss: 0.4734, loss: 0.3344 ||:  45%|####5     | 3242/7204 [12:29<15:47,  4.18it/s]
2022-03-21 22:10:39,672 - INFO - tqdm - f1: 0.5796, accuracy: 0.8608, batch_loss: 0.5461, loss: 0.3341 ||:  46%|####5     | 3288/7204 [12:39<13:43,  4.75it/s]
2022-03-21 22:10:49,687 - INFO - tqdm - f1: 0.5817, accuracy: 0.8607, batch_loss: 0.7578, loss: 0.3344 ||:  46%|####6     | 3333/7204 [12:49<12:18,  5.24it/s]
2022-03-21 22:10:59,858 - INFO - tqdm - f1: 0.5830, accuracy: 0.8608, batch_loss: 0.2482, loss: 0.3342 ||:  47%|####6     | 3376/7204 [12:59<14:51,  4.29it/s]
2022-03-21 22:11:10,099 - INFO - tqdm - f1: 0.5831, accuracy: 0.8609, batch_loss: 0.2006, loss: 0.3339 ||:  47%|####7     | 3419/7204 [13:09<16:34,  3.80it/s]
2022-03-21 22:11:20,204 - INFO - tqdm - f1: 0.5842, accuracy: 0.8611, batch_loss: 0.0912, loss: 0.3336 ||:  48%|####8     | 3463/7204 [13:19<16:54,  3.69it/s]
2022-03-21 22:11:30,266 - INFO - tqdm - f1: 0.5839, accuracy: 0.8611, batch_loss: 0.0800, loss: 0.3337 ||:  49%|####8     | 3508/7204 [13:30<14:44,  4.18it/s]
2022-03-21 22:11:40,561 - INFO - tqdm - f1: 0.5836, accuracy: 0.8612, batch_loss: 0.0841, loss: 0.3333 ||:  49%|####9     | 3552/7204 [13:40<15:54,  3.83it/s]
2022-03-21 22:11:50,624 - INFO - tqdm - f1: 0.5829, accuracy: 0.8611, batch_loss: 0.1874, loss: 0.3337 ||:  50%|####9     | 3596/7204 [13:50<15:43,  3.83it/s]
2022-03-21 22:12:00,821 - INFO - tqdm - f1: 0.5829, accuracy: 0.8613, batch_loss: 0.0455, loss: 0.3332 ||:  50%|#####     | 3638/7204 [14:00<17:32,  3.39it/s]
2022-03-21 22:12:10,938 - INFO - tqdm - f1: 0.5836, accuracy: 0.8615, batch_loss: 0.2943, loss: 0.3332 ||:  51%|#####1    | 3680/7204 [14:10<13:58,  4.20it/s]
2022-03-21 22:12:21,065 - INFO - tqdm - f1: 0.5848, accuracy: 0.8615, batch_loss: 0.4186, loss: 0.3334 ||:  52%|#####1    | 3726/7204 [14:20<11:42,  4.95it/s]
2022-03-21 22:12:31,294 - INFO - tqdm - f1: 0.5848, accuracy: 0.8616, batch_loss: 0.0844, loss: 0.3330 ||:  52%|#####2    | 3770/7204 [14:31<13:35,  4.21it/s]
2022-03-21 22:12:41,354 - INFO - tqdm - f1: 0.5857, accuracy: 0.8620, batch_loss: 0.1457, loss: 0.3324 ||:  53%|#####2    | 3810/7204 [14:41<13:23,  4.22it/s]
2022-03-21 22:12:51,387 - INFO - tqdm - f1: 0.5863, accuracy: 0.8620, batch_loss: 0.4961, loss: 0.3323 ||:  53%|#####3    | 3854/7204 [14:51<13:07,  4.25it/s]
2022-03-21 22:13:01,423 - INFO - tqdm - f1: 0.5868, accuracy: 0.8620, batch_loss: 0.2258, loss: 0.3321 ||:  54%|#####4    | 3895/7204 [15:01<12:46,  4.32it/s]
2022-03-21 22:13:11,565 - INFO - tqdm - f1: 0.5862, accuracy: 0.8618, batch_loss: 0.4261, loss: 0.3321 ||:  55%|#####4    | 3940/7204 [15:11<13:12,  4.12it/s]
2022-03-21 22:13:21,966 - INFO - tqdm - f1: 0.5858, accuracy: 0.8619, batch_loss: 0.1652, loss: 0.3320 ||:  55%|#####5    | 3982/7204 [15:21<13:03,  4.11it/s]
2022-03-21 22:13:32,055 - INFO - tqdm - f1: 0.5866, accuracy: 0.8620, batch_loss: 0.3251, loss: 0.3317 ||:  56%|#####5    | 4024/7204 [15:31<15:44,  3.37it/s]
2022-03-21 22:13:42,168 - INFO - tqdm - f1: 0.5861, accuracy: 0.8620, batch_loss: 0.1327, loss: 0.3316 ||:  56%|#####6    | 4065/7204 [15:41<10:55,  4.79it/s]
2022-03-21 22:13:52,210 - INFO - tqdm - f1: 0.5864, accuracy: 0.8624, batch_loss: 0.0671, loss: 0.3309 ||:  57%|#####7    | 4108/7204 [15:51<13:47,  3.74it/s]
2022-03-21 22:14:02,459 - INFO - tqdm - f1: 0.5865, accuracy: 0.8623, batch_loss: 0.3159, loss: 0.3313 ||:  58%|#####7    | 4156/7204 [16:02<11:38,  4.36it/s]
2022-03-21 22:14:12,578 - INFO - tqdm - f1: 0.5869, accuracy: 0.8623, batch_loss: 0.3377, loss: 0.3311 ||:  58%|#####8    | 4198/7204 [16:12<09:43,  5.15it/s]
2022-03-21 22:14:22,742 - INFO - tqdm - f1: 0.5871, accuracy: 0.8624, batch_loss: 0.0733, loss: 0.3309 ||:  59%|#####8    | 4241/7204 [16:22<11:10,  4.42it/s]
2022-03-21 22:14:32,779 - INFO - tqdm - f1: 0.5871, accuracy: 0.8624, batch_loss: 0.4372, loss: 0.3310 ||:  59%|#####9    | 4286/7204 [16:32<09:56,  4.89it/s]
2022-03-21 22:14:42,842 - INFO - tqdm - f1: 0.5875, accuracy: 0.8625, batch_loss: 0.5133, loss: 0.3307 ||:  60%|######    | 4326/7204 [16:42<10:48,  4.44it/s]
2022-03-21 22:14:53,219 - INFO - tqdm - f1: 0.5882, accuracy: 0.8627, batch_loss: 0.0186, loss: 0.3306 ||:  61%|######    | 4367/7204 [16:53<15:06,  3.13it/s]
2022-03-21 22:15:03,376 - INFO - tqdm - f1: 0.5882, accuracy: 0.8625, batch_loss: 0.5752, loss: 0.3310 ||:  61%|######1   | 4414/7204 [17:03<08:56,  5.20it/s]
2022-03-21 22:15:13,394 - INFO - tqdm - f1: 0.5884, accuracy: 0.8624, batch_loss: 0.3540, loss: 0.3309 ||:  62%|######1   | 4454/7204 [17:13<11:16,  4.07it/s]
2022-03-21 22:15:23,447 - INFO - tqdm - f1: 0.5888, accuracy: 0.8623, batch_loss: 0.2794, loss: 0.3309 ||:  62%|######2   | 4497/7204 [17:23<09:24,  4.79it/s]
2022-03-21 22:15:33,690 - INFO - tqdm - f1: 0.5893, accuracy: 0.8621, batch_loss: 0.3949, loss: 0.3311 ||:  63%|######2   | 4538/7204 [17:33<09:07,  4.87it/s]
2022-03-21 22:15:43,967 - INFO - tqdm - f1: 0.5906, accuracy: 0.8622, batch_loss: 0.1090, loss: 0.3308 ||:  64%|######3   | 4581/7204 [17:43<12:48,  3.41it/s]
2022-03-21 22:15:54,132 - INFO - tqdm - f1: 0.5905, accuracy: 0.8622, batch_loss: 0.2062, loss: 0.3306 ||:  64%|######4   | 4625/7204 [17:53<08:22,  5.14it/s]
2022-03-21 22:16:04,325 - INFO - tqdm - f1: 0.5901, accuracy: 0.8624, batch_loss: 0.2146, loss: 0.3306 ||:  65%|######4   | 4668/7204 [18:04<09:34,  4.41it/s]
2022-03-21 22:16:14,370 - INFO - tqdm - f1: 0.5902, accuracy: 0.8624, batch_loss: 0.2222, loss: 0.3306 ||:  65%|######5   | 4711/7204 [18:14<10:01,  4.15it/s]
2022-03-21 22:16:24,497 - INFO - tqdm - f1: 0.5900, accuracy: 0.8625, batch_loss: 0.3576, loss: 0.3304 ||:  66%|######5   | 4751/7204 [18:24<08:26,  4.84it/s]
2022-03-21 22:16:34,624 - INFO - tqdm - f1: 0.5907, accuracy: 0.8625, batch_loss: 0.2854, loss: 0.3303 ||:  67%|######6   | 4793/7204 [18:34<07:46,  5.17it/s]
2022-03-21 22:16:44,817 - INFO - tqdm - f1: 0.5907, accuracy: 0.8627, batch_loss: 0.3273, loss: 0.3299 ||:  67%|######7   | 4837/7204 [18:44<09:00,  4.38it/s]
2022-03-21 22:16:54,930 - INFO - tqdm - f1: 0.5912, accuracy: 0.8627, batch_loss: 0.1730, loss: 0.3301 ||:  68%|######7   | 4883/7204 [18:54<09:51,  3.93it/s]
2022-03-21 22:17:05,109 - INFO - tqdm - f1: 0.5915, accuracy: 0.8627, batch_loss: 0.5842, loss: 0.3301 ||:  68%|######8   | 4925/7204 [19:04<08:06,  4.69it/s]
2022-03-21 22:17:15,456 - INFO - tqdm - f1: 0.5920, accuracy: 0.8629, batch_loss: 0.5607, loss: 0.3298 ||:  69%|######8   | 4968/7204 [19:15<10:24,  3.58it/s]
2022-03-21 22:17:25,617 - INFO - tqdm - f1: 0.5922, accuracy: 0.8627, batch_loss: 0.1860, loss: 0.3299 ||:  70%|######9   | 5019/7204 [19:25<07:57,  4.58it/s]
2022-03-21 22:17:35,875 - INFO - tqdm - f1: 0.5919, accuracy: 0.8627, batch_loss: 0.1423, loss: 0.3300 ||:  70%|#######   | 5065/7204 [19:35<08:21,  4.27it/s]
2022-03-21 22:17:46,233 - INFO - tqdm - f1: 0.5924, accuracy: 0.8627, batch_loss: 0.1625, loss: 0.3299 ||:  71%|#######   | 5109/7204 [19:46<10:28,  3.33it/s]
2022-03-21 22:17:56,355 - INFO - tqdm - f1: 0.5925, accuracy: 0.8625, batch_loss: 0.4014, loss: 0.3300 ||:  72%|#######1  | 5152/7204 [19:56<06:47,  5.04it/s]
2022-03-21 22:18:06,378 - INFO - tqdm - f1: 0.5929, accuracy: 0.8625, batch_loss: 0.0323, loss: 0.3301 ||:  72%|#######2  | 5196/7204 [20:06<08:28,  3.95it/s]
2022-03-21 22:18:16,459 - INFO - tqdm - f1: 0.5939, accuracy: 0.8626, batch_loss: 0.5167, loss: 0.3297 ||:  73%|#######2  | 5237/7204 [20:16<08:29,  3.86it/s]
2022-03-21 22:18:26,756 - INFO - tqdm - f1: 0.5952, accuracy: 0.8627, batch_loss: 0.3014, loss: 0.3296 ||:  73%|#######3  | 5284/7204 [20:26<08:11,  3.90it/s]
2022-03-21 22:18:36,903 - INFO - tqdm - f1: 0.5953, accuracy: 0.8629, batch_loss: 0.3109, loss: 0.3294 ||:  74%|#######3  | 5328/7204 [20:36<09:40,  3.23it/s]
2022-03-21 22:18:47,044 - INFO - tqdm - f1: 0.5955, accuracy: 0.8630, batch_loss: 0.0350, loss: 0.3292 ||:  75%|#######4  | 5372/7204 [20:46<08:29,  3.60it/s]
2022-03-21 22:18:57,217 - INFO - tqdm - f1: 0.5954, accuracy: 0.8630, batch_loss: 0.2216, loss: 0.3291 ||:  75%|#######5  | 5413/7204 [20:57<07:37,  3.92it/s]
2022-03-21 22:19:07,295 - INFO - tqdm - f1: 0.5961, accuracy: 0.8632, batch_loss: 0.2480, loss: 0.3286 ||:  76%|#######5  | 5454/7204 [21:07<05:48,  5.02it/s]
2022-03-21 22:19:17,437 - INFO - tqdm - f1: 0.5968, accuracy: 0.8632, batch_loss: 0.3001, loss: 0.3284 ||:  76%|#######6  | 5500/7204 [21:17<06:09,  4.62it/s]
2022-03-21 22:19:27,629 - INFO - tqdm - f1: 0.5973, accuracy: 0.8632, batch_loss: 0.3940, loss: 0.3284 ||:  77%|#######6  | 5544/7204 [21:27<07:31,  3.68it/s]
2022-03-21 22:19:37,871 - INFO - tqdm - f1: 0.5978, accuracy: 0.8632, batch_loss: 0.1251, loss: 0.3283 ||:  78%|#######7  | 5587/7204 [21:37<07:01,  3.84it/s]
2022-03-21 22:19:48,237 - INFO - tqdm - f1: 0.5978, accuracy: 0.8632, batch_loss: 0.1639, loss: 0.3283 ||:  78%|#######8  | 5631/7204 [21:48<06:40,  3.93it/s]
2022-03-21 22:19:58,409 - INFO - tqdm - f1: 0.5979, accuracy: 0.8632, batch_loss: 0.1396, loss: 0.3284 ||:  79%|#######8  | 5675/7204 [21:58<06:52,  3.71it/s]
2022-03-21 22:20:08,588 - INFO - tqdm - f1: 0.5980, accuracy: 0.8634, batch_loss: 0.0702, loss: 0.3280 ||:  79%|#######9  | 5718/7204 [22:08<06:06,  4.05it/s]
2022-03-21 22:20:18,694 - INFO - tqdm - f1: 0.5984, accuracy: 0.8632, batch_loss: 0.2975, loss: 0.3283 ||:  80%|#######9  | 5762/7204 [22:18<05:32,  4.33it/s]
2022-03-21 22:20:28,888 - INFO - tqdm - f1: 0.5986, accuracy: 0.8632, batch_loss: 0.3014, loss: 0.3283 ||:  81%|########  | 5804/7204 [22:28<05:08,  4.53it/s]
2022-03-21 22:20:38,974 - INFO - tqdm - f1: 0.5990, accuracy: 0.8633, batch_loss: 0.2151, loss: 0.3282 ||:  81%|########1 | 5848/7204 [22:38<05:51,  3.86it/s]
2022-03-21 22:20:49,203 - INFO - tqdm - f1: 0.5992, accuracy: 0.8632, batch_loss: 0.3367, loss: 0.3281 ||:  82%|########1 | 5892/7204 [22:48<05:30,  3.97it/s]
2022-03-21 22:20:59,356 - INFO - tqdm - f1: 0.5996, accuracy: 0.8632, batch_loss: 0.3220, loss: 0.3283 ||:  82%|########2 | 5939/7204 [22:59<04:39,  4.52it/s]
2022-03-21 22:21:09,376 - INFO - tqdm - f1: 0.6004, accuracy: 0.8634, batch_loss: 0.2094, loss: 0.3278 ||:  83%|########3 | 5980/7204 [23:09<04:52,  4.18it/s]
2022-03-21 22:21:19,444 - INFO - tqdm - f1: 0.6006, accuracy: 0.8635, batch_loss: 0.3349, loss: 0.3277 ||:  84%|########3 | 6022/7204 [23:19<04:31,  4.36it/s]
2022-03-21 22:21:29,609 - INFO - tqdm - f1: 0.6015, accuracy: 0.8637, batch_loss: 0.1686, loss: 0.3274 ||:  84%|########4 | 6066/7204 [23:29<03:53,  4.87it/s]
2022-03-21 22:21:39,726 - INFO - tqdm - f1: 0.6015, accuracy: 0.8637, batch_loss: 0.4969, loss: 0.3274 ||:  85%|########4 | 6107/7204 [23:39<04:08,  4.42it/s]
2022-03-21 22:21:49,776 - INFO - tqdm - f1: 0.6019, accuracy: 0.8639, batch_loss: 0.3945, loss: 0.3271 ||:  85%|########5 | 6147/7204 [23:49<04:37,  3.81it/s]
2022-03-21 22:21:59,967 - INFO - tqdm - f1: 0.6025, accuracy: 0.8639, batch_loss: 0.1480, loss: 0.3269 ||:  86%|########5 | 6191/7204 [23:59<03:25,  4.94it/s]
2022-03-21 22:22:10,119 - INFO - tqdm - f1: 0.6024, accuracy: 0.8642, batch_loss: 0.3331, loss: 0.3265 ||:  87%|########6 | 6233/7204 [24:09<03:41,  4.39it/s]
2022-03-21 22:22:20,160 - INFO - tqdm - f1: 0.6029, accuracy: 0.8641, batch_loss: 0.3111, loss: 0.3265 ||:  87%|########7 | 6277/7204 [24:19<03:34,  4.31it/s]
2022-03-21 22:22:30,298 - INFO - tqdm - f1: 0.6027, accuracy: 0.8641, batch_loss: 0.3755, loss: 0.3264 ||:  88%|########7 | 6320/7204 [24:30<03:06,  4.74it/s]
2022-03-21 22:22:40,367 - INFO - tqdm - f1: 0.6030, accuracy: 0.8639, batch_loss: 0.2514, loss: 0.3266 ||:  88%|########8 | 6365/7204 [24:40<02:59,  4.66it/s]
2022-03-21 22:22:50,708 - INFO - tqdm - f1: 0.6029, accuracy: 0.8638, batch_loss: 0.0249, loss: 0.3268 ||:  89%|########9 | 6412/7204 [24:50<03:19,  3.96it/s]
2022-03-21 22:23:00,840 - INFO - tqdm - f1: 0.6030, accuracy: 0.8639, batch_loss: 0.1115, loss: 0.3265 ||:  90%|########9 | 6453/7204 [25:00<02:43,  4.61it/s]
2022-03-21 22:23:11,127 - INFO - tqdm - f1: 0.6034, accuracy: 0.8641, batch_loss: 0.1638, loss: 0.3264 ||:  90%|######### | 6495/7204 [25:10<03:30,  3.37it/s]
2022-03-21 22:23:21,297 - INFO - tqdm - f1: 0.6032, accuracy: 0.8640, batch_loss: 0.4997, loss: 0.3263 ||:  91%|######### | 6538/7204 [25:21<02:11,  5.08it/s]
2022-03-21 22:23:31,636 - INFO - tqdm - f1: 0.6036, accuracy: 0.8640, batch_loss: 0.2507, loss: 0.3265 ||:  91%|#########1| 6579/7204 [25:31<03:29,  2.99it/s]
2022-03-21 22:23:41,729 - INFO - tqdm - f1: 0.6038, accuracy: 0.8638, batch_loss: 0.6922, loss: 0.3265 ||:  92%|#########1| 6623/7204 [25:41<01:57,  4.97it/s]
2022-03-21 22:23:51,819 - INFO - tqdm - f1: 0.6042, accuracy: 0.8638, batch_loss: 0.2719, loss: 0.3265 ||:  93%|#########2| 6665/7204 [25:51<02:25,  3.70it/s]
2022-03-21 22:24:01,965 - INFO - tqdm - f1: 0.6039, accuracy: 0.8639, batch_loss: 0.4330, loss: 0.3265 ||:  93%|#########3| 6706/7204 [26:01<02:12,  3.77it/s]
2022-03-21 22:24:12,058 - INFO - tqdm - f1: 0.6043, accuracy: 0.8640, batch_loss: 0.2245, loss: 0.3265 ||:  94%|#########3| 6748/7204 [26:11<01:45,  4.31it/s]
2022-03-21 22:24:22,089 - INFO - tqdm - f1: 0.6048, accuracy: 0.8640, batch_loss: 0.5043, loss: 0.3264 ||:  94%|#########4| 6792/7204 [26:21<01:26,  4.76it/s]
2022-03-21 22:24:32,101 - INFO - tqdm - f1: 0.6052, accuracy: 0.8641, batch_loss: 0.4074, loss: 0.3263 ||:  95%|#########4| 6836/7204 [26:31<01:36,  3.82it/s]
2022-03-21 22:24:42,312 - INFO - tqdm - f1: 0.6058, accuracy: 0.8642, batch_loss: 0.4178, loss: 0.3261 ||:  95%|#########5| 6876/7204 [26:42<01:28,  3.72it/s]
2022-03-21 22:24:52,396 - INFO - tqdm - f1: 0.6060, accuracy: 0.8642, batch_loss: 0.3107, loss: 0.3260 ||:  96%|#########6| 6919/7204 [26:52<00:59,  4.76it/s]
2022-03-21 22:25:02,538 - INFO - tqdm - f1: 0.6058, accuracy: 0.8642, batch_loss: 0.2477, loss: 0.3260 ||:  97%|#########6| 6961/7204 [27:02<01:02,  3.89it/s]
2022-03-21 22:25:12,666 - INFO - tqdm - f1: 0.6060, accuracy: 0.8643, batch_loss: 0.3052, loss: 0.3259 ||:  97%|#########7| 7004/7204 [27:12<00:41,  4.79it/s]
2022-03-21 22:25:22,732 - INFO - tqdm - f1: 0.6063, accuracy: 0.8644, batch_loss: 0.1300, loss: 0.3258 ||:  98%|#########7| 7045/7204 [27:22<00:45,  3.46it/s]
2022-03-21 22:25:32,783 - INFO - tqdm - f1: 0.6067, accuracy: 0.8644, batch_loss: 0.2264, loss: 0.3256 ||:  98%|#########8| 7090/7204 [27:32<00:25,  4.43it/s]
2022-03-21 22:25:42,823 - INFO - tqdm - f1: 0.6072, accuracy: 0.8645, batch_loss: 0.1845, loss: 0.3255 ||:  99%|#########8| 7131/7204 [27:42<00:17,  4.28it/s]
2022-03-21 22:25:51,450 - INFO - tqdm - f1: 0.6075, accuracy: 0.8645, batch_loss: 0.1679, loss: 0.3256 ||: 100%|#########9| 7168/7204 [27:51<00:07,  5.04it/s]
2022-03-21 22:25:51,674 - INFO - tqdm - f1: 0.6075, accuracy: 0.8645, batch_loss: 0.2377, loss: 0.3256 ||: 100%|#########9| 7169/7204 [27:51<00:07,  4.86it/s]
2022-03-21 22:25:51,905 - INFO - tqdm - f1: 0.6076, accuracy: 0.8645, batch_loss: 0.1862, loss: 0.3256 ||: 100%|#########9| 7170/7204 [27:51<00:07,  4.68it/s]
2022-03-21 22:25:52,058 - INFO - tqdm - f1: 0.6075, accuracy: 0.8645, batch_loss: 0.3457, loss: 0.3256 ||: 100%|#########9| 7171/7204 [27:51<00:06,  5.12it/s]
2022-03-21 22:25:52,327 - INFO - tqdm - f1: 0.6075, accuracy: 0.8645, batch_loss: 0.2618, loss: 0.3256 ||: 100%|#########9| 7172/7204 [27:52<00:06,  4.60it/s]
2022-03-21 22:25:52,555 - INFO - tqdm - f1: 0.6076, accuracy: 0.8645, batch_loss: 0.2214, loss: 0.3256 ||: 100%|#########9| 7173/7204 [27:52<00:06,  4.53it/s]
2022-03-21 22:25:52,958 - INFO - tqdm - f1: 0.6076, accuracy: 0.8645, batch_loss: 0.2049, loss: 0.3256 ||: 100%|#########9| 7174/7204 [27:52<00:08,  3.63it/s]
2022-03-21 22:25:53,212 - INFO - tqdm - f1: 0.6076, accuracy: 0.8645, batch_loss: 0.3253, loss: 0.3256 ||: 100%|#########9| 7175/7204 [27:53<00:07,  3.72it/s]
2022-03-21 22:25:53,391 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.1882, loss: 0.3255 ||: 100%|#########9| 7176/7204 [27:53<00:06,  4.13it/s]
2022-03-21 22:25:53,584 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.2678, loss: 0.3255 ||: 100%|#########9| 7177/7204 [27:53<00:06,  4.40it/s]
2022-03-21 22:25:53,993 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.0569, loss: 0.3255 ||: 100%|#########9| 7178/7204 [27:53<00:07,  3.55it/s]
2022-03-21 22:25:54,158 - INFO - tqdm - f1: 0.6078, accuracy: 0.8646, batch_loss: 0.4152, loss: 0.3255 ||: 100%|#########9| 7179/7204 [27:53<00:06,  4.05it/s]
2022-03-21 22:25:54,429 - INFO - tqdm - f1: 0.6078, accuracy: 0.8646, batch_loss: 0.1306, loss: 0.3255 ||: 100%|#########9| 7180/7204 [27:54<00:06,  3.94it/s]
2022-03-21 22:25:54,733 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.4475, loss: 0.3255 ||: 100%|#########9| 7181/7204 [27:54<00:06,  3.72it/s]
2022-03-21 22:25:54,908 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.3494, loss: 0.3255 ||: 100%|#########9| 7182/7204 [27:54<00:05,  4.15it/s]
2022-03-21 22:25:55,219 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.1284, loss: 0.3255 ||: 100%|#########9| 7183/7204 [27:55<00:05,  3.82it/s]
2022-03-21 22:25:55,393 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.7564, loss: 0.3255 ||: 100%|#########9| 7184/7204 [27:55<00:04,  4.25it/s]
2022-03-21 22:25:55,617 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.3212, loss: 0.3255 ||: 100%|#########9| 7185/7204 [27:55<00:04,  4.31it/s]
2022-03-21 22:25:55,789 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.3175, loss: 0.3255 ||: 100%|#########9| 7186/7204 [27:55<00:03,  4.67it/s]
2022-03-21 22:25:56,078 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.2244, loss: 0.3255 ||: 100%|#########9| 7187/7204 [27:55<00:04,  4.23it/s]
2022-03-21 22:25:56,511 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.0765, loss: 0.3255 ||: 100%|#########9| 7188/7204 [27:56<00:04,  3.39it/s]
2022-03-21 22:25:56,721 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.4574, loss: 0.3255 ||: 100%|#########9| 7189/7204 [27:56<00:04,  3.70it/s]
2022-03-21 22:25:56,983 - INFO - tqdm - f1: 0.6078, accuracy: 0.8646, batch_loss: 0.1970, loss: 0.3255 ||: 100%|#########9| 7190/7204 [27:56<00:03,  3.74it/s]
2022-03-21 22:25:57,209 - INFO - tqdm - f1: 0.6078, accuracy: 0.8646, batch_loss: 0.5144, loss: 0.3255 ||: 100%|#########9| 7191/7204 [27:56<00:03,  3.92it/s]
2022-03-21 22:25:57,371 - INFO - tqdm - f1: 0.6078, accuracy: 0.8646, batch_loss: 0.3621, loss: 0.3255 ||: 100%|#########9| 7192/7204 [27:57<00:02,  4.40it/s]
2022-03-21 22:25:57,601 - INFO - tqdm - f1: 0.6078, accuracy: 0.8646, batch_loss: 0.1242, loss: 0.3255 ||: 100%|#########9| 7193/7204 [27:57<00:02,  4.39it/s]
2022-03-21 22:25:57,868 - INFO - tqdm - f1: 0.6078, accuracy: 0.8646, batch_loss: 0.3848, loss: 0.3255 ||: 100%|#########9| 7194/7204 [27:57<00:02,  4.17it/s]
2022-03-21 22:25:58,023 - INFO - tqdm - f1: 0.6078, accuracy: 0.8646, batch_loss: 0.3412, loss: 0.3255 ||: 100%|#########9| 7195/7204 [27:57<00:01,  4.67it/s]
2022-03-21 22:25:58,225 - INFO - tqdm - f1: 0.6078, accuracy: 0.8646, batch_loss: 0.3703, loss: 0.3255 ||: 100%|#########9| 7196/7204 [27:58<00:01,  4.75it/s]
2022-03-21 22:25:58,523 - INFO - tqdm - f1: 0.6078, accuracy: 0.8646, batch_loss: 0.1394, loss: 0.3255 ||: 100%|#########9| 7197/7204 [27:58<00:01,  4.22it/s]
2022-03-21 22:25:58,690 - INFO - tqdm - f1: 0.6078, accuracy: 0.8646, batch_loss: 0.2652, loss: 0.3255 ||: 100%|#########9| 7198/7204 [27:58<00:01,  4.63it/s]
2022-03-21 22:25:58,962 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.2179, loss: 0.3254 ||: 100%|#########9| 7199/7204 [27:58<00:01,  4.30it/s]
2022-03-21 22:25:59,196 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.2478, loss: 0.3254 ||: 100%|#########9| 7200/7204 [27:58<00:00,  4.29it/s]
2022-03-21 22:25:59,356 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.1965, loss: 0.3254 ||: 100%|#########9| 7201/7204 [27:59<00:00,  4.74it/s]
2022-03-21 22:25:59,654 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.3510, loss: 0.3254 ||: 100%|#########9| 7202/7204 [27:59<00:00,  4.22it/s]
2022-03-21 22:25:59,928 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.2014, loss: 0.3254 ||: 100%|#########9| 7203/7204 [27:59<00:00,  4.02it/s]
2022-03-21 22:26:00,249 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.2931, loss: 0.3254 ||: 100%|##########| 7204/7204 [28:00<00:00,  3.70it/s]
2022-03-21 22:26:00,308 - INFO - tqdm - f1: 0.6077, accuracy: 0.8646, batch_loss: 0.2931, loss: 0.3254 ||: 100%|##########| 7204/7204 [28:00<00:00,  4.29it/s]
2022-03-21 22:26:00,347 - INFO - allennlp.training.trainer - Validating
2022-03-21 22:26:00,350 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 22:26:00,358 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 22:26:00,361 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 22:26:10,518 - INFO - tqdm - f1: 0.6182, accuracy: 0.8715, batch_loss: 0.5870, loss: 0.3138 ||:  29%|##8       | 90/313 [00:10<00:23,  9.48it/s]
2022-03-21 22:26:20,605 - INFO - tqdm - f1: 0.6272, accuracy: 0.8747, batch_loss: 0.0525, loss: 0.3122 ||:  58%|#####8    | 182/313 [00:20<00:15,  8.20it/s]
2022-03-21 22:26:28,397 - INFO - tqdm - f1: 0.6131, accuracy: 0.8706, batch_loss: 0.0269, loss: 0.3142 ||: 100%|##########| 313/313 [00:28<00:00, 11.16it/s]
2022-03-21 22:26:28,415 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/amazon_base_hyper_small_seed_47/best.th'.
2022-03-21 22:26:30,939 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 22:26:30,941 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.865  |     0.871
2022-03-21 22:26:30,943 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.608  |     0.613
2022-03-21 22:26:30,944 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 22:26:30,946 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.325  |     0.314
2022-03-21 22:26:30,948 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13507.660  |       N/A
2022-03-21 22:26:30,949 - INFO - allennlp.training.trainer - Epoch duration: 0:28:30.746583
2022-03-21 22:26:30,951 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:16:36
2022-03-21 22:26:30,952 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-21 22:26:30,954 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-21 22:26:30,955 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 22:26:30,958 - INFO - allennlp.training.trainer - Training
2022-03-21 22:26:30,960 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-21 22:26:41,038 - INFO - tqdm - f1: 0.6364, accuracy: 0.8889, batch_loss: 0.3349, loss: 0.2753 ||:   1%|          | 54/7204 [00:10<18:22,  6.49it/s]
2022-03-21 22:26:51,184 - INFO - tqdm - f1: 0.6698, accuracy: 0.8845, batch_loss: 0.2922, loss: 0.2871 ||:   2%|1         | 112/7204 [00:20<19:44,  5.99it/s]
2022-03-21 22:27:01,363 - INFO - tqdm - f1: 0.6903, accuracy: 0.8801, batch_loss: 0.0148, loss: 0.2895 ||:   2%|2         | 171/7204 [00:30<22:24,  5.23it/s]
2022-03-21 22:27:11,489 - INFO - tqdm - f1: 0.6931, accuracy: 0.8773, batch_loss: 0.1840, loss: 0.2923 ||:   3%|3         | 217/7204 [00:40<33:12,  3.51it/s]
2022-03-21 22:27:21,630 - INFO - tqdm - f1: 0.6884, accuracy: 0.8779, batch_loss: 0.1690, loss: 0.2880 ||:   4%|3         | 260/7204 [00:50<31:39,  3.66it/s]
2022-03-21 22:27:31,706 - INFO - tqdm - f1: 0.6913, accuracy: 0.8762, batch_loss: 0.5127, loss: 0.2927 ||:   4%|4         | 302/7204 [01:00<27:29,  4.19it/s]
2022-03-21 22:27:41,785 - INFO - tqdm - f1: 0.6924, accuracy: 0.8754, batch_loss: 0.6013, loss: 0.2955 ||:   5%|4         | 347/7204 [01:10<24:52,  4.60it/s]
2022-03-21 22:27:51,834 - INFO - tqdm - f1: 0.6971, accuracy: 0.8740, batch_loss: 0.4688, loss: 0.2997 ||:   5%|5         | 392/7204 [01:20<27:16,  4.16it/s]
2022-03-21 22:28:01,960 - INFO - tqdm - f1: 0.6974, accuracy: 0.8721, batch_loss: 0.1625, loss: 0.3025 ||:   6%|6         | 433/7204 [01:30<25:01,  4.51it/s]
2022-03-21 22:28:12,057 - INFO - tqdm - f1: 0.6925, accuracy: 0.8703, batch_loss: 0.5783, loss: 0.3059 ||:   7%|6         | 480/7204 [01:41<21:15,  5.27it/s]
2022-03-21 22:28:22,326 - INFO - tqdm - f1: 0.6943, accuracy: 0.8720, batch_loss: 0.1582, loss: 0.3040 ||:   7%|7         | 525/7204 [01:51<28:25,  3.92it/s]
2022-03-21 22:28:32,598 - INFO - tqdm - f1: 0.6957, accuracy: 0.8735, batch_loss: 0.0372, loss: 0.3023 ||:   8%|7         | 569/7204 [02:01<28:00,  3.95it/s]
2022-03-21 22:28:42,717 - INFO - tqdm - f1: 0.6904, accuracy: 0.8731, batch_loss: 0.3975, loss: 0.3024 ||:   8%|8         | 612/7204 [02:11<28:57,  3.79it/s]
2022-03-21 22:28:52,899 - INFO - tqdm - f1: 0.6914, accuracy: 0.8735, batch_loss: 0.2888, loss: 0.3018 ||:   9%|9         | 656/7204 [02:21<26:19,  4.14it/s]
2022-03-21 22:29:03,025 - INFO - tqdm - f1: 0.6886, accuracy: 0.8730, batch_loss: 0.2272, loss: 0.3026 ||:  10%|9         | 696/7204 [02:32<24:07,  4.50it/s]
2022-03-21 22:29:13,342 - INFO - tqdm - f1: 0.6859, accuracy: 0.8741, batch_loss: 0.2395, loss: 0.3007 ||:  10%|#         | 738/7204 [02:42<31:34,  3.41it/s]
2022-03-21 22:29:23,494 - INFO - tqdm - f1: 0.6886, accuracy: 0.8755, batch_loss: 0.5065, loss: 0.2991 ||:  11%|#         | 780/7204 [02:52<22:09,  4.83it/s]
2022-03-21 22:29:33,634 - INFO - tqdm - f1: 0.6891, accuracy: 0.8742, batch_loss: 0.4535, loss: 0.3009 ||:  11%|#1        | 824/7204 [03:02<22:21,  4.76it/s]
2022-03-21 22:29:43,692 - INFO - tqdm - f1: 0.6892, accuracy: 0.8744, batch_loss: 0.2899, loss: 0.3015 ||:  12%|#2        | 868/7204 [03:12<24:36,  4.29it/s]
2022-03-21 22:29:53,759 - INFO - tqdm - f1: 0.6874, accuracy: 0.8748, batch_loss: 0.2176, loss: 0.3005 ||:  13%|#2        | 909/7204 [03:22<23:23,  4.48it/s]
2022-03-21 22:30:03,937 - INFO - tqdm - f1: 0.6845, accuracy: 0.8739, batch_loss: 0.4094, loss: 0.3008 ||:  13%|#3        | 951/7204 [03:32<27:15,  3.82it/s]
2022-03-21 22:30:14,110 - INFO - tqdm - f1: 0.6844, accuracy: 0.8745, batch_loss: 0.1995, loss: 0.2987 ||:  14%|#3        | 990/7204 [03:43<28:37,  3.62it/s]
2022-03-21 22:30:24,539 - INFO - tqdm - f1: 0.6837, accuracy: 0.8727, batch_loss: 0.1314, loss: 0.3008 ||:  14%|#4        | 1038/7204 [03:53<28:02,  3.66it/s]
2022-03-21 22:30:34,634 - INFO - tqdm - f1: 0.6869, accuracy: 0.8734, batch_loss: 0.3503, loss: 0.2997 ||:  15%|#5        | 1085/7204 [04:03<18:55,  5.39it/s]
2022-03-21 22:30:44,719 - INFO - tqdm - f1: 0.6878, accuracy: 0.8741, batch_loss: 0.4641, loss: 0.2985 ||:  16%|#5        | 1127/7204 [04:13<27:43,  3.65it/s]
2022-03-21 22:30:54,746 - INFO - tqdm - f1: 0.6851, accuracy: 0.8738, batch_loss: 0.3250, loss: 0.2984 ||:  16%|#6        | 1171/7204 [04:23<19:18,  5.21it/s]
2022-03-21 22:31:04,870 - INFO - tqdm - f1: 0.6842, accuracy: 0.8743, batch_loss: 0.2587, loss: 0.2972 ||:  17%|#6        | 1213/7204 [04:33<24:34,  4.06it/s]
2022-03-21 22:31:15,054 - INFO - tqdm - f1: 0.6853, accuracy: 0.8747, batch_loss: 0.1829, loss: 0.2962 ||:  17%|#7        | 1257/7204 [04:44<21:34,  4.60it/s]
2022-03-21 22:31:25,086 - INFO - tqdm - f1: 0.6864, accuracy: 0.8746, batch_loss: 0.4666, loss: 0.2960 ||:  18%|#8        | 1298/7204 [04:54<23:50,  4.13it/s]
2022-03-21 22:31:35,217 - INFO - tqdm - f1: 0.6879, accuracy: 0.8749, batch_loss: 0.4630, loss: 0.2957 ||:  19%|#8        | 1338/7204 [05:04<25:36,  3.82it/s]
2022-03-21 22:31:45,603 - INFO - tqdm - f1: 0.6872, accuracy: 0.8744, batch_loss: 0.4106, loss: 0.2959 ||:  19%|#9        | 1380/7204 [05:14<30:25,  3.19it/s]
2022-03-21 22:31:55,792 - INFO - tqdm - f1: 0.6857, accuracy: 0.8735, batch_loss: 0.5212, loss: 0.2972 ||:  20%|#9        | 1424/7204 [05:24<26:00,  3.70it/s]
2022-03-21 22:32:05,933 - INFO - tqdm - f1: 0.6857, accuracy: 0.8740, batch_loss: 0.2553, loss: 0.2967 ||:  20%|##        | 1467/7204 [05:34<23:13,  4.12it/s]
2022-03-21 22:32:16,275 - INFO - tqdm - f1: 0.6843, accuracy: 0.8736, batch_loss: 0.1081, loss: 0.2971 ||:  21%|##1       | 1513/7204 [05:45<25:39,  3.70it/s]
2022-03-21 22:32:26,394 - INFO - tqdm - f1: 0.6852, accuracy: 0.8736, batch_loss: 0.3680, loss: 0.2975 ||:  22%|##1       | 1559/7204 [05:55<22:05,  4.26it/s]
2022-03-21 22:32:36,567 - INFO - tqdm - f1: 0.6844, accuracy: 0.8730, batch_loss: 0.0772, loss: 0.2978 ||:  22%|##2       | 1605/7204 [06:05<21:18,  4.38it/s]
2022-03-21 22:32:46,571 - INFO - tqdm - f1: 0.6843, accuracy: 0.8730, batch_loss: 0.3317, loss: 0.2980 ||:  23%|##2       | 1649/7204 [06:15<20:29,  4.52it/s]
2022-03-21 22:32:56,924 - INFO - tqdm - f1: 0.6849, accuracy: 0.8736, batch_loss: 0.2918, loss: 0.2977 ||:  24%|##3       | 1697/7204 [06:25<27:41,  3.32it/s]
2022-03-21 22:33:07,332 - INFO - tqdm - f1: 0.6843, accuracy: 0.8736, batch_loss: 0.2822, loss: 0.2976 ||:  24%|##4       | 1739/7204 [06:36<32:07,  2.83it/s]
2022-03-21 22:33:17,403 - INFO - tqdm - f1: 0.6844, accuracy: 0.8739, batch_loss: 0.1300, loss: 0.2977 ||:  25%|##4       | 1785/7204 [06:46<19:57,  4.52it/s]
2022-03-21 22:33:27,681 - INFO - tqdm - f1: 0.6853, accuracy: 0.8747, batch_loss: 0.6274, loss: 0.2964 ||:  25%|##5       | 1831/7204 [06:56<27:12,  3.29it/s]
2022-03-21 22:33:37,684 - INFO - tqdm - f1: 0.6846, accuracy: 0.8747, batch_loss: 0.3916, loss: 0.2967 ||:  26%|##5       | 1872/7204 [07:06<21:12,  4.19it/s]
2022-03-21 22:33:47,796 - INFO - tqdm - f1: 0.6828, accuracy: 0.8741, batch_loss: 0.3178, loss: 0.2978 ||:  27%|##6       | 1914/7204 [07:16<19:01,  4.63it/s]
2022-03-21 22:33:57,820 - INFO - tqdm - f1: 0.6825, accuracy: 0.8745, batch_loss: 0.0363, loss: 0.2973 ||:  27%|##7       | 1956/7204 [07:26<24:30,  3.57it/s]
2022-03-21 22:34:07,850 - INFO - tqdm - f1: 0.6821, accuracy: 0.8745, batch_loss: 0.1899, loss: 0.2973 ||:  28%|##7       | 1998/7204 [07:36<20:25,  4.25it/s]
2022-03-21 22:34:18,093 - INFO - tqdm - f1: 0.6812, accuracy: 0.8745, batch_loss: 0.1670, loss: 0.2975 ||:  28%|##8       | 2042/7204 [07:47<21:37,  3.98it/s]
2022-03-21 22:34:28,189 - INFO - tqdm - f1: 0.6827, accuracy: 0.8744, batch_loss: 0.3356, loss: 0.2975 ||:  29%|##9       | 2090/7204 [07:57<17:39,  4.83it/s]
2022-03-21 22:34:38,399 - INFO - tqdm - f1: 0.6827, accuracy: 0.8746, batch_loss: 0.1892, loss: 0.2972 ||:  30%|##9       | 2134/7204 [08:07<20:40,  4.09it/s]
2022-03-21 22:34:48,629 - INFO - tqdm - f1: 0.6829, accuracy: 0.8748, batch_loss: 0.2266, loss: 0.2966 ||:  30%|###       | 2178/7204 [08:17<19:24,  4.32it/s]
2022-03-21 22:34:58,836 - INFO - tqdm - f1: 0.6813, accuracy: 0.8746, batch_loss: 0.2788, loss: 0.2975 ||:  31%|###       | 2222/7204 [08:27<18:08,  4.58it/s]
2022-03-21 22:35:08,860 - INFO - tqdm - f1: 0.6824, accuracy: 0.8750, batch_loss: 0.0954, loss: 0.2970 ||:  31%|###1      | 2265/7204 [08:37<20:43,  3.97it/s]
2022-03-21 22:35:19,081 - INFO - tqdm - f1: 0.6827, accuracy: 0.8754, batch_loss: 0.2332, loss: 0.2967 ||:  32%|###2      | 2309/7204 [08:48<19:31,  4.18it/s]
2022-03-21 22:35:29,203 - INFO - tqdm - f1: 0.6834, accuracy: 0.8754, batch_loss: 0.0697, loss: 0.2972 ||:  33%|###2      | 2353/7204 [08:58<24:57,  3.24it/s]
2022-03-21 22:35:39,570 - INFO - tqdm - f1: 0.6837, accuracy: 0.8752, batch_loss: 0.1202, loss: 0.2973 ||:  33%|###3      | 2399/7204 [09:08<21:00,  3.81it/s]
2022-03-21 22:35:49,652 - INFO - tqdm - f1: 0.6834, accuracy: 0.8751, batch_loss: 0.5279, loss: 0.2970 ||:  34%|###3      | 2447/7204 [09:18<18:20,  4.32it/s]
2022-03-21 22:35:59,837 - INFO - tqdm - f1: 0.6834, accuracy: 0.8749, batch_loss: 0.3357, loss: 0.2972 ||:  35%|###4      | 2493/7204 [09:28<18:31,  4.24it/s]
2022-03-21 22:36:09,950 - INFO - tqdm - f1: 0.6841, accuracy: 0.8752, batch_loss: 0.1569, loss: 0.2968 ||:  35%|###5      | 2537/7204 [09:38<18:21,  4.24it/s]
2022-03-21 22:36:20,122 - INFO - tqdm - f1: 0.6846, accuracy: 0.8754, batch_loss: 0.1962, loss: 0.2966 ||:  36%|###5      | 2580/7204 [09:49<18:16,  4.22it/s]
2022-03-21 22:36:30,210 - INFO - tqdm - f1: 0.6853, accuracy: 0.8755, batch_loss: 0.2823, loss: 0.2966 ||:  36%|###6      | 2622/7204 [09:59<26:08,  2.92it/s]
2022-03-21 22:36:40,361 - INFO - tqdm - f1: 0.6856, accuracy: 0.8756, batch_loss: 0.1179, loss: 0.2966 ||:  37%|###7      | 2666/7204 [10:09<16:21,  4.62it/s]
2022-03-21 22:36:50,418 - INFO - tqdm - f1: 0.6851, accuracy: 0.8756, batch_loss: 0.4512, loss: 0.2967 ||:  38%|###7      | 2711/7204 [10:19<15:27,  4.85it/s]
2022-03-21 22:37:00,651 - INFO - tqdm - f1: 0.6855, accuracy: 0.8755, batch_loss: 0.2549, loss: 0.2967 ||:  38%|###8      | 2758/7204 [10:29<17:52,  4.14it/s]
2022-03-21 22:37:10,812 - INFO - tqdm - f1: 0.6851, accuracy: 0.8757, batch_loss: 0.1399, loss: 0.2964 ||:  39%|###8      | 2798/7204 [10:39<20:25,  3.60it/s]
2022-03-21 22:37:20,939 - INFO - tqdm - f1: 0.6856, accuracy: 0.8758, batch_loss: 0.4932, loss: 0.2961 ||:  39%|###9      | 2841/7204 [10:49<15:25,  4.71it/s]
2022-03-21 22:37:31,061 - INFO - tqdm - f1: 0.6857, accuracy: 0.8759, batch_loss: 0.0642, loss: 0.2957 ||:  40%|####      | 2884/7204 [11:00<18:41,  3.85it/s]
2022-03-21 22:37:41,169 - INFO - tqdm - f1: 0.6859, accuracy: 0.8758, batch_loss: 0.4716, loss: 0.2956 ||:  41%|####      | 2924/7204 [11:10<16:05,  4.44it/s]
2022-03-21 22:37:51,291 - INFO - tqdm - f1: 0.6867, accuracy: 0.8758, batch_loss: 0.5567, loss: 0.2961 ||:  41%|####1     | 2970/7204 [11:20<14:41,  4.81it/s]
2022-03-21 22:38:01,338 - INFO - tqdm - f1: 0.6863, accuracy: 0.8759, batch_loss: 0.4734, loss: 0.2955 ||:  42%|####1     | 3010/7204 [11:30<19:30,  3.58it/s]
2022-03-21 22:38:11,432 - INFO - tqdm - f1: 0.6862, accuracy: 0.8761, batch_loss: 0.5068, loss: 0.2952 ||:  42%|####2     | 3050/7204 [11:40<15:57,  4.34it/s]
2022-03-21 22:38:21,543 - INFO - tqdm - f1: 0.6868, accuracy: 0.8764, batch_loss: 0.2106, loss: 0.2947 ||:  43%|####2     | 3094/7204 [11:50<14:51,  4.61it/s]
2022-03-21 22:38:31,601 - INFO - tqdm - f1: 0.6868, accuracy: 0.8767, batch_loss: 0.4986, loss: 0.2945 ||:  44%|####3     | 3137/7204 [12:00<14:49,  4.57it/s]
2022-03-21 22:38:41,766 - INFO - tqdm - f1: 0.6864, accuracy: 0.8767, batch_loss: 0.0630, loss: 0.2946 ||:  44%|####4     | 3183/7204 [12:10<17:43,  3.78it/s]
2022-03-21 22:38:51,895 - INFO - tqdm - f1: 0.6869, accuracy: 0.8768, batch_loss: 0.3422, loss: 0.2944 ||:  45%|####4     | 3227/7204 [12:20<14:04,  4.71it/s]
2022-03-21 22:39:01,983 - INFO - tqdm - f1: 0.6859, accuracy: 0.8766, batch_loss: 0.3858, loss: 0.2947 ||:  45%|####5     | 3269/7204 [12:31<16:02,  4.09it/s]
2022-03-21 22:39:12,067 - INFO - tqdm - f1: 0.6860, accuracy: 0.8763, batch_loss: 0.4071, loss: 0.2954 ||:  46%|####6     | 3315/7204 [12:41<11:46,  5.50it/s]
2022-03-21 22:39:22,108 - INFO - tqdm - f1: 0.6871, accuracy: 0.8766, batch_loss: 0.3115, loss: 0.2948 ||:  47%|####6     | 3356/7204 [12:51<20:11,  3.18it/s]
2022-03-21 22:39:32,343 - INFO - tqdm - f1: 0.6872, accuracy: 0.8769, batch_loss: 0.3964, loss: 0.2944 ||:  47%|####7     | 3395/7204 [13:01<17:07,  3.71it/s]
2022-03-21 22:39:42,343 - INFO - tqdm - f1: 0.6879, accuracy: 0.8770, batch_loss: 0.5591, loss: 0.2942 ||:  48%|####7     | 3437/7204 [13:11<11:28,  5.47it/s]
2022-03-21 22:39:52,719 - INFO - tqdm - f1: 0.6883, accuracy: 0.8771, batch_loss: 0.2183, loss: 0.2939 ||:  48%|####8     | 3477/7204 [13:21<22:45,  2.73it/s]
2022-03-21 22:40:02,878 - INFO - tqdm - f1: 0.6884, accuracy: 0.8772, batch_loss: 0.0888, loss: 0.2938 ||:  49%|####8     | 3520/7204 [13:31<16:29,  3.72it/s]
2022-03-21 22:40:13,078 - INFO - tqdm - f1: 0.6885, accuracy: 0.8772, batch_loss: 0.2362, loss: 0.2938 ||:  49%|####9     | 3561/7204 [13:42<12:22,  4.90it/s]
2022-03-21 22:40:23,300 - INFO - tqdm - f1: 0.6890, accuracy: 0.8774, batch_loss: 0.4321, loss: 0.2935 ||:  50%|#####     | 3603/7204 [13:52<17:35,  3.41it/s]
2022-03-21 22:40:33,348 - INFO - tqdm - f1: 0.6887, accuracy: 0.8769, batch_loss: 0.3979, loss: 0.2943 ||:  51%|#####     | 3648/7204 [14:02<14:54,  3.98it/s]
2022-03-21 22:40:43,369 - INFO - tqdm - f1: 0.6887, accuracy: 0.8771, batch_loss: 0.0954, loss: 0.2939 ||:  51%|#####1    | 3687/7204 [14:12<20:21,  2.88it/s]
2022-03-21 22:40:53,688 - INFO - tqdm - f1: 0.6886, accuracy: 0.8771, batch_loss: 0.0334, loss: 0.2939 ||:  52%|#####1    | 3727/7204 [14:22<20:12,  2.87it/s]
2022-03-21 22:41:03,784 - INFO - tqdm - f1: 0.6881, accuracy: 0.8770, batch_loss: 0.3229, loss: 0.2938 ||:  52%|#####2    | 3773/7204 [14:32<11:48,  4.85it/s]
2022-03-21 22:41:13,840 - INFO - tqdm - f1: 0.6887, accuracy: 0.8771, batch_loss: 0.1593, loss: 0.2937 ||:  53%|#####2    | 3818/7204 [14:42<15:06,  3.73it/s]
2022-03-21 22:41:23,896 - INFO - tqdm - f1: 0.6883, accuracy: 0.8773, batch_loss: 0.4713, loss: 0.2934 ||:  54%|#####3    | 3863/7204 [14:52<12:37,  4.41it/s]
2022-03-21 22:41:33,901 - INFO - tqdm - f1: 0.6880, accuracy: 0.8772, batch_loss: 0.3657, loss: 0.2935 ||:  54%|#####4    | 3906/7204 [15:02<12:46,  4.30it/s]
2022-03-21 22:41:44,036 - INFO - tqdm - f1: 0.6878, accuracy: 0.8771, batch_loss: 0.3488, loss: 0.2936 ||:  55%|#####4    | 3950/7204 [15:13<13:06,  4.14it/s]
2022-03-21 22:41:54,228 - INFO - tqdm - f1: 0.6872, accuracy: 0.8771, batch_loss: 0.2893, loss: 0.2935 ||:  55%|#####5    | 3994/7204 [15:23<13:04,  4.09it/s]
2022-03-21 22:42:04,287 - INFO - tqdm - f1: 0.6874, accuracy: 0.8770, batch_loss: 0.0496, loss: 0.2935 ||:  56%|#####6    | 4036/7204 [15:33<15:32,  3.40it/s]
2022-03-21 22:42:14,366 - INFO - tqdm - f1: 0.6874, accuracy: 0.8768, batch_loss: 0.6599, loss: 0.2938 ||:  57%|#####6    | 4079/7204 [15:43<09:45,  5.33it/s]
2022-03-21 22:42:24,563 - INFO - tqdm - f1: 0.6875, accuracy: 0.8770, batch_loss: 0.2982, loss: 0.2934 ||:  57%|#####7    | 4117/7204 [15:53<12:04,  4.26it/s]
2022-03-21 22:42:34,606 - INFO - tqdm - f1: 0.6872, accuracy: 0.8771, batch_loss: 0.2017, loss: 0.2934 ||:  58%|#####7    | 4158/7204 [16:03<12:44,  3.98it/s]
2022-03-21 22:42:44,810 - INFO - tqdm - f1: 0.6870, accuracy: 0.8769, batch_loss: 0.2772, loss: 0.2937 ||:  58%|#####8    | 4205/7204 [16:13<10:29,  4.76it/s]
2022-03-21 22:42:54,981 - INFO - tqdm - f1: 0.6871, accuracy: 0.8769, batch_loss: 0.4907, loss: 0.2935 ||:  59%|#####8    | 4250/7204 [16:24<09:20,  5.27it/s]
2022-03-21 22:43:05,034 - INFO - tqdm - f1: 0.6868, accuracy: 0.8770, batch_loss: 0.3701, loss: 0.2934 ||:  60%|#####9    | 4292/7204 [16:34<10:14,  4.74it/s]
2022-03-21 22:43:15,237 - INFO - tqdm - f1: 0.6863, accuracy: 0.8767, batch_loss: 0.1656, loss: 0.2938 ||:  60%|######    | 4337/7204 [16:44<09:11,  5.20it/s]
2022-03-21 22:43:25,260 - INFO - tqdm - f1: 0.6861, accuracy: 0.8767, batch_loss: 0.3156, loss: 0.2936 ||:  61%|######    | 4375/7204 [16:54<11:01,  4.28it/s]
2022-03-21 22:43:35,690 - INFO - tqdm - f1: 0.6865, accuracy: 0.8766, batch_loss: 0.0248, loss: 0.2941 ||:  61%|######1   | 4423/7204 [17:04<11:49,  3.92it/s]
2022-03-21 22:43:45,845 - INFO - tqdm - f1: 0.6866, accuracy: 0.8767, batch_loss: 0.0358, loss: 0.2941 ||:  62%|######1   | 4465/7204 [17:14<14:09,  3.23it/s]
2022-03-21 22:43:56,047 - INFO - tqdm - f1: 0.6868, accuracy: 0.8768, batch_loss: 0.3762, loss: 0.2937 ||:  63%|######2   | 4508/7204 [17:25<11:38,  3.86it/s]
2022-03-21 22:44:06,188 - INFO - tqdm - f1: 0.6873, accuracy: 0.8769, batch_loss: 0.7345, loss: 0.2938 ||:  63%|######3   | 4554/7204 [17:35<08:53,  4.97it/s]
2022-03-21 22:44:16,265 - INFO - tqdm - f1: 0.6867, accuracy: 0.8767, batch_loss: 0.3201, loss: 0.2940 ||:  64%|######3   | 4597/7204 [17:45<11:03,  3.93it/s]
2022-03-21 22:44:26,360 - INFO - tqdm - f1: 0.6866, accuracy: 0.8767, batch_loss: 0.3487, loss: 0.2940 ||:  64%|######4   | 4634/7204 [17:55<12:48,  3.35it/s]
2022-03-21 22:44:36,577 - INFO - tqdm - f1: 0.6864, accuracy: 0.8767, batch_loss: 0.2370, loss: 0.2939 ||:  65%|######4   | 4675/7204 [18:05<11:25,  3.69it/s]
2022-03-21 22:44:46,605 - INFO - tqdm - f1: 0.6863, accuracy: 0.8766, batch_loss: 0.0771, loss: 0.2939 ||:  66%|######6   | 4763/7204 [18:15<07:32,  5.39it/s]
2022-03-21 22:44:56,671 - INFO - tqdm - f1: 0.6865, accuracy: 0.8767, batch_loss: 0.2070, loss: 0.2938 ||:  67%|######6   | 4820/7204 [18:25<06:36,  6.02it/s]
2022-03-21 22:45:06,852 - INFO - tqdm - f1: 0.6863, accuracy: 0.8765, batch_loss: 0.0496, loss: 0.2941 ||:  68%|######7   | 4879/7204 [18:35<07:45,  5.00it/s]
2022-03-21 22:45:16,910 - INFO - tqdm - f1: 0.6863, accuracy: 0.8766, batch_loss: 0.1176, loss: 0.2940 ||:  68%|######8   | 4933/7204 [18:45<09:56,  3.81it/s]
2022-03-21 22:45:27,162 - INFO - tqdm - f1: 0.6868, accuracy: 0.8766, batch_loss: 0.2585, loss: 0.2939 ||:  69%|######9   | 4975/7204 [18:56<09:47,  3.79it/s]
2022-03-21 22:45:37,239 - INFO - tqdm - f1: 0.6866, accuracy: 0.8765, batch_loss: 0.3683, loss: 0.2940 ||:  70%|######9   | 5019/7204 [19:06<06:32,  5.57it/s]
2022-03-21 22:45:47,297 - INFO - tqdm - f1: 0.6860, accuracy: 0.8762, batch_loss: 0.1762, loss: 0.2943 ||:  70%|#######   | 5063/7204 [19:16<08:25,  4.24it/s]
2022-03-21 22:45:57,412 - INFO - tqdm - f1: 0.6862, accuracy: 0.8762, batch_loss: 0.3735, loss: 0.2943 ||:  71%|#######   | 5107/7204 [19:26<07:26,  4.69it/s]
2022-03-21 22:46:07,525 - INFO - tqdm - f1: 0.6867, accuracy: 0.8762, batch_loss: 0.3992, loss: 0.2942 ||:  71%|#######1  | 5150/7204 [19:36<07:17,  4.70it/s]
2022-03-21 22:46:17,703 - INFO - tqdm - f1: 0.6868, accuracy: 0.8763, batch_loss: 0.2144, loss: 0.2943 ||:  72%|#######2  | 5196/7204 [19:46<09:08,  3.66it/s]
2022-03-21 22:46:27,767 - INFO - tqdm - f1: 0.6868, accuracy: 0.8762, batch_loss: 0.2375, loss: 0.2943 ||:  73%|#######2  | 5237/7204 [19:56<07:23,  4.43it/s]
2022-03-21 22:46:37,800 - INFO - tqdm - f1: 0.6865, accuracy: 0.8761, batch_loss: 0.3010, loss: 0.2943 ||:  73%|#######3  | 5279/7204 [20:06<08:24,  3.82it/s]
2022-03-21 22:46:47,968 - INFO - tqdm - f1: 0.6861, accuracy: 0.8762, batch_loss: 0.1210, loss: 0.2941 ||:  74%|#######3  | 5317/7204 [20:17<07:33,  4.16it/s]
2022-03-21 22:46:57,978 - INFO - tqdm - f1: 0.6864, accuracy: 0.8762, batch_loss: 0.1390, loss: 0.2943 ||:  74%|#######4  | 5358/7204 [20:27<08:07,  3.79it/s]
2022-03-21 22:47:08,120 - INFO - tqdm - f1: 0.6863, accuracy: 0.8761, batch_loss: 0.3158, loss: 0.2944 ||:  75%|#######5  | 5405/7204 [20:37<07:08,  4.20it/s]
2022-03-21 22:47:18,310 - INFO - tqdm - f1: 0.6863, accuracy: 0.8762, batch_loss: 0.1985, loss: 0.2943 ||:  76%|#######5  | 5447/7204 [20:47<06:42,  4.37it/s]
2022-03-21 22:47:28,338 - INFO - tqdm - f1: 0.6864, accuracy: 0.8763, batch_loss: 0.1653, loss: 0.2943 ||:  76%|#######6  | 5491/7204 [20:57<07:47,  3.66it/s]
2022-03-21 22:47:38,718 - INFO - tqdm - f1: 0.6865, accuracy: 0.8764, batch_loss: 0.0532, loss: 0.2941 ||:  77%|#######6  | 5537/7204 [21:07<06:49,  4.07it/s]
2022-03-21 22:47:48,951 - INFO - tqdm - f1: 0.6866, accuracy: 0.8764, batch_loss: 0.0144, loss: 0.2942 ||:  77%|#######7  | 5580/7204 [21:17<08:57,  3.02it/s]
2022-03-21 22:47:58,978 - INFO - tqdm - f1: 0.6863, accuracy: 0.8765, batch_loss: 0.0493, loss: 0.2940 ||:  78%|#######8  | 5620/7204 [21:28<05:46,  4.57it/s]
2022-03-21 22:48:09,225 - INFO - tqdm - f1: 0.6864, accuracy: 0.8765, batch_loss: 0.1302, loss: 0.2939 ||:  79%|#######8  | 5659/7204 [21:38<07:34,  3.40it/s]
2022-03-21 22:48:19,340 - INFO - tqdm - f1: 0.6867, accuracy: 0.8765, batch_loss: 0.2576, loss: 0.2941 ||:  79%|#######9  | 5704/7204 [21:48<07:01,  3.56it/s]
2022-03-21 22:48:29,745 - INFO - tqdm - f1: 0.6865, accuracy: 0.8767, batch_loss: 0.0659, loss: 0.2937 ||:  80%|#######9  | 5748/7204 [21:58<06:31,  3.72it/s]
2022-03-21 22:48:39,947 - INFO - tqdm - f1: 0.6864, accuracy: 0.8768, batch_loss: 0.1860, loss: 0.2936 ||:  80%|########  | 5791/7204 [22:08<06:18,  3.73it/s]
2022-03-21 22:48:50,071 - INFO - tqdm - f1: 0.6866, accuracy: 0.8767, batch_loss: 0.5009, loss: 0.2937 ||:  81%|########1 | 5839/7204 [22:19<03:40,  6.20it/s]
2022-03-21 22:49:00,470 - INFO - tqdm - f1: 0.6865, accuracy: 0.8767, batch_loss: 0.0093, loss: 0.2938 ||:  82%|########1 | 5883/7204 [22:29<06:12,  3.55it/s]
2022-03-21 22:49:10,513 - INFO - tqdm - f1: 0.6862, accuracy: 0.8768, batch_loss: 0.7950, loss: 0.2938 ||:  82%|########2 | 5925/7204 [22:39<04:12,  5.06it/s]
2022-03-21 22:49:20,520 - INFO - tqdm - f1: 0.6865, accuracy: 0.8768, batch_loss: 0.3118, loss: 0.2939 ||:  83%|########2 | 5970/7204 [22:49<04:15,  4.83it/s]
2022-03-21 22:49:30,637 - INFO - tqdm - f1: 0.6867, accuracy: 0.8769, batch_loss: 0.2146, loss: 0.2936 ||:  83%|########3 | 6011/7204 [22:59<04:31,  4.39it/s]
2022-03-21 22:49:40,643 - INFO - tqdm - f1: 0.6862, accuracy: 0.8768, batch_loss: 0.6739, loss: 0.2940 ||:  84%|########4 | 6054/7204 [23:09<04:51,  3.94it/s]
2022-03-21 22:49:50,687 - INFO - tqdm - f1: 0.6861, accuracy: 0.8768, batch_loss: 0.5491, loss: 0.2938 ||:  85%|########4 | 6096/7204 [23:19<04:34,  4.04it/s]
2022-03-21 22:50:00,825 - INFO - tqdm - f1: 0.6863, accuracy: 0.8768, batch_loss: 0.6060, loss: 0.2938 ||:  85%|########5 | 6142/7204 [23:29<03:36,  4.91it/s]
2022-03-21 22:50:11,012 - INFO - tqdm - f1: 0.6868, accuracy: 0.8769, batch_loss: 0.0496, loss: 0.2938 ||:  86%|########5 | 6183/7204 [23:40<03:46,  4.52it/s]
2022-03-21 22:50:21,092 - INFO - tqdm - f1: 0.6870, accuracy: 0.8770, batch_loss: 0.4098, loss: 0.2936 ||:  86%|########6 | 6226/7204 [23:50<03:24,  4.77it/s]
2022-03-21 22:50:31,187 - INFO - tqdm - f1: 0.6868, accuracy: 0.8768, batch_loss: 0.2778, loss: 0.2936 ||:  87%|########7 | 6269/7204 [24:00<03:04,  5.08it/s]
2022-03-21 22:50:41,192 - INFO - tqdm - f1: 0.6863, accuracy: 0.8767, batch_loss: 0.3526, loss: 0.2937 ||:  88%|########7 | 6311/7204 [24:10<03:15,  4.56it/s]
2022-03-21 22:50:51,383 - INFO - tqdm - f1: 0.6861, accuracy: 0.8767, batch_loss: 0.2469, loss: 0.2936 ||:  88%|########8 | 6353/7204 [24:20<04:00,  3.54it/s]
2022-03-21 22:51:01,547 - INFO - tqdm - f1: 0.6862, accuracy: 0.8768, batch_loss: 0.4581, loss: 0.2935 ||:  89%|########8 | 6396/7204 [24:30<02:49,  4.76it/s]
2022-03-21 22:51:11,699 - INFO - tqdm - f1: 0.6860, accuracy: 0.8767, batch_loss: 0.4572, loss: 0.2936 ||:  89%|########9 | 6439/7204 [24:40<02:53,  4.42it/s]
2022-03-21 22:51:21,790 - INFO - tqdm - f1: 0.6859, accuracy: 0.8768, batch_loss: 0.2263, loss: 0.2934 ||:  90%|########9 | 6482/7204 [24:50<02:37,  4.59it/s]
2022-03-21 22:51:31,954 - INFO - tqdm - f1: 0.6860, accuracy: 0.8769, batch_loss: 0.3351, loss: 0.2933 ||:  91%|######### | 6523/7204 [25:00<02:58,  3.81it/s]
2022-03-21 22:51:42,112 - INFO - tqdm - f1: 0.6859, accuracy: 0.8768, batch_loss: 0.1469, loss: 0.2935 ||:  91%|#########1| 6568/7204 [25:11<02:50,  3.74it/s]
2022-03-21 22:51:52,131 - INFO - tqdm - f1: 0.6857, accuracy: 0.8768, batch_loss: 0.3685, loss: 0.2935 ||:  92%|#########1| 6610/7204 [25:21<02:30,  3.96it/s]
2022-03-21 22:52:02,181 - INFO - tqdm - f1: 0.6861, accuracy: 0.8768, batch_loss: 0.2551, loss: 0.2937 ||:  92%|#########2| 6656/7204 [25:31<01:55,  4.74it/s]
2022-03-21 22:52:12,199 - INFO - tqdm - f1: 0.6864, accuracy: 0.8768, batch_loss: 0.3771, loss: 0.2936 ||:  93%|#########3| 6701/7204 [25:41<01:55,  4.35it/s]
2022-03-21 22:52:22,216 - INFO - tqdm - f1: 0.6864, accuracy: 0.8767, batch_loss: 0.1790, loss: 0.2938 ||:  94%|#########3| 6747/7204 [25:51<01:41,  4.51it/s]
2022-03-21 22:52:32,282 - INFO - tqdm - f1: 0.6866, accuracy: 0.8769, batch_loss: 0.1867, loss: 0.2935 ||:  94%|#########4| 6790/7204 [26:01<01:35,  4.35it/s]
2022-03-21 22:52:42,617 - INFO - tqdm - f1: 0.6865, accuracy: 0.8769, batch_loss: 0.0461, loss: 0.2936 ||:  95%|#########4| 6837/7204 [26:11<01:44,  3.53it/s]
2022-03-21 22:52:52,654 - INFO - tqdm - f1: 0.6863, accuracy: 0.8771, batch_loss: 0.3846, loss: 0.2933 ||:  95%|#########5| 6877/7204 [26:21<01:28,  3.68it/s]
2022-03-21 22:53:02,937 - INFO - tqdm - f1: 0.6863, accuracy: 0.8770, batch_loss: 0.0184, loss: 0.2935 ||:  96%|#########6| 6921/7204 [26:31<01:19,  3.58it/s]
2022-03-21 22:53:13,136 - INFO - tqdm - f1: 0.6865, accuracy: 0.8772, batch_loss: 0.4837, loss: 0.2932 ||:  97%|#########6| 6959/7204 [26:42<01:12,  3.39it/s]
2022-03-21 22:53:23,263 - INFO - tqdm - f1: 0.6865, accuracy: 0.8772, batch_loss: 0.2027, loss: 0.2931 ||:  97%|#########7| 7003/7204 [26:52<00:55,  3.62it/s]
2022-03-21 22:53:33,443 - INFO - tqdm - f1: 0.6864, accuracy: 0.8771, batch_loss: 0.1065, loss: 0.2932 ||:  98%|#########7| 7044/7204 [27:02<00:45,  3.48it/s]
2022-03-21 22:53:43,483 - INFO - tqdm - f1: 0.6870, accuracy: 0.8773, batch_loss: 0.2843, loss: 0.2929 ||:  98%|#########8| 7089/7204 [27:12<00:24,  4.61it/s]
2022-03-21 22:53:53,541 - INFO - tqdm - f1: 0.6868, accuracy: 0.8775, batch_loss: 0.7519, loss: 0.2928 ||:  99%|#########8| 7129/7204 [27:22<00:16,  4.54it/s]
2022-03-21 22:54:02,653 - INFO - tqdm - f1: 0.6869, accuracy: 0.8775, batch_loss: 0.1757, loss: 0.2927 ||: 100%|#########9| 7168/7204 [27:31<00:09,  3.74it/s]
2022-03-21 22:54:02,784 - INFO - tqdm - f1: 0.6869, accuracy: 0.8775, batch_loss: 0.3067, loss: 0.2927 ||: 100%|#########9| 7169/7204 [27:31<00:07,  4.42it/s]
2022-03-21 22:54:02,962 - INFO - tqdm - f1: 0.6870, accuracy: 0.8775, batch_loss: 0.5927, loss: 0.2927 ||: 100%|#########9| 7170/7204 [27:32<00:07,  4.72it/s]
2022-03-21 22:54:03,394 - INFO - tqdm - f1: 0.6870, accuracy: 0.8775, batch_loss: 0.1168, loss: 0.2927 ||: 100%|#########9| 7171/7204 [27:32<00:09,  3.60it/s]
2022-03-21 22:54:03,687 - INFO - tqdm - f1: 0.6870, accuracy: 0.8775, batch_loss: 0.2268, loss: 0.2927 ||: 100%|#########9| 7172/7204 [27:32<00:09,  3.54it/s]
2022-03-21 22:54:04,009 - INFO - tqdm - f1: 0.6870, accuracy: 0.8775, batch_loss: 0.2276, loss: 0.2927 ||: 100%|#########9| 7173/7204 [27:33<00:09,  3.40it/s]
2022-03-21 22:54:04,293 - INFO - tqdm - f1: 0.6870, accuracy: 0.8775, batch_loss: 0.0486, loss: 0.2926 ||: 100%|#########9| 7174/7204 [27:33<00:08,  3.43it/s]
2022-03-21 22:54:04,725 - INFO - tqdm - f1: 0.6870, accuracy: 0.8775, batch_loss: 0.2863, loss: 0.2926 ||: 100%|#########9| 7175/7204 [27:33<00:09,  3.00it/s]
2022-03-21 22:54:04,911 - INFO - tqdm - f1: 0.6870, accuracy: 0.8775, batch_loss: 0.1665, loss: 0.2926 ||: 100%|#########9| 7176/7204 [27:33<00:08,  3.46it/s]
2022-03-21 22:54:05,080 - INFO - tqdm - f1: 0.6870, accuracy: 0.8775, batch_loss: 0.7595, loss: 0.2927 ||: 100%|#########9| 7177/7204 [27:34<00:06,  3.95it/s]
2022-03-21 22:54:05,351 - INFO - tqdm - f1: 0.6870, accuracy: 0.8775, batch_loss: 0.1710, loss: 0.2927 ||: 100%|#########9| 7178/7204 [27:34<00:06,  3.87it/s]
2022-03-21 22:54:05,512 - INFO - tqdm - f1: 0.6870, accuracy: 0.8775, batch_loss: 0.0856, loss: 0.2926 ||: 100%|#########9| 7179/7204 [27:34<00:05,  4.36it/s]
2022-03-21 22:54:05,724 - INFO - tqdm - f1: 0.6869, accuracy: 0.8775, batch_loss: 0.3891, loss: 0.2927 ||: 100%|#########9| 7180/7204 [27:34<00:05,  4.46it/s]
2022-03-21 22:54:05,952 - INFO - tqdm - f1: 0.6869, accuracy: 0.8775, batch_loss: 0.3252, loss: 0.2927 ||: 100%|#########9| 7181/7204 [27:34<00:05,  4.44it/s]
2022-03-21 22:54:06,121 - INFO - tqdm - f1: 0.6869, accuracy: 0.8775, batch_loss: 0.1463, loss: 0.2926 ||: 100%|#########9| 7182/7204 [27:35<00:04,  4.80it/s]
2022-03-21 22:54:06,283 - INFO - tqdm - f1: 0.6869, accuracy: 0.8775, batch_loss: 0.4980, loss: 0.2927 ||: 100%|#########9| 7183/7204 [27:35<00:04,  5.14it/s]
2022-03-21 22:54:06,721 - INFO - tqdm - f1: 0.6869, accuracy: 0.8775, batch_loss: 0.3690, loss: 0.2927 ||: 100%|#########9| 7184/7204 [27:35<00:05,  3.74it/s]
2022-03-21 22:54:07,080 - INFO - tqdm - f1: 0.6869, accuracy: 0.8775, batch_loss: 0.2141, loss: 0.2927 ||: 100%|#########9| 7185/7204 [27:36<00:05,  3.39it/s]
2022-03-21 22:54:07,327 - INFO - tqdm - f1: 0.6868, accuracy: 0.8775, batch_loss: 0.6247, loss: 0.2927 ||: 100%|#########9| 7186/7204 [27:36<00:05,  3.56it/s]
2022-03-21 22:54:07,724 - INFO - tqdm - f1: 0.6868, accuracy: 0.8775, batch_loss: 0.2960, loss: 0.2927 ||: 100%|#########9| 7187/7204 [27:36<00:05,  3.17it/s]
2022-03-21 22:54:07,896 - INFO - tqdm - f1: 0.6868, accuracy: 0.8775, batch_loss: 0.2297, loss: 0.2927 ||: 100%|#########9| 7188/7204 [27:36<00:04,  3.67it/s]
2022-03-21 22:54:08,160 - INFO - tqdm - f1: 0.6868, accuracy: 0.8775, batch_loss: 0.2539, loss: 0.2927 ||: 100%|#########9| 7189/7204 [27:37<00:04,  3.70it/s]
2022-03-21 22:54:08,302 - INFO - tqdm - f1: 0.6867, accuracy: 0.8775, batch_loss: 0.3418, loss: 0.2927 ||: 100%|#########9| 7190/7204 [27:37<00:03,  4.32it/s]
2022-03-21 22:54:08,642 - INFO - tqdm - f1: 0.6867, accuracy: 0.8775, batch_loss: 0.3155, loss: 0.2927 ||: 100%|#########9| 7191/7204 [27:37<00:03,  3.79it/s]
2022-03-21 22:54:08,867 - INFO - tqdm - f1: 0.6867, accuracy: 0.8775, batch_loss: 0.3748, loss: 0.2927 ||: 100%|#########9| 7192/7204 [27:37<00:03,  3.96it/s]
2022-03-21 22:54:09,254 - INFO - tqdm - f1: 0.6867, accuracy: 0.8775, batch_loss: 0.1412, loss: 0.2927 ||: 100%|#########9| 7193/7204 [27:38<00:03,  3.42it/s]
2022-03-21 22:54:09,507 - INFO - tqdm - f1: 0.6867, accuracy: 0.8775, batch_loss: 0.2685, loss: 0.2927 ||: 100%|#########9| 7194/7204 [27:38<00:02,  3.56it/s]
2022-03-21 22:54:09,692 - INFO - tqdm - f1: 0.6867, accuracy: 0.8775, batch_loss: 0.3375, loss: 0.2927 ||: 100%|#########9| 7195/7204 [27:38<00:02,  3.96it/s]
2022-03-21 22:54:09,932 - INFO - tqdm - f1: 0.6866, accuracy: 0.8775, batch_loss: 0.1518, loss: 0.2927 ||: 100%|#########9| 7196/7204 [27:38<00:01,  4.02it/s]
2022-03-21 22:54:10,198 - INFO - tqdm - f1: 0.6866, accuracy: 0.8775, batch_loss: 0.2276, loss: 0.2927 ||: 100%|#########9| 7197/7204 [27:39<00:01,  3.94it/s]
2022-03-21 22:54:10,348 - INFO - tqdm - f1: 0.6866, accuracy: 0.8775, batch_loss: 0.3480, loss: 0.2927 ||: 100%|#########9| 7198/7204 [27:39<00:01,  4.49it/s]
2022-03-21 22:54:10,607 - INFO - tqdm - f1: 0.6866, accuracy: 0.8775, batch_loss: 0.1359, loss: 0.2927 ||: 100%|#########9| 7199/7204 [27:39<00:01,  4.28it/s]
2022-03-21 22:54:10,926 - INFO - tqdm - f1: 0.6866, accuracy: 0.8775, batch_loss: 0.5444, loss: 0.2927 ||: 100%|#########9| 7200/7204 [27:39<00:01,  3.86it/s]
2022-03-21 22:54:11,141 - INFO - tqdm - f1: 0.6866, accuracy: 0.8775, batch_loss: 0.2286, loss: 0.2927 ||: 100%|#########9| 7201/7204 [27:40<00:00,  4.07it/s]
2022-03-21 22:54:11,304 - INFO - tqdm - f1: 0.6865, accuracy: 0.8775, batch_loss: 0.7718, loss: 0.2928 ||: 100%|#########9| 7202/7204 [27:40<00:00,  4.53it/s]
2022-03-21 22:54:11,515 - INFO - tqdm - f1: 0.6865, accuracy: 0.8775, batch_loss: 0.3432, loss: 0.2928 ||: 100%|#########9| 7203/7204 [27:40<00:00,  4.58it/s]
2022-03-21 22:54:11,629 - INFO - tqdm - f1: 0.6865, accuracy: 0.8774, batch_loss: 0.4665, loss: 0.2928 ||: 100%|##########| 7204/7204 [27:40<00:00,  5.35it/s]
2022-03-21 22:54:11,681 - INFO - tqdm - f1: 0.6865, accuracy: 0.8774, batch_loss: 0.4665, loss: 0.2928 ||: 100%|##########| 7204/7204 [27:40<00:00,  4.34it/s]
2022-03-21 22:54:11,718 - INFO - allennlp.training.trainer - Validating
2022-03-21 22:54:11,721 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 22:54:21,736 - INFO - tqdm - f1: 0.5920, accuracy: 0.8622, batch_loss: 0.0475, loss: 0.3348 ||:  30%|##9       | 93/313 [00:10<00:21, 10.40it/s]
2022-03-21 22:54:31,799 - INFO - tqdm - f1: 0.5867, accuracy: 0.8665, batch_loss: 0.4958, loss: 0.3227 ||:  58%|#####8    | 183/313 [00:20<00:15,  8.46it/s]
2022-03-21 22:54:41,850 - INFO - tqdm - f1: 0.5839, accuracy: 0.8659, batch_loss: 0.3826, loss: 0.3205 ||:  88%|########8 | 276/313 [00:30<00:04,  8.47it/s]
2022-03-21 22:54:46,078 - INFO - tqdm - f1: 0.5782, accuracy: 0.8666, batch_loss: 0.3135, loss: 0.3175 ||: 100%|#########9| 312/313 [00:34<00:00,  8.80it/s]
2022-03-21 22:54:46,141 - INFO - tqdm - f1: 0.5793, accuracy: 0.8662, batch_loss: 0.5368, loss: 0.3182 ||: 100%|##########| 313/313 [00:34<00:00,  9.09it/s]
2022-03-21 22:54:46,155 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 22:54:46,158 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.877  |     0.866
2022-03-21 22:54:46,159 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.687  |     0.579
2022-03-21 22:54:46,161 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 22:54:46,163 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.293  |     0.318
2022-03-21 22:54:46,164 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13602.809  |       N/A
2022-03-21 22:54:46,166 - INFO - allennlp.training.trainer - Epoch duration: 0:28:15.213296
2022-03-21 22:54:46,167 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:47:03
2022-03-21 22:54:46,169 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-21 22:54:46,171 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-21 22:54:46,174 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 22:54:46,178 - INFO - allennlp.training.trainer - Training
2022-03-21 22:54:46,180 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-21 22:54:56,283 - INFO - tqdm - f1: 0.7123, accuracy: 0.8734, batch_loss: 0.1260, loss: 0.3004 ||:   1%|          | 40/7204 [00:10<24:39,  4.84it/s]
2022-03-21 22:55:06,423 - INFO - tqdm - f1: 0.6922, accuracy: 0.8765, batch_loss: 0.3260, loss: 0.2913 ||:   1%|1         | 84/7204 [00:20<31:20,  3.79it/s]
2022-03-21 22:55:16,432 - INFO - tqdm - f1: 0.7324, accuracy: 0.8804, batch_loss: 0.3109, loss: 0.2824 ||:   2%|1         | 128/7204 [00:30<22:08,  5.33it/s]
2022-03-21 22:55:26,508 - INFO - tqdm - f1: 0.7331, accuracy: 0.8764, batch_loss: 0.2345, loss: 0.2895 ||:   2%|2         | 175/7204 [00:40<29:52,  3.92it/s]
2022-03-21 22:55:36,637 - INFO - tqdm - f1: 0.7368, accuracy: 0.8750, batch_loss: 0.4037, loss: 0.2935 ||:   3%|3         | 222/7204 [00:50<26:17,  4.43it/s]
2022-03-21 22:55:46,664 - INFO - tqdm - f1: 0.7374, accuracy: 0.8783, batch_loss: 0.2324, loss: 0.2861 ||:   4%|3         | 265/7204 [01:00<23:08,  5.00it/s]
2022-03-21 22:55:56,873 - INFO - tqdm - f1: 0.7413, accuracy: 0.8799, batch_loss: 0.3576, loss: 0.2843 ||:   4%|4         | 309/7204 [01:10<25:26,  4.52it/s]
2022-03-21 22:56:07,204 - INFO - tqdm - f1: 0.7448, accuracy: 0.8821, batch_loss: 0.5367, loss: 0.2809 ||:   5%|4         | 350/7204 [01:21<31:10,  3.66it/s]
2022-03-21 22:56:17,343 - INFO - tqdm - f1: 0.7432, accuracy: 0.8812, batch_loss: 0.1727, loss: 0.2793 ||:   5%|5         | 394/7204 [01:31<30:40,  3.70it/s]
2022-03-21 22:56:27,473 - INFO - tqdm - f1: 0.7451, accuracy: 0.8835, batch_loss: 0.2782, loss: 0.2755 ||:   6%|6         | 434/7204 [01:41<25:10,  4.48it/s]
2022-03-21 22:56:37,585 - INFO - tqdm - f1: 0.7396, accuracy: 0.8835, batch_loss: 0.4824, loss: 0.2748 ||:   7%|6         | 479/7204 [01:51<22:37,  4.95it/s]
2022-03-21 22:56:47,764 - INFO - tqdm - f1: 0.7435, accuracy: 0.8846, batch_loss: 0.1884, loss: 0.2752 ||:   7%|7         | 526/7204 [02:01<26:55,  4.13it/s]
2022-03-21 22:56:57,871 - INFO - tqdm - f1: 0.7434, accuracy: 0.8850, batch_loss: 0.4947, loss: 0.2728 ||:   8%|7         | 565/7204 [02:11<24:16,  4.56it/s]
2022-03-21 22:57:07,872 - INFO - tqdm - f1: 0.7412, accuracy: 0.8859, batch_loss: 0.1766, loss: 0.2724 ||:   8%|8         | 608/7204 [02:21<28:07,  3.91it/s]
2022-03-21 22:57:17,947 - INFO - tqdm - f1: 0.7381, accuracy: 0.8853, batch_loss: 0.3141, loss: 0.2725 ||:   9%|9         | 650/7204 [02:31<27:44,  3.94it/s]
2022-03-21 22:57:27,971 - INFO - tqdm - f1: 0.7379, accuracy: 0.8861, batch_loss: 0.2614, loss: 0.2715 ||:  10%|9         | 690/7204 [02:41<28:21,  3.83it/s]
2022-03-21 22:57:38,003 - INFO - tqdm - f1: 0.7379, accuracy: 0.8862, batch_loss: 0.5197, loss: 0.2711 ||:  10%|#         | 732/7204 [02:51<21:19,  5.06it/s]
2022-03-21 22:57:48,145 - INFO - tqdm - f1: 0.7370, accuracy: 0.8869, batch_loss: 0.3613, loss: 0.2691 ||:  11%|#         | 775/7204 [03:01<21:26,  5.00it/s]
2022-03-21 22:57:58,519 - INFO - tqdm - f1: 0.7364, accuracy: 0.8864, batch_loss: 0.1729, loss: 0.2692 ||:  11%|#1        | 817/7204 [03:12<29:17,  3.63it/s]
2022-03-21 22:58:08,651 - INFO - tqdm - f1: 0.7384, accuracy: 0.8872, batch_loss: 0.5629, loss: 0.2679 ||:  12%|#1        | 861/7204 [03:22<22:54,  4.62it/s]
2022-03-21 22:58:18,827 - INFO - tqdm - f1: 0.7391, accuracy: 0.8877, batch_loss: 0.3081, loss: 0.2673 ||:  13%|#2        | 906/7204 [03:32<20:30,  5.12it/s]
2022-03-21 22:58:28,878 - INFO - tqdm - f1: 0.7400, accuracy: 0.8876, batch_loss: 0.2199, loss: 0.2676 ||:  13%|#3        | 951/7204 [03:42<22:48,  4.57it/s]
2022-03-21 22:58:39,067 - INFO - tqdm - f1: 0.7416, accuracy: 0.8883, batch_loss: 0.0331, loss: 0.2662 ||:  14%|#3        | 994/7204 [03:52<30:07,  3.44it/s]
2022-03-21 22:58:49,071 - INFO - tqdm - f1: 0.7431, accuracy: 0.8891, batch_loss: 0.4532, loss: 0.2652 ||:  14%|#4        | 1035/7204 [04:02<27:24,  3.75it/s]
2022-03-21 22:58:59,212 - INFO - tqdm - f1: 0.7439, accuracy: 0.8901, batch_loss: 0.1242, loss: 0.2622 ||:  15%|#4        | 1078/7204 [04:13<22:27,  4.55it/s]
2022-03-21 22:59:09,257 - INFO - tqdm - f1: 0.7434, accuracy: 0.8906, batch_loss: 0.0609, loss: 0.2613 ||:  16%|#5        | 1124/7204 [04:23<18:52,  5.37it/s]
2022-03-21 22:59:19,586 - INFO - tqdm - f1: 0.7431, accuracy: 0.8905, batch_loss: 0.2029, loss: 0.2617 ||:  16%|#6        | 1165/7204 [04:33<27:47,  3.62it/s]
2022-03-21 22:59:29,737 - INFO - tqdm - f1: 0.7439, accuracy: 0.8906, batch_loss: 0.0169, loss: 0.2611 ||:  17%|#6        | 1208/7204 [04:43<30:20,  3.29it/s]
2022-03-21 22:59:39,782 - INFO - tqdm - f1: 0.7441, accuracy: 0.8909, batch_loss: 0.1104, loss: 0.2607 ||:  17%|#7        | 1250/7204 [04:53<25:26,  3.90it/s]
2022-03-21 22:59:49,846 - INFO - tqdm - f1: 0.7436, accuracy: 0.8913, batch_loss: 0.4484, loss: 0.2605 ||:  18%|#7        | 1291/7204 [05:03<20:01,  4.92it/s]
2022-03-21 23:00:00,008 - INFO - tqdm - f1: 0.7432, accuracy: 0.8916, batch_loss: 0.1304, loss: 0.2600 ||:  19%|#8        | 1334/7204 [05:13<18:54,  5.17it/s]
2022-03-21 23:00:10,169 - INFO - tqdm - f1: 0.7420, accuracy: 0.8918, batch_loss: 0.2758, loss: 0.2590 ||:  19%|#9        | 1371/7204 [05:23<29:32,  3.29it/s]
2022-03-21 23:00:20,311 - INFO - tqdm - f1: 0.7409, accuracy: 0.8918, batch_loss: 0.4537, loss: 0.2592 ||:  20%|#9        | 1416/7204 [05:34<24:16,  3.97it/s]
2022-03-21 23:00:30,475 - INFO - tqdm - f1: 0.7422, accuracy: 0.8916, batch_loss: 0.3085, loss: 0.2606 ||:  20%|##        | 1461/7204 [05:44<25:12,  3.80it/s]
2022-03-21 23:00:40,605 - INFO - tqdm - f1: 0.7400, accuracy: 0.8911, batch_loss: 0.0478, loss: 0.2616 ||:  21%|##        | 1507/7204 [05:54<30:34,  3.11it/s]
2022-03-21 23:00:50,797 - INFO - tqdm - f1: 0.7395, accuracy: 0.8909, batch_loss: 0.0718, loss: 0.2614 ||:  22%|##1       | 1549/7204 [06:04<22:15,  4.23it/s]
2022-03-21 23:01:00,923 - INFO - tqdm - f1: 0.7407, accuracy: 0.8911, batch_loss: 0.3354, loss: 0.2611 ||:  22%|##2       | 1592/7204 [06:14<22:52,  4.09it/s]
2022-03-21 23:01:11,040 - INFO - tqdm - f1: 0.7410, accuracy: 0.8912, batch_loss: 0.2502, loss: 0.2605 ||:  23%|##2       | 1634/7204 [06:24<22:06,  4.20it/s]
2022-03-21 23:01:21,141 - INFO - tqdm - f1: 0.7394, accuracy: 0.8909, batch_loss: 0.1654, loss: 0.2611 ||:  23%|##3       | 1675/7204 [06:34<19:29,  4.73it/s]
2022-03-21 23:01:31,149 - INFO - tqdm - f1: 0.7405, accuracy: 0.8912, batch_loss: 0.5489, loss: 0.2605 ||:  24%|##3       | 1719/7204 [06:44<17:52,  5.11it/s]
2022-03-21 23:01:41,271 - INFO - tqdm - f1: 0.7405, accuracy: 0.8911, batch_loss: 0.3241, loss: 0.2605 ||:  25%|##4       | 1765/7204 [06:55<18:34,  4.88it/s]
2022-03-21 23:01:51,429 - INFO - tqdm - f1: 0.7407, accuracy: 0.8915, batch_loss: 0.2286, loss: 0.2604 ||:  25%|##5       | 1807/7204 [07:05<19:52,  4.52it/s]
2022-03-21 23:02:01,452 - INFO - tqdm - f1: 0.7404, accuracy: 0.8913, batch_loss: 0.1393, loss: 0.2604 ||:  26%|##5       | 1850/7204 [07:15<26:30,  3.37it/s]
2022-03-21 23:02:11,596 - INFO - tqdm - f1: 0.7401, accuracy: 0.8917, batch_loss: 0.5037, loss: 0.2600 ||:  26%|##6       | 1891/7204 [07:25<21:12,  4.18it/s]
2022-03-21 23:02:21,728 - INFO - tqdm - f1: 0.7395, accuracy: 0.8911, batch_loss: 0.1561, loss: 0.2614 ||:  27%|##6       | 1935/7204 [07:35<23:24,  3.75it/s]
2022-03-21 23:02:31,878 - INFO - tqdm - f1: 0.7389, accuracy: 0.8911, batch_loss: 0.3408, loss: 0.2615 ||:  27%|##7       | 1978/7204 [07:45<19:32,  4.46it/s]
2022-03-21 23:02:42,156 - INFO - tqdm - f1: 0.7390, accuracy: 0.8912, batch_loss: 0.0908, loss: 0.2611 ||:  28%|##8       | 2021/7204 [07:55<22:54,  3.77it/s]
2022-03-21 23:02:52,170 - INFO - tqdm - f1: 0.7396, accuracy: 0.8910, batch_loss: 0.2995, loss: 0.2610 ||:  29%|##9       | 2091/7204 [08:05<08:43,  9.76it/s]
2022-03-21 23:03:02,465 - INFO - tqdm - f1: 0.7411, accuracy: 0.8913, batch_loss: 0.0134, loss: 0.2608 ||:  30%|##9       | 2156/7204 [08:16<18:36,  4.52it/s]
2022-03-21 23:03:12,738 - INFO - tqdm - f1: 0.7424, accuracy: 0.8921, batch_loss: 0.0414, loss: 0.2600 ||:  31%|###       | 2214/7204 [08:26<18:29,  4.50it/s]
2022-03-21 23:03:22,895 - INFO - tqdm - f1: 0.7419, accuracy: 0.8919, batch_loss: 0.0924, loss: 0.2607 ||:  32%|###1      | 2274/7204 [08:36<20:40,  3.97it/s]
2022-03-21 23:03:32,979 - INFO - tqdm - f1: 0.7412, accuracy: 0.8916, batch_loss: 0.1564, loss: 0.2614 ||:  32%|###2      | 2321/7204 [08:46<21:06,  3.85it/s]
2022-03-21 23:03:43,007 - INFO - tqdm - f1: 0.7407, accuracy: 0.8916, batch_loss: 0.3790, loss: 0.2616 ||:  33%|###2      | 2362/7204 [08:56<18:47,  4.30it/s]
2022-03-21 23:03:53,124 - INFO - tqdm - f1: 0.7414, accuracy: 0.8917, batch_loss: 0.3049, loss: 0.2618 ||:  33%|###3      | 2407/7204 [09:06<20:21,  3.93it/s]
2022-03-21 23:04:03,269 - INFO - tqdm - f1: 0.7423, accuracy: 0.8918, batch_loss: 0.3666, loss: 0.2619 ||:  34%|###4      | 2451/7204 [09:17<19:56,  3.97it/s]
2022-03-21 23:04:13,663 - INFO - tqdm - f1: 0.7433, accuracy: 0.8918, batch_loss: 0.3294, loss: 0.2618 ||:  35%|###4      | 2494/7204 [09:27<21:54,  3.58it/s]
2022-03-21 23:04:23,893 - INFO - tqdm - f1: 0.7439, accuracy: 0.8919, batch_loss: 0.1459, loss: 0.2620 ||:  35%|###5      | 2540/7204 [09:37<16:55,  4.59it/s]
2022-03-21 23:04:33,939 - INFO - tqdm - f1: 0.7443, accuracy: 0.8920, batch_loss: 0.1837, loss: 0.2621 ||:  36%|###5      | 2583/7204 [09:47<17:53,  4.30it/s]
2022-03-21 23:04:43,987 - INFO - tqdm - f1: 0.7439, accuracy: 0.8920, batch_loss: 0.0470, loss: 0.2622 ||:  36%|###6      | 2624/7204 [09:57<25:42,  2.97it/s]
2022-03-21 23:04:54,070 - INFO - tqdm - f1: 0.7439, accuracy: 0.8922, batch_loss: 0.4590, loss: 0.2621 ||:  37%|###6      | 2665/7204 [10:07<16:57,  4.46it/s]
2022-03-21 23:05:04,239 - INFO - tqdm - f1: 0.7440, accuracy: 0.8924, batch_loss: 0.0514, loss: 0.2615 ||:  38%|###7      | 2710/7204 [10:18<15:34,  4.81it/s]
2022-03-21 23:05:14,256 - INFO - tqdm - f1: 0.7445, accuracy: 0.8925, batch_loss: 0.1529, loss: 0.2611 ||:  38%|###8      | 2750/7204 [10:28<21:18,  3.48it/s]
2022-03-21 23:05:24,401 - INFO - tqdm - f1: 0.7445, accuracy: 0.8927, batch_loss: 0.5285, loss: 0.2610 ||:  39%|###8      | 2794/7204 [10:38<17:14,  4.26it/s]
2022-03-21 23:05:34,519 - INFO - tqdm - f1: 0.7440, accuracy: 0.8926, batch_loss: 0.1283, loss: 0.2613 ||:  39%|###9      | 2838/7204 [10:48<17:52,  4.07it/s]
2022-03-21 23:05:44,756 - INFO - tqdm - f1: 0.7436, accuracy: 0.8930, batch_loss: 0.0158, loss: 0.2607 ||:  40%|###9      | 2876/7204 [10:58<23:22,  3.09it/s]
2022-03-21 23:05:54,990 - INFO - tqdm - f1: 0.7435, accuracy: 0.8932, batch_loss: 0.1591, loss: 0.2607 ||:  41%|####      | 2921/7204 [11:08<18:07,  3.94it/s]
2022-03-21 23:06:05,030 - INFO - tqdm - f1: 0.7433, accuracy: 0.8932, batch_loss: 0.2498, loss: 0.2608 ||:  41%|####1     | 2964/7204 [11:18<14:24,  4.91it/s]
2022-03-21 23:06:15,052 - INFO - tqdm - f1: 0.7432, accuracy: 0.8934, batch_loss: 0.2716, loss: 0.2604 ||:  42%|####1     | 3009/7204 [11:28<14:04,  4.97it/s]
2022-03-21 23:06:25,287 - INFO - tqdm - f1: 0.7426, accuracy: 0.8935, batch_loss: 0.0582, loss: 0.2604 ||:  42%|####2     | 3048/7204 [11:39<18:10,  3.81it/s]
2022-03-21 23:06:35,602 - INFO - tqdm - f1: 0.7420, accuracy: 0.8936, batch_loss: 0.3637, loss: 0.2602 ||:  43%|####2     | 3087/7204 [11:49<19:38,  3.49it/s]
2022-03-21 23:06:45,749 - INFO - tqdm - f1: 0.7420, accuracy: 0.8936, batch_loss: 0.5117, loss: 0.2601 ||:  43%|####3     | 3130/7204 [11:59<15:06,  4.50it/s]
2022-03-21 23:06:56,061 - INFO - tqdm - f1: 0.7422, accuracy: 0.8935, batch_loss: 0.1474, loss: 0.2600 ||:  44%|####4     | 3174/7204 [12:09<17:23,  3.86it/s]
2022-03-21 23:07:06,229 - INFO - tqdm - f1: 0.7425, accuracy: 0.8934, batch_loss: 0.3189, loss: 0.2603 ||:  45%|####4     | 3221/7204 [12:20<13:10,  5.04it/s]
2022-03-21 23:07:16,456 - INFO - tqdm - f1: 0.7421, accuracy: 0.8935, batch_loss: 0.3266, loss: 0.2601 ||:  45%|####5     | 3262/7204 [12:30<16:44,  3.92it/s]
2022-03-21 23:07:26,580 - INFO - tqdm - f1: 0.7418, accuracy: 0.8933, batch_loss: 0.1919, loss: 0.2608 ||:  46%|####5     | 3309/7204 [12:40<14:10,  4.58it/s]
2022-03-21 23:07:36,988 - INFO - tqdm - f1: 0.7421, accuracy: 0.8932, batch_loss: 0.1616, loss: 0.2608 ||:  47%|####6     | 3355/7204 [12:50<17:09,  3.74it/s]
2022-03-21 23:07:47,022 - INFO - tqdm - f1: 0.7420, accuracy: 0.8933, batch_loss: 0.2480, loss: 0.2604 ||:  47%|####7     | 3399/7204 [13:00<16:01,  3.96it/s]
2022-03-21 23:07:57,410 - INFO - tqdm - f1: 0.7419, accuracy: 0.8933, batch_loss: 0.1106, loss: 0.2602 ||:  48%|####7     | 3442/7204 [13:11<16:52,  3.71it/s]
2022-03-21 23:08:07,610 - INFO - tqdm - f1: 0.7416, accuracy: 0.8932, batch_loss: 0.3358, loss: 0.2601 ||:  48%|####8     | 3485/7204 [13:21<14:46,  4.19it/s]
2022-03-21 23:08:17,747 - INFO - tqdm - f1: 0.7415, accuracy: 0.8930, batch_loss: 0.0310, loss: 0.2605 ||:  49%|####8     | 3527/7204 [13:31<14:18,  4.28it/s]
2022-03-21 23:08:27,791 - INFO - tqdm - f1: 0.7418, accuracy: 0.8931, batch_loss: 0.1937, loss: 0.2603 ||:  50%|####9     | 3569/7204 [13:41<16:46,  3.61it/s]
2022-03-21 23:08:37,955 - INFO - tqdm - f1: 0.7416, accuracy: 0.8932, batch_loss: 0.0580, loss: 0.2603 ||:  50%|#####     | 3609/7204 [13:51<17:34,  3.41it/s]
2022-03-21 23:08:48,174 - INFO - tqdm - f1: 0.7414, accuracy: 0.8931, batch_loss: 0.3757, loss: 0.2605 ||:  51%|#####     | 3650/7204 [14:01<17:36,  3.36it/s]
2022-03-21 23:08:58,193 - INFO - tqdm - f1: 0.7413, accuracy: 0.8929, batch_loss: 0.4004, loss: 0.2608 ||:  51%|#####1    | 3695/7204 [14:12<14:52,  3.93it/s]
2022-03-21 23:09:08,336 - INFO - tqdm - f1: 0.7419, accuracy: 0.8930, batch_loss: 0.1828, loss: 0.2608 ||:  52%|#####1    | 3739/7204 [14:22<16:52,  3.42it/s]
2022-03-21 23:09:18,679 - INFO - tqdm - f1: 0.7424, accuracy: 0.8930, batch_loss: 0.1314, loss: 0.2604 ||:  52%|#####2    | 3779/7204 [14:32<15:38,  3.65it/s]
2022-03-21 23:09:28,919 - INFO - tqdm - f1: 0.7427, accuracy: 0.8930, batch_loss: 0.1488, loss: 0.2605 ||:  53%|#####3    | 3822/7204 [14:42<14:02,  4.01it/s]
2022-03-21 23:09:39,048 - INFO - tqdm - f1: 0.7427, accuracy: 0.8930, batch_loss: 0.2056, loss: 0.2605 ||:  54%|#####3    | 3864/7204 [14:52<11:09,  4.99it/s]
2022-03-21 23:09:49,203 - INFO - tqdm - f1: 0.7425, accuracy: 0.8931, batch_loss: 0.3891, loss: 0.2607 ||:  54%|#####4    | 3908/7204 [15:03<11:19,  4.85it/s]
2022-03-21 23:09:59,234 - INFO - tqdm - f1: 0.7418, accuracy: 0.8928, batch_loss: 0.1508, loss: 0.2610 ||:  55%|#####4    | 3948/7204 [15:13<15:07,  3.59it/s]
2022-03-21 23:10:09,412 - INFO - tqdm - f1: 0.7423, accuracy: 0.8930, batch_loss: 0.0498, loss: 0.2607 ||:  55%|#####5    | 3991/7204 [15:23<11:02,  4.85it/s]
2022-03-21 23:10:19,455 - INFO - tqdm - f1: 0.7424, accuracy: 0.8930, batch_loss: 0.4597, loss: 0.2610 ||:  56%|#####6    | 4038/7204 [15:33<11:27,  4.60it/s]
2022-03-21 23:10:29,496 - INFO - tqdm - f1: 0.7420, accuracy: 0.8929, batch_loss: 0.4924, loss: 0.2611 ||:  57%|#####6    | 4082/7204 [15:43<09:39,  5.38it/s]
2022-03-21 23:10:39,515 - INFO - tqdm - f1: 0.7422, accuracy: 0.8930, batch_loss: 0.0591, loss: 0.2611 ||:  57%|#####7    | 4122/7204 [15:53<15:13,  3.37it/s]
2022-03-21 23:10:49,895 - INFO - tqdm - f1: 0.7430, accuracy: 0.8932, batch_loss: 0.5043, loss: 0.2608 ||:  58%|#####7    | 4168/7204 [16:03<13:22,  3.78it/s]
2022-03-21 23:11:00,062 - INFO - tqdm - f1: 0.7433, accuracy: 0.8934, batch_loss: 0.1212, loss: 0.2605 ||:  58%|#####8    | 4208/7204 [16:13<11:23,  4.38it/s]
2022-03-21 23:11:10,214 - INFO - tqdm - f1: 0.7433, accuracy: 0.8933, batch_loss: 0.3958, loss: 0.2609 ||:  59%|#####9    | 4254/7204 [16:24<09:14,  5.32it/s]
2022-03-21 23:11:20,303 - INFO - tqdm - f1: 0.7435, accuracy: 0.8934, batch_loss: 0.0962, loss: 0.2608 ||:  60%|#####9    | 4297/7204 [16:34<12:31,  3.87it/s]
2022-03-21 23:11:30,337 - INFO - tqdm - f1: 0.7435, accuracy: 0.8934, batch_loss: 0.2907, loss: 0.2607 ||:  60%|######    | 4340/7204 [16:44<10:38,  4.49it/s]
2022-03-21 23:11:40,533 - INFO - tqdm - f1: 0.7436, accuracy: 0.8935, batch_loss: 0.1879, loss: 0.2603 ||:  61%|######    | 4382/7204 [16:54<10:29,  4.48it/s]
2022-03-21 23:11:50,555 - INFO - tqdm - f1: 0.7436, accuracy: 0.8934, batch_loss: 0.2243, loss: 0.2606 ||:  61%|######1   | 4424/7204 [17:04<10:13,  4.53it/s]
2022-03-21 23:12:00,840 - INFO - tqdm - f1: 0.7437, accuracy: 0.8933, batch_loss: 0.2776, loss: 0.2605 ||:  62%|######2   | 4469/7204 [17:14<11:38,  3.92it/s]
2022-03-21 23:12:10,968 - INFO - tqdm - f1: 0.7433, accuracy: 0.8933, batch_loss: 0.0539, loss: 0.2606 ||:  63%|######2   | 4513/7204 [17:24<09:47,  4.58it/s]
2022-03-21 23:12:21,116 - INFO - tqdm - f1: 0.7436, accuracy: 0.8931, batch_loss: 0.1471, loss: 0.2608 ||:  63%|######3   | 4558/7204 [17:34<10:03,  4.39it/s]
2022-03-21 23:12:31,392 - INFO - tqdm - f1: 0.7437, accuracy: 0.8932, batch_loss: 0.4930, loss: 0.2607 ||:  64%|######3   | 4598/7204 [17:45<12:20,  3.52it/s]
2022-03-21 23:12:41,683 - INFO - tqdm - f1: 0.7439, accuracy: 0.8935, batch_loss: 0.0167, loss: 0.2600 ||:  64%|######4   | 4639/7204 [17:55<12:39,  3.38it/s]
2022-03-21 23:12:51,773 - INFO - tqdm - f1: 0.7439, accuracy: 0.8936, batch_loss: 0.1172, loss: 0.2601 ||:  65%|######5   | 4684/7204 [18:05<11:30,  3.65it/s]
2022-03-21 23:13:01,813 - INFO - tqdm - f1: 0.7442, accuracy: 0.8936, batch_loss: 0.2249, loss: 0.2602 ||:  66%|######5   | 4727/7204 [18:15<09:44,  4.24it/s]
2022-03-21 23:13:11,890 - INFO - tqdm - f1: 0.7444, accuracy: 0.8936, batch_loss: 0.1240, loss: 0.2606 ||:  66%|######6   | 4774/7204 [18:25<08:20,  4.86it/s]
2022-03-21 23:13:22,153 - INFO - tqdm - f1: 0.7440, accuracy: 0.8933, batch_loss: 0.2904, loss: 0.2612 ||:  67%|######6   | 4821/7204 [18:35<08:15,  4.81it/s]
2022-03-21 23:13:32,447 - INFO - tqdm - f1: 0.7437, accuracy: 0.8934, batch_loss: 0.1179, loss: 0.2610 ||:  67%|######7   | 4859/7204 [18:46<11:27,  3.41it/s]
2022-03-21 23:13:42,694 - INFO - tqdm - f1: 0.7439, accuracy: 0.8935, batch_loss: 0.1165, loss: 0.2607 ||:  68%|######8   | 4902/7204 [18:56<08:45,  4.38it/s]
2022-03-21 23:13:52,709 - INFO - tqdm - f1: 0.7439, accuracy: 0.8933, batch_loss: 0.2792, loss: 0.2611 ||:  69%|######8   | 4947/7204 [19:06<08:47,  4.28it/s]
2022-03-21 23:14:02,784 - INFO - tqdm - f1: 0.7436, accuracy: 0.8933, batch_loss: 0.1288, loss: 0.2612 ||:  69%|######9   | 4991/7204 [19:16<11:35,  3.18it/s]
2022-03-21 23:14:12,793 - INFO - tqdm - f1: 0.7432, accuracy: 0.8933, batch_loss: 0.3012, loss: 0.2612 ||:  70%|######9   | 5032/7204 [19:26<09:27,  3.83it/s]
2022-03-21 23:14:22,825 - INFO - tqdm - f1: 0.7431, accuracy: 0.8933, batch_loss: 0.1406, loss: 0.2612 ||:  70%|#######   | 5074/7204 [19:36<09:33,  3.71it/s]
2022-03-21 23:14:33,168 - INFO - tqdm - f1: 0.7435, accuracy: 0.8933, batch_loss: 0.2014, loss: 0.2614 ||:  71%|#######1  | 5119/7204 [19:46<10:35,  3.28it/s]
2022-03-21 23:14:43,349 - INFO - tqdm - f1: 0.7433, accuracy: 0.8932, batch_loss: 0.8283, loss: 0.2615 ||:  72%|#######1  | 5164/7204 [19:57<07:33,  4.50it/s]
2022-03-21 23:14:53,463 - INFO - tqdm - f1: 0.7430, accuracy: 0.8932, batch_loss: 0.1379, loss: 0.2614 ||:  72%|#######2  | 5207/7204 [20:07<08:07,  4.10it/s]
2022-03-21 23:15:03,630 - INFO - tqdm - f1: 0.7427, accuracy: 0.8932, batch_loss: 0.0236, loss: 0.2614 ||:  73%|#######2  | 5254/7204 [20:17<08:46,  3.70it/s]
2022-03-21 23:15:13,775 - INFO - tqdm - f1: 0.7421, accuracy: 0.8932, batch_loss: 0.1375, loss: 0.2613 ||:  74%|#######3  | 5295/7204 [20:27<07:18,  4.35it/s]
2022-03-21 23:15:23,898 - INFO - tqdm - f1: 0.7416, accuracy: 0.8931, batch_loss: 0.3948, loss: 0.2615 ||:  74%|#######4  | 5341/7204 [20:37<05:36,  5.53it/s]
2022-03-21 23:15:33,993 - INFO - tqdm - f1: 0.7414, accuracy: 0.8931, batch_loss: 0.1315, loss: 0.2613 ||:  75%|#######4  | 5383/7204 [20:47<06:45,  4.49it/s]
2022-03-21 23:15:44,101 - INFO - tqdm - f1: 0.7417, accuracy: 0.8932, batch_loss: 0.3241, loss: 0.2614 ||:  75%|#######5  | 5425/7204 [20:57<07:00,  4.23it/s]
2022-03-21 23:15:54,278 - INFO - tqdm - f1: 0.7414, accuracy: 0.8932, batch_loss: 0.6102, loss: 0.2616 ||:  76%|#######5  | 5464/7204 [21:08<06:22,  4.55it/s]
2022-03-21 23:16:04,341 - INFO - tqdm - f1: 0.7415, accuracy: 0.8933, batch_loss: 0.1920, loss: 0.2613 ||:  76%|#######6  | 5504/7204 [21:18<07:16,  3.89it/s]
2022-03-21 23:16:14,400 - INFO - tqdm - f1: 0.7415, accuracy: 0.8934, batch_loss: 0.3198, loss: 0.2615 ||:  77%|#######7  | 5548/7204 [21:28<05:24,  5.11it/s]
2022-03-21 23:16:24,474 - INFO - tqdm - f1: 0.7417, accuracy: 0.8934, batch_loss: 0.0385, loss: 0.2615 ||:  78%|#######7  | 5593/7204 [21:38<07:25,  3.62it/s]
2022-03-21 23:16:34,630 - INFO - tqdm - f1: 0.7414, accuracy: 0.8932, batch_loss: 0.2560, loss: 0.2617 ||:  78%|#######8  | 5639/7204 [21:48<06:05,  4.28it/s]
2022-03-21 23:16:44,767 - INFO - tqdm - f1: 0.7417, accuracy: 0.8931, batch_loss: 0.4234, loss: 0.2618 ||:  79%|#######8  | 5685/7204 [21:58<06:11,  4.09it/s]
2022-03-21 23:16:54,791 - INFO - tqdm - f1: 0.7415, accuracy: 0.8930, batch_loss: 0.0981, loss: 0.2620 ||:  80%|#######9  | 5731/7204 [22:08<05:34,  4.41it/s]
2022-03-21 23:17:04,819 - INFO - tqdm - f1: 0.7416, accuracy: 0.8930, batch_loss: 0.2951, loss: 0.2620 ||:  80%|########  | 5770/7204 [22:18<06:02,  3.96it/s]
2022-03-21 23:17:14,892 - INFO - tqdm - f1: 0.7417, accuracy: 0.8932, batch_loss: 0.0984, loss: 0.2615 ||:  81%|########  | 5807/7204 [22:28<05:27,  4.27it/s]
2022-03-21 23:17:25,200 - INFO - tqdm - f1: 0.7416, accuracy: 0.8934, batch_loss: 0.0287, loss: 0.2613 ||:  81%|########1 | 5853/7204 [22:39<06:09,  3.65it/s]
2022-03-21 23:17:35,446 - INFO - tqdm - f1: 0.7418, accuracy: 0.8934, batch_loss: 0.0654, loss: 0.2614 ||:  82%|########1 | 5897/7204 [22:49<05:57,  3.65it/s]
2022-03-21 23:17:45,645 - INFO - tqdm - f1: 0.7416, accuracy: 0.8932, batch_loss: 0.3617, loss: 0.2615 ||:  82%|########2 | 5940/7204 [22:59<04:39,  4.53it/s]
2022-03-21 23:17:55,731 - INFO - tqdm - f1: 0.7414, accuracy: 0.8931, batch_loss: 0.2736, loss: 0.2617 ||:  83%|########3 | 5986/7204 [23:09<04:25,  4.59it/s]
2022-03-21 23:18:05,774 - INFO - tqdm - f1: 0.7413, accuracy: 0.8931, batch_loss: 0.5043, loss: 0.2617 ||:  84%|########3 | 6029/7204 [23:19<04:07,  4.74it/s]
2022-03-21 23:18:16,128 - INFO - tqdm - f1: 0.7412, accuracy: 0.8931, batch_loss: 0.0368, loss: 0.2617 ||:  84%|########4 | 6071/7204 [23:29<05:09,  3.66it/s]
2022-03-21 23:18:26,324 - INFO - tqdm - f1: 0.7414, accuracy: 0.8932, batch_loss: 0.3867, loss: 0.2617 ||:  85%|########4 | 6112/7204 [23:40<03:54,  4.65it/s]
2022-03-21 23:18:36,537 - INFO - tqdm - f1: 0.7415, accuracy: 0.8931, batch_loss: 0.0257, loss: 0.2619 ||:  85%|########5 | 6156/7204 [23:50<05:08,  3.40it/s]
2022-03-21 23:18:46,627 - INFO - tqdm - f1: 0.7415, accuracy: 0.8931, batch_loss: 0.2252, loss: 0.2620 ||:  86%|########6 | 6200/7204 [24:00<04:12,  3.98it/s]
2022-03-21 23:18:56,789 - INFO - tqdm - f1: 0.7420, accuracy: 0.8931, batch_loss: 0.3636, loss: 0.2620 ||:  87%|########6 | 6247/7204 [24:10<04:45,  3.35it/s]
2022-03-21 23:19:06,916 - INFO - tqdm - f1: 0.7420, accuracy: 0.8930, batch_loss: 0.3252, loss: 0.2622 ||:  87%|########7 | 6292/7204 [24:20<03:19,  4.56it/s]
2022-03-21 23:19:16,978 - INFO - tqdm - f1: 0.7420, accuracy: 0.8930, batch_loss: 0.7315, loss: 0.2621 ||:  88%|########7 | 6336/7204 [24:30<03:27,  4.19it/s]
2022-03-21 23:19:27,063 - INFO - tqdm - f1: 0.7418, accuracy: 0.8930, batch_loss: 0.3641, loss: 0.2623 ||:  89%|########8 | 6381/7204 [24:40<02:51,  4.79it/s]
2022-03-21 23:19:37,194 - INFO - tqdm - f1: 0.7417, accuracy: 0.8929, batch_loss: 0.1110, loss: 0.2626 ||:  89%|########9 | 6425/7204 [24:51<03:54,  3.33it/s]
2022-03-21 23:19:47,557 - INFO - tqdm - f1: 0.7421, accuracy: 0.8930, batch_loss: 0.2717, loss: 0.2625 ||:  90%|########9 | 6466/7204 [25:01<04:15,  2.89it/s]
2022-03-21 23:19:57,569 - INFO - tqdm - f1: 0.7421, accuracy: 0.8930, batch_loss: 0.4466, loss: 0.2626 ||:  90%|######### | 6507/7204 [25:11<02:47,  4.16it/s]
2022-03-21 23:20:07,601 - INFO - tqdm - f1: 0.7419, accuracy: 0.8930, batch_loss: 0.3004, loss: 0.2628 ||:  91%|######### | 6550/7204 [25:21<02:07,  5.12it/s]
2022-03-21 23:20:17,759 - INFO - tqdm - f1: 0.7423, accuracy: 0.8930, batch_loss: 0.2121, loss: 0.2628 ||:  92%|#########1| 6594/7204 [25:31<01:59,  5.12it/s]
2022-03-21 23:20:27,977 - INFO - tqdm - f1: 0.7425, accuracy: 0.8930, batch_loss: 0.0627, loss: 0.2630 ||:  92%|#########2| 6640/7204 [25:41<02:43,  3.44it/s]
2022-03-21 23:20:38,297 - INFO - tqdm - f1: 0.7428, accuracy: 0.8930, batch_loss: 0.1437, loss: 0.2630 ||:  93%|#########2| 6687/7204 [25:52<02:21,  3.66it/s]
2022-03-21 23:20:48,554 - INFO - tqdm - f1: 0.7436, accuracy: 0.8931, batch_loss: 0.0657, loss: 0.2627 ||:  93%|#########3| 6732/7204 [26:02<02:17,  3.43it/s]
2022-03-21 23:20:58,601 - INFO - tqdm - f1: 0.7435, accuracy: 0.8932, batch_loss: 0.1886, loss: 0.2627 ||:  94%|#########3| 6771/7204 [26:12<01:32,  4.66it/s]
2022-03-21 23:21:08,732 - INFO - tqdm - f1: 0.7432, accuracy: 0.8932, batch_loss: 0.2665, loss: 0.2629 ||:  95%|#########5| 6855/7204 [26:22<00:48,  7.20it/s]
2022-03-21 23:21:18,922 - INFO - tqdm - f1: 0.7434, accuracy: 0.8932, batch_loss: 0.1630, loss: 0.2628 ||:  96%|#########5| 6912/7204 [26:32<00:52,  5.57it/s]
2022-03-21 23:21:28,923 - INFO - tqdm - f1: 0.7433, accuracy: 0.8932, batch_loss: 0.0925, loss: 0.2628 ||:  97%|#########6| 6971/7204 [26:42<00:35,  6.58it/s]
2022-03-21 23:21:38,944 - INFO - tqdm - f1: 0.7431, accuracy: 0.8931, batch_loss: 0.1114, loss: 0.2628 ||:  98%|#########7| 7027/7204 [26:52<00:31,  5.65it/s]
2022-03-21 23:21:48,958 - INFO - tqdm - f1: 0.7432, accuracy: 0.8931, batch_loss: 0.1600, loss: 0.2629 ||:  98%|#########8| 7070/7204 [27:02<00:35,  3.76it/s]
2022-03-21 23:21:59,213 - INFO - tqdm - f1: 0.7432, accuracy: 0.8929, batch_loss: 0.1897, loss: 0.2634 ||:  99%|#########8| 7115/7204 [27:13<00:21,  4.09it/s]
2022-03-21 23:22:09,348 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.5167, loss: 0.2634 ||:  99%|#########9| 7159/7204 [27:23<00:09,  4.99it/s]
2022-03-21 23:22:11,288 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.4131, loss: 0.2635 ||: 100%|#########9| 7168/7204 [27:25<00:07,  4.52it/s]
2022-03-21 23:22:11,539 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.1744, loss: 0.2634 ||: 100%|#########9| 7169/7204 [27:25<00:08,  4.34it/s]
2022-03-21 23:22:11,761 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.5401, loss: 0.2635 ||: 100%|#########9| 7170/7204 [27:25<00:07,  4.39it/s]
2022-03-21 23:22:11,998 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.0593, loss: 0.2635 ||: 100%|#########9| 7171/7204 [27:25<00:07,  4.34it/s]
2022-03-21 23:22:12,213 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.3826, loss: 0.2635 ||: 100%|#########9| 7172/7204 [27:26<00:07,  4.43it/s]
2022-03-21 23:22:12,454 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.1915, loss: 0.2635 ||: 100%|#########9| 7173/7204 [27:26<00:07,  4.34it/s]
2022-03-21 23:22:12,772 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.1331, loss: 0.2634 ||: 100%|#########9| 7174/7204 [27:26<00:07,  3.90it/s]
2022-03-21 23:22:13,198 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.1586, loss: 0.2634 ||: 100%|#########9| 7175/7204 [27:27<00:08,  3.25it/s]
2022-03-21 23:22:13,383 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.2630, loss: 0.2634 ||: 100%|#########9| 7176/7204 [27:27<00:07,  3.70it/s]
2022-03-21 23:22:13,602 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.4401, loss: 0.2634 ||: 100%|#########9| 7177/7204 [27:27<00:06,  3.92it/s]
2022-03-21 23:22:13,932 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.1802, loss: 0.2634 ||: 100%|#########9| 7178/7204 [27:27<00:07,  3.60it/s]
2022-03-21 23:22:14,333 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.2556, loss: 0.2634 ||: 100%|#########9| 7179/7204 [27:28<00:07,  3.18it/s]
2022-03-21 23:22:14,613 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.0895, loss: 0.2634 ||: 100%|#########9| 7180/7204 [27:28<00:07,  3.29it/s]
2022-03-21 23:22:14,755 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.1977, loss: 0.2634 ||: 100%|#########9| 7181/7204 [27:28<00:05,  3.91it/s]
2022-03-21 23:22:14,960 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.2742, loss: 0.2634 ||: 100%|#########9| 7182/7204 [27:28<00:05,  4.16it/s]
2022-03-21 23:22:15,204 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.2014, loss: 0.2634 ||: 100%|#########9| 7183/7204 [27:29<00:05,  4.14it/s]
2022-03-21 23:22:15,318 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.1891, loss: 0.2634 ||: 100%|#########9| 7184/7204 [27:29<00:04,  4.92it/s]
2022-03-21 23:22:15,485 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.6224, loss: 0.2634 ||: 100%|#########9| 7185/7204 [27:29<00:03,  5.20it/s]
2022-03-21 23:22:15,660 - INFO - tqdm - f1: 0.7430, accuracy: 0.8927, batch_loss: 0.6355, loss: 0.2635 ||: 100%|#########9| 7186/7204 [27:29<00:03,  5.35it/s]
2022-03-21 23:22:16,061 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.0412, loss: 0.2635 ||: 100%|#########9| 7187/7204 [27:29<00:04,  3.98it/s]
2022-03-21 23:22:16,522 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.2571, loss: 0.2635 ||: 100%|#########9| 7188/7204 [27:30<00:05,  3.18it/s]
2022-03-21 23:22:16,716 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.5602, loss: 0.2635 ||: 100%|#########9| 7189/7204 [27:30<00:04,  3.59it/s]
2022-03-21 23:22:17,085 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.2382, loss: 0.2635 ||: 100%|#########9| 7190/7204 [27:30<00:04,  3.27it/s]
2022-03-21 23:22:17,301 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.2103, loss: 0.2635 ||: 100%|#########9| 7191/7204 [27:31<00:03,  3.59it/s]
2022-03-21 23:22:17,456 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.2437, loss: 0.2635 ||: 100%|#########9| 7192/7204 [27:31<00:02,  4.14it/s]
2022-03-21 23:22:17,695 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.1273, loss: 0.2635 ||: 100%|#########9| 7193/7204 [27:31<00:02,  4.15it/s]
2022-03-21 23:22:17,904 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.2231, loss: 0.2635 ||: 100%|#########9| 7194/7204 [27:31<00:02,  4.32it/s]
2022-03-21 23:22:18,025 - INFO - tqdm - f1: 0.7430, accuracy: 0.8928, batch_loss: 0.3828, loss: 0.2635 ||: 100%|#########9| 7195/7204 [27:31<00:01,  5.04it/s]
2022-03-21 23:22:18,233 - INFO - tqdm - f1: 0.7430, accuracy: 0.8927, batch_loss: 0.4472, loss: 0.2635 ||: 100%|#########9| 7196/7204 [27:32<00:01,  4.97it/s]
2022-03-21 23:22:18,447 - INFO - tqdm - f1: 0.7430, accuracy: 0.8927, batch_loss: 0.1217, loss: 0.2635 ||: 100%|#########9| 7197/7204 [27:32<00:01,  4.88it/s]
2022-03-21 23:22:18,619 - INFO - tqdm - f1: 0.7430, accuracy: 0.8927, batch_loss: 0.2676, loss: 0.2635 ||: 100%|#########9| 7198/7204 [27:32<00:01,  5.13it/s]
2022-03-21 23:22:18,811 - INFO - tqdm - f1: 0.7430, accuracy: 0.8927, batch_loss: 0.4534, loss: 0.2635 ||: 100%|#########9| 7199/7204 [27:32<00:00,  5.15it/s]
2022-03-21 23:22:19,053 - INFO - tqdm - f1: 0.7431, accuracy: 0.8927, batch_loss: 0.4914, loss: 0.2635 ||: 100%|#########9| 7200/7204 [27:32<00:00,  4.80it/s]
2022-03-21 23:22:19,243 - INFO - tqdm - f1: 0.7431, accuracy: 0.8927, batch_loss: 0.1105, loss: 0.2635 ||: 100%|#########9| 7201/7204 [27:33<00:00,  4.93it/s]
2022-03-21 23:22:19,473 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.1970, loss: 0.2635 ||: 100%|#########9| 7202/7204 [27:33<00:00,  4.74it/s]
2022-03-21 23:22:19,763 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.1470, loss: 0.2635 ||: 100%|#########9| 7203/7204 [27:33<00:00,  4.26it/s]
2022-03-21 23:22:19,895 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.1723, loss: 0.2635 ||: 100%|##########| 7204/7204 [27:33<00:00,  4.90it/s]
2022-03-21 23:22:19,952 - INFO - tqdm - f1: 0.7431, accuracy: 0.8928, batch_loss: 0.1723, loss: 0.2635 ||: 100%|##########| 7204/7204 [27:33<00:00,  4.36it/s]
2022-03-21 23:22:19,990 - INFO - allennlp.training.trainer - Validating
2022-03-21 23:22:19,992 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 23:22:30,092 - INFO - tqdm - f1: 0.6833, accuracy: 0.8792, batch_loss: 0.7635, loss: 0.3032 ||:  28%|##8       | 89/313 [00:10<00:25,  8.90it/s]
2022-03-21 23:22:40,119 - INFO - tqdm - f1: 0.6880, accuracy: 0.8771, batch_loss: 0.0500, loss: 0.3179 ||:  57%|#####6    | 178/313 [00:20<00:14,  9.32it/s]
2022-03-21 23:22:50,172 - INFO - tqdm - f1: 0.6771, accuracy: 0.8722, batch_loss: 0.5014, loss: 0.3265 ||:  86%|########5 | 268/313 [00:30<00:04, 10.78it/s]
2022-03-21 23:22:55,067 - INFO - tqdm - f1: 0.6809, accuracy: 0.8706, batch_loss: 0.1122, loss: 0.3294 ||: 100%|##########| 313/313 [00:35<00:00,  9.80it/s]
2022-03-21 23:22:55,070 - INFO - tqdm - f1: 0.6809, accuracy: 0.8706, batch_loss: 0.1122, loss: 0.3294 ||: 100%|##########| 313/313 [00:35<00:00,  8.92it/s]
2022-03-21 23:22:55,114 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/amazon_base_hyper_small_seed_47/best.th'.
2022-03-21 23:22:57,705 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 23:22:57,707 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.893  |     0.871
2022-03-21 23:22:57,708 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.743  |     0.681
2022-03-21 23:22:57,710 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 23:22:57,711 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.263  |     0.329
2022-03-21 23:22:57,713 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13602.809  |       N/A
2022-03-21 23:22:57,714 - INFO - allennlp.training.trainer - Epoch duration: 0:28:11.544523
2022-03-21 23:22:57,716 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:18:14
2022-03-21 23:22:57,717 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-21 23:22:57,719 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-21 23:22:57,720 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 23:22:57,723 - INFO - allennlp.training.trainer - Training
2022-03-21 23:22:57,725 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-21 23:23:07,903 - INFO - tqdm - f1: 0.8087, accuracy: 0.9142, batch_loss: 0.1951, loss: 0.2516 ||:   1%|          | 43/7204 [00:10<26:56,  4.43it/s]
2022-03-21 23:23:17,953 - INFO - tqdm - f1: 0.8320, accuracy: 0.9186, batch_loss: 0.2536, loss: 0.2339 ||:   1%|1         | 86/7204 [00:20<30:02,  3.95it/s]
2022-03-21 23:23:27,961 - INFO - tqdm - f1: 0.8220, accuracy: 0.9126, batch_loss: 0.0110, loss: 0.2353 ||:   2%|1         | 128/7204 [00:30<37:17,  3.16it/s]
2022-03-21 23:23:37,975 - INFO - tqdm - f1: 0.8111, accuracy: 0.9099, batch_loss: 0.0126, loss: 0.2348 ||:   2%|2         | 172/7204 [00:40<29:45,  3.94it/s]
2022-03-21 23:23:48,151 - INFO - tqdm - f1: 0.8159, accuracy: 0.9110, batch_loss: 0.1483, loss: 0.2295 ||:   3%|3         | 219/7204 [00:50<26:57,  4.32it/s]
2022-03-21 23:23:58,279 - INFO - tqdm - f1: 0.8147, accuracy: 0.9106, batch_loss: 0.3525, loss: 0.2302 ||:   4%|3         | 263/7204 [01:00<28:20,  4.08it/s]
2022-03-21 23:24:08,412 - INFO - tqdm - f1: 0.8184, accuracy: 0.9112, batch_loss: 0.2866, loss: 0.2301 ||:   4%|4         | 306/7204 [01:10<21:04,  5.46it/s]
2022-03-21 23:24:18,539 - INFO - tqdm - f1: 0.8176, accuracy: 0.9128, batch_loss: 0.2592, loss: 0.2287 ||:   5%|4         | 347/7204 [01:20<29:22,  3.89it/s]
2022-03-21 23:24:28,755 - INFO - tqdm - f1: 0.8181, accuracy: 0.9143, batch_loss: 0.0131, loss: 0.2243 ||:   5%|5         | 391/7204 [01:31<33:33,  3.38it/s]
2022-03-21 23:24:38,844 - INFO - tqdm - f1: 0.8198, accuracy: 0.9163, batch_loss: 0.1284, loss: 0.2201 ||:   6%|5         | 431/7204 [01:41<27:29,  4.11it/s]
2022-03-21 23:24:48,982 - INFO - tqdm - f1: 0.8178, accuracy: 0.9151, batch_loss: 0.2208, loss: 0.2214 ||:   7%|6         | 475/7204 [01:51<24:41,  4.54it/s]
2022-03-21 23:24:59,085 - INFO - tqdm - f1: 0.8143, accuracy: 0.9145, batch_loss: 0.3539, loss: 0.2213 ||:   7%|7         | 519/7204 [02:01<25:46,  4.32it/s]
2022-03-21 23:25:09,163 - INFO - tqdm - f1: 0.8134, accuracy: 0.9143, batch_loss: 0.2098, loss: 0.2220 ||:   8%|7         | 558/7204 [02:11<32:37,  3.39it/s]
2022-03-21 23:25:19,396 - INFO - tqdm - f1: 0.8121, accuracy: 0.9140, batch_loss: 0.0701, loss: 0.2227 ||:   8%|8         | 599/7204 [02:21<30:56,  3.56it/s]
2022-03-21 23:25:29,543 - INFO - tqdm - f1: 0.8098, accuracy: 0.9136, batch_loss: 0.3919, loss: 0.2232 ||:   9%|8         | 642/7204 [02:31<22:17,  4.91it/s]
2022-03-21 23:25:39,708 - INFO - tqdm - f1: 0.8104, accuracy: 0.9144, batch_loss: 0.3393, loss: 0.2219 ||:  10%|9         | 687/7204 [02:41<24:05,  4.51it/s]
2022-03-21 23:25:49,778 - INFO - tqdm - f1: 0.8114, accuracy: 0.9143, batch_loss: 0.3444, loss: 0.2232 ||:  10%|#         | 730/7204 [02:52<25:02,  4.31it/s]
2022-03-21 23:25:59,983 - INFO - tqdm - f1: 0.8147, accuracy: 0.9155, batch_loss: 0.1234, loss: 0.2205 ||:  11%|#         | 774/7204 [03:02<22:42,  4.72it/s]
2022-03-21 23:26:10,037 - INFO - tqdm - f1: 0.8163, accuracy: 0.9165, batch_loss: 0.0579, loss: 0.2187 ||:  11%|#1        | 811/7204 [03:12<25:40,  4.15it/s]
2022-03-21 23:26:20,286 - INFO - tqdm - f1: 0.8137, accuracy: 0.9154, batch_loss: 0.0454, loss: 0.2207 ||:  12%|#1        | 857/7204 [03:22<26:04,  4.06it/s]
2022-03-21 23:26:30,319 - INFO - tqdm - f1: 0.8138, accuracy: 0.9162, batch_loss: 0.1178, loss: 0.2193 ||:  12%|#2        | 900/7204 [03:32<23:38,  4.44it/s]
2022-03-21 23:26:40,390 - INFO - tqdm - f1: 0.8141, accuracy: 0.9165, batch_loss: 0.5087, loss: 0.2188 ||:  13%|#3        | 944/7204 [03:42<22:24,  4.66it/s]
2022-03-21 23:26:50,463 - INFO - tqdm - f1: 0.8137, accuracy: 0.9165, batch_loss: 0.2344, loss: 0.2185 ||:  14%|#3        | 987/7204 [03:52<19:31,  5.30it/s]
2022-03-21 23:27:00,624 - INFO - tqdm - f1: 0.8140, accuracy: 0.9169, batch_loss: 0.0549, loss: 0.2173 ||:  14%|#4        | 1034/7204 [04:02<23:56,  4.29it/s]
2022-03-21 23:27:10,627 - INFO - tqdm - f1: 0.8149, accuracy: 0.9173, batch_loss: 0.3007, loss: 0.2166 ||:  15%|#5        | 1081/7204 [04:12<23:16,  4.39it/s]
2022-03-21 23:27:20,643 - INFO - tqdm - f1: 0.8150, accuracy: 0.9169, batch_loss: 0.1110, loss: 0.2169 ||:  16%|#5        | 1123/7204 [04:22<24:52,  4.08it/s]
2022-03-21 23:27:30,678 - INFO - tqdm - f1: 0.8133, accuracy: 0.9164, batch_loss: 0.0705, loss: 0.2180 ||:  16%|#6        | 1165/7204 [04:32<25:38,  3.92it/s]
2022-03-21 23:27:40,733 - INFO - tqdm - f1: 0.8143, accuracy: 0.9171, batch_loss: 0.0292, loss: 0.2171 ||:  17%|#6        | 1205/7204 [04:43<20:23,  4.90it/s]
2022-03-21 23:27:51,021 - INFO - tqdm - f1: 0.8139, accuracy: 0.9166, batch_loss: 0.0426, loss: 0.2184 ||:  17%|#7        | 1248/7204 [04:53<27:59,  3.55it/s]
2022-03-21 23:28:01,048 - INFO - tqdm - f1: 0.8141, accuracy: 0.9168, batch_loss: 0.0420, loss: 0.2173 ||:  18%|#7        | 1289/7204 [05:03<26:44,  3.69it/s]
2022-03-21 23:28:11,175 - INFO - tqdm - f1: 0.8136, accuracy: 0.9169, batch_loss: 0.0755, loss: 0.2173 ||:  18%|#8        | 1331/7204 [05:13<27:50,  3.52it/s]
2022-03-21 23:28:21,250 - INFO - tqdm - f1: 0.8134, accuracy: 0.9164, batch_loss: 0.1603, loss: 0.2173 ||:  19%|#9        | 1372/7204 [05:23<26:01,  3.73it/s]
2022-03-21 23:28:31,328 - INFO - tqdm - f1: 0.8149, accuracy: 0.9173, batch_loss: 0.0842, loss: 0.2158 ||:  20%|#9        | 1414/7204 [05:33<25:33,  3.77it/s]
2022-03-21 23:28:41,695 - INFO - tqdm - f1: 0.8160, accuracy: 0.9177, batch_loss: 0.0564, loss: 0.2155 ||:  20%|##        | 1456/7204 [05:43<28:34,  3.35it/s]
2022-03-21 23:28:51,727 - INFO - tqdm - f1: 0.8149, accuracy: 0.9169, batch_loss: 0.1482, loss: 0.2171 ||:  21%|##        | 1499/7204 [05:54<20:59,  4.53it/s]
2022-03-21 23:29:01,983 - INFO - tqdm - f1: 0.8128, accuracy: 0.9163, batch_loss: 0.1063, loss: 0.2175 ||:  21%|##1       | 1542/7204 [06:04<25:54,  3.64it/s]
2022-03-21 23:29:12,051 - INFO - tqdm - f1: 0.8133, accuracy: 0.9163, batch_loss: 0.3641, loss: 0.2172 ||:  22%|##2       | 1585/7204 [06:14<20:32,  4.56it/s]
2022-03-21 23:29:22,086 - INFO - tqdm - f1: 0.8142, accuracy: 0.9165, batch_loss: 0.1407, loss: 0.2169 ||:  23%|##2       | 1630/7204 [06:24<17:08,  5.42it/s]
2022-03-21 23:29:32,139 - INFO - tqdm - f1: 0.8136, accuracy: 0.9158, batch_loss: 0.5107, loss: 0.2182 ||:  23%|##3       | 1674/7204 [06:34<17:57,  5.13it/s]
2022-03-21 23:29:42,255 - INFO - tqdm - f1: 0.8144, accuracy: 0.9158, batch_loss: 0.2432, loss: 0.2186 ||:  24%|##3       | 1716/7204 [06:44<28:30,  3.21it/s]
2022-03-21 23:29:52,414 - INFO - tqdm - f1: 0.8141, accuracy: 0.9157, batch_loss: 0.0300, loss: 0.2190 ||:  24%|##4       | 1758/7204 [06:54<20:51,  4.35it/s]
2022-03-21 23:30:02,623 - INFO - tqdm - f1: 0.8145, accuracy: 0.9159, batch_loss: 0.2740, loss: 0.2187 ||:  25%|##5       | 1802/7204 [07:04<18:52,  4.77it/s]
2022-03-21 23:30:12,803 - INFO - tqdm - f1: 0.8142, accuracy: 0.9161, batch_loss: 0.3062, loss: 0.2186 ||:  26%|##5       | 1843/7204 [07:15<20:00,  4.47it/s]
2022-03-21 23:30:22,910 - INFO - tqdm - f1: 0.8128, accuracy: 0.9155, batch_loss: 0.1031, loss: 0.2196 ||:  26%|##6       | 1881/7204 [07:25<28:27,  3.12it/s]
2022-03-21 23:30:33,147 - INFO - tqdm - f1: 0.8128, accuracy: 0.9159, batch_loss: 0.1817, loss: 0.2187 ||:  27%|##6       | 1924/7204 [07:35<23:22,  3.77it/s]
2022-03-21 23:30:43,271 - INFO - tqdm - f1: 0.8130, accuracy: 0.9160, batch_loss: 0.0962, loss: 0.2187 ||:  27%|##7       | 1967/7204 [07:45<23:44,  3.68it/s]
2022-03-21 23:30:53,336 - INFO - tqdm - f1: 0.8129, accuracy: 0.9160, batch_loss: 0.1505, loss: 0.2185 ||:  28%|##7       | 2008/7204 [07:55<21:11,  4.09it/s]
2022-03-21 23:31:03,543 - INFO - tqdm - f1: 0.8128, accuracy: 0.9161, batch_loss: 0.0373, loss: 0.2185 ||:  28%|##8       | 2051/7204 [08:05<24:49,  3.46it/s]
2022-03-21 23:31:13,616 - INFO - tqdm - f1: 0.8121, accuracy: 0.9157, batch_loss: 0.3306, loss: 0.2190 ||:  29%|##9       | 2093/7204 [08:15<22:18,  3.82it/s]
2022-03-21 23:31:23,665 - INFO - tqdm - f1: 0.8121, accuracy: 0.9160, batch_loss: 0.7573, loss: 0.2185 ||:  30%|##9       | 2136/7204 [08:25<18:33,  4.55it/s]
2022-03-21 23:31:33,868 - INFO - tqdm - f1: 0.8114, accuracy: 0.9158, batch_loss: 0.1622, loss: 0.2183 ||:  30%|###       | 2181/7204 [08:36<18:27,  4.54it/s]
2022-03-21 23:31:43,969 - INFO - tqdm - f1: 0.8117, accuracy: 0.9162, batch_loss: 0.0537, loss: 0.2174 ||:  31%|###       | 2222/7204 [08:46<19:54,  4.17it/s]
2022-03-21 23:31:53,972 - INFO - tqdm - f1: 0.8117, accuracy: 0.9159, batch_loss: 0.2346, loss: 0.2176 ||:  31%|###1      | 2266/7204 [08:56<20:11,  4.08it/s]
2022-03-21 23:32:04,116 - INFO - tqdm - f1: 0.8114, accuracy: 0.9158, batch_loss: 0.2614, loss: 0.2174 ||:  32%|###2      | 2311/7204 [09:06<14:49,  5.50it/s]
2022-03-21 23:32:14,123 - INFO - tqdm - f1: 0.8119, accuracy: 0.9160, batch_loss: 0.2536, loss: 0.2169 ||:  33%|###2      | 2349/7204 [09:16<18:19,  4.42it/s]
2022-03-21 23:32:24,333 - INFO - tqdm - f1: 0.8108, accuracy: 0.9156, batch_loss: 0.0567, loss: 0.2176 ||:  33%|###3      | 2391/7204 [09:26<20:12,  3.97it/s]
2022-03-21 23:32:34,479 - INFO - tqdm - f1: 0.8108, accuracy: 0.9156, batch_loss: 0.2710, loss: 0.2179 ||:  34%|###3      | 2431/7204 [09:36<19:26,  4.09it/s]
2022-03-21 23:32:44,576 - INFO - tqdm - f1: 0.8105, accuracy: 0.9153, batch_loss: 0.2409, loss: 0.2184 ||:  34%|###4      | 2474/7204 [09:46<17:07,  4.60it/s]
2022-03-21 23:32:54,614 - INFO - tqdm - f1: 0.8106, accuracy: 0.9152, batch_loss: 0.1006, loss: 0.2187 ||:  35%|###4      | 2519/7204 [09:56<21:10,  3.69it/s]
2022-03-21 23:33:04,638 - INFO - tqdm - f1: 0.8097, accuracy: 0.9148, batch_loss: 0.3027, loss: 0.2193 ||:  36%|###5      | 2562/7204 [10:06<18:22,  4.21it/s]
2022-03-21 23:33:14,737 - INFO - tqdm - f1: 0.8096, accuracy: 0.9149, batch_loss: 0.3341, loss: 0.2193 ||:  36%|###6      | 2604/7204 [10:17<15:10,  5.05it/s]
2022-03-21 23:33:24,848 - INFO - tqdm - f1: 0.8101, accuracy: 0.9149, batch_loss: 0.3036, loss: 0.2191 ||:  37%|###6      | 2649/7204 [10:27<14:13,  5.34it/s]
2022-03-21 23:33:34,858 - INFO - tqdm - f1: 0.8106, accuracy: 0.9151, batch_loss: 0.1353, loss: 0.2188 ||:  37%|###7      | 2689/7204 [10:37<13:30,  5.57it/s]
2022-03-21 23:33:45,022 - INFO - tqdm - f1: 0.8109, accuracy: 0.9152, batch_loss: 0.0385, loss: 0.2185 ||:  38%|###7      | 2727/7204 [10:47<21:43,  3.44it/s]
2022-03-21 23:33:55,129 - INFO - tqdm - f1: 0.8107, accuracy: 0.9152, batch_loss: 0.2363, loss: 0.2186 ||:  38%|###8      | 2768/7204 [10:57<17:08,  4.31it/s]
2022-03-21 23:34:05,200 - INFO - tqdm - f1: 0.8104, accuracy: 0.9151, batch_loss: 0.1259, loss: 0.2186 ||:  39%|###8      | 2805/7204 [11:07<22:53,  3.20it/s]
2022-03-21 23:34:15,353 - INFO - tqdm - f1: 0.8104, accuracy: 0.9152, batch_loss: 0.0444, loss: 0.2185 ||:  40%|###9      | 2846/7204 [11:17<15:42,  4.62it/s]
2022-03-21 23:34:25,488 - INFO - tqdm - f1: 0.8102, accuracy: 0.9149, batch_loss: 0.2922, loss: 0.2189 ||:  40%|####      | 2892/7204 [11:27<15:12,  4.72it/s]
2022-03-21 23:34:35,605 - INFO - tqdm - f1: 0.8095, accuracy: 0.9148, batch_loss: 0.1706, loss: 0.2193 ||:  41%|####      | 2935/7204 [11:37<19:21,  3.67it/s]
2022-03-21 23:34:45,648 - INFO - tqdm - f1: 0.8092, accuracy: 0.9148, batch_loss: 0.3287, loss: 0.2191 ||:  41%|####1     | 2978/7204 [11:47<15:18,  4.60it/s]
2022-03-21 23:34:55,745 - INFO - tqdm - f1: 0.8095, accuracy: 0.9149, batch_loss: 0.0623, loss: 0.2188 ||:  42%|####1     | 3019/7204 [11:58<14:08,  4.93it/s]
2022-03-21 23:35:05,812 - INFO - tqdm - f1: 0.8094, accuracy: 0.9150, batch_loss: 0.2155, loss: 0.2185 ||:  43%|####2     | 3065/7204 [12:08<13:37,  5.06it/s]
2022-03-21 23:35:16,016 - INFO - tqdm - f1: 0.8095, accuracy: 0.9149, batch_loss: 0.2348, loss: 0.2188 ||:  43%|####3     | 3113/7204 [12:18<15:52,  4.29it/s]
2022-03-21 23:35:26,143 - INFO - tqdm - f1: 0.8097, accuracy: 0.9149, batch_loss: 0.0430, loss: 0.2185 ||:  44%|####3     | 3157/7204 [12:28<14:05,  4.79it/s]
2022-03-21 23:35:36,551 - INFO - tqdm - f1: 0.8096, accuracy: 0.9148, batch_loss: 0.2935, loss: 0.2186 ||:  44%|####4     | 3197/7204 [12:38<18:18,  3.65it/s]
2022-03-21 23:35:46,556 - INFO - tqdm - f1: 0.8098, accuracy: 0.9151, batch_loss: 0.1675, loss: 0.2180 ||:  45%|####4     | 3239/7204 [12:48<13:09,  5.02it/s]
2022-03-21 23:35:56,902 - INFO - tqdm - f1: 0.8096, accuracy: 0.9150, batch_loss: 0.0320, loss: 0.2181 ||:  46%|####5     | 3281/7204 [12:59<18:04,  3.62it/s]
2022-03-21 23:36:07,126 - INFO - tqdm - f1: 0.8091, accuracy: 0.9149, batch_loss: 0.2728, loss: 0.2183 ||:  46%|####6     | 3323/7204 [13:09<16:30,  3.92it/s]
2022-03-21 23:36:17,461 - INFO - tqdm - f1: 0.8089, accuracy: 0.9148, batch_loss: 0.1960, loss: 0.2185 ||:  47%|####6     | 3363/7204 [13:19<20:05,  3.19it/s]
2022-03-21 23:36:27,536 - INFO - tqdm - f1: 0.8085, accuracy: 0.9147, batch_loss: 0.0897, loss: 0.2183 ||:  47%|####7     | 3406/7204 [13:29<14:51,  4.26it/s]
2022-03-21 23:36:37,744 - INFO - tqdm - f1: 0.8085, accuracy: 0.9147, batch_loss: 0.0464, loss: 0.2186 ||:  48%|####7     | 3445/7204 [13:40<19:22,  3.23it/s]
2022-03-21 23:36:47,824 - INFO - tqdm - f1: 0.8084, accuracy: 0.9148, batch_loss: 0.4423, loss: 0.2187 ||:  48%|####8     | 3490/7204 [13:50<14:18,  4.32it/s]
2022-03-21 23:36:57,918 - INFO - tqdm - f1: 0.8084, accuracy: 0.9146, batch_loss: 0.0660, loss: 0.2190 ||:  49%|####9     | 3539/7204 [14:00<11:27,  5.33it/s]
2022-03-21 23:37:08,230 - INFO - tqdm - f1: 0.8080, accuracy: 0.9145, batch_loss: 0.1923, loss: 0.2191 ||:  50%|####9     | 3584/7204 [14:10<15:21,  3.93it/s]
2022-03-21 23:37:18,239 - INFO - tqdm - f1: 0.8084, accuracy: 0.9144, batch_loss: 0.0619, loss: 0.2193 ||:  50%|#####     | 3628/7204 [14:20<14:47,  4.03it/s]
2022-03-21 23:37:28,306 - INFO - tqdm - f1: 0.8082, accuracy: 0.9146, batch_loss: 0.1328, loss: 0.2189 ||:  51%|#####     | 3668/7204 [14:30<13:22,  4.40it/s]
2022-03-21 23:37:38,319 - INFO - tqdm - f1: 0.8079, accuracy: 0.9145, batch_loss: 0.3082, loss: 0.2191 ||:  52%|#####1    | 3711/7204 [14:40<11:48,  4.93it/s]
2022-03-21 23:37:48,503 - INFO - tqdm - f1: 0.8073, accuracy: 0.9142, batch_loss: 0.1412, loss: 0.2198 ||:  52%|#####2    | 3755/7204 [14:50<13:08,  4.37it/s]
2022-03-21 23:37:58,642 - INFO - tqdm - f1: 0.8070, accuracy: 0.9140, batch_loss: 0.3033, loss: 0.2203 ||:  53%|#####2    | 3802/7204 [15:00<11:09,  5.08it/s]
2022-03-21 23:38:08,662 - INFO - tqdm - f1: 0.8069, accuracy: 0.9139, batch_loss: 0.1163, loss: 0.2204 ||:  53%|#####3    | 3848/7204 [15:10<11:01,  5.07it/s]
2022-03-21 23:38:18,667 - INFO - tqdm - f1: 0.8064, accuracy: 0.9137, batch_loss: 0.1563, loss: 0.2207 ||:  54%|#####3    | 3890/7204 [15:20<12:52,  4.29it/s]
2022-03-21 23:38:28,839 - INFO - tqdm - f1: 0.8062, accuracy: 0.9134, batch_loss: 0.1805, loss: 0.2211 ||:  55%|#####4    | 3934/7204 [15:31<12:48,  4.25it/s]
2022-03-21 23:38:38,871 - INFO - tqdm - f1: 0.8063, accuracy: 0.9134, batch_loss: 0.2039, loss: 0.2212 ||:  55%|#####5    | 3975/7204 [15:41<10:47,  4.98it/s]
2022-03-21 23:38:48,873 - INFO - tqdm - f1: 0.8062, accuracy: 0.9134, batch_loss: 0.3845, loss: 0.2213 ||:  56%|#####5    | 4018/7204 [15:51<09:57,  5.34it/s]
2022-03-21 23:38:58,994 - INFO - tqdm - f1: 0.8057, accuracy: 0.9133, batch_loss: 0.2103, loss: 0.2214 ||:  56%|#####6    | 4062/7204 [16:01<11:43,  4.47it/s]
2022-03-21 23:39:09,177 - INFO - tqdm - f1: 0.8055, accuracy: 0.9132, batch_loss: 0.1686, loss: 0.2217 ||:  57%|#####7    | 4108/7204 [16:11<11:58,  4.31it/s]
2022-03-21 23:39:19,188 - INFO - tqdm - f1: 0.8065, accuracy: 0.9134, batch_loss: 0.1762, loss: 0.2219 ||:  58%|#####8    | 4202/7204 [16:21<07:30,  6.67it/s]
2022-03-21 23:39:29,311 - INFO - tqdm - f1: 0.8063, accuracy: 0.9133, batch_loss: 0.1762, loss: 0.2220 ||:  59%|#####9    | 4261/7204 [16:31<09:41,  5.06it/s]
2022-03-21 23:39:39,394 - INFO - tqdm - f1: 0.8057, accuracy: 0.9130, batch_loss: 0.0448, loss: 0.2220 ||:  60%|#####9    | 4320/7204 [16:41<12:13,  3.93it/s]
2022-03-21 23:39:49,407 - INFO - tqdm - f1: 0.8055, accuracy: 0.9129, batch_loss: 0.0867, loss: 0.2219 ||:  61%|######    | 4380/7204 [16:51<08:26,  5.58it/s]
2022-03-21 23:39:59,469 - INFO - tqdm - f1: 0.8053, accuracy: 0.9128, batch_loss: 0.2983, loss: 0.2220 ||:  61%|######1   | 4426/7204 [17:01<08:42,  5.31it/s]
2022-03-21 23:40:09,730 - INFO - tqdm - f1: 0.8057, accuracy: 0.9128, batch_loss: 0.3477, loss: 0.2219 ||:  62%|######2   | 4470/7204 [17:12<12:24,  3.67it/s]
2022-03-21 23:40:19,754 - INFO - tqdm - f1: 0.8056, accuracy: 0.9128, batch_loss: 0.4406, loss: 0.2221 ||:  63%|######2   | 4508/7204 [17:22<09:45,  4.60it/s]
2022-03-21 23:40:29,865 - INFO - tqdm - f1: 0.8055, accuracy: 0.9128, batch_loss: 0.1737, loss: 0.2221 ||:  63%|######3   | 4552/7204 [17:32<09:28,  4.66it/s]
2022-03-21 23:40:40,066 - INFO - tqdm - f1: 0.8053, accuracy: 0.9128, batch_loss: 0.2369, loss: 0.2220 ||:  64%|######3   | 4597/7204 [17:42<08:55,  4.86it/s]
2022-03-21 23:40:50,085 - INFO - tqdm - f1: 0.8053, accuracy: 0.9129, batch_loss: 0.1492, loss: 0.2219 ||:  64%|######4   | 4640/7204 [17:52<10:46,  3.97it/s]
2022-03-21 23:41:00,274 - INFO - tqdm - f1: 0.8049, accuracy: 0.9128, batch_loss: 0.0967, loss: 0.2219 ||:  65%|######5   | 4684/7204 [18:02<10:49,  3.88it/s]
2022-03-21 23:41:10,317 - INFO - tqdm - f1: 0.8051, accuracy: 0.9128, batch_loss: 0.1505, loss: 0.2220 ||:  66%|######5   | 4729/7204 [18:12<10:17,  4.01it/s]
2022-03-21 23:41:20,398 - INFO - tqdm - f1: 0.8048, accuracy: 0.9126, batch_loss: 0.6798, loss: 0.2222 ||:  66%|######6   | 4771/7204 [18:22<08:53,  4.56it/s]
2022-03-21 23:41:30,478 - INFO - tqdm - f1: 0.8049, accuracy: 0.9128, batch_loss: 0.7450, loss: 0.2220 ||:  67%|######6   | 4810/7204 [18:32<08:17,  4.81it/s]
2022-03-21 23:41:40,732 - INFO - tqdm - f1: 0.8047, accuracy: 0.9127, batch_loss: 0.0874, loss: 0.2222 ||:  67%|######7   | 4855/7204 [18:43<10:12,  3.84it/s]
2022-03-21 23:41:50,997 - INFO - tqdm - f1: 0.8044, accuracy: 0.9125, batch_loss: 0.0326, loss: 0.2226 ||:  68%|######8   | 4901/7204 [18:53<10:09,  3.78it/s]
2022-03-21 23:42:01,152 - INFO - tqdm - f1: 0.8039, accuracy: 0.9124, batch_loss: 0.0616, loss: 0.2230 ||:  69%|######8   | 4942/7204 [19:03<10:47,  3.49it/s]
2022-03-21 23:42:11,225 - INFO - tqdm - f1: 0.8040, accuracy: 0.9124, batch_loss: 0.1951, loss: 0.2230 ||:  69%|######9   | 4986/7204 [19:13<07:47,  4.75it/s]
2022-03-21 23:42:21,351 - INFO - tqdm - f1: 0.8040, accuracy: 0.9125, batch_loss: 0.0118, loss: 0.2227 ||:  70%|######9   | 5028/7204 [19:23<09:45,  3.72it/s]
2022-03-21 23:42:31,378 - INFO - tqdm - f1: 0.8040, accuracy: 0.9125, batch_loss: 0.1834, loss: 0.2226 ||:  70%|#######   | 5067/7204 [19:33<07:43,  4.61it/s]
2022-03-21 23:42:41,697 - INFO - tqdm - f1: 0.8037, accuracy: 0.9123, batch_loss: 0.2211, loss: 0.2229 ||:  71%|#######   | 5110/7204 [19:43<09:39,  3.61it/s]
2022-03-21 23:42:51,891 - INFO - tqdm - f1: 0.8037, accuracy: 0.9124, batch_loss: 0.0625, loss: 0.2228 ||:  72%|#######1  | 5155/7204 [19:54<09:54,  3.45it/s]
2022-03-21 23:43:02,006 - INFO - tqdm - f1: 0.8040, accuracy: 0.9125, batch_loss: 0.2828, loss: 0.2227 ||:  72%|#######2  | 5199/7204 [20:04<06:30,  5.14it/s]
2022-03-21 23:43:12,070 - INFO - tqdm - f1: 0.8041, accuracy: 0.9126, batch_loss: 0.1942, loss: 0.2225 ||:  73%|#######2  | 5242/7204 [20:14<09:05,  3.60it/s]
2022-03-21 23:43:22,282 - INFO - tqdm - f1: 0.8038, accuracy: 0.9125, batch_loss: 0.1031, loss: 0.2225 ||:  73%|#######3  | 5284/7204 [20:24<08:01,  3.99it/s]
2022-03-21 23:43:32,474 - INFO - tqdm - f1: 0.8039, accuracy: 0.9125, batch_loss: 0.0682, loss: 0.2224 ||:  74%|#######3  | 5328/7204 [20:34<07:17,  4.29it/s]
2022-03-21 23:43:42,732 - INFO - tqdm - f1: 0.8037, accuracy: 0.9125, batch_loss: 0.1585, loss: 0.2225 ||:  75%|#######4  | 5371/7204 [20:45<08:27,  3.61it/s]
2022-03-21 23:43:52,764 - INFO - tqdm - f1: 0.8037, accuracy: 0.9124, batch_loss: 0.5496, loss: 0.2226 ||:  75%|#######5  | 5416/7204 [20:55<06:49,  4.36it/s]
2022-03-21 23:44:02,961 - INFO - tqdm - f1: 0.8038, accuracy: 0.9124, batch_loss: 0.0931, loss: 0.2226 ||:  76%|#######5  | 5458/7204 [21:05<08:16,  3.51it/s]
2022-03-21 23:44:13,063 - INFO - tqdm - f1: 0.8035, accuracy: 0.9123, batch_loss: 0.2973, loss: 0.2228 ||:  76%|#######6  | 5503/7204 [21:15<06:42,  4.23it/s]
2022-03-21 23:44:23,064 - INFO - tqdm - f1: 0.8036, accuracy: 0.9122, batch_loss: 0.0895, loss: 0.2231 ||:  77%|#######7  | 5551/7204 [21:25<07:11,  3.83it/s]
2022-03-21 23:44:33,259 - INFO - tqdm - f1: 0.8037, accuracy: 0.9122, batch_loss: 0.1396, loss: 0.2230 ||:  78%|#######7  | 5594/7204 [21:35<05:33,  4.83it/s]
2022-03-21 23:44:43,331 - INFO - tqdm - f1: 0.8037, accuracy: 0.9121, batch_loss: 0.4261, loss: 0.2231 ||:  78%|#######8  | 5640/7204 [21:45<05:18,  4.91it/s]
2022-03-21 23:44:53,402 - INFO - tqdm - f1: 0.8037, accuracy: 0.9120, batch_loss: 0.2614, loss: 0.2235 ||:  79%|#######8  | 5685/7204 [21:55<06:04,  4.17it/s]
2022-03-21 23:45:03,469 - INFO - tqdm - f1: 0.8037, accuracy: 0.9120, batch_loss: 0.1127, loss: 0.2235 ||:  80%|#######9  | 5729/7204 [22:05<05:49,  4.22it/s]
2022-03-21 23:45:13,613 - INFO - tqdm - f1: 0.8039, accuracy: 0.9119, batch_loss: 0.3372, loss: 0.2237 ||:  80%|########  | 5772/7204 [22:15<05:27,  4.37it/s]
2022-03-21 23:45:23,648 - INFO - tqdm - f1: 0.8038, accuracy: 0.9119, batch_loss: 0.2396, loss: 0.2236 ||:  81%|########  | 5816/7204 [22:25<04:52,  4.74it/s]
2022-03-21 23:45:33,710 - INFO - tqdm - f1: 0.8037, accuracy: 0.9119, batch_loss: 0.2463, loss: 0.2238 ||:  81%|########1 | 5863/7204 [22:35<05:24,  4.13it/s]
2022-03-21 23:45:44,011 - INFO - tqdm - f1: 0.8038, accuracy: 0.9120, batch_loss: 0.1125, loss: 0.2237 ||:  82%|########1 | 5904/7204 [22:46<05:27,  3.97it/s]
2022-03-21 23:45:54,160 - INFO - tqdm - f1: 0.8038, accuracy: 0.9119, batch_loss: 0.0613, loss: 0.2238 ||:  83%|########2 | 5948/7204 [22:56<04:48,  4.35it/s]
2022-03-21 23:46:04,265 - INFO - tqdm - f1: 0.8039, accuracy: 0.9120, batch_loss: 0.3821, loss: 0.2236 ||:  83%|########3 | 5992/7204 [23:06<04:00,  5.03it/s]
2022-03-21 23:46:14,340 - INFO - tqdm - f1: 0.8040, accuracy: 0.9120, batch_loss: 0.1839, loss: 0.2235 ||:  84%|########3 | 6037/7204 [23:16<04:41,  4.14it/s]
2022-03-21 23:46:24,444 - INFO - tqdm - f1: 0.8039, accuracy: 0.9121, batch_loss: 0.4085, loss: 0.2235 ||:  84%|########4 | 6078/7204 [23:26<04:42,  3.99it/s]
2022-03-21 23:46:34,638 - INFO - tqdm - f1: 0.8040, accuracy: 0.9120, batch_loss: 0.2758, loss: 0.2238 ||:  85%|########4 | 6122/7204 [23:36<04:23,  4.11it/s]
2022-03-21 23:46:44,751 - INFO - tqdm - f1: 0.8040, accuracy: 0.9120, batch_loss: 0.1238, loss: 0.2238 ||:  86%|########5 | 6163/7204 [23:47<05:17,  3.28it/s]
2022-03-21 23:46:54,935 - INFO - tqdm - f1: 0.8037, accuracy: 0.9118, batch_loss: 0.2625, loss: 0.2241 ||:  86%|########6 | 6208/7204 [23:57<03:41,  4.49it/s]
2022-03-21 23:47:05,126 - INFO - tqdm - f1: 0.8038, accuracy: 0.9118, batch_loss: 0.1300, loss: 0.2243 ||:  87%|########6 | 6253/7204 [24:07<03:11,  4.97it/s]
2022-03-21 23:47:15,324 - INFO - tqdm - f1: 0.8036, accuracy: 0.9118, batch_loss: 0.2612, loss: 0.2243 ||:  87%|########7 | 6295/7204 [24:17<04:24,  3.44it/s]
2022-03-21 23:47:25,579 - INFO - tqdm - f1: 0.8032, accuracy: 0.9118, batch_loss: 0.1134, loss: 0.2244 ||:  88%|########8 | 6340/7204 [24:27<03:41,  3.90it/s]
2022-03-21 23:47:35,735 - INFO - tqdm - f1: 0.8034, accuracy: 0.9118, batch_loss: 0.3679, loss: 0.2245 ||:  89%|########8 | 6384/7204 [24:38<03:25,  3.99it/s]
2022-03-21 23:47:45,808 - INFO - tqdm - f1: 0.8030, accuracy: 0.9116, batch_loss: 0.4377, loss: 0.2249 ||:  89%|########9 | 6432/7204 [24:48<02:47,  4.61it/s]
2022-03-21 23:47:55,993 - INFO - tqdm - f1: 0.8027, accuracy: 0.9115, batch_loss: 0.1740, loss: 0.2250 ||:  90%|########9 | 6476/7204 [24:58<03:59,  3.03it/s]
2022-03-21 23:48:06,063 - INFO - tqdm - f1: 0.8024, accuracy: 0.9114, batch_loss: 0.0494, loss: 0.2250 ||:  91%|######### | 6520/7204 [25:08<02:21,  4.82it/s]
2022-03-21 23:48:16,118 - INFO - tqdm - f1: 0.8026, accuracy: 0.9114, batch_loss: 0.2741, loss: 0.2249 ||:  91%|#########1| 6562/7204 [25:18<02:17,  4.68it/s]
2022-03-21 23:48:26,296 - INFO - tqdm - f1: 0.8021, accuracy: 0.9113, batch_loss: 0.5628, loss: 0.2249 ||:  92%|#########1| 6604/7204 [25:28<02:51,  3.50it/s]
2022-03-21 23:48:36,469 - INFO - tqdm - f1: 0.8018, accuracy: 0.9112, batch_loss: 0.3292, loss: 0.2250 ||:  92%|#########2| 6644/7204 [25:38<02:31,  3.70it/s]
2022-03-21 23:48:46,582 - INFO - tqdm - f1: 0.8014, accuracy: 0.9111, batch_loss: 0.0158, loss: 0.2251 ||:  93%|#########2| 6687/7204 [25:48<02:30,  3.44it/s]
2022-03-21 23:48:56,707 - INFO - tqdm - f1: 0.8013, accuracy: 0.9110, batch_loss: 0.3696, loss: 0.2250 ||:  93%|#########3| 6732/7204 [25:58<01:39,  4.76it/s]
2022-03-21 23:49:06,934 - INFO - tqdm - f1: 0.8012, accuracy: 0.9110, batch_loss: 0.5434, loss: 0.2252 ||:  94%|#########4| 6776/7204 [26:09<01:48,  3.93it/s]
2022-03-21 23:49:17,235 - INFO - tqdm - f1: 0.8010, accuracy: 0.9110, batch_loss: 0.0167, loss: 0.2252 ||:  95%|#########4| 6816/7204 [26:19<01:50,  3.51it/s]
2022-03-21 23:49:27,409 - INFO - tqdm - f1: 0.8012, accuracy: 0.9110, batch_loss: 0.0218, loss: 0.2251 ||:  95%|#########5| 6860/7204 [26:29<01:37,  3.52it/s]
2022-03-21 23:49:37,476 - INFO - tqdm - f1: 0.8011, accuracy: 0.9111, batch_loss: 0.1008, loss: 0.2251 ||:  96%|#########5| 6903/7204 [26:39<01:18,  3.82it/s]
2022-03-21 23:49:47,618 - INFO - tqdm - f1: 0.8012, accuracy: 0.9111, batch_loss: 0.0742, loss: 0.2251 ||:  96%|#########6| 6947/7204 [26:49<01:04,  3.98it/s]
2022-03-21 23:49:57,722 - INFO - tqdm - f1: 0.8010, accuracy: 0.9111, batch_loss: 0.3456, loss: 0.2252 ||:  97%|#########7| 6992/7204 [26:59<00:42,  5.03it/s]
2022-03-21 23:50:07,826 - INFO - tqdm - f1: 0.8010, accuracy: 0.9110, batch_loss: 0.3621, loss: 0.2252 ||:  98%|#########7| 7032/7204 [27:10<00:35,  4.82it/s]
2022-03-21 23:50:17,947 - INFO - tqdm - f1: 0.8008, accuracy: 0.9110, batch_loss: 0.1856, loss: 0.2251 ||:  98%|#########8| 7074/7204 [27:20<00:32,  3.98it/s]
2022-03-21 23:50:28,021 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.0122, loss: 0.2255 ||:  99%|#########8| 7118/7204 [27:30<00:24,  3.55it/s]
2022-03-21 23:50:38,072 - INFO - tqdm - f1: 0.8004, accuracy: 0.9108, batch_loss: 0.1823, loss: 0.2256 ||:  99%|#########9| 7161/7204 [27:40<00:08,  5.20it/s]
2022-03-21 23:50:39,855 - INFO - tqdm - f1: 0.8004, accuracy: 0.9108, batch_loss: 0.0950, loss: 0.2255 ||: 100%|#########9| 7168/7204 [27:42<00:07,  4.54it/s]
2022-03-21 23:50:39,998 - INFO - tqdm - f1: 0.8004, accuracy: 0.9108, batch_loss: 0.1006, loss: 0.2255 ||: 100%|#########9| 7169/7204 [27:42<00:06,  5.07it/s]
2022-03-21 23:50:40,197 - INFO - tqdm - f1: 0.8004, accuracy: 0.9108, batch_loss: 0.4296, loss: 0.2255 ||: 100%|#########9| 7170/7204 [27:42<00:06,  5.05it/s]
2022-03-21 23:50:40,614 - INFO - tqdm - f1: 0.8004, accuracy: 0.9108, batch_loss: 0.0261, loss: 0.2255 ||: 100%|#########9| 7171/7204 [27:42<00:08,  3.79it/s]
2022-03-21 23:50:40,823 - INFO - tqdm - f1: 0.8004, accuracy: 0.9108, batch_loss: 0.2452, loss: 0.2255 ||: 100%|#########9| 7172/7204 [27:43<00:07,  4.05it/s]
2022-03-21 23:50:41,123 - INFO - tqdm - f1: 0.8004, accuracy: 0.9108, batch_loss: 0.0483, loss: 0.2255 ||: 100%|#########9| 7173/7204 [27:43<00:08,  3.80it/s]
2022-03-21 23:50:41,308 - INFO - tqdm - f1: 0.8004, accuracy: 0.9108, batch_loss: 0.0525, loss: 0.2254 ||: 100%|#########9| 7174/7204 [27:43<00:07,  4.17it/s]
2022-03-21 23:50:41,520 - INFO - tqdm - f1: 0.8004, accuracy: 0.9109, batch_loss: 0.0562, loss: 0.2254 ||: 100%|#########9| 7175/7204 [27:43<00:06,  4.32it/s]
2022-03-21 23:50:41,712 - INFO - tqdm - f1: 0.8004, accuracy: 0.9108, batch_loss: 0.3974, loss: 0.2254 ||: 100%|#########9| 7176/7204 [27:43<00:06,  4.56it/s]
2022-03-21 23:50:42,102 - INFO - tqdm - f1: 0.8004, accuracy: 0.9109, batch_loss: 0.0092, loss: 0.2254 ||: 100%|#########9| 7177/7204 [27:44<00:07,  3.69it/s]
2022-03-21 23:50:42,315 - INFO - tqdm - f1: 0.8004, accuracy: 0.9109, batch_loss: 0.0905, loss: 0.2254 ||: 100%|#########9| 7178/7204 [27:44<00:06,  3.95it/s]
2022-03-21 23:50:42,485 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.2604, loss: 0.2254 ||: 100%|#########9| 7179/7204 [27:44<00:05,  4.38it/s]
2022-03-21 23:50:42,624 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.2257, loss: 0.2254 ||: 100%|#########9| 7180/7204 [27:44<00:04,  4.96it/s]
2022-03-21 23:50:42,839 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.4060, loss: 0.2254 ||: 100%|#########9| 7181/7204 [27:45<00:04,  4.87it/s]
2022-03-21 23:50:43,048 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.3971, loss: 0.2254 ||: 100%|#########9| 7182/7204 [27:45<00:04,  4.84it/s]
2022-03-21 23:50:43,232 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.1569, loss: 0.2254 ||: 100%|#########9| 7183/7204 [27:45<00:04,  5.01it/s]
2022-03-21 23:50:43,444 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.1793, loss: 0.2254 ||: 100%|#########9| 7184/7204 [27:45<00:04,  4.91it/s]
2022-03-21 23:50:43,645 - INFO - tqdm - f1: 0.8005, accuracy: 0.9108, batch_loss: 0.2908, loss: 0.2254 ||: 100%|#########9| 7185/7204 [27:45<00:03,  4.94it/s]
2022-03-21 23:50:43,835 - INFO - tqdm - f1: 0.8005, accuracy: 0.9108, batch_loss: 0.1979, loss: 0.2254 ||: 100%|#########9| 7186/7204 [27:46<00:03,  5.02it/s]
2022-03-21 23:50:44,137 - INFO - tqdm - f1: 0.8005, accuracy: 0.9108, batch_loss: 0.4120, loss: 0.2255 ||: 100%|#########9| 7187/7204 [27:46<00:03,  4.35it/s]
2022-03-21 23:50:44,311 - INFO - tqdm - f1: 0.8005, accuracy: 0.9108, batch_loss: 0.2368, loss: 0.2255 ||: 100%|#########9| 7188/7204 [27:46<00:03,  4.69it/s]
2022-03-21 23:50:44,493 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.1400, loss: 0.2254 ||: 100%|#########9| 7189/7204 [27:46<00:03,  4.91it/s]
2022-03-21 23:50:44,653 - INFO - tqdm - f1: 0.8005, accuracy: 0.9108, batch_loss: 0.2988, loss: 0.2255 ||: 100%|#########9| 7190/7204 [27:46<00:02,  5.24it/s]
2022-03-21 23:50:44,937 - INFO - tqdm - f1: 0.8005, accuracy: 0.9108, batch_loss: 0.2292, loss: 0.2255 ||: 100%|#########9| 7191/7204 [27:47<00:02,  4.57it/s]
2022-03-21 23:50:45,333 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.0168, loss: 0.2254 ||: 100%|#########9| 7192/7204 [27:47<00:03,  3.68it/s]
2022-03-21 23:50:45,777 - INFO - tqdm - f1: 0.8006, accuracy: 0.9109, batch_loss: 0.1249, loss: 0.2254 ||: 100%|#########9| 7193/7204 [27:48<00:03,  3.09it/s]
2022-03-21 23:50:46,144 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.0735, loss: 0.2254 ||: 100%|#########9| 7194/7204 [27:48<00:03,  2.97it/s]
2022-03-21 23:50:46,427 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.0127, loss: 0.2254 ||: 100%|#########9| 7195/7204 [27:48<00:02,  3.12it/s]
2022-03-21 23:50:46,807 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.2663, loss: 0.2254 ||: 100%|#########9| 7196/7204 [27:49<00:02,  2.96it/s]
2022-03-21 23:50:47,065 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.1810, loss: 0.2254 ||: 100%|#########9| 7197/7204 [27:49<00:02,  3.18it/s]
2022-03-21 23:50:47,256 - INFO - tqdm - f1: 0.8005, accuracy: 0.9108, batch_loss: 0.5607, loss: 0.2254 ||: 100%|#########9| 7198/7204 [27:49<00:01,  3.61it/s]
2022-03-21 23:50:47,457 - INFO - tqdm - f1: 0.8005, accuracy: 0.9108, batch_loss: 0.2642, loss: 0.2254 ||: 100%|#########9| 7199/7204 [27:49<00:01,  3.93it/s]
2022-03-21 23:50:47,726 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.1279, loss: 0.2254 ||: 100%|#########9| 7200/7204 [27:49<00:01,  3.87it/s]
2022-03-21 23:50:47,965 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.1535, loss: 0.2254 ||: 100%|#########9| 7201/7204 [27:50<00:00,  3.96it/s]
2022-03-21 23:50:48,198 - INFO - tqdm - f1: 0.8005, accuracy: 0.9108, batch_loss: 0.2846, loss: 0.2254 ||: 100%|#########9| 7202/7204 [27:50<00:00,  4.05it/s]
2022-03-21 23:50:48,640 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.0061, loss: 0.2254 ||: 100%|#########9| 7203/7204 [27:50<00:00,  3.27it/s]
2022-03-21 23:50:48,794 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.2364, loss: 0.2254 ||: 100%|##########| 7204/7204 [27:51<00:00,  3.85it/s]
2022-03-21 23:50:48,855 - INFO - tqdm - f1: 0.8005, accuracy: 0.9109, batch_loss: 0.2364, loss: 0.2254 ||: 100%|##########| 7204/7204 [27:51<00:00,  4.31it/s]
2022-03-21 23:50:48,891 - INFO - allennlp.training.trainer - Validating
2022-03-21 23:50:48,893 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 23:50:59,010 - INFO - tqdm - f1: 0.6551, accuracy: 0.8907, batch_loss: 0.8219, loss: 0.3867 ||:  29%|##9       | 92/313 [00:10<00:23,  9.40it/s]
2022-03-21 23:51:09,025 - INFO - tqdm - f1: 0.6614, accuracy: 0.8774, batch_loss: 0.7911, loss: 0.4174 ||:  58%|#####7    | 180/313 [00:20<00:14,  9.04it/s]
2022-03-21 23:51:19,081 - INFO - tqdm - f1: 0.6526, accuracy: 0.8727, batch_loss: 0.3263, loss: 0.4186 ||:  87%|########6 | 271/313 [00:30<00:04,  9.08it/s]
2022-03-21 23:51:23,722 - INFO - tqdm - f1: 0.6553, accuracy: 0.8700, batch_loss: 0.4017, loss: 0.4222 ||: 100%|##########| 313/313 [00:34<00:00,  9.49it/s]
2022-03-21 23:51:23,731 - INFO - tqdm - f1: 0.6553, accuracy: 0.8700, batch_loss: 0.4017, loss: 0.4222 ||: 100%|##########| 313/313 [00:34<00:00,  8.98it/s]
2022-03-21 23:51:23,776 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 23:51:23,780 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.911  |     0.870
2022-03-21 23:51:23,821 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.801  |     0.655
2022-03-21 23:51:23,824 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 23:51:23,825 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.225  |     0.422
2022-03-21 23:51:23,826 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13603.871  |       N/A
2022-03-21 23:51:23,828 - INFO - allennlp.training.trainer - Epoch duration: 0:28:26.110610
2022-03-21 23:51:23,829 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:50:05
2022-03-21 23:51:23,831 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-21 23:51:23,832 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-21 23:51:23,834 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 23:51:23,837 - INFO - allennlp.training.trainer - Training
2022-03-21 23:51:23,839 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-21 23:51:34,007 - INFO - tqdm - f1: 0.8561, accuracy: 0.9390, batch_loss: 0.2876, loss: 0.1718 ||:   1%|          | 41/7204 [00:10<25:56,  4.60it/s]
2022-03-21 23:51:44,143 - INFO - tqdm - f1: 0.8553, accuracy: 0.9330, batch_loss: 0.0120, loss: 0.1778 ||:   1%|1         | 83/7204 [00:20<35:38,  3.33it/s]
2022-03-21 23:51:54,162 - INFO - tqdm - f1: 0.8619, accuracy: 0.9360, batch_loss: 0.3041, loss: 0.1757 ||:   2%|1         | 124/7204 [00:30<31:52,  3.70it/s]
2022-03-21 23:52:04,222 - INFO - tqdm - f1: 0.8658, accuracy: 0.9361, batch_loss: 0.1308, loss: 0.1697 ||:   2%|2         | 173/7204 [00:40<22:00,  5.33it/s]
2022-03-21 23:52:14,394 - INFO - tqdm - f1: 0.8615, accuracy: 0.9343, batch_loss: 0.1184, loss: 0.1751 ||:   3%|3         | 217/7204 [00:50<29:18,  3.97it/s]
2022-03-21 23:52:24,599 - INFO - tqdm - f1: 0.8590, accuracy: 0.9346, batch_loss: 0.0823, loss: 0.1728 ||:   4%|3         | 260/7204 [01:00<25:58,  4.46it/s]
2022-03-21 23:52:34,705 - INFO - tqdm - f1: 0.8607, accuracy: 0.9346, batch_loss: 0.1894, loss: 0.1718 ||:   4%|4         | 307/7204 [01:10<23:44,  4.84it/s]
2022-03-21 23:52:44,763 - INFO - tqdm - f1: 0.8605, accuracy: 0.9345, batch_loss: 0.4003, loss: 0.1740 ||:   5%|4         | 349/7204 [01:20<28:38,  3.99it/s]
2022-03-21 23:52:54,874 - INFO - tqdm - f1: 0.8603, accuracy: 0.9354, batch_loss: 0.2243, loss: 0.1731 ||:   5%|5         | 391/7204 [01:31<27:39,  4.11it/s]
2022-03-21 23:53:04,975 - INFO - tqdm - f1: 0.8564, accuracy: 0.9329, batch_loss: 0.0080, loss: 0.1774 ||:   6%|6         | 436/7204 [01:41<30:29,  3.70it/s]
2022-03-21 23:53:14,996 - INFO - tqdm - f1: 0.8578, accuracy: 0.9323, batch_loss: 0.0876, loss: 0.1798 ||:   7%|6         | 481/7204 [01:51<23:33,  4.76it/s]
2022-03-21 23:53:25,303 - INFO - tqdm - f1: 0.8609, accuracy: 0.9338, batch_loss: 0.0238, loss: 0.1782 ||:   7%|7         | 523/7204 [02:01<33:06,  3.36it/s]
2022-03-21 23:53:35,587 - INFO - tqdm - f1: 0.8633, accuracy: 0.9345, batch_loss: 0.0165, loss: 0.1760 ||:   8%|7         | 566/7204 [02:11<24:04,  4.60it/s]
2022-03-21 23:53:45,772 - INFO - tqdm - f1: 0.8626, accuracy: 0.9343, batch_loss: 0.0148, loss: 0.1772 ||:   8%|8         | 608/7204 [02:21<30:40,  3.58it/s]
2022-03-21 23:53:55,932 - INFO - tqdm - f1: 0.8629, accuracy: 0.9340, batch_loss: 0.4798, loss: 0.1773 ||:   9%|9         | 653/7204 [02:32<21:15,  5.14it/s]
2022-03-21 23:54:06,239 - INFO - tqdm - f1: 0.8610, accuracy: 0.9333, batch_loss: 0.0209, loss: 0.1779 ||:  10%|9         | 695/7204 [02:42<27:04,  4.01it/s]
2022-03-21 23:54:16,307 - INFO - tqdm - f1: 0.8622, accuracy: 0.9336, batch_loss: 0.3022, loss: 0.1787 ||:  10%|#         | 739/7204 [02:52<21:32,  5.00it/s]
2022-03-21 23:54:26,434 - INFO - tqdm - f1: 0.8615, accuracy: 0.9337, batch_loss: 0.2185, loss: 0.1780 ||:  11%|#         | 781/7204 [03:02<21:56,  4.88it/s]
2022-03-21 23:54:36,544 - INFO - tqdm - f1: 0.8601, accuracy: 0.9331, batch_loss: 0.1529, loss: 0.1796 ||:  11%|#1        | 828/7204 [03:12<19:27,  5.46it/s]
2022-03-21 23:54:46,707 - INFO - tqdm - f1: 0.8589, accuracy: 0.9326, batch_loss: 0.0621, loss: 0.1810 ||:  12%|#2        | 873/7204 [03:22<24:08,  4.37it/s]
2022-03-21 23:54:56,801 - INFO - tqdm - f1: 0.8588, accuracy: 0.9325, batch_loss: 0.3420, loss: 0.1801 ||:  13%|#2        | 916/7204 [03:32<23:47,  4.40it/s]
2022-03-21 23:55:07,008 - INFO - tqdm - f1: 0.8613, accuracy: 0.9337, batch_loss: 0.0603, loss: 0.1779 ||:  13%|#3        | 959/7204 [03:43<26:33,  3.92it/s]
2022-03-21 23:55:17,086 - INFO - tqdm - f1: 0.8611, accuracy: 0.9336, batch_loss: 0.4775, loss: 0.1778 ||:  14%|#3        | 1003/7204 [03:53<17:35,  5.88it/s]
2022-03-21 23:55:27,192 - INFO - tqdm - f1: 0.8623, accuracy: 0.9341, batch_loss: 0.0106, loss: 0.1768 ||:  15%|#4        | 1048/7204 [04:03<32:42,  3.14it/s]
2022-03-21 23:55:37,311 - INFO - tqdm - f1: 0.8609, accuracy: 0.9337, batch_loss: 0.0813, loss: 0.1769 ||:  15%|#5        | 1091/7204 [04:13<19:51,  5.13it/s]
2022-03-21 23:55:47,492 - INFO - tqdm - f1: 0.8601, accuracy: 0.9331, batch_loss: 0.0733, loss: 0.1788 ||:  16%|#5        | 1134/7204 [04:23<26:40,  3.79it/s]
2022-03-21 23:55:57,724 - INFO - tqdm - f1: 0.8586, accuracy: 0.9328, batch_loss: 0.2107, loss: 0.1802 ||:  16%|#6        | 1179/7204 [04:33<25:41,  3.91it/s]
2022-03-21 23:56:07,839 - INFO - tqdm - f1: 0.8582, accuracy: 0.9331, batch_loss: 0.1489, loss: 0.1794 ||:  17%|#6        | 1220/7204 [04:43<25:54,  3.85it/s]
2022-03-21 23:56:17,928 - INFO - tqdm - f1: 0.8585, accuracy: 0.9332, batch_loss: 0.2460, loss: 0.1785 ||:  18%|#7        | 1261/7204 [04:54<25:30,  3.88it/s]
2022-03-21 23:56:28,088 - INFO - tqdm - f1: 0.8585, accuracy: 0.9328, batch_loss: 0.0279, loss: 0.1793 ||:  18%|#8        | 1307/7204 [05:04<23:48,  4.13it/s]
2022-03-21 23:56:38,233 - INFO - tqdm - f1: 0.8583, accuracy: 0.9330, batch_loss: 0.0965, loss: 0.1788 ||:  19%|#8        | 1352/7204 [05:14<21:34,  4.52it/s]
2022-03-21 23:56:48,454 - INFO - tqdm - f1: 0.8590, accuracy: 0.9335, batch_loss: 0.0706, loss: 0.1778 ||:  19%|#9        | 1395/7204 [05:24<28:13,  3.43it/s]
2022-03-21 23:56:58,472 - INFO - tqdm - f1: 0.8583, accuracy: 0.9329, batch_loss: 0.2368, loss: 0.1783 ||:  20%|#9        | 1439/7204 [05:34<25:23,  3.78it/s]
2022-03-21 23:57:08,483 - INFO - tqdm - f1: 0.8579, accuracy: 0.9326, batch_loss: 0.2612, loss: 0.1785 ||:  21%|##        | 1484/7204 [05:44<18:06,  5.26it/s]
2022-03-21 23:57:18,542 - INFO - tqdm - f1: 0.8582, accuracy: 0.9328, batch_loss: 0.0871, loss: 0.1779 ||:  21%|##1       | 1526/7204 [05:54<20:19,  4.66it/s]
2022-03-21 23:57:28,573 - INFO - tqdm - f1: 0.8590, accuracy: 0.9327, batch_loss: 0.2353, loss: 0.1777 ||:  22%|##2       | 1615/7204 [06:04<22:21,  4.17it/s]
2022-03-21 23:57:38,599 - INFO - tqdm - f1: 0.8590, accuracy: 0.9328, batch_loss: 0.1852, loss: 0.1779 ||:  23%|##3       | 1671/7204 [06:14<15:16,  6.04it/s]
2022-03-21 23:57:48,771 - INFO - tqdm - f1: 0.8581, accuracy: 0.9327, batch_loss: 0.0718, loss: 0.1779 ||:  24%|##4       | 1734/7204 [06:24<20:34,  4.43it/s]
2022-03-21 23:57:58,851 - INFO - tqdm - f1: 0.8580, accuracy: 0.9329, batch_loss: 0.1662, loss: 0.1770 ||:  25%|##4       | 1785/7204 [06:35<19:54,  4.54it/s]
2022-03-21 23:58:08,903 - INFO - tqdm - f1: 0.8589, accuracy: 0.9334, batch_loss: 0.2080, loss: 0.1765 ||:  25%|##5       | 1823/7204 [06:45<19:55,  4.50it/s]
2022-03-21 23:58:18,952 - INFO - tqdm - f1: 0.8587, accuracy: 0.9334, batch_loss: 0.1884, loss: 0.1769 ||:  26%|##5       | 1868/7204 [06:55<18:50,  4.72it/s]
2022-03-21 23:58:28,969 - INFO - tqdm - f1: 0.8585, accuracy: 0.9336, batch_loss: 0.1778, loss: 0.1773 ||:  26%|##6       | 1909/7204 [07:05<19:42,  4.48it/s]
2022-03-21 23:58:39,190 - INFO - tqdm - f1: 0.8578, accuracy: 0.9333, batch_loss: 0.0768, loss: 0.1774 ||:  27%|##7       | 1953/7204 [07:15<17:11,  5.09it/s]
2022-03-21 23:58:49,366 - INFO - tqdm - f1: 0.8581, accuracy: 0.9335, batch_loss: 0.3633, loss: 0.1770 ||:  28%|##7       | 1995/7204 [07:25<25:29,  3.41it/s]
2022-03-21 23:58:59,482 - INFO - tqdm - f1: 0.8578, accuracy: 0.9331, batch_loss: 0.3632, loss: 0.1780 ||:  28%|##8       | 2041/7204 [07:35<17:16,  4.98it/s]
2022-03-21 23:59:09,851 - INFO - tqdm - f1: 0.8580, accuracy: 0.9332, batch_loss: 0.0114, loss: 0.1776 ||:  29%|##8       | 2079/7204 [07:46<23:33,  3.63it/s]
2022-03-21 23:59:19,862 - INFO - tqdm - f1: 0.8578, accuracy: 0.9331, batch_loss: 0.0824, loss: 0.1775 ||:  29%|##9       | 2123/7204 [07:56<17:29,  4.84it/s]
2022-03-21 23:59:29,933 - INFO - tqdm - f1: 0.8577, accuracy: 0.9331, batch_loss: 0.1061, loss: 0.1776 ||:  30%|###       | 2167/7204 [08:06<16:28,  5.09it/s]
2022-03-21 23:59:39,979 - INFO - tqdm - f1: 0.8574, accuracy: 0.9331, batch_loss: 0.2554, loss: 0.1778 ||:  31%|###       | 2211/7204 [08:16<19:10,  4.34it/s]
2022-03-21 23:59:50,121 - INFO - tqdm - f1: 0.8573, accuracy: 0.9331, batch_loss: 0.1651, loss: 0.1782 ||:  31%|###1      | 2254/7204 [08:26<21:38,  3.81it/s]
2022-03-22 00:00:00,256 - INFO - tqdm - f1: 0.8572, accuracy: 0.9330, batch_loss: 0.3742, loss: 0.1784 ||:  32%|###1      | 2298/7204 [08:36<17:30,  4.67it/s]
2022-03-22 00:00:10,363 - INFO - tqdm - f1: 0.8571, accuracy: 0.9330, batch_loss: 0.1616, loss: 0.1784 ||:  32%|###2      | 2341/7204 [08:46<17:02,  4.76it/s]
2022-03-22 00:00:20,472 - INFO - tqdm - f1: 0.8571, accuracy: 0.9331, batch_loss: 0.3413, loss: 0.1784 ||:  33%|###3      | 2387/7204 [08:56<16:34,  4.85it/s]
2022-03-22 00:00:30,497 - INFO - tqdm - f1: 0.8570, accuracy: 0.9332, batch_loss: 0.0195, loss: 0.1785 ||:  34%|###3      | 2429/7204 [09:06<21:05,  3.77it/s]
2022-03-22 00:00:40,543 - INFO - tqdm - f1: 0.8572, accuracy: 0.9333, batch_loss: 0.0466, loss: 0.1783 ||:  34%|###4      | 2471/7204 [09:16<19:27,  4.06it/s]
2022-03-22 00:00:50,679 - INFO - tqdm - f1: 0.8572, accuracy: 0.9333, batch_loss: 0.5194, loss: 0.1780 ||:  35%|###4      | 2516/7204 [09:26<15:49,  4.94it/s]
2022-03-22 00:01:00,756 - INFO - tqdm - f1: 0.8579, accuracy: 0.9334, batch_loss: 0.2435, loss: 0.1777 ||:  36%|###5      | 2559/7204 [09:36<18:38,  4.15it/s]
2022-03-22 00:01:10,841 - INFO - tqdm - f1: 0.8580, accuracy: 0.9336, batch_loss: 0.2213, loss: 0.1776 ||:  36%|###6      | 2600/7204 [09:46<15:52,  4.84it/s]
2022-03-22 00:01:21,039 - INFO - tqdm - f1: 0.8573, accuracy: 0.9334, batch_loss: 0.0591, loss: 0.1778 ||:  37%|###6      | 2641/7204 [09:57<20:02,  3.79it/s]
2022-03-22 00:01:31,325 - INFO - tqdm - f1: 0.8573, accuracy: 0.9333, batch_loss: 0.2039, loss: 0.1778 ||:  37%|###7      | 2686/7204 [10:07<19:13,  3.92it/s]
2022-03-22 00:01:41,513 - INFO - tqdm - f1: 0.8572, accuracy: 0.9332, batch_loss: 0.0883, loss: 0.1777 ||:  38%|###7      | 2729/7204 [10:17<15:57,  4.67it/s]
2022-03-22 00:01:51,616 - INFO - tqdm - f1: 0.8572, accuracy: 0.9332, batch_loss: 0.3725, loss: 0.1777 ||:  38%|###8      | 2773/7204 [10:27<17:28,  4.23it/s]
2022-03-22 00:02:01,838 - INFO - tqdm - f1: 0.8573, accuracy: 0.9333, batch_loss: 0.1829, loss: 0.1776 ||:  39%|###9      | 2816/7204 [10:37<17:31,  4.17it/s]
2022-03-22 00:02:12,080 - INFO - tqdm - f1: 0.8572, accuracy: 0.9333, batch_loss: 0.0439, loss: 0.1776 ||:  40%|###9      | 2860/7204 [10:48<16:30,  4.39it/s]
2022-03-22 00:02:22,227 - INFO - tqdm - f1: 0.8575, accuracy: 0.9334, batch_loss: 0.0518, loss: 0.1774 ||:  40%|####      | 2904/7204 [10:58<18:10,  3.94it/s]
2022-03-22 00:02:32,398 - INFO - tqdm - f1: 0.8575, accuracy: 0.9334, batch_loss: 0.1586, loss: 0.1773 ||:  41%|####      | 2945/7204 [11:08<17:57,  3.95it/s]
2022-03-22 00:02:42,494 - INFO - tqdm - f1: 0.8571, accuracy: 0.9333, batch_loss: 0.0250, loss: 0.1778 ||:  42%|####1     | 2990/7204 [11:18<13:56,  5.04it/s]
2022-03-22 00:02:52,501 - INFO - tqdm - f1: 0.8571, accuracy: 0.9332, batch_loss: 0.2263, loss: 0.1784 ||:  42%|####2     | 3035/7204 [11:28<14:32,  4.78it/s]
2022-03-22 00:03:02,517 - INFO - tqdm - f1: 0.8569, accuracy: 0.9332, batch_loss: 0.1007, loss: 0.1784 ||:  43%|####2     | 3079/7204 [11:38<16:33,  4.15it/s]
2022-03-22 00:03:12,615 - INFO - tqdm - f1: 0.8570, accuracy: 0.9334, batch_loss: 0.0089, loss: 0.1779 ||:  43%|####3     | 3119/7204 [11:48<17:03,  3.99it/s]
2022-03-22 00:03:22,694 - INFO - tqdm - f1: 0.8567, accuracy: 0.9334, batch_loss: 0.4988, loss: 0.1782 ||:  44%|####3     | 3159/7204 [11:58<17:39,  3.82it/s]
2022-03-22 00:03:33,098 - INFO - tqdm - f1: 0.8567, accuracy: 0.9333, batch_loss: 0.0272, loss: 0.1784 ||:  44%|####4     | 3203/7204 [12:09<18:00,  3.70it/s]
2022-03-22 00:03:43,188 - INFO - tqdm - f1: 0.8564, accuracy: 0.9331, batch_loss: 0.2581, loss: 0.1787 ||:  45%|####5     | 3248/7204 [12:19<15:23,  4.28it/s]
2022-03-22 00:03:53,242 - INFO - tqdm - f1: 0.8564, accuracy: 0.9330, batch_loss: 0.5080, loss: 0.1789 ||:  46%|####5     | 3290/7204 [12:29<16:39,  3.91it/s]
2022-03-22 00:04:03,348 - INFO - tqdm - f1: 0.8561, accuracy: 0.9328, batch_loss: 0.2883, loss: 0.1792 ||:  46%|####6     | 3334/7204 [12:39<15:28,  4.17it/s]
2022-03-22 00:04:13,523 - INFO - tqdm - f1: 0.8561, accuracy: 0.9329, batch_loss: 0.1395, loss: 0.1788 ||:  47%|####6     | 3376/7204 [12:49<18:03,  3.53it/s]
2022-03-22 00:04:23,550 - INFO - tqdm - f1: 0.8561, accuracy: 0.9328, batch_loss: 0.0909, loss: 0.1788 ||:  48%|####7     | 3424/7204 [12:59<16:01,  3.93it/s]
2022-03-22 00:04:33,582 - INFO - tqdm - f1: 0.8561, accuracy: 0.9328, batch_loss: 0.1642, loss: 0.1787 ||:  48%|####8     | 3467/7204 [13:09<12:34,  4.95it/s]
2022-03-22 00:04:43,627 - INFO - tqdm - f1: 0.8560, accuracy: 0.9328, batch_loss: 0.2018, loss: 0.1787 ||:  49%|####8     | 3508/7204 [13:19<11:30,  5.35it/s]
2022-03-22 00:04:53,786 - INFO - tqdm - f1: 0.8560, accuracy: 0.9329, batch_loss: 0.2207, loss: 0.1784 ||:  49%|####9     | 3548/7204 [13:29<18:17,  3.33it/s]
2022-03-22 00:05:03,819 - INFO - tqdm - f1: 0.8560, accuracy: 0.9328, batch_loss: 0.0842, loss: 0.1785 ||:  50%|####9     | 3591/7204 [13:39<15:44,  3.83it/s]
2022-03-22 00:05:13,962 - INFO - tqdm - f1: 0.8557, accuracy: 0.9326, batch_loss: 0.1790, loss: 0.1790 ||:  51%|#####     | 3640/7204 [13:50<12:35,  4.72it/s]
2022-03-22 00:05:24,102 - INFO - tqdm - f1: 0.8556, accuracy: 0.9325, batch_loss: 0.1726, loss: 0.1789 ||:  51%|#####1    | 3683/7204 [14:00<14:30,  4.04it/s]
2022-03-22 00:05:34,182 - INFO - tqdm - f1: 0.8555, accuracy: 0.9324, batch_loss: 0.2902, loss: 0.1791 ||:  52%|#####1    | 3725/7204 [14:10<13:53,  4.17it/s]
2022-03-22 00:05:44,271 - INFO - tqdm - f1: 0.8556, accuracy: 0.9323, batch_loss: 0.5849, loss: 0.1794 ||:  52%|#####2    | 3772/7204 [14:20<12:07,  4.72it/s]
2022-03-22 00:05:54,424 - INFO - tqdm - f1: 0.8557, accuracy: 0.9324, batch_loss: 0.0984, loss: 0.1793 ||:  53%|#####2    | 3811/7204 [14:30<14:03,  4.02it/s]
2022-03-22 00:06:04,589 - INFO - tqdm - f1: 0.8556, accuracy: 0.9324, batch_loss: 0.2097, loss: 0.1794 ||:  53%|#####3    | 3854/7204 [14:40<13:51,  4.03it/s]
2022-03-22 00:06:14,822 - INFO - tqdm - f1: 0.8556, accuracy: 0.9324, batch_loss: 0.0213, loss: 0.1794 ||:  54%|#####4    | 3898/7204 [14:50<13:07,  4.20it/s]
2022-03-22 00:06:24,989 - INFO - tqdm - f1: 0.8557, accuracy: 0.9324, batch_loss: 0.2859, loss: 0.1793 ||:  55%|#####4    | 3939/7204 [15:01<14:18,  3.80it/s]
2022-03-22 00:06:35,033 - INFO - tqdm - f1: 0.8557, accuracy: 0.9326, batch_loss: 0.0935, loss: 0.1790 ||:  55%|#####5    | 3986/7204 [15:11<11:33,  4.64it/s]
2022-03-22 00:06:45,239 - INFO - tqdm - f1: 0.8549, accuracy: 0.9323, batch_loss: 0.1421, loss: 0.1792 ||:  56%|#####5    | 4032/7204 [15:21<10:45,  4.92it/s]
2022-03-22 00:06:55,404 - INFO - tqdm - f1: 0.8548, accuracy: 0.9321, batch_loss: 0.2237, loss: 0.1797 ||:  57%|#####6    | 4079/7204 [15:31<13:49,  3.77it/s]
2022-03-22 00:07:05,438 - INFO - tqdm - f1: 0.8543, accuracy: 0.9321, batch_loss: 0.1321, loss: 0.1799 ||:  57%|#####7    | 4121/7204 [15:41<11:32,  4.45it/s]
2022-03-22 00:07:15,555 - INFO - tqdm - f1: 0.8544, accuracy: 0.9321, batch_loss: 0.1497, loss: 0.1800 ||:  58%|#####7    | 4165/7204 [15:51<12:46,  3.97it/s]
2022-03-22 00:07:25,727 - INFO - tqdm - f1: 0.8539, accuracy: 0.9317, batch_loss: 0.5957, loss: 0.1806 ||:  58%|#####8    | 4212/7204 [16:01<09:08,  5.46it/s]
2022-03-22 00:07:35,815 - INFO - tqdm - f1: 0.8541, accuracy: 0.9318, batch_loss: 0.1508, loss: 0.1806 ||:  59%|#####9    | 4257/7204 [16:11<11:17,  4.35it/s]
2022-03-22 00:07:45,963 - INFO - tqdm - f1: 0.8541, accuracy: 0.9318, batch_loss: 0.1025, loss: 0.1806 ||:  60%|#####9    | 4299/7204 [16:22<12:00,  4.03it/s]
2022-03-22 00:07:56,072 - INFO - tqdm - f1: 0.8540, accuracy: 0.9317, batch_loss: 0.2051, loss: 0.1809 ||:  60%|######    | 4340/7204 [16:32<13:21,  3.57it/s]
2022-03-22 00:08:06,135 - INFO - tqdm - f1: 0.8539, accuracy: 0.9316, batch_loss: 0.5598, loss: 0.1810 ||:  61%|######    | 4384/7204 [16:42<11:49,  3.98it/s]
2022-03-22 00:08:16,502 - INFO - tqdm - f1: 0.8535, accuracy: 0.9314, batch_loss: 0.0143, loss: 0.1813 ||:  62%|######1   | 4431/7204 [16:52<12:07,  3.81it/s]
2022-03-22 00:08:26,711 - INFO - tqdm - f1: 0.8534, accuracy: 0.9314, batch_loss: 0.2988, loss: 0.1814 ||:  62%|######2   | 4475/7204 [17:02<10:23,  4.38it/s]
2022-03-22 00:08:37,077 - INFO - tqdm - f1: 0.8530, accuracy: 0.9313, batch_loss: 0.2235, loss: 0.1815 ||:  63%|######2   | 4518/7204 [17:13<13:24,  3.34it/s]
2022-03-22 00:08:47,160 - INFO - tqdm - f1: 0.8532, accuracy: 0.9315, batch_loss: 0.0905, loss: 0.1813 ||:  63%|######3   | 4560/7204 [17:23<10:30,  4.20it/s]
2022-03-22 00:08:57,166 - INFO - tqdm - f1: 0.8533, accuracy: 0.9315, batch_loss: 0.1212, loss: 0.1814 ||:  64%|######3   | 4604/7204 [17:33<10:23,  4.17it/s]
2022-03-22 00:09:07,213 - INFO - tqdm - f1: 0.8534, accuracy: 0.9316, batch_loss: 0.1006, loss: 0.1814 ||:  64%|######4   | 4646/7204 [17:43<10:49,  3.94it/s]
2022-03-22 00:09:17,387 - INFO - tqdm - f1: 0.8531, accuracy: 0.9314, batch_loss: 0.2031, loss: 0.1817 ||:  65%|######5   | 4687/7204 [17:53<09:27,  4.43it/s]
2022-03-22 00:09:27,630 - INFO - tqdm - f1: 0.8533, accuracy: 0.9314, batch_loss: 0.0107, loss: 0.1816 ||:  66%|######5   | 4732/7204 [18:03<12:00,  3.43it/s]
2022-03-22 00:09:37,661 - INFO - tqdm - f1: 0.8536, accuracy: 0.9315, batch_loss: 0.2894, loss: 0.1814 ||:  66%|######6   | 4774/7204 [18:13<08:50,  4.58it/s]
2022-03-22 00:09:47,708 - INFO - tqdm - f1: 0.8532, accuracy: 0.9314, batch_loss: 0.1420, loss: 0.1815 ||:  67%|######6   | 4814/7204 [18:23<11:06,  3.59it/s]
2022-03-22 00:09:57,785 - INFO - tqdm - f1: 0.8532, accuracy: 0.9314, batch_loss: 0.0412, loss: 0.1816 ||:  67%|######7   | 4860/7204 [18:33<07:47,  5.01it/s]
2022-03-22 00:10:07,870 - INFO - tqdm - f1: 0.8527, accuracy: 0.9312, batch_loss: 0.2811, loss: 0.1819 ||:  68%|######8   | 4903/7204 [18:44<11:13,  3.42it/s]
2022-03-22 00:10:18,046 - INFO - tqdm - f1: 0.8529, accuracy: 0.9312, batch_loss: 0.0677, loss: 0.1819 ||:  69%|######8   | 4948/7204 [18:54<08:05,  4.65it/s]
2022-03-22 00:10:28,194 - INFO - tqdm - f1: 0.8527, accuracy: 0.9313, batch_loss: 0.0182, loss: 0.1818 ||:  69%|######9   | 4989/7204 [19:04<10:53,  3.39it/s]
2022-03-22 00:10:38,241 - INFO - tqdm - f1: 0.8525, accuracy: 0.9312, batch_loss: 0.0788, loss: 0.1819 ||:  70%|######9   | 5025/7204 [19:14<09:07,  3.98it/s]
2022-03-22 00:10:48,324 - INFO - tqdm - f1: 0.8525, accuracy: 0.9312, batch_loss: 0.1995, loss: 0.1821 ||:  70%|#######   | 5068/7204 [19:24<08:11,  4.35it/s]
2022-03-22 00:10:58,464 - INFO - tqdm - f1: 0.8521, accuracy: 0.9310, batch_loss: 0.1028, loss: 0.1822 ||:  71%|#######   | 5111/7204 [19:34<07:08,  4.89it/s]
2022-03-22 00:11:08,525 - INFO - tqdm - f1: 0.8521, accuracy: 0.9310, batch_loss: 0.1851, loss: 0.1821 ||:  72%|#######1  | 5154/7204 [19:44<08:14,  4.15it/s]
2022-03-22 00:11:18,669 - INFO - tqdm - f1: 0.8517, accuracy: 0.9309, batch_loss: 0.0519, loss: 0.1821 ||:  72%|#######2  | 5196/7204 [19:54<08:02,  4.16it/s]
2022-03-22 00:11:28,852 - INFO - tqdm - f1: 0.8517, accuracy: 0.9309, batch_loss: 0.0865, loss: 0.1822 ||:  73%|#######2  | 5243/7204 [20:05<08:25,  3.88it/s]
2022-03-22 00:11:38,867 - INFO - tqdm - f1: 0.8516, accuracy: 0.9310, batch_loss: 0.1438, loss: 0.1820 ||:  73%|#######3  | 5283/7204 [20:15<06:53,  4.64it/s]
2022-03-22 00:11:49,100 - INFO - tqdm - f1: 0.8513, accuracy: 0.9309, batch_loss: 0.5808, loss: 0.1821 ||:  74%|#######3  | 5326/7204 [20:25<07:19,  4.27it/s]
2022-03-22 00:11:59,221 - INFO - tqdm - f1: 0.8511, accuracy: 0.9308, batch_loss: 0.0136, loss: 0.1821 ||:  75%|#######4  | 5370/7204 [20:35<07:51,  3.89it/s]
2022-03-22 00:12:09,280 - INFO - tqdm - f1: 0.8508, accuracy: 0.9308, batch_loss: 0.1663, loss: 0.1822 ||:  75%|#######5  | 5414/7204 [20:45<06:40,  4.47it/s]
2022-03-22 00:12:19,382 - INFO - tqdm - f1: 0.8508, accuracy: 0.9308, batch_loss: 0.0548, loss: 0.1822 ||:  76%|#######5  | 5457/7204 [20:55<06:44,  4.32it/s]
2022-03-22 00:12:29,703 - INFO - tqdm - f1: 0.8507, accuracy: 0.9307, batch_loss: 0.1396, loss: 0.1822 ||:  76%|#######6  | 5502/7204 [21:05<08:24,  3.37it/s]
2022-03-22 00:12:39,777 - INFO - tqdm - f1: 0.8507, accuracy: 0.9308, batch_loss: 0.4109, loss: 0.1821 ||:  77%|#######6  | 5543/7204 [21:15<07:17,  3.80it/s]
2022-03-22 00:12:49,812 - INFO - tqdm - f1: 0.8506, accuracy: 0.9308, batch_loss: 0.4284, loss: 0.1821 ||:  78%|#######7  | 5585/7204 [21:25<07:03,  3.82it/s]
2022-03-22 00:13:00,149 - INFO - tqdm - f1: 0.8508, accuracy: 0.9309, batch_loss: 0.0638, loss: 0.1819 ||:  78%|#######8  | 5627/7204 [21:36<07:16,  3.61it/s]
2022-03-22 00:13:10,554 - INFO - tqdm - f1: 0.8508, accuracy: 0.9310, batch_loss: 0.1303, loss: 0.1816 ||:  79%|#######8  | 5670/7204 [21:46<07:04,  3.61it/s]
2022-03-22 00:13:20,703 - INFO - tqdm - f1: 0.8507, accuracy: 0.9309, batch_loss: 0.1134, loss: 0.1818 ||:  79%|#######9  | 5716/7204 [21:56<06:09,  4.03it/s]
2022-03-22 00:13:31,053 - INFO - tqdm - f1: 0.8511, accuracy: 0.9310, batch_loss: 0.2836, loss: 0.1816 ||:  80%|#######9  | 5760/7204 [22:07<06:10,  3.90it/s]
2022-03-22 00:13:41,211 - INFO - tqdm - f1: 0.8511, accuracy: 0.9311, batch_loss: 0.1999, loss: 0.1816 ||:  81%|########  | 5804/7204 [22:17<05:21,  4.35it/s]
2022-03-22 00:13:51,362 - INFO - tqdm - f1: 0.8511, accuracy: 0.9311, batch_loss: 0.1223, loss: 0.1815 ||:  81%|########1 | 5847/7204 [22:27<04:35,  4.93it/s]
2022-03-22 00:14:01,497 - INFO - tqdm - f1: 0.8510, accuracy: 0.9310, batch_loss: 0.0778, loss: 0.1818 ||:  82%|########1 | 5892/7204 [22:37<04:29,  4.86it/s]
2022-03-22 00:14:11,588 - INFO - tqdm - f1: 0.8511, accuracy: 0.9310, batch_loss: 0.0671, loss: 0.1818 ||:  82%|########2 | 5936/7204 [22:47<04:25,  4.77it/s]
2022-03-22 00:14:21,710 - INFO - tqdm - f1: 0.8509, accuracy: 0.9308, batch_loss: 0.1222, loss: 0.1822 ||:  83%|########3 | 5981/7204 [22:57<04:19,  4.72it/s]
2022-03-22 00:14:31,976 - INFO - tqdm - f1: 0.8508, accuracy: 0.9308, batch_loss: 0.1420, loss: 0.1824 ||:  84%|########3 | 6027/7204 [23:08<04:29,  4.37it/s]
2022-03-22 00:14:42,011 - INFO - tqdm - f1: 0.8506, accuracy: 0.9308, batch_loss: 0.1385, loss: 0.1824 ||:  84%|########4 | 6064/7204 [23:18<05:39,  3.35it/s]
2022-03-22 00:14:52,094 - INFO - tqdm - f1: 0.8505, accuracy: 0.9307, batch_loss: 0.0889, loss: 0.1825 ||:  85%|########4 | 6108/7204 [23:28<04:05,  4.47it/s]
2022-03-22 00:15:02,209 - INFO - tqdm - f1: 0.8504, accuracy: 0.9306, batch_loss: 0.1130, loss: 0.1825 ||:  85%|########5 | 6153/7204 [23:38<03:36,  4.85it/s]
2022-03-22 00:15:12,355 - INFO - tqdm - f1: 0.8505, accuracy: 0.9306, batch_loss: 0.2017, loss: 0.1826 ||:  86%|########6 | 6198/7204 [23:48<04:03,  4.14it/s]
2022-03-22 00:15:22,366 - INFO - tqdm - f1: 0.8505, accuracy: 0.9306, batch_loss: 0.3412, loss: 0.1827 ||:  87%|########6 | 6238/7204 [23:58<04:31,  3.56it/s]
2022-03-22 00:15:32,683 - INFO - tqdm - f1: 0.8504, accuracy: 0.9306, batch_loss: 0.0484, loss: 0.1829 ||:  87%|########7 | 6280/7204 [24:08<04:28,  3.45it/s]
2022-03-22 00:15:42,715 - INFO - tqdm - f1: 0.8503, accuracy: 0.9305, batch_loss: 0.3350, loss: 0.1831 ||:  88%|########8 | 6369/7204 [24:18<02:17,  6.07it/s]
2022-03-22 00:15:52,820 - INFO - tqdm - f1: 0.8502, accuracy: 0.9304, batch_loss: 0.0616, loss: 0.1833 ||:  89%|########9 | 6430/7204 [24:28<02:06,  6.10it/s]
2022-03-22 00:16:02,855 - INFO - tqdm - f1: 0.8503, accuracy: 0.9304, batch_loss: 0.2612, loss: 0.1832 ||:  90%|######### | 6491/7204 [24:39<02:15,  5.26it/s]
2022-03-22 00:16:12,877 - INFO - tqdm - f1: 0.8505, accuracy: 0.9305, batch_loss: 0.2642, loss: 0.1832 ||:  91%|######### | 6551/7204 [24:49<01:51,  5.87it/s]
2022-03-22 00:16:23,043 - INFO - tqdm - f1: 0.8505, accuracy: 0.9305, batch_loss: 0.0507, loss: 0.1831 ||:  91%|#########1| 6591/7204 [24:59<02:45,  3.70it/s]
2022-03-22 00:16:33,142 - INFO - tqdm - f1: 0.8502, accuracy: 0.9304, batch_loss: 0.0613, loss: 0.1832 ||:  92%|#########2| 6636/7204 [25:09<02:46,  3.41it/s]
2022-03-22 00:16:43,185 - INFO - tqdm - f1: 0.8503, accuracy: 0.9304, batch_loss: 0.1541, loss: 0.1832 ||:  93%|#########2| 6681/7204 [25:19<01:50,  4.74it/s]
2022-03-22 00:16:53,271 - INFO - tqdm - f1: 0.8502, accuracy: 0.9304, batch_loss: 0.0851, loss: 0.1834 ||:  93%|#########3| 6722/7204 [25:29<02:12,  3.63it/s]
2022-03-22 00:17:03,536 - INFO - tqdm - f1: 0.8502, accuracy: 0.9305, batch_loss: 0.0074, loss: 0.1832 ||:  94%|#########3| 6762/7204 [25:39<02:11,  3.37it/s]
2022-03-22 00:17:13,646 - INFO - tqdm - f1: 0.8499, accuracy: 0.9303, batch_loss: 0.1334, loss: 0.1835 ||:  94%|#########4| 6806/7204 [25:49<01:37,  4.09it/s]
2022-03-22 00:17:23,665 - INFO - tqdm - f1: 0.8498, accuracy: 0.9303, batch_loss: 0.4114, loss: 0.1836 ||:  95%|#########5| 6849/7204 [25:59<01:18,  4.50it/s]
2022-03-22 00:17:33,808 - INFO - tqdm - f1: 0.8497, accuracy: 0.9302, batch_loss: 0.1409, loss: 0.1836 ||:  96%|#########5| 6895/7204 [26:09<01:06,  4.62it/s]
2022-03-22 00:17:44,039 - INFO - tqdm - f1: 0.8497, accuracy: 0.9303, batch_loss: 0.0412, loss: 0.1836 ||:  96%|#########6| 6936/7204 [26:20<01:14,  3.58it/s]
2022-03-22 00:17:54,230 - INFO - tqdm - f1: 0.8495, accuracy: 0.9302, batch_loss: 0.0885, loss: 0.1837 ||:  97%|#########6| 6977/7204 [26:30<01:10,  3.20it/s]
2022-03-22 00:18:04,271 - INFO - tqdm - f1: 0.8495, accuracy: 0.9302, batch_loss: 0.0634, loss: 0.1838 ||:  97%|#########7| 7023/7204 [26:40<00:43,  4.20it/s]
2022-03-22 00:18:14,459 - INFO - tqdm - f1: 0.8494, accuracy: 0.9302, batch_loss: 0.0948, loss: 0.1839 ||:  98%|#########8| 7066/7204 [26:50<00:31,  4.33it/s]
2022-03-22 00:18:24,606 - INFO - tqdm - f1: 0.8493, accuracy: 0.9302, batch_loss: 0.2799, loss: 0.1840 ||:  99%|#########8| 7109/7204 [27:00<00:20,  4.69it/s]
2022-03-22 00:18:34,800 - INFO - tqdm - f1: 0.8492, accuracy: 0.9302, batch_loss: 0.1229, loss: 0.1840 ||:  99%|#########9| 7152/7204 [27:10<00:14,  3.51it/s]
2022-03-22 00:18:39,291 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.4373, loss: 0.1840 ||: 100%|#########9| 7168/7204 [27:15<00:09,  3.62it/s]
2022-03-22 00:18:39,556 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.1974, loss: 0.1840 ||: 100%|#########9| 7169/7204 [27:15<00:09,  3.67it/s]
2022-03-22 00:18:39,929 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.0748, loss: 0.1840 ||: 100%|#########9| 7170/7204 [27:16<00:10,  3.30it/s]
2022-03-22 00:18:40,101 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.2024, loss: 0.1840 ||: 100%|#########9| 7171/7204 [27:16<00:08,  3.79it/s]
2022-03-22 00:18:40,451 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.0407, loss: 0.1839 ||: 100%|#########9| 7172/7204 [27:16<00:09,  3.45it/s]
2022-03-22 00:18:40,586 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.2803, loss: 0.1840 ||: 100%|#########9| 7173/7204 [27:16<00:07,  4.11it/s]
2022-03-22 00:18:40,767 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.5094, loss: 0.1840 ||: 100%|#########9| 7174/7204 [27:16<00:06,  4.46it/s]
2022-03-22 00:18:41,020 - INFO - tqdm - f1: 0.8490, accuracy: 0.9301, batch_loss: 0.1154, loss: 0.1840 ||: 100%|#########9| 7175/7204 [27:17<00:06,  4.29it/s]
2022-03-22 00:18:41,175 - INFO - tqdm - f1: 0.8490, accuracy: 0.9301, batch_loss: 0.1021, loss: 0.1840 ||: 100%|#########9| 7176/7204 [27:17<00:05,  4.77it/s]
2022-03-22 00:18:41,422 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.0569, loss: 0.1840 ||: 100%|#########9| 7177/7204 [27:17<00:05,  4.53it/s]
2022-03-22 00:18:41,771 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.0648, loss: 0.1839 ||: 100%|#########9| 7178/7204 [27:17<00:06,  3.86it/s]
2022-03-22 00:18:42,034 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.2087, loss: 0.1839 ||: 100%|#########9| 7179/7204 [27:18<00:06,  3.84it/s]
2022-03-22 00:18:42,285 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.5780, loss: 0.1840 ||: 100%|#########9| 7180/7204 [27:18<00:06,  3.88it/s]
2022-03-22 00:18:42,514 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.1091, loss: 0.1840 ||: 100%|#########9| 7181/7204 [27:18<00:05,  4.02it/s]
2022-03-22 00:18:42,654 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.1894, loss: 0.1840 ||: 100%|#########9| 7182/7204 [27:18<00:04,  4.62it/s]
2022-03-22 00:18:42,933 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.1150, loss: 0.1840 ||: 100%|#########9| 7183/7204 [27:19<00:04,  4.25it/s]
2022-03-22 00:18:43,149 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.1540, loss: 0.1840 ||: 100%|#########9| 7184/7204 [27:19<00:04,  4.36it/s]
2022-03-22 00:18:43,530 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.0960, loss: 0.1840 ||: 100%|#########9| 7185/7204 [27:19<00:05,  3.64it/s]
2022-03-22 00:18:43,738 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.1578, loss: 0.1840 ||: 100%|#########9| 7186/7204 [27:19<00:04,  3.93it/s]
2022-03-22 00:18:43,936 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.5056, loss: 0.1840 ||: 100%|#########9| 7187/7204 [27:20<00:04,  4.21it/s]
2022-03-22 00:18:44,350 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.0414, loss: 0.1840 ||: 100%|#########9| 7188/7204 [27:20<00:04,  3.44it/s]
2022-03-22 00:18:44,522 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.1230, loss: 0.1840 ||: 100%|#########9| 7189/7204 [27:20<00:03,  3.92it/s]
2022-03-22 00:18:44,635 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.2476, loss: 0.1840 ||: 100%|#########9| 7190/7204 [27:20<00:02,  4.70it/s]
2022-03-22 00:18:44,944 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.0675, loss: 0.1840 ||: 100%|#########9| 7191/7204 [27:21<00:03,  4.14it/s]
2022-03-22 00:18:45,195 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.1006, loss: 0.1840 ||: 100%|#########9| 7192/7204 [27:21<00:02,  4.09it/s]
2022-03-22 00:18:45,297 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.4407, loss: 0.1840 ||: 100%|#########9| 7193/7204 [27:21<00:02,  4.96it/s]
2022-03-22 00:18:45,679 - INFO - tqdm - f1: 0.8491, accuracy: 0.9302, batch_loss: 0.0482, loss: 0.1840 ||: 100%|#########9| 7194/7204 [27:21<00:02,  3.91it/s]
2022-03-22 00:18:45,867 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.1691, loss: 0.1840 ||: 100%|#########9| 7195/7204 [27:22<00:02,  4.25it/s]
2022-03-22 00:18:45,973 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.1924, loss: 0.1840 ||: 100%|#########9| 7196/7204 [27:22<00:01,  5.09it/s]
2022-03-22 00:18:46,193 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.1502, loss: 0.1840 ||: 100%|#########9| 7197/7204 [27:22<00:01,  4.91it/s]
2022-03-22 00:18:46,537 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.1216, loss: 0.1840 ||: 100%|#########9| 7198/7204 [27:22<00:01,  4.07it/s]
2022-03-22 00:18:46,721 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.1461, loss: 0.1840 ||: 100%|#########9| 7199/7204 [27:22<00:01,  4.40it/s]
2022-03-22 00:18:46,892 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.2387, loss: 0.1840 ||: 100%|#########9| 7200/7204 [27:23<00:00,  4.76it/s]
2022-03-22 00:18:47,113 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.1040, loss: 0.1840 ||: 100%|#########9| 7201/7204 [27:23<00:00,  4.68it/s]
2022-03-22 00:18:47,271 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.2686, loss: 0.1840 ||: 100%|#########9| 7202/7204 [27:23<00:00,  5.08it/s]
2022-03-22 00:18:47,661 - INFO - tqdm - f1: 0.8491, accuracy: 0.9301, batch_loss: 0.4706, loss: 0.1840 ||: 100%|#########9| 7203/7204 [27:23<00:00,  3.93it/s]
2022-03-22 00:18:47,866 - INFO - tqdm - f1: 0.8490, accuracy: 0.9301, batch_loss: 0.3745, loss: 0.1840 ||: 100%|##########| 7204/7204 [27:24<00:00,  4.17it/s]
2022-03-22 00:18:47,955 - INFO - tqdm - f1: 0.8490, accuracy: 0.9301, batch_loss: 0.3745, loss: 0.1840 ||: 100%|##########| 7204/7204 [27:24<00:00,  4.38it/s]
2022-03-22 00:18:47,992 - INFO - allennlp.training.trainer - Validating
2022-03-22 00:18:47,994 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-22 00:18:58,036 - INFO - tqdm - f1: 0.6786, accuracy: 0.8673, batch_loss: 0.5334, loss: 0.4387 ||:  28%|##8       | 89/313 [00:10<00:19, 11.45it/s]
2022-03-22 00:19:08,064 - INFO - tqdm - f1: 0.6653, accuracy: 0.8660, batch_loss: 0.6119, loss: 0.4424 ||:  58%|#####7    | 180/313 [00:20<00:14,  8.88it/s]
2022-03-22 00:19:18,086 - INFO - tqdm - f1: 0.6690, accuracy: 0.8648, batch_loss: 0.0084, loss: 0.4424 ||:  87%|########6 | 271/313 [00:30<00:04, 10.11it/s]
2022-03-22 00:19:22,930 - INFO - tqdm - f1: 0.6681, accuracy: 0.8676, batch_loss: 0.0061, loss: 0.4291 ||: 100%|#########9| 312/313 [00:34<00:00, 10.01it/s]
2022-03-22 00:19:23,044 - INFO - tqdm - f1: 0.6675, accuracy: 0.8674, batch_loss: 0.8510, loss: 0.4304 ||: 100%|##########| 313/313 [00:35<00:00,  9.72it/s]
2022-03-22 00:19:23,049 - INFO - tqdm - f1: 0.6675, accuracy: 0.8674, batch_loss: 0.8510, loss: 0.4304 ||: 100%|##########| 313/313 [00:35<00:00,  8.93it/s]
2022-03-22 00:19:23,083 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-22 00:19:23,084 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.930  |     0.867
2022-03-22 00:19:23,086 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.849  |     0.667
2022-03-22 00:19:23,087 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-22 00:19:23,088 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.184  |     0.430
2022-03-22 00:19:23,090 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  13603.871  |       N/A
2022-03-22 00:19:23,091 - INFO - allennlp.training.trainer - Epoch duration: 0:27:59.260511
2022-03-22 00:19:23,092 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:21:22
2022-03-22 00:19:23,094 - INFO - allennlp.training.trainer - Epoch 5/9
2022-03-22 00:19:23,095 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2022-03-22 00:19:23,097 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-22 00:19:23,100 - INFO - allennlp.training.trainer - Training
2022-03-22 00:19:23,101 - INFO - tqdm - 0%|          | 0/7204 [00:00<?, ?it/s]
2022-03-22 00:19:33,331 - INFO - tqdm - f1: 0.9034, accuracy: 0.9543, batch_loss: 0.0720, loss: 0.1417 ||:   1%|          | 41/7204 [00:10<30:15,  3.95it/s]
2022-03-22 00:19:43,407 - INFO - tqdm - f1: 0.9022, accuracy: 0.9589, batch_loss: 0.1260, loss: 0.1279 ||:   1%|1         | 79/7204 [00:20<33:19,  3.56it/s]
2022-03-22 00:19:53,454 - INFO - tqdm - f1: 0.9106, accuracy: 0.9626, batch_loss: 0.0392, loss: 0.1192 ||:   2%|1         | 122/7204 [00:30<24:23,  4.84it/s]
2022-03-22 00:20:03,705 - INFO - tqdm - f1: 0.9104, accuracy: 0.9609, batch_loss: 0.0154, loss: 0.1246 ||:   2%|2         | 168/7204 [00:40<28:17,  4.14it/s]
2022-03-22 00:20:13,764 - INFO - tqdm - f1: 0.9119, accuracy: 0.9610, batch_loss: 0.0722, loss: 0.1187 ||:   3%|2         | 213/7204 [00:50<33:23,  3.49it/s]
2022-03-22 00:20:23,893 - INFO - tqdm - f1: 0.9072, accuracy: 0.9583, batch_loss: 0.0589, loss: 0.1255 ||:   4%|3         | 253/7204 [01:00<29:01,  3.99it/s]
2022-03-22 00:20:34,208 - INFO - tqdm - f1: 0.9083, accuracy: 0.9592, batch_loss: 0.0111, loss: 0.1226 ||:   4%|4         | 297/7204 [01:11<29:18,  3.93it/s]
2022-03-22 00:20:44,295 - INFO - tqdm - f1: 0.9040, accuracy: 0.9570, batch_loss: 0.0955, loss: 0.1262 ||:   5%|4         | 337/7204 [01:21<26:33,  4.31it/s]
2022-03-22 00:20:54,329 - INFO - tqdm - f1: 0.9062, accuracy: 0.9576, batch_loss: 0.0642, loss: 0.1238 ||:   5%|5         | 382/7204 [01:31<31:47,  3.58it/s]
2022-03-22 00:21:04,444 - INFO - tqdm - f1: 0.9060, accuracy: 0.9571, batch_loss: 0.0630, loss: 0.1248 ||:   6%|5         | 427/7204 [01:41<21:23,  5.28it/s]
2022-03-22 00:21:14,703 - INFO - tqdm - f1: 0.9030, accuracy: 0.9560, batch_loss: 0.0366, loss: 0.1278 ||:   7%|6         | 470/7204 [01:51<30:11,  3.72it/s]
2022-03-22 00:21:24,833 - INFO - tqdm - f1: 0.9040, accuracy: 0.9565, batch_loss: 0.0088, loss: 0.1270 ||:   7%|7         | 513/7204 [02:01<25:36,  4.35it/s]
2022-03-22 00:21:34,991 - INFO - tqdm - f1: 0.9051, accuracy: 0.9567, batch_loss: 0.0431, loss: 0.1269 ||:   8%|7         | 562/7204 [02:11<22:39,  4.89it/s]
2022-03-22 00:21:45,066 - INFO - tqdm - f1: 0.9061, accuracy: 0.9573, batch_loss: 0.0668, loss: 0.1248 ||:   8%|8         | 603/7204 [02:21<25:26,  4.33it/s]
2022-03-22 00:21:55,121 - INFO - tqdm - f1: 0.9054, accuracy: 0.9570, batch_loss: 0.0545, loss: 0.1271 ||:   9%|8         | 644/7204 [02:32<23:41,  4.61it/s]
2022-03-22 00:22:05,140 - INFO - tqdm - f1: 0.9033, accuracy: 0.9565, batch_loss: 0.0131, loss: 0.1282 ||:  10%|9         | 687/7204 [02:42<25:36,  4.24it/s]
2022-03-22 00:22:15,335 - INFO - tqdm - f1: 0.9028, accuracy: 0.9563, batch_loss: 0.0288, loss: 0.1284 ||:  10%|#         | 729/7204 [02:52<27:49,  3.88it/s]
2022-03-22 00:22:25,486 - INFO - tqdm - f1: 0.9019, accuracy: 0.9563, batch_loss: 0.1198, loss: 0.1277 ||:  11%|#         | 770/7204 [03:02<20:47,  5.16it/s]
2022-03-22 00:22:35,490 - INFO - tqdm - f1: 0.9029, accuracy: 0.9568, batch_loss: 0.0058, loss: 0.1263 ||:  11%|#1        | 811/7204 [03:12<28:03,  3.80it/s]
2022-03-22 00:22:45,575 - INFO - tqdm - f1: 0.9034, accuracy: 0.9570, batch_loss: 0.2857, loss: 0.1262 ||:  12%|#1        | 854/7204 [03:22<21:14,  4.98it/s]
2022-03-22 00:22:55,605 - INFO - tqdm - f1: 0.9029, accuracy: 0.9570, batch_loss: 0.2362, loss: 0.1265 ||:  12%|#2        | 895/7204 [03:32<28:03,  3.75it/s]
2022-03-22 00:23:05,735 - INFO - tqdm - f1: 0.9026, accuracy: 0.9568, batch_loss: 0.5074, loss: 0.1260 ||:  13%|#2        | 936/7204 [03:42<21:18,  4.90it/s]
2022-03-22 00:23:15,788 - INFO - tqdm - f1: 0.9025, accuracy: 0.9565, batch_loss: 0.1641, loss: 0.1269 ||:  14%|#3        | 978/7204 [03:52<22:01,  4.71it/s]
2022-03-22 00:23:25,935 - INFO - tqdm - f1: 0.9027, accuracy: 0.9565, batch_loss: 0.0127, loss: 0.1279 ||:  14%|#4        | 1019/7204 [04:02<26:25,  3.90it/s]
2022-03-22 00:23:35,953 - INFO - tqdm - f1: 0.9021, accuracy: 0.9561, batch_loss: 0.0150, loss: 0.1289 ||:  15%|#4        | 1065/7204 [04:12<19:59,  5.12it/s]
2022-03-22 00:23:46,050 - INFO - tqdm - f1: 0.9014, accuracy: 0.9561, batch_loss: 0.3175, loss: 0.1287 ||:  15%|#5        | 1105/7204 [04:22<25:31,  3.98it/s]
2022-03-22 00:23:56,139 - INFO - tqdm - f1: 0.9015, accuracy: 0.9561, batch_loss: 0.0656, loss: 0.1276 ||:  16%|#5        | 1147/7204 [04:33<22:17,  4.53it/s]
2022-03-22 00:24:06,322 - INFO - tqdm - f1: 0.9014, accuracy: 0.9558, batch_loss: 0.0193, loss: 0.1287 ||:  16%|#6        | 1187/7204 [04:43<26:34,  3.77it/s]
2022-03-22 00:24:16,500 - INFO - tqdm - f1: 0.9000, accuracy: 0.9553, batch_loss: 0.0131, loss: 0.1298 ||:  17%|#7        | 1229/7204 [04:53<26:00,  3.83it/s]
2022-03-22 00:24:26,660 - INFO - tqdm - f1: 0.8991, accuracy: 0.9546, batch_loss: 0.1647, loss: 0.1312 ||:  18%|#7        | 1278/7204 [05:03<19:56,  4.95it/s]
2022-03-22 00:24:36,788 - INFO - tqdm - f1: 0.8990, accuracy: 0.9544, batch_loss: 0.0280, loss: 0.1314 ||:  18%|#8        | 1315/7204 [05:13<32:37,  3.01it/s]
2022-03-22 00:24:46,885 - INFO - tqdm - f1: 0.8991, accuracy: 0.9545, batch_loss: 0.1329, loss: 0.1312 ||:  19%|#8        | 1356/7204 [05:23<24:41,  3.95it/s]
2022-03-22 00:24:56,970 - INFO - tqdm - f1: 0.8983, accuracy: 0.9542, batch_loss: 0.0386, loss: 0.1318 ||:  19%|#9        | 1398/7204 [05:33<28:15,  3.42it/s]
2022-03-22 00:25:07,070 - INFO - tqdm - f1: 0.8983, accuracy: 0.9541, batch_loss: 0.1475, loss: 0.1318 ||:  20%|#9        | 1438/7204 [05:43<31:13,  3.08it/s]
2022-03-22 00:25:17,112 - INFO - tqdm - f1: 0.8976, accuracy: 0.9537, batch_loss: 0.0545, loss: 0.1322 ||:  21%|##        | 1481/7204 [05:54<19:48,  4.82it/s]
2022-03-22 00:25:27,244 - INFO - tqdm - f1: 0.8969, accuracy: 0.9533, batch_loss: 0.3041, loss: 0.1328 ||:  21%|##1       | 1527/7204 [06:04<20:55,  4.52it/s]
2022-03-22 00:25:37,277 - INFO - tqdm - f1: 0.8967, accuracy: 0.9535, batch_loss: 0.0649, loss: 0.1324 ||:  22%|##1       | 1569/7204 [06:14<22:11,  4.23it/s]
2022-03-22 00:25:47,351 - INFO - tqdm - f1: 0.8959, accuracy: 0.9532, batch_loss: 0.1185, loss: 0.1332 ||:  22%|##2       | 1609/7204 [06:24<26:50,  3.47it/s]
2022-03-22 00:25:57,489 - INFO - tqdm - f1: 0.8962, accuracy: 0.9533, batch_loss: 0.0528, loss: 0.1329 ||:  23%|##2       | 1655/7204 [06:34<16:53,  5.48it/s]
2022-03-22 00:26:07,651 - INFO - tqdm - f1: 0.8963, accuracy: 0.9533, batch_loss: 0.0147, loss: 0.1330 ||:  24%|##3       | 1694/7204 [06:44<27:42,  3.31it/s]
2022-03-22 00:26:17,776 - INFO - tqdm - f1: 0.8967, accuracy: 0.9532, batch_loss: 0.6116, loss: 0.1327 ||:  24%|##4       | 1740/7204 [06:54<18:15,  4.99it/s]
2022-03-22 00:26:27,909 - INFO - tqdm - f1: 0.8965, accuracy: 0.9530, batch_loss: 0.3084, loss: 0.1333 ||:  25%|##4       | 1787/7204 [07:04<15:54,  5.67it/s]
2022-03-22 00:26:37,923 - INFO - tqdm - f1: 0.8967, accuracy: 0.9530, batch_loss: 0.0882, loss: 0.1332 ||:  25%|##5       | 1830/7204 [07:14<19:38,  4.56it/s]
2022-03-22 00:26:48,071 - INFO - tqdm - f1: 0.8970, accuracy: 0.9532, batch_loss: 0.0971, loss: 0.1332 ||:  26%|##5       | 1872/7204 [07:24<23:22,  3.80it/s]
2022-03-22 00:26:58,138 - INFO - tqdm - f1: 0.8970, accuracy: 0.9530, batch_loss: 0.0119, loss: 0.1335 ||:  27%|##6       | 1914/7204 [07:35<24:24,  3.61it/s]
2022-03-22 00:27:08,209 - INFO - tqdm - f1: 0.8976, accuracy: 0.9534, batch_loss: 0.0326, loss: 0.1328 ||:  27%|##7       | 1955/7204 [07:45<19:48,  4.42it/s]
2022-03-22 00:27:18,421 - INFO - tqdm - f1: 0.8979, accuracy: 0.9535, batch_loss: 0.0744, loss: 0.1324 ||:  28%|##7       | 2002/7204 [07:55<21:39,  4.00it/s]
2022-03-22 00:27:28,633 - INFO - tqdm - f1: 0.8972, accuracy: 0.9529, batch_loss: 0.0193, loss: 0.1337 ||:  28%|##8       | 2044/7204 [08:05<24:46,  3.47it/s]
2022-03-22 00:27:38,691 - INFO - tqdm - f1: 0.8968, accuracy: 0.9528, batch_loss: 0.1878, loss: 0.1338 ||:  29%|##8       | 2086/7204 [08:15<21:42,  3.93it/s]
2022-03-22 00:27:48,911 - INFO - tqdm - f1: 0.8969, accuracy: 0.9526, batch_loss: 0.0487, loss: 0.1346 ||:  30%|##9       | 2133/7204 [08:25<21:20,  3.96it/s]
2022-03-22 00:27:59,050 - INFO - tqdm - f1: 0.8969, accuracy: 0.9522, batch_loss: 0.0790, loss: 0.1349 ||:  30%|###       | 2180/7204 [08:35<15:38,  5.35it/s]
2022-03-22 00:28:09,081 - INFO - tqdm - f1: 0.8974, accuracy: 0.9525, batch_loss: 0.0078, loss: 0.1345 ||:  31%|###       | 2222/7204 [08:45<25:47,  3.22it/s]
2022-03-22 00:28:19,248 - INFO - tqdm - f1: 0.8973, accuracy: 0.9524, batch_loss: 0.1376, loss: 0.1344 ||:  31%|###1      | 2266/7204 [08:56<16:59,  4.84it/s]
2022-03-22 00:28:29,479 - INFO - tqdm - f1: 0.8976, accuracy: 0.9525, batch_loss: 0.0679, loss: 0.1341 ||:  32%|###2      | 2308/7204 [09:06<21:10,  3.85it/s]
2022-03-22 00:28:39,522 - INFO - tqdm - f1: 0.8978, accuracy: 0.9527, batch_loss: 0.0867, loss: 0.1333 ||:  33%|###2      | 2350/7204 [09:16<19:27,  4.16it/s]
2022-03-22 00:28:49,755 - INFO - tqdm - f1: 0.8975, accuracy: 0.9524, batch_loss: 0.0419, loss: 0.1341 ||:  33%|###3      | 2395/7204 [09:26<21:22,  3.75it/s]
2022-03-22 00:28:59,812 - INFO - tqdm - f1: 0.8975, accuracy: 0.9523, batch_loss: 0.0396, loss: 0.1340 ||:  34%|###3      | 2440/7204 [09:36<16:50,  4.71it/s]
2022-03-22 00:29:09,984 - INFO - tqdm - f1: 0.8968, accuracy: 0.9520, batch_loss: 0.1203, loss: 0.1353 ||:  35%|###4      | 2487/7204 [09:46<16:24,  4.79it/s]
2022-03-22 00:29:20,115 - INFO - tqdm - f1: 0.8972, accuracy: 0.9523, batch_loss: 0.0067, loss: 0.1345 ||:  35%|###5      | 2530/7204 [09:57<17:56,  4.34it/s]
2022-03-22 00:29:30,295 - INFO - tqdm - f1: 0.8967, accuracy: 0.9521, batch_loss: 0.0134, loss: 0.1352 ||:  36%|###5      | 2575/7204 [10:07<21:30,  3.59it/s]
2022-03-22 00:29:40,662 - INFO - tqdm - f1: 0.8966, accuracy: 0.9519, batch_loss: 0.2354, loss: 0.1352 ||:  36%|###6      | 2621/7204 [10:17<20:10,  3.79it/s]
2022-03-22 00:29:50,955 - INFO - tqdm - f1: 0.8968, accuracy: 0.9519, batch_loss: 0.0102, loss: 0.1353 ||:  37%|###7      | 2666/7204 [10:27<22:19,  3.39it/s]
2022-03-22 00:30:01,082 - INFO - tqdm - f1: 0.8966, accuracy: 0.9517, batch_loss: 0.2851, loss: 0.1359 ||:  38%|###7      | 2717/7204 [10:37<14:53,  5.02it/s]
2022-03-22 00:30:11,082 - INFO - tqdm - f1: 0.8968, accuracy: 0.9517, batch_loss: 0.1356, loss: 0.1358 ||:  38%|###8      | 2760/7204 [10:47<21:27,  3.45it/s]
2022-03-22 00:30:21,334 - INFO - tqdm - f1: 0.8966, accuracy: 0.9516, batch_loss: 0.0102, loss: 0.1361 ||:  39%|###8      | 2807/7204 [10:58<21:40,  3.38it/s]
2022-03-22 00:30:31,389 - INFO - tqdm - f1: 0.8962, accuracy: 0.9515, batch_loss: 0.0561, loss: 0.1365 ||:  40%|###9      | 2849/7204 [11:08<17:43,  4.09it/s]
2022-03-22 00:30:41,466 - INFO - tqdm - f1: 0.8965, accuracy: 0.9516, batch_loss: 0.0598, loss: 0.1362 ||:  40%|####      | 2890/7204 [11:18<15:13,  4.72it/s]
2022-03-22 00:30:51,832 - INFO - tqdm - f1: 0.8960, accuracy: 0.9514, batch_loss: 0.0371, loss: 0.1368 ||:  41%|####      | 2936/7204 [11:28<20:05,  3.54it/s]
2022-03-22 00:31:02,016 - INFO - tqdm - f1: 0.8958, accuracy: 0.9513, batch_loss: 0.0060, loss: 0.1368 ||:  41%|####1     | 2979/7204 [11:38<15:47,  4.46it/s]
2022-03-22 00:31:12,149 - INFO - tqdm - f1: 0.8958, accuracy: 0.9513, batch_loss: 0.3014, loss: 0.1369 ||:  42%|####1     | 3025/7204 [11:49<13:15,  5.25it/s]
2022-03-22 00:31:22,521 - INFO - tqdm - f1: 0.8956, accuracy: 0.9512, batch_loss: 0.0217, loss: 0.1367 ||:  43%|####2     | 3064/7204 [11:59<21:06,  3.27it/s]
2022-03-22 00:31:32,535 - INFO - tqdm - f1: 0.8956, accuracy: 0.9513, batch_loss: 0.2798, loss: 0.1368 ||:  43%|####3     | 3105/7204 [12:09<15:57,  4.28it/s]
2022-03-22 00:31:42,732 - INFO - tqdm - f1: 0.8958, accuracy: 0.9513, batch_loss: 0.1451, loss: 0.1366 ||:  44%|####3     | 3150/7204 [12:19<13:29,  5.01it/s]
2022-03-22 00:31:52,820 - INFO - tqdm - f1: 0.8957, accuracy: 0.9513, batch_loss: 0.0982, loss: 0.1368 ||:  44%|####4     | 3191/7204 [12:29<20:25,  3.28it/s]
2022-03-22 00:32:02,967 - INFO - tqdm - f1: 0.8954, accuracy: 0.9512, batch_loss: 0.1307, loss: 0.1369 ||:  45%|####4     | 3236/7204 [12:39<14:52,  4.45it/s]
2022-03-22 00:32:12,971 - INFO - tqdm - f1: 0.8953, accuracy: 0.9512, batch_loss: 0.0539, loss: 0.1368 ||:  46%|####5     | 3281/7204 [12:49<14:18,  4.57it/s]
2022-03-22 00:32:22,972 - INFO - tqdm - f1: 0.8953, accuracy: 0.9512, batch_loss: 0.3366, loss: 0.1369 ||:  46%|####6     | 3323/7204 [12:59<15:33,  4.16it/s]
2022-03-22 00:32:33,110 - INFO - tqdm - f1: 0.8951, accuracy: 0.9510, batch_loss: 0.1500, loss: 0.1370 ||:  47%|####6     | 3369/7204 [13:10<13:04,  4.89it/s]
2022-03-22 00:32:43,337 - INFO - tqdm - f1: 0.8948, accuracy: 0.9510, batch_loss: 0.1503, loss: 0.1373 ||:  47%|####7     | 3412/7204 [13:20<17:24,  3.63it/s]
2022-03-22 00:32:53,363 - INFO - tqdm - f1: 0.8946, accuracy: 0.9509, batch_loss: 0.0144, loss: 0.1373 ||:  48%|####7     | 3454/7204 [13:30<14:21,  4.35it/s]
2022-03-22 00:33:03,535 - INFO - tqdm - f1: 0.8947, accuracy: 0.9508, batch_loss: 0.0259, loss: 0.1375 ||:  49%|####8     | 3501/7204 [13:40<13:02,  4.73it/s]
2022-03-22 00:33:13,705 - INFO - tqdm - f1: 0.8946, accuracy: 0.9508, batch_loss: 0.1874, loss: 0.1375 ||:  49%|####9     | 3544/7204 [13:50<13:33,  4.50it/s]
2022-03-22 00:33:23,869 - INFO - tqdm - f1: 0.8939, accuracy: 0.9505, batch_loss: 0.0714, loss: 0.1384 ||:  50%|####9     | 3585/7204 [14:00<13:40,  4.41it/s]
2022-03-22 00:33:34,075 - INFO - tqdm - f1: 0.8937, accuracy: 0.9504, batch_loss: 0.0195, loss: 0.1387 ||:  50%|#####     | 3628/7204 [14:10<16:20,  3.65it/s]
2022-03-22 00:33:44,199 - INFO - tqdm - f1: 0.8938, accuracy: 0.9505, batch_loss: 0.1947, loss: 0.1385 ||:  51%|#####     | 3672/7204 [14:21<16:35,  3.55it/s]
2022-03-22 00:33:54,373 - INFO - tqdm - f1: 0.8935, accuracy: 0.9504, batch_loss: 0.1079, loss: 0.1387 ||:  52%|#####2    | 3755/7204 [14:31<05:40, 10.13it/s]
2022-03-22 00:34:04,457 - INFO - tqdm - f1: 0.8934, accuracy: 0.9504, batch_loss: 0.2554, loss: 0.1389 ||:  53%|#####2    | 3817/7204 [14:41<08:40,  6.51it/s]
2022-03-22 00:34:14,565 - INFO - tqdm - f1: 0.8932, accuracy: 0.9502, batch_loss: 0.5667, loss: 0.1395 ||:  54%|#####3    | 3877/7204 [14:51<12:37,  4.39it/s]
2022-03-22 00:34:24,762 - INFO - tqdm - f1: 0.8930, accuracy: 0.9502, batch_loss: 0.1394, loss: 0.1398 ||:  55%|#####4    | 3934/7204 [15:01<12:33,  4.34it/s]
2022-03-22 00:34:34,822 - INFO - tqdm - f1: 0.8930, accuracy: 0.9501, batch_loss: 0.0936, loss: 0.1398 ||:  55%|#####5    | 3983/7204 [15:11<11:44,  4.57it/s]
2022-03-22 00:34:44,931 - INFO - tqdm - f1: 0.8928, accuracy: 0.9500, batch_loss: 0.0109, loss: 0.1401 ||:  56%|#####5    | 4028/7204 [15:21<13:28,  3.93it/s]
2022-03-22 00:34:55,089 - INFO - tqdm - f1: 0.8924, accuracy: 0.9498, batch_loss: 0.1106, loss: 0.1404 ||:  57%|#####6    | 4072/7204 [15:31<11:48,  4.42it/s]
2022-03-22 00:35:05,156 - INFO - tqdm - f1: 0.8924, accuracy: 0.9497, batch_loss: 0.2157, loss: 0.1407 ||:  57%|#####7    | 4117/7204 [15:42<10:19,  4.98it/s]
2022-03-22 00:35:15,403 - INFO - tqdm - f1: 0.8925, accuracy: 0.9498, batch_loss: 0.0329, loss: 0.1407 ||:  58%|#####7    | 4162/7204 [15:52<11:42,  4.33it/s]
2022-03-22 00:35:25,593 - INFO - tqdm - f1: 0.8925, accuracy: 0.9499, batch_loss: 0.0122, loss: 0.1406 ||:  58%|#####8    | 4205/7204 [16:02<16:01,  3.12it/s]
2022-03-22 00:35:35,632 - INFO - tqdm - f1: 0.8924, accuracy: 0.9497, batch_loss: 0.2827, loss: 0.1407 ||:  59%|#####8    | 4250/7204 [16:12<10:11,  4.83it/s]
2022-03-22 00:35:45,748 - INFO - tqdm - f1: 0.8924, accuracy: 0.9498, batch_loss: 0.0659, loss: 0.1406 ||:  60%|#####9    | 4291/7204 [16:22<11:50,  4.10it/s]
2022-03-22 00:35:55,965 - INFO - tqdm - f1: 0.8921, accuracy: 0.9496, batch_loss: 0.0327, loss: 0.1409 ||:  60%|######    | 4333/7204 [16:32<13:16,  3.61it/s]
2022-03-22 00:36:06,231 - INFO - tqdm - f1: 0.8919, accuracy: 0.9496, batch_loss: 0.0101, loss: 0.1408 ||:  61%|######    | 4376/7204 [16:43<11:55,  3.95it/s]
2022-03-22 00:36:16,321 - INFO - tqdm - f1: 0.8920, accuracy: 0.9496, batch_loss: 0.0192, loss: 0.1408 ||:  61%|######1   | 4421/7204 [16:53<08:45,  5.30it/s]
2022-03-22 00:36:26,428 - INFO - tqdm - f1: 0.8919, accuracy: 0.9495, batch_loss: 0.3861, loss: 0.1411 ||:  62%|######1   | 4466/7204 [17:03<08:08,  5.61it/s]
2022-03-22 00:36:36,536 - INFO - tqdm - f1: 0.8920, accuracy: 0.9495, batch_loss: 0.2638, loss: 0.1413 ||:  63%|######2   | 4509/7204 [17:13<08:54,  5.04it/s]
2022-03-22 00:36:46,582 - INFO - tqdm - f1: 0.8920, accuracy: 0.9495, batch_loss: 0.3032, loss: 0.1416 ||:  63%|######3   | 4555/7204 [17:23<08:42,  5.07it/s]
2022-03-22 00:36:56,744 - INFO - tqdm - f1: 0.8923, accuracy: 0.9496, batch_loss: 0.0264, loss: 0.1414 ||:  64%|######3   | 4598/7204 [17:33<09:12,  4.72it/s]
2022-03-22 00:37:06,774 - INFO - tqdm - f1: 0.8925, accuracy: 0.9496, batch_loss: 0.0696, loss: 0.1415 ||:  64%|######4   | 4642/7204 [17:43<09:03,  4.71it/s]
2022-03-22 00:37:16,824 - INFO - tqdm - f1: 0.8919, accuracy: 0.9494, batch_loss: 0.0756, loss: 0.1420 ||:  65%|######5   | 4684/7204 [17:53<10:30,  4.00it/s]
2022-03-22 00:37:27,019 - INFO - tqdm - f1: 0.8918, accuracy: 0.9494, batch_loss: 0.2410, loss: 0.1421 ||:  66%|######5   | 4729/7204 [18:03<09:50,  4.19it/s]
2022-03-22 00:37:37,152 - INFO - tqdm - f1: 0.8916, accuracy: 0.9492, batch_loss: 0.2458, loss: 0.1426 ||:  66%|######6   | 4772/7204 [18:14<09:48,  4.13it/s]
2022-03-22 00:37:47,239 - INFO - tqdm - f1: 0.8914, accuracy: 0.9491, batch_loss: 0.2995, loss: 0.1427 ||:  67%|######6   | 4816/7204 [18:24<07:46,  5.12it/s]
2022-03-22 00:37:57,368 - INFO - tqdm - f1: 0.8911, accuracy: 0.9489, batch_loss: 0.1823, loss: 0.1430 ||:  67%|######7   | 4861/7204 [18:34<10:23,  3.75it/s]
2022-03-22 00:38:07,409 - INFO - tqdm - f1: 0.8912, accuracy: 0.9489, batch_loss: 0.0096, loss: 0.1430 ||:  68%|######8   | 4905/7204 [18:44<09:19,  4.11it/s]
2022-03-22 00:38:17,419 - INFO - tqdm - f1: 0.8910, accuracy: 0.9488, batch_loss: 0.2602, loss: 0.1431 ||:  69%|######8   | 4948/7204 [18:54<07:28,  5.03it/s]
2022-03-22 00:38:27,508 - INFO - tqdm - f1: 0.8911, accuracy: 0.9488, batch_loss: 0.4093, loss: 0.1428 ||:  69%|######9   | 4991/7204 [19:04<07:48,  4.72it/s]
2022-03-22 00:38:37,541 - INFO - tqdm - f1: 0.8908, accuracy: 0.9487, batch_loss: 0.2174, loss: 0.1432 ||:  70%|######9   | 5033/7204 [19:14<07:04,  5.12it/s]
2022-03-22 00:38:47,643 - INFO - tqdm - f1: 0.8904, accuracy: 0.9484, batch_loss: 0.3145, loss: 0.1437 ||:  71%|#######   | 5080/7204 [19:24<06:56,  5.10it/s]
2022-03-22 00:38:57,669 - INFO - tqdm - f1: 0.8903, accuracy: 0.9483, batch_loss: 0.2259, loss: 0.1438 ||:  71%|#######1  | 5126/7204 [19:34<06:41,  5.17it/s]
2022-03-22 00:39:07,783 - INFO - tqdm - f1: 0.8902, accuracy: 0.9483, batch_loss: 0.1251, loss: 0.1439 ||:  72%|#######1  | 5173/7204 [19:44<08:52,  3.81it/s]
2022-03-22 00:39:17,823 - INFO - tqdm - f1: 0.8901, accuracy: 0.9482, batch_loss: 0.1547, loss: 0.1440 ||:  72%|#######2  | 5215/7204 [19:54<09:49,  3.37it/s]
2022-03-22 00:39:27,944 - INFO - tqdm - f1: 0.8898, accuracy: 0.9481, batch_loss: 0.0382, loss: 0.1442 ||:  73%|#######3  | 5259/7204 [20:04<07:28,  4.34it/s]
2022-03-22 00:39:38,048 - INFO - tqdm - f1: 0.8899, accuracy: 0.9481, batch_loss: 0.1147, loss: 0.1443 ||:  74%|#######3  | 5303/7204 [20:14<07:20,  4.32it/s]
2022-03-22 00:39:48,140 - INFO - tqdm - f1: 0.8897, accuracy: 0.9480, batch_loss: 0.2487, loss: 0.1444 ||:  74%|#######4  | 5346/7204 [20:25<07:54,  3.92it/s]
2022-03-22 00:39:58,302 - INFO - tqdm - f1: 0.8897, accuracy: 0.9480, batch_loss: 0.0510, loss: 0.1444 ||:  75%|#######4  | 5390/7204 [20:35<07:01,  4.30it/s]
2022-03-22 00:40:08,527 - INFO - tqdm - f1: 0.8899, accuracy: 0.9480, batch_loss: 0.0103, loss: 0.1444 ||:  75%|#######5  | 5435/7204 [20:45<06:42,  4.40it/s]
2022-03-22 00:40:18,746 - INFO - tqdm - f1: 0.8899, accuracy: 0.9481, batch_loss: 0.0583, loss: 0.1446 ||:  76%|#######6  | 5478/7204 [20:55<06:30,  4.42it/s]
2022-03-22 00:40:28,815 - INFO - tqdm - f1: 0.8899, accuracy: 0.9481, batch_loss: 0.0217, loss: 0.1445 ||:  77%|#######6  | 5518/7204 [21:05<06:54,  4.06it/s]
2022-03-22 00:40:38,819 - INFO - tqdm - f1: 0.8900, accuracy: 0.9481, batch_loss: 0.2737, loss: 0.1445 ||:  77%|#######7  | 5558/7204 [21:15<08:00,  3.42it/s]
2022-03-22 00:40:48,908 - INFO - tqdm - f1: 0.8901, accuracy: 0.9481, batch_loss: 0.2114, loss: 0.1445 ||:  78%|#######7  | 5607/7204 [21:25<05:17,  5.03it/s]
2022-03-22 00:40:59,034 - INFO - tqdm - f1: 0.8900, accuracy: 0.9481, batch_loss: 0.1156, loss: 0.1447 ||:  79%|#######8  | 5656/7204 [21:35<05:12,  4.95it/s]
2022-03-22 00:41:09,118 - INFO - tqdm - f1: 0.8900, accuracy: 0.9481, batch_loss: 0.0076, loss: 0.1447 ||:  79%|#######9  | 5699/7204 [21:46<06:59,  3.59it/s]
2022-03-22 00:41:19,168 - INFO - tqdm - f1: 0.8899, accuracy: 0.9480, batch_loss: 0.0483, loss: 0.1450 ||:  80%|#######9  | 5745/7204 [21:56<05:20,  4.55it/s]
2022-03-22 00:41:29,345 - INFO - tqdm - f1: 0.8900, accuracy: 0.9480, batch_loss: 0.1177, loss: 0.1453 ||:  80%|########  | 5788/7204 [22:06<07:39,  3.08it/s]
2022-03-22 00:41:39,530 - INFO - tqdm - f1: 0.8902, accuracy: 0.9480, batch_loss: 0.0416, loss: 0.1452 ||:  81%|########  | 5831/7204 [22:16<05:17,  4.32it/s]
2022-03-22 00:41:49,645 - INFO - tqdm - f1: 0.8903, accuracy: 0.9481, batch_loss: 0.1808, loss: 0.1451 ||:  82%|########1 | 5875/7204 [22:26<04:18,  5.14it/s]
2022-03-22 00:41:59,744 - INFO - tqdm - f1: 0.8902, accuracy: 0.9480, batch_loss: 0.4521, loss: 0.1452 ||:  82%|########2 | 5919/7204 [22:36<04:09,  5.15it/s]
2022-03-22 00:42:09,935 - INFO - tqdm - f1: 0.8901, accuracy: 0.9480, batch_loss: 0.4284, loss: 0.1454 ||:  83%|########2 | 5963/7204 [22:46<05:39,  3.66it/s]
2022-03-22 00:42:20,084 - INFO - tqdm - f1: 0.8901, accuracy: 0.9480, batch_loss: 0.1717, loss: 0.1452 ||:  83%|########3 | 6006/7204 [22:56<04:00,  4.98it/s]
2022-03-22 00:42:30,220 - INFO - tqdm - f1: 0.8900, accuracy: 0.9480, batch_loss: 0.0124, loss: 0.1452 ||:  84%|########4 | 6052/7204 [23:07<04:38,  4.14it/s]
2022-03-22 00:42:40,432 - INFO - tqdm - f1: 0.8901, accuracy: 0.9481, batch_loss: 0.0076, loss: 0.1451 ||:  85%|########4 | 6099/7204 [23:17<04:04,  4.53it/s]
2022-03-22 00:42:50,524 - INFO - tqdm - f1: 0.8902, accuracy: 0.9481, batch_loss: 0.1252, loss: 0.1451 ||:  85%|########5 | 6144/7204 [23:27<03:27,  5.11it/s]
2022-03-22 00:43:00,763 - INFO - tqdm - f1: 0.8901, accuracy: 0.9481, batch_loss: 0.0472, loss: 0.1452 ||:  86%|########5 | 6187/7204 [23:37<03:37,  4.68it/s]
2022-03-22 00:43:11,138 - INFO - tqdm - f1: 0.8901, accuracy: 0.9481, batch_loss: 0.0087, loss: 0.1453 ||:  86%|########6 | 6228/7204 [23:48<04:54,  3.31it/s]
2022-03-22 00:43:21,149 - INFO - tqdm - f1: 0.8900, accuracy: 0.9481, batch_loss: 0.0272, loss: 0.1452 ||:  87%|########7 | 6270/7204 [23:58<03:56,  3.95it/s]
2022-03-22 00:43:31,301 - INFO - tqdm - f1: 0.8899, accuracy: 0.9481, batch_loss: 0.0209, loss: 0.1453 ||:  88%|########7 | 6314/7204 [24:08<03:47,  3.91it/s]
2022-03-22 00:43:41,339 - INFO - tqdm - f1: 0.8898, accuracy: 0.9481, batch_loss: 0.4769, loss: 0.1453 ||:  88%|########8 | 6357/7204 [24:18<03:17,  4.28it/s]
2022-03-22 00:43:51,359 - INFO - tqdm - f1: 0.8897, accuracy: 0.9480, batch_loss: 0.2126, loss: 0.1453 ||:  89%|########8 | 6399/7204 [24:28<03:02,  4.40it/s]
2022-03-22 00:44:01,694 - INFO - tqdm - f1: 0.8896, accuracy: 0.9480, batch_loss: 0.0531, loss: 0.1455 ||:  89%|########9 | 6442/7204 [24:38<03:20,  3.80it/s]
2022-03-22 00:44:11,929 - INFO - tqdm - f1: 0.8896, accuracy: 0.9480, batch_loss: 0.0104, loss: 0.1455 ||:  90%|######### | 6485/7204 [24:48<03:38,  3.29it/s]
2022-03-22 00:44:21,959 - INFO - tqdm - f1: 0.8899, accuracy: 0.9481, batch_loss: 0.1162, loss: 0.1452 ||:  91%|######### | 6525/7204 [24:58<02:08,  5.28it/s]
2022-03-22 00:44:32,229 - INFO - tqdm - f1: 0.8897, accuracy: 0.9480, batch_loss: 0.0277, loss: 0.1453 ||:  91%|#########1| 6570/7204 [25:09<02:27,  4.28it/s]
2022-03-22 00:44:42,309 - INFO - tqdm - f1: 0.8897, accuracy: 0.9480, batch_loss: 0.0438, loss: 0.1454 ||:  92%|#########1| 6611/7204 [25:19<03:04,  3.21it/s]
2022-03-22 00:44:52,337 - INFO - tqdm - f1: 0.8898, accuracy: 0.9480, batch_loss: 0.0576, loss: 0.1453 ||:  92%|#########2| 6655/7204 [25:29<02:26,  3.76it/s]
2022-03-22 00:45:02,619 - INFO - tqdm - f1: 0.8897, accuracy: 0.9480, batch_loss: 0.0276, loss: 0.1455 ||:  93%|#########2| 6699/7204 [25:39<02:13,  3.77it/s]
2022-03-22 00:45:12,845 - INFO - tqdm - f1: 0.8894, accuracy: 0.9479, batch_loss: 0.1762, loss: 0.1458 ||:  94%|#########3| 6741/7204 [25:49<02:09,  3.58it/s]
2022-03-22 00:45:22,942 - INFO - tqdm - f1: 0.8896, accuracy: 0.9479, batch_loss: 0.0876, loss: 0.1457 ||:  94%|#########4| 6782/7204 [25:59<01:32,  4.55it/s]
2022-03-22 00:45:33,117 - INFO - tqdm - f1: 0.8895, accuracy: 0.9478, batch_loss: 0.0788, loss: 0.1458 ||:  95%|#########4| 6827/7204 [26:10<01:25,  4.43it/s]
2022-03-22 00:45:43,276 - INFO - tqdm - f1: 0.8894, accuracy: 0.9477, batch_loss: 0.1387, loss: 0.1459 ||:  95%|#########5| 6872/7204 [26:20<01:10,  4.69it/s]
2022-03-22 00:45:53,392 - INFO - tqdm - f1: 0.8893, accuracy: 0.9476, batch_loss: 0.0191, loss: 0.1460 ||:  96%|#########6| 6917/7204 [26:30<01:20,  3.58it/s]
2022-03-22 00:46:03,500 - INFO - tqdm - f1: 0.8892, accuracy: 0.9476, batch_loss: 0.2258, loss: 0.1461 ||:  97%|#########6| 6964/7204 [26:40<00:47,  5.05it/s]
2022-03-22 00:46:13,646 - INFO - tqdm - f1: 0.8891, accuracy: 0.9475, batch_loss: 0.1256, loss: 0.1465 ||:  97%|#########7| 7010/7204 [26:50<00:41,  4.62it/s]
2022-03-22 00:46:23,718 - INFO - tqdm - f1: 0.8892, accuracy: 0.9475, batch_loss: 0.0290, loss: 0.1464 ||:  98%|#########7| 7049/7204 [27:00<00:48,  3.18it/s]
2022-03-22 00:46:33,821 - INFO - tqdm - f1: 0.8890, accuracy: 0.9475, batch_loss: 0.2260, loss: 0.1465 ||:  99%|#########8| 7096/7204 [27:10<00:24,  4.39it/s]
2022-03-22 00:46:43,868 - INFO - tqdm - f1: 0.8890, accuracy: 0.9475, batch_loss: 0.0142, loss: 0.1466 ||:  99%|#########9| 7133/7204 [27:20<00:18,  3.78it/s]
2022-03-22 00:46:51,507 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.2506, loss: 0.1467 ||: 100%|#########9| 7168/7204 [27:28<00:08,  4.27it/s]
2022-03-22 00:46:51,771 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.0371, loss: 0.1467 ||: 100%|#########9| 7169/7204 [27:28<00:08,  4.11it/s]
2022-03-22 00:46:52,022 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.0529, loss: 0.1467 ||: 100%|#########9| 7170/7204 [27:28<00:08,  4.07it/s]
2022-03-22 00:46:52,216 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.3184, loss: 0.1467 ||: 100%|#########9| 7171/7204 [27:29<00:07,  4.35it/s]
2022-03-22 00:46:52,392 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.0382, loss: 0.1467 ||: 100%|#########9| 7172/7204 [27:29<00:06,  4.67it/s]
2022-03-22 00:46:52,629 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.1734, loss: 0.1467 ||: 100%|#########9| 7173/7204 [27:29<00:06,  4.53it/s]
2022-03-22 00:46:52,908 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.1384, loss: 0.1467 ||: 100%|#########9| 7174/7204 [27:29<00:07,  4.20it/s]
2022-03-22 00:46:53,068 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.1804, loss: 0.1467 ||: 100%|#########9| 7175/7204 [27:29<00:06,  4.66it/s]
2022-03-22 00:46:53,249 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.0676, loss: 0.1467 ||: 100%|#########9| 7176/7204 [27:30<00:05,  4.89it/s]
2022-03-22 00:46:53,493 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.0991, loss: 0.1467 ||: 100%|#########9| 7177/7204 [27:30<00:05,  4.62it/s]
2022-03-22 00:46:53,771 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.1296, loss: 0.1467 ||: 100%|#########9| 7178/7204 [27:30<00:06,  4.26it/s]
2022-03-22 00:46:54,001 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.3575, loss: 0.1467 ||: 100%|#########9| 7179/7204 [27:30<00:05,  4.28it/s]
2022-03-22 00:46:54,189 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.4610, loss: 0.1468 ||: 100%|#########9| 7180/7204 [27:31<00:05,  4.55it/s]
2022-03-22 00:46:54,399 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.0760, loss: 0.1468 ||: 100%|#########9| 7181/7204 [27:31<00:04,  4.61it/s]
2022-03-22 00:46:54,590 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.3260, loss: 0.1468 ||: 100%|#########9| 7182/7204 [27:31<00:04,  4.78it/s]
2022-03-22 00:46:54,886 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.0432, loss: 0.1468 ||: 100%|#########9| 7183/7204 [27:31<00:04,  4.25it/s]
2022-03-22 00:46:55,114 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.0804, loss: 0.1468 ||: 100%|#########9| 7184/7204 [27:32<00:04,  4.29it/s]
2022-03-22 00:46:55,365 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.1447, loss: 0.1468 ||: 100%|#########9| 7185/7204 [27:32<00:04,  4.19it/s]
2022-03-22 00:46:55,725 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.0129, loss: 0.1467 ||: 100%|#########9| 7186/7204 [27:32<00:04,  3.64it/s]
2022-03-22 00:46:55,912 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.0525, loss: 0.1467 ||: 100%|#########9| 7187/7204 [27:32<00:04,  4.02it/s]
2022-03-22 00:46:56,123 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.3633, loss: 0.1468 ||: 100%|#########9| 7188/7204 [27:33<00:03,  4.21it/s]
2022-03-22 00:46:56,276 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.2105, loss: 0.1468 ||: 100%|#########9| 7189/7204 [27:33<00:03,  4.71it/s]
2022-03-22 00:46:56,565 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.0450, loss: 0.1467 ||: 100%|#########9| 7190/7204 [27:33<00:03,  4.25it/s]
2022-03-22 00:46:56,753 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.0924, loss: 0.1467 ||: 100%|#########9| 7191/7204 [27:33<00:02,  4.53it/s]
2022-03-22 00:46:56,894 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.1262, loss: 0.1467 ||: 100%|#########9| 7192/7204 [27:33<00:02,  5.07it/s]
2022-03-22 00:46:57,241 - INFO - tqdm - f1: 0.8891, accuracy: 0.9474, batch_loss: 0.2489, loss: 0.1468 ||: 100%|#########9| 7193/7204 [27:34<00:02,  4.13it/s]
2022-03-22 00:46:57,510 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.2777, loss: 0.1468 ||: 100%|#########9| 7194/7204 [27:34<00:02,  4.00it/s]
2022-03-22 00:46:57,772 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.0358, loss: 0.1468 ||: 100%|#########9| 7195/7204 [27:34<00:02,  3.94it/s]
2022-03-22 00:46:58,189 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.0599, loss: 0.1467 ||: 100%|#########9| 7196/7204 [27:35<00:02,  3.30it/s]
2022-03-22 00:46:58,330 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.9501, loss: 0.1469 ||: 100%|#########9| 7197/7204 [27:35<00:01,  3.93it/s]
2022-03-22 00:46:58,569 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.1263, loss: 0.1469 ||: 100%|#########9| 7198/7204 [27:35<00:01,  4.01it/s]
2022-03-22 00:46:58,978 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.0147, loss: 0.1468 ||: 100%|#########9| 7199/7204 [27:35<00:01,  3.36it/s]
2022-03-22 00:46:59,144 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.1741, loss: 0.1468 ||: 100%|#########9| 7200/7204 [27:36<00:01,  3.88it/s]
2022-03-22 00:46:59,435 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.1521, loss: 0.1468 ||: 100%|#########9| 7201/7204 [27:36<00:00,  3.73it/s]
2022-03-22 00:46:59,586 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.1830, loss: 0.1468 ||: 100%|#########9| 7202/7204 [27:36<00:00,  4.30it/s]
2022-03-22 00:46:59,771 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.0695, loss: 0.1468 ||: 100%|#########9| 7203/7204 [27:36<00:00,  4.58it/s]
2022-03-22 00:46:59,994 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.2147, loss: 0.1468 ||: 100%|##########| 7204/7204 [27:36<00:00,  4.55it/s]
2022-03-22 00:47:00,051 - INFO - tqdm - f1: 0.8890, accuracy: 0.9474, batch_loss: 0.2147, loss: 0.1468 ||: 100%|##########| 7204/7204 [27:36<00:00,  4.35it/s]
2022-03-22 00:47:00,089 - INFO - allennlp.training.trainer - Validating
2022-03-22 00:47:00,092 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-22 00:47:10,276 - INFO - tqdm - f1: 0.6528, accuracy: 0.8737, batch_loss: 0.4705, loss: 0.4265 ||:  31%|###       | 97/313 [00:10<00:24,  8.75it/s]
2022-03-22 00:47:20,419 - INFO - tqdm - f1: 0.6418, accuracy: 0.8649, batch_loss: 0.7906, loss: 0.4712 ||:  61%|######1   | 192/313 [00:20<00:12,  9.61it/s]
2022-03-22 00:47:30,612 - INFO - tqdm - f1: 0.6343, accuracy: 0.8683, batch_loss: 0.7014, loss: 0.4600 ||:  90%|######### | 282/313 [00:30<00:03,  9.75it/s]
2022-03-22 00:47:33,674 - INFO - tqdm - f1: 0.6357, accuracy: 0.8678, batch_loss: 0.6811, loss: 0.4577 ||: 100%|##########| 313/313 [00:33<00:00, 10.55it/s]
2022-03-22 00:47:33,683 - INFO - tqdm - f1: 0.6357, accuracy: 0.8678, batch_loss: 0.6811, loss: 0.4577 ||: 100%|##########| 313/313 [00:33<00:00,  9.32it/s]
2022-03-22 00:47:33,686 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-22 00:47:33,688 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-22 00:47:34,158 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-22 00:47:34,165 - INFO - allennlp.training.util - Iterating over dataset
2022-03-22 00:47:34,167 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-22 00:47:34,204 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-22 00:47:34,206 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-22 00:47:44,413 - INFO - tqdm - f1: 0.69, accuracy: 0.87, loss: 0.33 ||: : 98it [00:10,  8.17it/s]
2022-03-22 00:47:54,456 - INFO - tqdm - f1: 0.67, accuracy: 0.87, loss: 0.34 ||: : 197it [00:20, 10.16it/s]
2022-03-22 00:48:04,590 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.33 ||: : 292it [00:30,  8.21it/s]
2022-03-22 00:48:14,845 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.33 ||: : 391it [00:40,  9.50it/s]
2022-03-22 00:48:24,915 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.33 ||: : 485it [00:50, 10.68it/s]
2022-03-22 00:48:34,918 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.33 ||: : 577it [01:00, 11.26it/s]
2022-03-22 00:48:44,970 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.33 ||: : 673it [01:10, 10.42it/s]
2022-03-22 00:48:55,011 - INFO - tqdm - f1: 0.68, accuracy: 0.88, loss: 0.32 ||: : 769it [01:20,  8.25it/s]
2022-03-22 00:49:05,117 - INFO - tqdm - f1: 0.69, accuracy: 0.88, loss: 0.32 ||: : 865it [01:30,  8.79it/s]
2022-03-22 00:49:15,252 - INFO - tqdm - f1: 0.69, accuracy: 0.88, loss: 0.32 ||: : 961it [01:41,  9.30it/s]
2022-03-22 00:49:25,538 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.33 ||: : 1062it [01:51,  9.24it/s]
2022-03-22 00:49:35,539 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.33 ||: : 1153it [02:01,  8.92it/s]
2022-03-22 00:49:45,558 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.33 ||: : 1249it [02:11,  9.07it/s]
2022-03-22 00:49:55,723 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.33 ||: : 1342it [02:21,  8.20it/s]
2022-03-22 00:50:05,988 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.33 ||: : 1443it [02:31,  9.30it/s]
2022-03-22 00:50:16,132 - INFO - tqdm - f1: 0.68, accuracy: 0.87, loss: 0.33 ||: : 1543it [02:41, 10.44it/s]
2022-03-22 00:50:18,081 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 2,
  "peak_worker_0_memory_MB": 13603.87109375,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "2:21:22.874722",
  "training_start_epoch": 0,
  "training_epochs": 4,
  "epoch": 4,
  "training_f1": 0.8490341603755951,
  "training_accuracy": 0.9301003895844722,
  "training_loss": 0.18403331326975692,
  "training_worker_0_memory_MB": 13603.87109375,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.6674648523330688,
  "validation_accuracy": 0.8674,
  "validation_loss": 0.43042397487480133,
  "best_validation_f1": 0.6809341907501221,
  "best_validation_accuracy": 0.8706,
  "best_validation_loss": 0.3293500272170328,
  "test_f1": 0.6764692068099976,
  "test_accuracy": 0.87268,
  "test_loss": 0.32933413250561294
}
2022-03-22 00:50:18,829 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/amazon_base_hyper_small_seed_47/model.tar.gz
