2022-03-21 14:24:37,237 - INFO - allennlp.common.params - random_seed = 314
2022-03-21 14:24:37,240 - INFO - allennlp.common.params - numpy_seed = 314
2022-03-21 14:24:37,242 - INFO - allennlp.common.params - pytorch_seed = 314
2022-03-21 14:24:37,248 - INFO - allennlp.common.checks - Pytorch version: 1.8.0+cu111
2022-03-21 14:24:37,250 - INFO - allennlp.common.params - type = default
2022-03-21 14:24:37,252 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling
2022-03-21 14:24:37,254 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 14:24:37,255 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 14:24:37,257 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 14:24:37,258 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 14:24:37,259 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 14:24:37,261 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 14:24:50,595 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 14:24:50,601 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 14:24:50,603 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 14:24:50,604 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512
2022-03-21 14:24:50,606 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0
2022-03-21 14:24:50,607 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 14:24:50,610 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512
2022-03-21 14:24:50,612 - INFO - allennlp.common.params - dataset_reader.sample = None
2022-03-21 14:24:50,613 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False
2022-03-21 14:24:50,615 - INFO - allennlp.common.params - train_data_path = datasets/ag/train.jsonl
2022-03-21 14:24:50,617 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7fc5dd963050>
2022-03-21 14:24:50,619 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-21 14:24:50,620 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling
2022-03-21 14:24:50,622 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer
2022-03-21 14:24:50,624 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-03-21 14:24:50,625 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = roberta-base
2022-03-21 14:24:50,627 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags
2022-03-21 14:24:50,628 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512
2022-03-21 14:24:50,630 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-03-21 14:24:50,632 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer
2022-03-21 14:24:50,634 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base
2022-03-21 14:24:50,636 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.add_special_tokens = True
2022-03-21 14:24:50,637 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.max_length = 512
2022-03-21 14:24:50,639 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.stride = 0
2022-03-21 14:24:50,640 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.tokenizer_kwargs = None
2022-03-21 14:24:50,642 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512
2022-03-21 14:24:50,645 - INFO - allennlp.common.params - validation_dataset_reader.sample = None
2022-03-21 14:24:50,646 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False
2022-03-21 14:24:50,648 - INFO - allennlp.common.params - validation_data_path = datasets/ag/dev.jsonl
2022-03-21 14:24:50,650 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-21 14:24:50,651 - INFO - allennlp.common.params - test_data_path = datasets/ag/test.jsonl
2022-03-21 14:24:50,653 - INFO - allennlp.common.params - evaluate_on_test = True
2022-03-21 14:24:50,654 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-21 14:24:50,656 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 14:24:50,658 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 14:24:50,659 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 14:24:50,660 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 14:24:50,662 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 14:24:50,664 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 14:24:50,665 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 14:24:50,667 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 14:24:50,668 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 14:24:50,669 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 14:24:50,671 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 14:24:50,674 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 14:24:50,675 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 14:24:50,677 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 14:24:50,679 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 14:25:00,688 - INFO - tqdm - loading instances: 31763it [00:10, 3730.44it/s]
2022-03-21 14:25:10,787 - INFO - tqdm - loading instances: 63847it [00:20, 3793.28it/s]
2022-03-21 14:25:20,789 - INFO - tqdm - loading instances: 94761it [00:30, 3649.25it/s]
2022-03-21 14:25:27,436 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 14:25:27,442 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 14:25:27,446 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 14:25:27,448 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 14:25:27,449 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 14:25:27,451 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 14:25:27,452 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 14:25:27,454 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 14:25:27,456 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 14:25:27,457 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 14:25:27,459 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 14:25:27,460 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 14:25:27,462 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 14:25:27,464 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 14:25:27,466 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 14:25:28,820 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-03-21 14:25:28,826 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-03-21 14:25:28,827 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-21 14:25:28,829 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-21 14:25:28,831 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-21 14:25:28,833 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2022-03-21 14:25:28,834 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-21 14:25:28,836 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-21 14:25:28,837 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-21 14:25:28,839 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-21 14:25:28,840 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-21 14:25:28,842 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-03-21 14:25:28,843 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-03-21 14:25:28,845 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-03-21 14:25:28,846 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-03-21 14:25:30,886 - INFO - allennlp.common.params - type = from_instances
2022-03-21 14:25:30,892 - INFO - allennlp.common.params - min_count = None
2022-03-21 14:25:30,894 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-21 14:25:30,895 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-21 14:25:30,897 - INFO - allennlp.common.params - pretrained_files = None
2022-03-21 14:25:30,898 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-21 14:25:30,900 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-21 14:25:30,901 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-21 14:25:30,903 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-21 14:25:30,904 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-21 14:25:30,906 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-21 14:25:30,907 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-21 14:25:31,621 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1
2022-03-21 14:25:31,627 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-03-21 14:25:31,629 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2022-03-21 14:25:31,631 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-base
2022-03-21 14:25:31,632 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512
2022-03-21 14:25:31,633 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2022-03-21 14:25:31,634 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-03-21 14:25:31,636 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-03-21 14:25:31,637 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2022-03-21 14:25:31,639 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2022-03-21 14:25:31,640 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-03-21 14:25:31,642 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-03-21 14:25:31,643 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-03-21 14:25:38,109 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler
2022-03-21 14:25:38,115 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768
2022-03-21 14:25:38,117 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False
2022-03-21 14:25:38,118 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768
2022-03-21 14:25:38,121 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1
2022-03-21 14:25:38,122 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768
2022-03-21 14:25:38,124 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh
2022-03-21 14:25:38,125 - INFO - allennlp.common.params - type = tanh
2022-03-21 14:25:38,127 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0
2022-03-21 14:25:38,136 - INFO - allennlp.common.params - model.seq2seq_encoder = None
2022-03-21 14:25:38,138 - INFO - allennlp.common.params - model.dropout = 0.1
2022-03-21 14:25:38,139 - INFO - allennlp.common.params - model.num_labels = None
2022-03-21 14:25:38,140 - INFO - allennlp.common.params - model.label_namespace = labels
2022-03-21 14:25:38,142 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fc5dd97c650>
2022-03-21 14:25:38,143 - INFO - allennlp.common.params - model.regularizer = None
2022-03-21 14:25:38,149 - INFO - allennlp.common.params - model.track_weights = False
2022-03-21 14:25:38,151 - INFO - allennlp.common.params - model.disable_layers = []
2022-03-21 14:25:38,153 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-21 14:25:38,156 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-21 14:25:38,158 - INFO - allennlp.nn.initializers -    _classification_layer.bias
2022-03-21 14:25:38,159 - INFO - allennlp.nn.initializers -    _classification_layer.weight
2022-03-21 14:25:38,160 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias
2022-03-21 14:25:38,162 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight
2022-03-21 14:25:38,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 14:25:38,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 14:25:38,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 14:25:38,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 14:25:38,168 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 14:25:38,169 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 14:25:38,171 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 14:25:38,172 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 14:25:38,173 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 14:25:38,174 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 14:25:38,176 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 14:25:38,177 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 14:25:38,178 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 14:25:38,179 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 14:25:38,185 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 14:25:38,186 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 14:25:38,188 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 14:25:38,189 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 14:25:38,190 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 14:25:38,192 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 14:25:38,193 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 14:25:38,195 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 14:25:38,196 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 14:25:38,197 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 14:25:38,199 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 14:25:38,200 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 14:25:38,201 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 14:25:38,203 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 14:25:38,204 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 14:25:38,205 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 14:25:38,207 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 14:25:38,208 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 14:25:38,210 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 14:25:38,211 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 14:25:38,215 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 14:25:38,218 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 14:25:38,219 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 14:25:38,221 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 14:25:38,223 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 14:25:38,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 14:25:38,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 14:25:38,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 14:25:38,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 14:25:38,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 14:25:38,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 14:25:38,232 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 14:25:38,233 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 14:25:38,234 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 14:25:38,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 14:25:38,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 14:25:38,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 14:25:38,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 14:25:38,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 14:25:38,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 14:25:38,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 14:25:38,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 14:25:38,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 14:25:38,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 14:25:38,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 14:25:38,250 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 14:25:38,252 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 14:25:38,253 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 14:25:38,254 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 14:25:38,256 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 14:25:38,257 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 14:25:38,259 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 14:25:38,260 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 14:25:38,261 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 14:25:38,262 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 14:25:38,264 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 14:25:38,265 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 14:25:38,266 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 14:25:38,268 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 14:25:38,269 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 14:25:38,270 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 14:25:38,272 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 14:25:38,273 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 14:25:38,274 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 14:25:38,275 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 14:25:38,277 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 14:25:38,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 14:25:38,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 14:25:38,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 14:25:38,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 14:25:38,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 14:25:38,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 14:25:38,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 14:25:38,287 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 14:25:38,289 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 14:25:38,291 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 14:25:38,292 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 14:25:38,293 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 14:25:38,294 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 14:25:38,295 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 14:25:38,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 14:25:38,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 14:25:38,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 14:25:38,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 14:25:38,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 14:25:38,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 14:25:38,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 14:25:38,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 14:25:38,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 14:25:38,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 14:25:38,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 14:25:38,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 14:25:38,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 14:25:38,313 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 14:25:38,315 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 14:25:38,316 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 14:25:38,317 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 14:25:38,319 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 14:25:38,321 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 14:25:38,322 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 14:25:38,325 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 14:25:38,327 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 14:25:38,328 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 14:25:38,331 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 14:25:38,334 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 14:25:38,335 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 14:25:38,336 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 14:25:38,338 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 14:25:38,339 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 14:25:38,340 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 14:25:38,342 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 14:25:38,343 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 14:25:38,344 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 14:25:38,345 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 14:25:38,347 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 14:25:38,348 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 14:25:38,349 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 14:25:38,351 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 14:25:38,352 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 14:25:38,353 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 14:25:38,355 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 14:25:38,356 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 14:25:38,357 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 14:25:38,359 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 14:25:38,360 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 14:25:38,361 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 14:25:38,363 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 14:25:38,364 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 14:25:38,365 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 14:25:38,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 14:25:38,367 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 14:25:38,369 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 14:25:38,370 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 14:25:38,371 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 14:25:38,372 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 14:25:38,373 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 14:25:38,375 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 14:25:38,376 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 14:25:38,378 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 14:25:38,379 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 14:25:38,380 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 14:25:38,381 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 14:25:38,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 14:25:38,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 14:25:38,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 14:25:38,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 14:25:38,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 14:25:38,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 14:25:38,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 14:25:38,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 14:25:38,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 14:25:38,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 14:25:38,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 14:25:38,402 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 14:25:38,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 14:25:38,404 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 14:25:38,405 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 14:25:38,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 14:25:38,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 14:25:38,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 14:25:38,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 14:25:38,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 14:25:38,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 14:25:38,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 14:25:38,417 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 14:25:38,418 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 14:25:38,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 14:25:38,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 14:25:38,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 14:25:38,424 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 14:25:38,425 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 14:25:38,427 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 14:25:38,429 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 14:25:38,430 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 14:25:38,432 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 14:25:38,433 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 14:25:38,435 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 14:25:38,436 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 14:25:38,438 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 14:25:38,439 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 14:25:38,441 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 14:25:38,442 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 14:25:38,443 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 14:25:38,445 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 14:25:38,447 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 14:25:44,219 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-21 14:25:44,226 - INFO - allennlp.common.params - trainer.patience = 3
2022-03-21 14:25:44,227 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2022-03-21 14:25:44,228 - INFO - allennlp.common.params - trainer.num_epochs = 10
2022-03-21 14:25:44,230 - INFO - allennlp.common.params - trainer.cuda_device = 2
2022-03-21 14:25:44,232 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-21 14:25:44,233 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-21 14:25:44,236 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-21 14:25:44,237 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-21 14:25:44,238 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-03-21 14:25:44,240 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-21 14:25:44,241 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-21 14:25:44,243 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-03-21 14:25:44,245 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-21 14:25:44,246 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-21 14:25:44,250 - INFO - allennlp.common.params - trainer.callbacks = None
2022-03-21 14:25:44,251 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-03-21 14:25:51,227 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw_str_lr
2022-03-21 14:25:51,234 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05
2022-03-21 14:25:51,235 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.98]
2022-03-21 14:25:51,237 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-06
2022-03-21 14:25:51,238 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1
2022-03-21 14:25:51,241 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = False
2022-03-21 14:25:51,245 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-03-21 14:25:51,247 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias'], {'weight_decay': 0}
2022-03-21 14:25:51,251 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight'], {}
2022-03-21 14:25:51,254 - WARNING - allennlp.training.optimizers - When constructing parameter groups, layer_norm.weight does not match any parameter name
2022-03-21 14:25:51,256 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125239300
2022-03-21 14:25:51,259 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-21 14:25:51,261 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-21 14:25:51,262 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2022-03-21 14:25:51,264 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2022-03-21 14:25:51,266 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2022-03-21 14:25:51,267 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2022-03-21 14:25:51,269 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2022-03-21 14:25:51,270 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2022-03-21 14:25:51,272 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2022-03-21 14:25:51,274 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2022-03-21 14:25:51,276 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2022-03-21 14:25:51,277 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2022-03-21 14:25:51,279 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2022-03-21 14:25:51,280 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-03-21 14:25:51,282 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-03-21 14:25:51,283 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-03-21 14:25:51,285 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-03-21 14:25:51,287 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-03-21 14:25:51,288 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-03-21 14:25:51,291 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2022-03-21 14:25:51,292 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2022-03-21 14:25:51,294 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-03-21 14:25:51,295 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-03-21 14:25:51,297 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2022-03-21 14:25:51,298 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2022-03-21 14:25:51,300 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2022-03-21 14:25:51,301 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2022-03-21 14:25:51,303 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2022-03-21 14:25:51,304 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2022-03-21 14:25:51,306 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-03-21 14:25:51,307 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-03-21 14:25:51,308 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-03-21 14:25:51,310 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-03-21 14:25:51,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-03-21 14:25:51,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-03-21 14:25:51,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2022-03-21 14:25:51,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2022-03-21 14:25:51,316 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-03-21 14:25:51,317 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-03-21 14:25:51,319 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2022-03-21 14:25:51,320 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2022-03-21 14:25:51,321 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2022-03-21 14:25:51,323 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2022-03-21 14:25:51,324 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2022-03-21 14:25:51,326 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2022-03-21 14:25:51,327 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-03-21 14:25:51,328 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-03-21 14:25:51,330 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-03-21 14:25:51,331 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-03-21 14:25:51,332 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-03-21 14:25:51,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-03-21 14:25:51,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2022-03-21 14:25:51,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2022-03-21 14:25:51,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-03-21 14:25:51,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-03-21 14:25:51,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2022-03-21 14:25:51,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2022-03-21 14:25:51,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2022-03-21 14:25:51,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2022-03-21 14:25:51,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2022-03-21 14:25:51,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2022-03-21 14:25:51,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-03-21 14:25:51,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-03-21 14:25:51,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-03-21 14:25:51,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-03-21 14:25:51,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-03-21 14:25:51,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-03-21 14:25:51,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2022-03-21 14:25:51,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2022-03-21 14:25:51,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-03-21 14:25:51,366 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-03-21 14:25:51,367 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2022-03-21 14:25:51,369 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2022-03-21 14:25:51,370 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2022-03-21 14:25:51,371 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2022-03-21 14:25:51,373 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2022-03-21 14:25:51,374 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2022-03-21 14:25:51,375 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-03-21 14:25:51,377 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-03-21 14:25:51,378 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-03-21 14:25:51,379 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-03-21 14:25:51,381 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-03-21 14:25:51,382 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-03-21 14:25:51,383 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2022-03-21 14:25:51,385 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2022-03-21 14:25:51,386 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-03-21 14:25:51,387 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-03-21 14:25:51,390 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2022-03-21 14:25:51,391 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2022-03-21 14:25:51,392 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2022-03-21 14:25:51,394 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2022-03-21 14:25:51,397 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2022-03-21 14:25:51,399 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2022-03-21 14:25:51,400 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-03-21 14:25:51,401 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-03-21 14:25:51,403 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-03-21 14:25:51,405 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-03-21 14:25:51,407 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-03-21 14:25:51,408 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-03-21 14:25:51,409 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2022-03-21 14:25:51,411 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2022-03-21 14:25:51,412 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-03-21 14:25:51,413 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-03-21 14:25:51,415 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2022-03-21 14:25:51,416 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2022-03-21 14:25:51,417 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2022-03-21 14:25:51,419 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2022-03-21 14:25:51,420 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2022-03-21 14:25:51,421 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2022-03-21 14:25:51,423 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-03-21 14:25:51,424 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-03-21 14:25:51,425 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-03-21 14:25:51,427 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-03-21 14:25:51,428 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-03-21 14:25:51,430 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-03-21 14:25:51,431 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2022-03-21 14:25:51,432 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2022-03-21 14:25:51,434 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-03-21 14:25:51,435 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-03-21 14:25:51,437 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2022-03-21 14:25:51,438 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2022-03-21 14:25:51,439 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2022-03-21 14:25:51,442 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2022-03-21 14:25:51,444 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2022-03-21 14:25:51,445 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2022-03-21 14:25:51,446 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-03-21 14:25:51,448 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-03-21 14:25:51,449 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-03-21 14:25:51,450 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-03-21 14:25:51,452 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-03-21 14:25:51,453 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-03-21 14:25:51,455 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2022-03-21 14:25:51,458 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2022-03-21 14:25:51,461 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-03-21 14:25:51,462 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-03-21 14:25:51,463 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2022-03-21 14:25:51,465 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2022-03-21 14:25:51,466 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2022-03-21 14:25:51,468 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2022-03-21 14:25:51,469 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2022-03-21 14:25:51,470 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2022-03-21 14:25:51,472 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-03-21 14:25:51,473 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-03-21 14:25:51,475 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-03-21 14:25:51,476 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-03-21 14:25:51,477 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-03-21 14:25:51,479 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-03-21 14:25:51,481 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2022-03-21 14:25:51,482 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2022-03-21 14:25:51,483 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-03-21 14:25:51,484 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-03-21 14:25:51,486 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2022-03-21 14:25:51,487 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2022-03-21 14:25:51,488 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2022-03-21 14:25:51,490 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2022-03-21 14:25:51,491 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2022-03-21 14:25:51,492 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2022-03-21 14:25:51,493 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-03-21 14:25:51,495 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-03-21 14:25:51,496 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-03-21 14:25:51,497 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-03-21 14:25:51,499 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-03-21 14:25:51,500 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-03-21 14:25:51,501 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2022-03-21 14:25:51,503 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2022-03-21 14:25:51,504 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-03-21 14:25:51,505 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-03-21 14:25:51,506 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2022-03-21 14:25:51,508 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2022-03-21 14:25:51,509 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2022-03-21 14:25:51,510 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2022-03-21 14:25:51,511 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2022-03-21 14:25:51,513 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2022-03-21 14:25:51,517 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-03-21 14:25:51,519 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-03-21 14:25:51,520 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-03-21 14:25:51,521 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-03-21 14:25:51,523 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-03-21 14:25:51,524 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-03-21 14:25:51,526 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2022-03-21 14:25:51,527 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2022-03-21 14:25:51,528 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-03-21 14:25:51,529 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-03-21 14:25:51,531 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2022-03-21 14:25:51,532 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2022-03-21 14:25:51,533 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2022-03-21 14:25:51,534 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2022-03-21 14:25:51,537 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2022-03-21 14:25:51,538 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2022-03-21 14:25:51,540 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-03-21 14:25:51,541 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-03-21 14:25:51,542 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-03-21 14:25:51,543 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-03-21 14:25:51,545 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-03-21 14:25:51,546 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-03-21 14:25:51,547 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2022-03-21 14:25:51,549 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2022-03-21 14:25:51,550 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-03-21 14:25:51,551 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-03-21 14:25:51,553 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2022-03-21 14:25:51,555 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2022-03-21 14:25:51,556 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.weight
2022-03-21 14:25:51,557 - INFO - allennlp.common.util - _feedforward_layer._linear_layers.0.bias
2022-03-21 14:25:51,558 - INFO - allennlp.common.util - _classification_layer.weight
2022-03-21 14:25:51,560 - INFO - allennlp.common.util - _classification_layer.bias
2022-03-21 14:25:51,561 - INFO - allennlp.common.params - trainer.checkpointer.type = roberta_default
2022-03-21 14:25:51,563 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-21 14:25:51,564 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 0
2022-03-21 14:25:51,566 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-21 14:25:51,567 - INFO - allennlp.common.params - trainer.checkpointer.num_epochs = 10
2022-03-21 14:25:51,569 - INFO - allennlp.common.params - trainer.checkpointer.skip_early_stopping = False
2022-03-21 14:25:51,575 - INFO - allennlp.training.trainer - Beginning training.
2022-03-21 14:25:51,577 - INFO - allennlp.training.trainer - Epoch 0/9
2022-03-21 14:25:51,581 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.2G
2022-03-21 14:25:51,583 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 14:25:51,586 - INFO - allennlp.training.trainer - Training
2022-03-21 14:25:51,588 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 14:25:51,697 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 14:25:51,699 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 14:26:01,825 - INFO - tqdm - f1: 0.5785, accuracy: 0.5865, batch_loss: 0.6237, loss: 1.0015 ||:   1%|          | 39/7188 [00:10<25:19,  4.71it/s]
2022-03-21 14:26:11,897 - INFO - tqdm - f1: 0.7438, accuracy: 0.7493, batch_loss: 0.2359, loss: 0.6580 ||:   1%|1         | 85/7188 [00:20<27:01,  4.38it/s]
2022-03-21 14:26:22,149 - INFO - tqdm - f1: 0.7879, accuracy: 0.7917, batch_loss: 0.2385, loss: 0.5579 ||:   2%|1         | 132/7188 [00:30<26:25,  4.45it/s]
2022-03-21 14:26:32,233 - INFO - tqdm - f1: 0.8087, accuracy: 0.8111, batch_loss: 0.4741, loss: 0.5206 ||:   2%|2         | 178/7188 [00:40<24:55,  4.69it/s]
2022-03-21 14:26:42,351 - INFO - tqdm - f1: 0.8242, accuracy: 0.8256, batch_loss: 0.7741, loss: 0.4865 ||:   3%|3         | 225/7188 [00:50<25:32,  4.54it/s]
2022-03-21 14:26:52,514 - INFO - tqdm - f1: 0.8352, accuracy: 0.8374, batch_loss: 0.3189, loss: 0.4540 ||:   4%|3         | 274/7188 [01:00<23:32,  4.90it/s]
2022-03-21 14:27:02,750 - INFO - tqdm - f1: 0.8452, accuracy: 0.8466, batch_loss: 0.0717, loss: 0.4333 ||:   5%|4         | 324/7188 [01:11<25:34,  4.47it/s]
2022-03-21 14:27:12,865 - INFO - tqdm - f1: 0.8509, accuracy: 0.8518, batch_loss: 0.3543, loss: 0.4226 ||:   5%|5         | 372/7188 [01:21<23:31,  4.83it/s]
2022-03-21 14:27:23,019 - INFO - tqdm - f1: 0.8537, accuracy: 0.8550, batch_loss: 0.6314, loss: 0.4155 ||:   6%|5         | 421/7188 [01:31<22:43,  4.96it/s]
2022-03-21 14:27:33,054 - INFO - tqdm - f1: 0.8583, accuracy: 0.8594, batch_loss: 0.6389, loss: 0.4039 ||:   7%|6         | 469/7188 [01:41<24:30,  4.57it/s]
2022-03-21 14:27:43,139 - INFO - tqdm - f1: 0.8608, accuracy: 0.8618, batch_loss: 0.4093, loss: 0.3986 ||:   7%|7         | 519/7188 [01:51<20:58,  5.30it/s]
2022-03-21 14:27:53,161 - INFO - tqdm - f1: 0.8648, accuracy: 0.8654, batch_loss: 0.1365, loss: 0.3892 ||:   8%|7         | 566/7188 [02:01<24:45,  4.46it/s]
2022-03-21 14:28:03,351 - INFO - tqdm - f1: 0.8683, accuracy: 0.8688, batch_loss: 0.2015, loss: 0.3794 ||:   9%|8         | 615/7188 [02:11<22:56,  4.77it/s]
2022-03-21 14:28:13,517 - INFO - tqdm - f1: 0.8708, accuracy: 0.8711, batch_loss: 0.0545, loss: 0.3720 ||:   9%|9         | 663/7188 [02:21<22:48,  4.77it/s]
2022-03-21 14:28:23,542 - INFO - tqdm - f1: 0.8726, accuracy: 0.8728, batch_loss: 0.2883, loss: 0.3682 ||:  10%|9         | 710/7188 [02:31<26:22,  4.09it/s]
2022-03-21 14:28:33,621 - INFO - tqdm - f1: 0.8737, accuracy: 0.8738, batch_loss: 0.3873, loss: 0.3648 ||:  11%|#         | 756/7188 [02:42<24:30,  4.37it/s]
2022-03-21 14:28:43,996 - INFO - tqdm - f1: 0.8753, accuracy: 0.8754, batch_loss: 0.1944, loss: 0.3598 ||:  11%|#1        | 800/7188 [02:52<51:39,  2.06it/s]
2022-03-21 14:28:54,194 - INFO - tqdm - f1: 0.8778, accuracy: 0.8779, batch_loss: 0.1619, loss: 0.3532 ||:  12%|#1        | 846/7188 [03:02<25:34,  4.13it/s]
2022-03-21 14:29:04,258 - INFO - tqdm - f1: 0.8785, accuracy: 0.8787, batch_loss: 0.0522, loss: 0.3517 ||:  12%|#2        | 898/7188 [03:12<21:43,  4.83it/s]
2022-03-21 14:29:14,264 - INFO - tqdm - f1: 0.8811, accuracy: 0.8813, batch_loss: 0.7841, loss: 0.3444 ||:  13%|#3        | 946/7188 [03:22<21:56,  4.74it/s]
2022-03-21 14:29:24,472 - INFO - tqdm - f1: 0.8829, accuracy: 0.8830, batch_loss: 0.2867, loss: 0.3397 ||:  14%|#3        | 995/7188 [03:32<22:18,  4.63it/s]
2022-03-21 14:29:34,618 - INFO - tqdm - f1: 0.8835, accuracy: 0.8837, batch_loss: 0.1516, loss: 0.3376 ||:  15%|#4        | 1044/7188 [03:43<24:12,  4.23it/s]
2022-03-21 14:29:44,737 - INFO - tqdm - f1: 0.8845, accuracy: 0.8847, batch_loss: 0.0662, loss: 0.3345 ||:  15%|#5        | 1090/7188 [03:53<22:51,  4.45it/s]
2022-03-21 14:29:54,838 - INFO - tqdm - f1: 0.8853, accuracy: 0.8855, batch_loss: 0.1678, loss: 0.3322 ||:  16%|#5        | 1136/7188 [04:03<22:43,  4.44it/s]
2022-03-21 14:30:05,080 - INFO - tqdm - f1: 0.8860, accuracy: 0.8863, batch_loss: 0.1012, loss: 0.3298 ||:  16%|#6        | 1183/7188 [04:13<22:29,  4.45it/s]
2022-03-21 14:30:15,259 - INFO - tqdm - f1: 0.8868, accuracy: 0.8870, batch_loss: 0.1696, loss: 0.3274 ||:  17%|#7        | 1231/7188 [04:23<22:09,  4.48it/s]
2022-03-21 14:30:25,429 - INFO - tqdm - f1: 0.8882, accuracy: 0.8885, batch_loss: 0.1826, loss: 0.3239 ||:  18%|#7        | 1279/7188 [04:33<20:26,  4.82it/s]
2022-03-21 14:30:35,607 - INFO - tqdm - f1: 0.8894, accuracy: 0.8896, batch_loss: 0.2251, loss: 0.3217 ||:  18%|#8        | 1328/7188 [04:44<20:19,  4.80it/s]
2022-03-21 14:30:45,659 - INFO - tqdm - f1: 0.8907, accuracy: 0.8908, batch_loss: 0.0137, loss: 0.3181 ||:  19%|#9        | 1376/7188 [04:54<21:38,  4.48it/s]
2022-03-21 14:30:55,813 - INFO - tqdm - f1: 0.8911, accuracy: 0.8912, batch_loss: 0.6072, loss: 0.3171 ||:  20%|#9        | 1426/7188 [05:04<20:46,  4.62it/s]
2022-03-21 14:31:06,043 - INFO - tqdm - f1: 0.8913, accuracy: 0.8914, batch_loss: 0.2834, loss: 0.3158 ||:  20%|##        | 1473/7188 [05:14<21:54,  4.35it/s]
2022-03-21 14:31:16,063 - INFO - tqdm - f1: 0.8924, accuracy: 0.8925, batch_loss: 0.4805, loss: 0.3124 ||:  21%|##1       | 1522/7188 [05:24<18:56,  4.98it/s]
2022-03-21 14:31:26,163 - INFO - tqdm - f1: 0.8924, accuracy: 0.8924, batch_loss: 0.0452, loss: 0.3119 ||:  22%|##1       | 1569/7188 [05:34<21:36,  4.33it/s]
2022-03-21 14:31:36,204 - INFO - tqdm - f1: 0.8936, accuracy: 0.8937, batch_loss: 0.4135, loss: 0.3088 ||:  22%|##2       | 1615/7188 [05:44<19:42,  4.71it/s]
2022-03-21 14:31:46,353 - INFO - tqdm - f1: 0.8945, accuracy: 0.8945, batch_loss: 0.1655, loss: 0.3070 ||:  23%|##3       | 1664/7188 [05:54<21:45,  4.23it/s]
2022-03-21 14:31:56,488 - INFO - tqdm - f1: 0.8952, accuracy: 0.8951, batch_loss: 0.4815, loss: 0.3057 ||:  24%|##3       | 1710/7188 [06:04<21:27,  4.25it/s]
2022-03-21 14:32:06,606 - INFO - tqdm - f1: 0.8959, accuracy: 0.8958, batch_loss: 0.0898, loss: 0.3035 ||:  24%|##4       | 1757/7188 [06:15<21:14,  4.26it/s]
2022-03-21 14:32:16,828 - INFO - tqdm - f1: 0.8964, accuracy: 0.8963, batch_loss: 0.2524, loss: 0.3022 ||:  25%|##5       | 1806/7188 [06:25<20:09,  4.45it/s]
2022-03-21 14:32:26,984 - INFO - tqdm - f1: 0.8966, accuracy: 0.8965, batch_loss: 0.4710, loss: 0.3019 ||:  26%|##5       | 1854/7188 [06:35<20:29,  4.34it/s]
2022-03-21 14:32:37,163 - INFO - tqdm - f1: 0.8970, accuracy: 0.8969, batch_loss: 0.0460, loss: 0.3006 ||:  26%|##6       | 1903/7188 [06:45<18:31,  4.75it/s]
2022-03-21 14:32:47,169 - INFO - tqdm - f1: 0.8972, accuracy: 0.8972, batch_loss: 0.0705, loss: 0.3000 ||:  27%|##7       | 1951/7188 [06:55<19:11,  4.55it/s]
2022-03-21 14:32:57,329 - INFO - tqdm - f1: 0.8975, accuracy: 0.8974, batch_loss: 0.0552, loss: 0.2988 ||:  28%|##7       | 1998/7188 [07:05<19:56,  4.34it/s]
2022-03-21 14:33:07,377 - INFO - tqdm - f1: 0.8982, accuracy: 0.8980, batch_loss: 0.1814, loss: 0.2969 ||:  28%|##8       | 2046/7188 [07:15<18:14,  4.70it/s]
2022-03-21 14:33:17,598 - INFO - tqdm - f1: 0.8987, accuracy: 0.8985, batch_loss: 0.0902, loss: 0.2956 ||:  29%|##9       | 2095/7188 [07:26<18:16,  4.65it/s]
2022-03-21 14:33:27,615 - INFO - tqdm - f1: 0.8989, accuracy: 0.8988, batch_loss: 0.3423, loss: 0.2942 ||:  30%|##9       | 2142/7188 [07:36<20:18,  4.14it/s]
2022-03-21 14:33:37,789 - INFO - tqdm - f1: 0.8997, accuracy: 0.8997, batch_loss: 0.2040, loss: 0.2925 ||:  30%|###       | 2191/7188 [07:46<18:12,  4.57it/s]
2022-03-21 14:33:47,847 - INFO - tqdm - f1: 0.9002, accuracy: 0.9002, batch_loss: 0.0715, loss: 0.2909 ||:  31%|###1      | 2239/7188 [07:56<15:37,  5.28it/s]
2022-03-21 14:33:57,924 - INFO - tqdm - f1: 0.9007, accuracy: 0.9007, batch_loss: 0.2270, loss: 0.2892 ||:  32%|###1      | 2288/7188 [08:06<16:33,  4.93it/s]
2022-03-21 14:34:08,086 - INFO - tqdm - f1: 0.9012, accuracy: 0.9012, batch_loss: 0.0599, loss: 0.2878 ||:  32%|###2      | 2336/7188 [08:16<18:23,  4.40it/s]
2022-03-21 14:34:18,233 - INFO - tqdm - f1: 0.9017, accuracy: 0.9018, batch_loss: 0.1922, loss: 0.2862 ||:  33%|###3      | 2383/7188 [08:26<16:31,  4.85it/s]
2022-03-21 14:34:28,441 - INFO - tqdm - f1: 0.9015, accuracy: 0.9015, batch_loss: 0.0212, loss: 0.2862 ||:  34%|###3      | 2432/7188 [08:36<16:29,  4.80it/s]
2022-03-21 14:34:38,649 - INFO - tqdm - f1: 0.9017, accuracy: 0.9018, batch_loss: 0.2406, loss: 0.2854 ||:  35%|###4      | 2481/7188 [08:47<17:04,  4.60it/s]
2022-03-21 14:34:48,773 - INFO - tqdm - f1: 0.9019, accuracy: 0.9020, batch_loss: 0.4184, loss: 0.2846 ||:  35%|###5      | 2528/7188 [08:57<18:16,  4.25it/s]
2022-03-21 14:34:59,010 - INFO - tqdm - f1: 0.9024, accuracy: 0.9025, batch_loss: 0.0770, loss: 0.2833 ||:  36%|###5      | 2578/7188 [09:07<17:48,  4.32it/s]
2022-03-21 14:35:09,094 - INFO - tqdm - f1: 0.9028, accuracy: 0.9029, batch_loss: 0.0928, loss: 0.2825 ||:  37%|###6      | 2624/7188 [09:17<17:03,  4.46it/s]
2022-03-21 14:35:19,100 - INFO - tqdm - f1: 0.9032, accuracy: 0.9032, batch_loss: 0.3871, loss: 0.2817 ||:  37%|###7      | 2670/7188 [09:27<16:17,  4.62it/s]
2022-03-21 14:35:29,101 - INFO - tqdm - f1: 0.9034, accuracy: 0.9034, batch_loss: 0.4618, loss: 0.2814 ||:  38%|###7      | 2719/7188 [09:37<13:40,  5.45it/s]
2022-03-21 14:35:39,224 - INFO - tqdm - f1: 0.9038, accuracy: 0.9038, batch_loss: 0.1056, loss: 0.2805 ||:  38%|###8      | 2765/7188 [09:47<16:52,  4.37it/s]
2022-03-21 14:35:49,384 - INFO - tqdm - f1: 0.9038, accuracy: 0.9038, batch_loss: 0.2081, loss: 0.2800 ||:  39%|###9      | 2812/7188 [09:57<16:54,  4.31it/s]
2022-03-21 14:35:59,423 - INFO - tqdm - f1: 0.9043, accuracy: 0.9043, batch_loss: 0.0169, loss: 0.2782 ||:  40%|###9      | 2859/7188 [10:07<16:19,  4.42it/s]
2022-03-21 14:36:09,587 - INFO - tqdm - f1: 0.9044, accuracy: 0.9044, batch_loss: 0.4380, loss: 0.2776 ||:  40%|####      | 2906/7188 [10:17<15:23,  4.64it/s]
2022-03-21 14:36:19,714 - INFO - tqdm - f1: 0.9050, accuracy: 0.9049, batch_loss: 0.2235, loss: 0.2761 ||:  41%|####1     | 2954/7188 [10:28<14:40,  4.81it/s]
2022-03-21 14:36:29,892 - INFO - tqdm - f1: 0.9052, accuracy: 0.9051, batch_loss: 0.2103, loss: 0.2757 ||:  42%|####1     | 3003/7188 [10:38<14:09,  4.93it/s]
2022-03-21 14:36:40,520 - INFO - tqdm - f1: 0.9055, accuracy: 0.9055, batch_loss: 0.2082, loss: 0.2746 ||:  42%|####2     | 3047/7188 [10:48<38:02,  1.81it/s]
2022-03-21 14:36:50,750 - INFO - tqdm - f1: 0.9060, accuracy: 0.9060, batch_loss: 0.3154, loss: 0.2735 ||:  43%|####3     | 3096/7188 [10:59<14:52,  4.58it/s]
2022-03-21 14:37:00,755 - INFO - tqdm - f1: 0.9069, accuracy: 0.9068, batch_loss: 0.5855, loss: 0.2718 ||:  44%|####4     | 3192/7188 [11:09<04:19, 15.42it/s]
2022-03-21 14:37:10,881 - INFO - tqdm - f1: 0.9077, accuracy: 0.9076, batch_loss: 0.1561, loss: 0.2698 ||:  46%|####6     | 3338/7188 [11:19<07:24,  8.66it/s]
2022-03-21 14:37:20,933 - INFO - tqdm - f1: 0.9084, accuracy: 0.9083, batch_loss: 0.4572, loss: 0.2678 ||:  47%|####7     | 3410/7188 [11:29<09:03,  6.95it/s]
2022-03-21 14:37:30,972 - INFO - tqdm - f1: 0.9084, accuracy: 0.9084, batch_loss: 0.1922, loss: 0.2674 ||:  48%|####8     | 3483/7188 [11:39<07:54,  7.81it/s]
2022-03-21 14:37:41,107 - INFO - tqdm - f1: 0.9089, accuracy: 0.9088, batch_loss: 0.3286, loss: 0.2664 ||:  49%|####9     | 3541/7188 [11:49<12:41,  4.79it/s]
2022-03-21 14:37:51,205 - INFO - tqdm - f1: 0.9092, accuracy: 0.9091, batch_loss: 0.0737, loss: 0.2657 ||:  50%|####9     | 3590/7188 [11:59<11:28,  5.23it/s]
2022-03-21 14:38:01,382 - INFO - tqdm - f1: 0.9092, accuracy: 0.9091, batch_loss: 0.1509, loss: 0.2655 ||:  50%|#####     | 3621/7188 [12:09<12:48,  4.64it/s]
2022-03-21 14:38:11,523 - INFO - tqdm - f1: 0.9092, accuracy: 0.9092, batch_loss: 0.4437, loss: 0.2654 ||:  51%|#####     | 3662/7188 [12:19<12:30,  4.70it/s]
2022-03-21 14:38:21,576 - INFO - tqdm - f1: 0.9095, accuracy: 0.9094, batch_loss: 0.1156, loss: 0.2645 ||:  52%|#####1    | 3711/7188 [12:29<11:51,  4.88it/s]
2022-03-21 14:38:31,791 - INFO - tqdm - f1: 0.9098, accuracy: 0.9097, batch_loss: 0.0724, loss: 0.2638 ||:  52%|#####2    | 3759/7188 [12:40<12:19,  4.64it/s]
2022-03-21 14:38:42,020 - INFO - tqdm - f1: 0.9098, accuracy: 0.9097, batch_loss: 0.0812, loss: 0.2639 ||:  53%|#####2    | 3806/7188 [12:50<13:25,  4.20it/s]
2022-03-21 14:38:52,067 - INFO - tqdm - f1: 0.9102, accuracy: 0.9102, batch_loss: 0.2643, loss: 0.2627 ||:  54%|#####3    | 3853/7188 [13:00<11:38,  4.78it/s]
2022-03-21 14:39:02,161 - INFO - tqdm - f1: 0.9103, accuracy: 0.9101, batch_loss: 0.2650, loss: 0.2627 ||:  54%|#####4    | 3900/7188 [13:10<12:03,  4.54it/s]
2022-03-21 14:39:12,164 - INFO - tqdm - f1: 0.9105, accuracy: 0.9104, batch_loss: 0.1775, loss: 0.2621 ||:  55%|#####4    | 3947/7188 [13:20<11:20,  4.76it/s]
2022-03-21 14:39:22,253 - INFO - tqdm - f1: 0.9106, accuracy: 0.9105, batch_loss: 0.0662, loss: 0.2619 ||:  56%|#####5    | 3994/7188 [13:30<10:21,  5.14it/s]
2022-03-21 14:39:32,301 - INFO - tqdm - f1: 0.9105, accuracy: 0.9104, batch_loss: 0.0483, loss: 0.2621 ||:  56%|#####6    | 4036/7188 [13:40<12:23,  4.24it/s]
2022-03-21 14:39:42,493 - INFO - tqdm - f1: 0.9106, accuracy: 0.9105, batch_loss: 0.3080, loss: 0.2617 ||:  57%|#####6    | 4084/7188 [13:50<11:36,  4.45it/s]
2022-03-21 14:39:52,556 - INFO - tqdm - f1: 0.9107, accuracy: 0.9106, batch_loss: 0.0845, loss: 0.2613 ||:  57%|#####7    | 4130/7188 [14:00<10:33,  4.83it/s]
2022-03-21 14:40:02,559 - INFO - tqdm - f1: 0.9107, accuracy: 0.9106, batch_loss: 0.2425, loss: 0.2612 ||:  58%|#####8    | 4179/7188 [14:10<09:48,  5.12it/s]
2022-03-21 14:40:12,693 - INFO - tqdm - f1: 0.9107, accuracy: 0.9106, batch_loss: 0.5918, loss: 0.2610 ||:  59%|#####8    | 4227/7188 [14:21<11:10,  4.42it/s]
2022-03-21 14:40:22,816 - INFO - tqdm - f1: 0.9107, accuracy: 0.9106, batch_loss: 0.0467, loss: 0.2609 ||:  59%|#####9    | 4274/7188 [14:31<09:48,  4.95it/s]
2022-03-21 14:40:32,895 - INFO - tqdm - f1: 0.9107, accuracy: 0.9106, batch_loss: 0.0931, loss: 0.2604 ||:  60%|######    | 4321/7188 [14:41<10:52,  4.40it/s]
2022-03-21 14:40:42,937 - INFO - tqdm - f1: 0.9107, accuracy: 0.9106, batch_loss: 0.0461, loss: 0.2605 ||:  61%|######    | 4368/7188 [14:51<10:30,  4.47it/s]
2022-03-21 14:40:52,945 - INFO - tqdm - f1: 0.9107, accuracy: 0.9107, batch_loss: 0.1220, loss: 0.2599 ||:  61%|######1   | 4416/7188 [15:01<09:45,  4.74it/s]
2022-03-21 14:41:03,068 - INFO - tqdm - f1: 0.9109, accuracy: 0.9109, batch_loss: 0.0931, loss: 0.2591 ||:  62%|######2   | 4463/7188 [15:11<10:20,  4.39it/s]
2022-03-21 14:41:13,265 - INFO - tqdm - f1: 0.9110, accuracy: 0.9110, batch_loss: 0.3312, loss: 0.2592 ||:  63%|######2   | 4512/7188 [15:21<09:11,  4.86it/s]
2022-03-21 14:41:23,395 - INFO - tqdm - f1: 0.9113, accuracy: 0.9113, batch_loss: 0.2670, loss: 0.2585 ||:  63%|######3   | 4558/7188 [15:31<09:04,  4.83it/s]
2022-03-21 14:41:33,397 - INFO - tqdm - f1: 0.9114, accuracy: 0.9114, batch_loss: 0.2389, loss: 0.2581 ||:  64%|######4   | 4607/7188 [15:41<09:06,  4.72it/s]
2022-03-21 14:41:43,549 - INFO - tqdm - f1: 0.9114, accuracy: 0.9115, batch_loss: 0.0687, loss: 0.2579 ||:  65%|######4   | 4655/7188 [15:51<08:45,  4.82it/s]
2022-03-21 14:41:53,732 - INFO - tqdm - f1: 0.9116, accuracy: 0.9116, batch_loss: 0.0671, loss: 0.2573 ||:  65%|######5   | 4703/7188 [16:02<08:54,  4.65it/s]
2022-03-21 14:42:03,853 - INFO - tqdm - f1: 0.9120, accuracy: 0.9120, batch_loss: 0.2000, loss: 0.2564 ||:  66%|######6   | 4750/7188 [16:12<08:54,  4.56it/s]
2022-03-21 14:42:13,994 - INFO - tqdm - f1: 0.9122, accuracy: 0.9121, batch_loss: 0.0183, loss: 0.2560 ||:  67%|######6   | 4798/7188 [16:22<08:18,  4.79it/s]
2022-03-21 14:42:24,050 - INFO - tqdm - f1: 0.9123, accuracy: 0.9123, batch_loss: 0.0673, loss: 0.2554 ||:  67%|######7   | 4846/7188 [16:32<08:20,  4.68it/s]
2022-03-21 14:42:34,172 - INFO - tqdm - f1: 0.9124, accuracy: 0.9124, batch_loss: 0.0787, loss: 0.2549 ||:  68%|######8   | 4893/7188 [16:42<08:45,  4.36it/s]
2022-03-21 14:42:44,261 - INFO - tqdm - f1: 0.9126, accuracy: 0.9125, batch_loss: 0.0717, loss: 0.2545 ||:  69%|######8   | 4938/7188 [16:52<08:30,  4.41it/s]
2022-03-21 14:42:54,408 - INFO - tqdm - f1: 0.9127, accuracy: 0.9126, batch_loss: 0.0566, loss: 0.2542 ||:  69%|######9   | 4987/7188 [17:02<07:35,  4.84it/s]
2022-03-21 14:43:04,469 - INFO - tqdm - f1: 0.9128, accuracy: 0.9127, batch_loss: 0.2359, loss: 0.2538 ||:  70%|#######   | 5035/7188 [17:12<07:54,  4.54it/s]
2022-03-21 14:43:14,494 - INFO - tqdm - f1: 0.9130, accuracy: 0.9129, batch_loss: 0.2658, loss: 0.2531 ||:  71%|#######   | 5082/7188 [17:22<07:15,  4.83it/s]
2022-03-21 14:43:24,577 - INFO - tqdm - f1: 0.9130, accuracy: 0.9129, batch_loss: 0.0901, loss: 0.2529 ||:  71%|#######1  | 5129/7188 [17:32<06:59,  4.91it/s]
2022-03-21 14:43:34,623 - INFO - tqdm - f1: 0.9129, accuracy: 0.9128, batch_loss: 0.0957, loss: 0.2534 ||:  72%|#######2  | 5177/7188 [17:43<06:48,  4.92it/s]
2022-03-21 14:43:44,768 - INFO - tqdm - f1: 0.9129, accuracy: 0.9128, batch_loss: 0.1330, loss: 0.2533 ||:  73%|#######2  | 5226/7188 [17:53<07:24,  4.41it/s]
2022-03-21 14:43:54,889 - INFO - tqdm - f1: 0.9129, accuracy: 0.9128, batch_loss: 0.3257, loss: 0.2531 ||:  73%|#######3  | 5274/7188 [18:03<07:32,  4.23it/s]
2022-03-21 14:44:05,020 - INFO - tqdm - f1: 0.9130, accuracy: 0.9129, batch_loss: 0.3534, loss: 0.2528 ||:  74%|#######4  | 5321/7188 [18:13<06:29,  4.79it/s]
2022-03-21 14:44:15,163 - INFO - tqdm - f1: 0.9130, accuracy: 0.9129, batch_loss: 0.2410, loss: 0.2526 ||:  75%|#######4  | 5370/7188 [18:23<06:11,  4.89it/s]
2022-03-21 14:44:25,198 - INFO - tqdm - f1: 0.9131, accuracy: 0.9130, batch_loss: 0.3264, loss: 0.2525 ||:  75%|#######5  | 5417/7188 [18:33<06:31,  4.52it/s]
2022-03-21 14:44:35,367 - INFO - tqdm - f1: 0.9133, accuracy: 0.9132, batch_loss: 0.1708, loss: 0.2520 ||:  76%|#######6  | 5463/7188 [18:43<06:36,  4.35it/s]
2022-03-21 14:44:45,513 - INFO - tqdm - f1: 0.9134, accuracy: 0.9134, batch_loss: 0.1095, loss: 0.2516 ||:  77%|#######6  | 5511/7188 [18:53<06:17,  4.44it/s]
2022-03-21 14:44:55,746 - INFO - tqdm - f1: 0.9135, accuracy: 0.9134, batch_loss: 0.3247, loss: 0.2514 ||:  77%|#######7  | 5560/7188 [19:04<05:47,  4.69it/s]
2022-03-21 14:45:05,809 - INFO - tqdm - f1: 0.9136, accuracy: 0.9136, batch_loss: 0.1545, loss: 0.2509 ||:  78%|#######7  | 5606/7188 [19:14<06:07,  4.31it/s]
2022-03-21 14:45:16,040 - INFO - tqdm - f1: 0.9136, accuracy: 0.9136, batch_loss: 0.1227, loss: 0.2509 ||:  79%|#######8  | 5655/7188 [19:24<05:09,  4.95it/s]
2022-03-21 14:45:26,253 - INFO - tqdm - f1: 0.9136, accuracy: 0.9136, batch_loss: 0.2793, loss: 0.2508 ||:  79%|#######9  | 5704/7188 [19:34<05:29,  4.51it/s]
2022-03-21 14:45:36,385 - INFO - tqdm - f1: 0.9138, accuracy: 0.9138, batch_loss: 0.4461, loss: 0.2503 ||:  80%|########  | 5751/7188 [19:44<05:15,  4.56it/s]
2022-03-21 14:45:46,526 - INFO - tqdm - f1: 0.9139, accuracy: 0.9139, batch_loss: 0.4876, loss: 0.2500 ||:  81%|########  | 5800/7188 [19:54<04:37,  5.00it/s]
2022-03-21 14:45:56,732 - INFO - tqdm - f1: 0.9140, accuracy: 0.9140, batch_loss: 0.4919, loss: 0.2496 ||:  81%|########1 | 5848/7188 [20:05<04:40,  4.78it/s]
2022-03-21 14:46:06,896 - INFO - tqdm - f1: 0.9140, accuracy: 0.9140, batch_loss: 0.2580, loss: 0.2493 ||:  82%|########2 | 5895/7188 [20:15<04:37,  4.66it/s]
2022-03-21 14:46:16,980 - INFO - tqdm - f1: 0.9141, accuracy: 0.9141, batch_loss: 0.1096, loss: 0.2490 ||:  83%|########2 | 5942/7188 [20:25<04:29,  4.63it/s]
2022-03-21 14:46:27,156 - INFO - tqdm - f1: 0.9142, accuracy: 0.9143, batch_loss: 0.0683, loss: 0.2486 ||:  83%|########3 | 5989/7188 [20:35<04:23,  4.55it/s]
2022-03-21 14:46:37,246 - INFO - tqdm - f1: 0.9143, accuracy: 0.9144, batch_loss: 0.3889, loss: 0.2482 ||:  84%|########3 | 6036/7188 [20:45<04:33,  4.21it/s]
2022-03-21 14:46:47,424 - INFO - tqdm - f1: 0.9144, accuracy: 0.9144, batch_loss: 0.0490, loss: 0.2480 ||:  85%|########4 | 6084/7188 [20:55<03:51,  4.76it/s]
2022-03-21 14:46:57,566 - INFO - tqdm - f1: 0.9145, accuracy: 0.9145, batch_loss: 0.2299, loss: 0.2477 ||:  85%|########5 | 6132/7188 [21:05<03:33,  4.94it/s]
2022-03-21 14:47:07,703 - INFO - tqdm - f1: 0.9147, accuracy: 0.9147, batch_loss: 0.0683, loss: 0.2473 ||:  86%|########5 | 6180/7188 [21:16<03:38,  4.62it/s]
2022-03-21 14:47:17,876 - INFO - tqdm - f1: 0.9147, accuracy: 0.9147, batch_loss: 0.1124, loss: 0.2473 ||:  87%|########6 | 6227/7188 [21:26<03:49,  4.20it/s]
2022-03-21 14:47:27,904 - INFO - tqdm - f1: 0.9147, accuracy: 0.9147, batch_loss: 0.0515, loss: 0.2471 ||:  87%|########7 | 6276/7188 [21:36<03:07,  4.87it/s]
2022-03-21 14:47:38,030 - INFO - tqdm - f1: 0.9149, accuracy: 0.9150, batch_loss: 0.5135, loss: 0.2465 ||:  88%|########7 | 6323/7188 [21:46<03:16,  4.39it/s]
2022-03-21 14:47:48,063 - INFO - tqdm - f1: 0.9150, accuracy: 0.9151, batch_loss: 0.3062, loss: 0.2464 ||:  89%|########8 | 6373/7188 [21:56<02:45,  4.94it/s]
2022-03-21 14:47:58,338 - INFO - tqdm - f1: 0.9150, accuracy: 0.9151, batch_loss: 0.1315, loss: 0.2465 ||:  89%|########9 | 6419/7188 [22:06<03:13,  3.98it/s]
2022-03-21 14:48:08,499 - INFO - tqdm - f1: 0.9151, accuracy: 0.9151, batch_loss: 0.3848, loss: 0.2464 ||:  90%|########9 | 6467/7188 [22:16<02:59,  4.01it/s]
2022-03-21 14:48:18,654 - INFO - tqdm - f1: 0.9152, accuracy: 0.9152, batch_loss: 0.0815, loss: 0.2460 ||:  91%|######### | 6513/7188 [22:27<02:36,  4.32it/s]
2022-03-21 14:48:28,798 - INFO - tqdm - f1: 0.9153, accuracy: 0.9153, batch_loss: 0.1789, loss: 0.2456 ||:  91%|#########1| 6560/7188 [22:37<02:15,  4.62it/s]
2022-03-21 14:48:38,976 - INFO - tqdm - f1: 0.9155, accuracy: 0.9155, batch_loss: 0.2989, loss: 0.2450 ||:  92%|#########1| 6609/7188 [22:47<01:59,  4.83it/s]
2022-03-21 14:48:49,108 - INFO - tqdm - f1: 0.9157, accuracy: 0.9157, batch_loss: 0.1194, loss: 0.2446 ||:  93%|#########2| 6655/7188 [22:57<02:03,  4.32it/s]
2022-03-21 14:48:59,185 - INFO - tqdm - f1: 0.9159, accuracy: 0.9159, batch_loss: 0.0920, loss: 0.2442 ||:  93%|#########3| 6702/7188 [23:07<01:51,  4.36it/s]
2022-03-21 14:49:09,276 - INFO - tqdm - f1: 0.9160, accuracy: 0.9160, batch_loss: 0.2510, loss: 0.2437 ||:  94%|#########3| 6750/7188 [23:17<01:33,  4.67it/s]
2022-03-21 14:49:19,480 - INFO - tqdm - f1: 0.9161, accuracy: 0.9161, batch_loss: 0.0416, loss: 0.2436 ||:  95%|#########4| 6797/7188 [23:27<01:31,  4.28it/s]
2022-03-21 14:49:29,676 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.0204, loss: 0.2433 ||:  95%|#########5| 6843/7188 [23:38<01:18,  4.38it/s]
2022-03-21 14:49:39,817 - INFO - tqdm - f1: 0.9164, accuracy: 0.9164, batch_loss: 0.5847, loss: 0.2431 ||:  96%|#########5| 6891/7188 [23:48<01:01,  4.82it/s]
2022-03-21 14:49:49,890 - INFO - tqdm - f1: 0.9163, accuracy: 0.9163, batch_loss: 0.1775, loss: 0.2431 ||:  97%|#########6| 6938/7188 [23:58<00:56,  4.44it/s]
2022-03-21 14:50:00,030 - INFO - tqdm - f1: 0.9165, accuracy: 0.9165, batch_loss: 0.0233, loss: 0.2426 ||:  97%|#########7| 6985/7188 [24:08<00:41,  4.88it/s]
2022-03-21 14:50:10,214 - INFO - tqdm - f1: 0.9164, accuracy: 0.9164, batch_loss: 0.2599, loss: 0.2429 ||:  98%|#########7| 7033/7188 [24:18<00:32,  4.74it/s]
2022-03-21 14:50:20,457 - INFO - tqdm - f1: 0.9165, accuracy: 0.9165, batch_loss: 0.1373, loss: 0.2425 ||:  99%|#########8| 7081/7188 [24:28<00:24,  4.32it/s]
2022-03-21 14:50:30,541 - INFO - tqdm - f1: 0.9166, accuracy: 0.9165, batch_loss: 0.2141, loss: 0.2423 ||:  99%|#########9| 7127/7188 [24:38<00:14,  4.15it/s]
2022-03-21 14:50:36,124 - INFO - tqdm - f1: 0.9166, accuracy: 0.9166, batch_loss: 0.2378, loss: 0.2421 ||: 100%|#########9| 7153/7188 [24:44<00:07,  4.83it/s]
2022-03-21 14:50:36,369 - INFO - tqdm - f1: 0.9166, accuracy: 0.9166, batch_loss: 0.3111, loss: 0.2421 ||: 100%|#########9| 7154/7188 [24:44<00:07,  4.58it/s]
2022-03-21 14:50:36,661 - INFO - tqdm - f1: 0.9167, accuracy: 0.9166, batch_loss: 0.0660, loss: 0.2421 ||: 100%|#########9| 7155/7188 [24:45<00:07,  4.16it/s]
2022-03-21 14:50:36,818 - INFO - tqdm - f1: 0.9166, accuracy: 0.9166, batch_loss: 0.2328, loss: 0.2421 ||: 100%|#########9| 7156/7188 [24:45<00:06,  4.64it/s]
2022-03-21 14:50:37,068 - INFO - tqdm - f1: 0.9166, accuracy: 0.9166, batch_loss: 0.1174, loss: 0.2421 ||: 100%|#########9| 7157/7188 [24:45<00:07,  4.43it/s]
2022-03-21 14:50:37,287 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.0579, loss: 0.2421 ||: 100%|#########9| 7158/7188 [24:45<00:06,  4.47it/s]
2022-03-21 14:50:37,431 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.1552, loss: 0.2421 ||: 100%|#########9| 7159/7188 [24:45<00:05,  5.00it/s]
2022-03-21 14:50:37,676 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.2161, loss: 0.2421 ||: 100%|#########9| 7160/7188 [24:46<00:05,  4.69it/s]
2022-03-21 14:50:37,887 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.2198, loss: 0.2421 ||: 100%|#########9| 7161/7188 [24:46<00:05,  4.70it/s]
2022-03-21 14:50:38,034 - INFO - tqdm - f1: 0.9167, accuracy: 0.9166, batch_loss: 0.4652, loss: 0.2421 ||: 100%|#########9| 7162/7188 [24:46<00:05,  5.18it/s]
2022-03-21 14:50:38,330 - INFO - tqdm - f1: 0.9167, accuracy: 0.9166, batch_loss: 0.1456, loss: 0.2421 ||: 100%|#########9| 7163/7188 [24:46<00:05,  4.47it/s]
2022-03-21 14:50:38,585 - INFO - tqdm - f1: 0.9167, accuracy: 0.9166, batch_loss: 0.1652, loss: 0.2421 ||: 100%|#########9| 7164/7188 [24:46<00:05,  4.29it/s]
2022-03-21 14:50:38,873 - INFO - tqdm - f1: 0.9166, accuracy: 0.9166, batch_loss: 0.6015, loss: 0.2421 ||: 100%|#########9| 7165/7188 [24:47<00:05,  4.01it/s]
2022-03-21 14:50:39,066 - INFO - tqdm - f1: 0.9166, accuracy: 0.9166, batch_loss: 0.1537, loss: 0.2421 ||: 100%|#########9| 7166/7188 [24:47<00:05,  4.30it/s]
2022-03-21 14:50:39,254 - INFO - tqdm - f1: 0.9166, accuracy: 0.9166, batch_loss: 0.1870, loss: 0.2421 ||: 100%|#########9| 7167/7188 [24:47<00:04,  4.56it/s]
2022-03-21 14:50:39,483 - INFO - tqdm - f1: 0.9166, accuracy: 0.9166, batch_loss: 0.1680, loss: 0.2421 ||: 100%|#########9| 7168/7188 [24:47<00:04,  4.50it/s]
2022-03-21 14:50:39,675 - INFO - tqdm - f1: 0.9166, accuracy: 0.9166, batch_loss: 0.3929, loss: 0.2421 ||: 100%|#########9| 7169/7188 [24:48<00:04,  4.69it/s]
2022-03-21 14:50:39,843 - INFO - tqdm - f1: 0.9166, accuracy: 0.9166, batch_loss: 0.1215, loss: 0.2421 ||: 100%|#########9| 7170/7188 [24:48<00:03,  5.01it/s]
2022-03-21 14:50:40,094 - INFO - tqdm - f1: 0.9166, accuracy: 0.9166, batch_loss: 0.2101, loss: 0.2421 ||: 100%|#########9| 7171/7188 [24:48<00:03,  4.65it/s]
2022-03-21 14:50:40,274 - INFO - tqdm - f1: 0.9166, accuracy: 0.9166, batch_loss: 0.0588, loss: 0.2421 ||: 100%|#########9| 7172/7188 [24:48<00:03,  4.89it/s]
2022-03-21 14:50:40,418 - INFO - tqdm - f1: 0.9167, accuracy: 0.9166, batch_loss: 0.2150, loss: 0.2421 ||: 100%|#########9| 7173/7188 [24:48<00:02,  5.37it/s]
2022-03-21 14:50:40,662 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.0271, loss: 0.2420 ||: 100%|#########9| 7174/7188 [24:49<00:02,  4.91it/s]
2022-03-21 14:50:40,871 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.1771, loss: 0.2420 ||: 100%|#########9| 7175/7188 [24:49<00:02,  4.87it/s]
2022-03-21 14:50:41,023 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.0794, loss: 0.2420 ||: 100%|#########9| 7176/7188 [24:49<00:02,  5.28it/s]
2022-03-21 14:50:41,275 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.0441, loss: 0.2420 ||: 100%|#########9| 7177/7188 [24:49<00:02,  4.80it/s]
2022-03-21 14:50:41,477 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.0176, loss: 0.2419 ||: 100%|#########9| 7178/7188 [24:49<00:02,  4.85it/s]
2022-03-21 14:50:41,655 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.0511, loss: 0.2419 ||: 100%|#########9| 7179/7188 [24:50<00:01,  5.06it/s]
2022-03-21 14:50:41,943 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.1912, loss: 0.2419 ||: 100%|#########9| 7180/7188 [24:50<00:01,  4.45it/s]
2022-03-21 14:50:42,182 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.1250, loss: 0.2419 ||: 100%|#########9| 7181/7188 [24:50<00:01,  4.37it/s]
2022-03-21 14:50:42,471 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.0468, loss: 0.2419 ||: 100%|#########9| 7182/7188 [24:50<00:01,  4.05it/s]
2022-03-21 14:50:42,668 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.0456, loss: 0.2418 ||: 100%|#########9| 7183/7188 [24:51<00:01,  4.31it/s]
2022-03-21 14:50:42,910 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.1537, loss: 0.2418 ||: 100%|#########9| 7184/7188 [24:51<00:00,  4.25it/s]
2022-03-21 14:50:43,150 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.0554, loss: 0.2418 ||: 100%|#########9| 7185/7188 [24:51<00:00,  4.23it/s]
2022-03-21 14:50:43,345 - INFO - tqdm - f1: 0.9168, accuracy: 0.9168, batch_loss: 0.0444, loss: 0.2418 ||: 100%|#########9| 7186/7188 [24:51<00:00,  4.46it/s]
2022-03-21 14:50:43,635 - INFO - tqdm - f1: 0.9167, accuracy: 0.9167, batch_loss: 0.1723, loss: 0.2418 ||: 100%|#########9| 7187/7188 [24:52<00:00,  4.10it/s]
2022-03-21 14:50:43,848 - INFO - tqdm - f1: 0.9168, accuracy: 0.9167, batch_loss: 0.3095, loss: 0.2418 ||: 100%|##########| 7188/7188 [24:52<00:00,  4.26it/s]
2022-03-21 14:50:43,889 - INFO - tqdm - f1: 0.9168, accuracy: 0.9167, batch_loss: 0.3095, loss: 0.2418 ||: 100%|##########| 7188/7188 [24:52<00:00,  4.82it/s]
2022-03-21 14:50:43,961 - INFO - allennlp.training.trainer - Validating
2022-03-21 14:50:43,964 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 14:50:43,972 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 14:50:43,975 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 14:50:54,031 - INFO - tqdm - f1: 0.9349, accuracy: 0.9337, batch_loss: 0.0163, loss: 0.1891 ||:  26%|##6       | 82/313 [00:10<00:27,  8.28it/s]
2022-03-21 14:51:04,091 - INFO - tqdm - f1: 0.9394, accuracy: 0.9394, batch_loss: 0.0139, loss: 0.1873 ||:  53%|#####3    | 166/313 [00:20<00:18,  7.87it/s]
2022-03-21 14:51:14,368 - INFO - tqdm - f1: 0.9402, accuracy: 0.9404, batch_loss: 0.2381, loss: 0.1917 ||:  81%|########  | 252/313 [00:30<00:07,  7.77it/s]
2022-03-21 14:51:21,600 - INFO - tqdm - f1: 0.9360, accuracy: 0.9360, batch_loss: 0.0589, loss: 0.2001 ||: 100%|#########9| 312/313 [00:37<00:00,  7.42it/s]
2022-03-21 14:51:21,677 - INFO - tqdm - f1: 0.9362, accuracy: 0.9362, batch_loss: 0.0672, loss: 0.1997 ||: 100%|##########| 313/313 [00:37<00:00,  8.30it/s]
2022-03-21 14:51:21,694 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_base_hyper_small_seed_314/best.th'.
2022-03-21 14:51:24,502 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 14:51:24,504 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.917  |     0.936
2022-03-21 14:51:24,509 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.917  |     0.936
2022-03-21 14:51:24,511 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 14:51:24,513 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.242  |     0.200
2022-03-21 14:51:24,519 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7394.621  |       N/A
2022-03-21 14:51:24,525 - INFO - allennlp.training.trainer - Epoch duration: 0:25:32.948507
2022-03-21 14:51:24,528 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:49:56
2022-03-21 14:51:24,531 - INFO - allennlp.training.trainer - Epoch 1/9
2022-03-21 14:51:24,534 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 14:51:24,536 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 14:51:24,540 - INFO - allennlp.training.trainer - Training
2022-03-21 14:51:24,543 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 14:51:34,759 - INFO - tqdm - f1: 0.9431, accuracy: 0.9432, batch_loss: 0.2585, loss: 0.1685 ||:   1%|          | 44/7188 [00:10<25:46,  4.62it/s]
2022-03-21 14:51:44,971 - INFO - tqdm - f1: 0.9514, accuracy: 0.9521, batch_loss: 0.0366, loss: 0.1579 ||:   1%|1         | 94/7188 [00:20<24:47,  4.77it/s]
2022-03-21 14:51:55,144 - INFO - tqdm - f1: 0.9485, accuracy: 0.9490, batch_loss: 0.0495, loss: 0.1622 ||:   2%|1         | 141/7188 [00:30<24:18,  4.83it/s]
2022-03-21 14:52:05,310 - INFO - tqdm - f1: 0.9482, accuracy: 0.9491, batch_loss: 0.0982, loss: 0.1614 ||:   3%|2         | 189/7188 [00:40<25:04,  4.65it/s]
2022-03-21 14:52:15,427 - INFO - tqdm - f1: 0.9441, accuracy: 0.9449, batch_loss: 0.5020, loss: 0.1671 ||:   3%|3         | 238/7188 [00:50<26:17,  4.40it/s]
2022-03-21 14:52:25,484 - INFO - tqdm - f1: 0.9420, accuracy: 0.9423, batch_loss: 0.1762, loss: 0.1735 ||:   4%|3         | 285/7188 [01:00<24:39,  4.67it/s]
2022-03-21 14:52:35,632 - INFO - tqdm - f1: 0.9425, accuracy: 0.9431, batch_loss: 0.2058, loss: 0.1745 ||:   5%|4         | 333/7188 [01:11<27:03,  4.22it/s]
2022-03-21 14:52:45,835 - INFO - tqdm - f1: 0.9427, accuracy: 0.9432, batch_loss: 0.2490, loss: 0.1727 ||:   5%|5         | 381/7188 [01:21<24:47,  4.58it/s]
2022-03-21 14:52:55,842 - INFO - tqdm - f1: 0.9416, accuracy: 0.9423, batch_loss: 0.0288, loss: 0.1724 ||:   6%|5         | 428/7188 [01:31<24:43,  4.56it/s]
2022-03-21 14:53:06,061 - INFO - tqdm - f1: 0.9435, accuracy: 0.9440, batch_loss: 0.0185, loss: 0.1678 ||:   7%|6         | 475/7188 [01:41<24:04,  4.65it/s]
2022-03-21 14:53:16,195 - INFO - tqdm - f1: 0.9430, accuracy: 0.9434, batch_loss: 0.2005, loss: 0.1697 ||:   8%|8         | 591/7188 [01:51<15:18,  7.18it/s]
2022-03-21 14:53:26,247 - INFO - tqdm - f1: 0.9438, accuracy: 0.9443, batch_loss: 0.1880, loss: 0.1671 ||:   9%|9         | 667/7188 [02:01<14:18,  7.60it/s]
2022-03-21 14:53:36,377 - INFO - tqdm - f1: 0.9439, accuracy: 0.9442, batch_loss: 0.0385, loss: 0.1668 ||:  10%|#         | 741/7188 [02:11<14:49,  7.25it/s]
2022-03-21 14:53:46,536 - INFO - tqdm - f1: 0.9443, accuracy: 0.9445, batch_loss: 0.1183, loss: 0.1665 ||:  11%|#1        | 805/7188 [02:21<23:24,  4.54it/s]
2022-03-21 14:53:56,739 - INFO - tqdm - f1: 0.9449, accuracy: 0.9451, batch_loss: 0.0071, loss: 0.1655 ||:  12%|#1        | 855/7188 [02:32<22:29,  4.69it/s]
2022-03-21 14:54:06,770 - INFO - tqdm - f1: 0.9454, accuracy: 0.9456, batch_loss: 0.0613, loss: 0.1636 ||:  13%|#2        | 901/7188 [02:42<24:17,  4.31it/s]
2022-03-21 14:54:16,903 - INFO - tqdm - f1: 0.9456, accuracy: 0.9458, batch_loss: 0.1198, loss: 0.1630 ||:  13%|#3        | 948/7188 [02:52<23:23,  4.45it/s]
2022-03-21 14:54:27,062 - INFO - tqdm - f1: 0.9452, accuracy: 0.9453, batch_loss: 0.1168, loss: 0.1639 ||:  14%|#3        | 995/7188 [03:02<25:19,  4.08it/s]
2022-03-21 14:54:37,205 - INFO - tqdm - f1: 0.9448, accuracy: 0.9450, batch_loss: 0.2871, loss: 0.1641 ||:  15%|#4        | 1043/7188 [03:12<22:56,  4.46it/s]
2022-03-21 14:54:47,361 - INFO - tqdm - f1: 0.9449, accuracy: 0.9451, batch_loss: 0.0224, loss: 0.1638 ||:  15%|#5        | 1090/7188 [03:22<21:00,  4.84it/s]
2022-03-21 14:54:57,590 - INFO - tqdm - f1: 0.9452, accuracy: 0.9454, batch_loss: 0.1015, loss: 0.1631 ||:  16%|#5        | 1136/7188 [03:33<22:52,  4.41it/s]
2022-03-21 14:55:07,617 - INFO - tqdm - f1: 0.9449, accuracy: 0.9450, batch_loss: 0.0195, loss: 0.1634 ||:  16%|#6        | 1183/7188 [03:43<23:30,  4.26it/s]
2022-03-21 14:55:17,790 - INFO - tqdm - f1: 0.9443, accuracy: 0.9444, batch_loss: 0.0481, loss: 0.1647 ||:  17%|#7        | 1230/7188 [03:53<22:22,  4.44it/s]
2022-03-21 14:55:27,868 - INFO - tqdm - f1: 0.9432, accuracy: 0.9432, batch_loss: 0.3513, loss: 0.1671 ||:  18%|#7        | 1278/7188 [04:03<22:16,  4.42it/s]
2022-03-21 14:55:38,105 - INFO - tqdm - f1: 0.9434, accuracy: 0.9435, batch_loss: 0.0383, loss: 0.1669 ||:  18%|#8        | 1324/7188 [04:13<23:40,  4.13it/s]
2022-03-21 14:55:48,324 - INFO - tqdm - f1: 0.9436, accuracy: 0.9437, batch_loss: 0.3873, loss: 0.1663 ||:  19%|#9        | 1373/7188 [04:23<20:58,  4.62it/s]
2022-03-21 14:55:58,436 - INFO - tqdm - f1: 0.9423, accuracy: 0.9423, batch_loss: 0.5436, loss: 0.1702 ||:  20%|#9        | 1422/7188 [04:33<20:46,  4.63it/s]
2022-03-21 14:56:08,573 - INFO - tqdm - f1: 0.9420, accuracy: 0.9420, batch_loss: 0.2719, loss: 0.1700 ||:  20%|##        | 1469/7188 [04:44<22:55,  4.16it/s]
2022-03-21 14:56:18,576 - INFO - tqdm - f1: 0.9422, accuracy: 0.9423, batch_loss: 0.0319, loss: 0.1692 ||:  21%|##1       | 1514/7188 [04:54<21:58,  4.30it/s]
2022-03-21 14:56:28,591 - INFO - tqdm - f1: 0.9427, accuracy: 0.9428, batch_loss: 0.0071, loss: 0.1681 ||:  22%|##1       | 1562/7188 [05:04<18:57,  4.95it/s]
2022-03-21 14:56:38,631 - INFO - tqdm - f1: 0.9429, accuracy: 0.9430, batch_loss: 0.0196, loss: 0.1674 ||:  22%|##2       | 1609/7188 [05:14<19:32,  4.76it/s]
2022-03-21 14:56:48,792 - INFO - tqdm - f1: 0.9430, accuracy: 0.9431, batch_loss: 0.3143, loss: 0.1680 ||:  23%|##3       | 1656/7188 [05:24<19:11,  4.80it/s]
2022-03-21 14:56:58,948 - INFO - tqdm - f1: 0.9424, accuracy: 0.9426, batch_loss: 0.0166, loss: 0.1687 ||:  24%|##3       | 1704/7188 [05:34<19:09,  4.77it/s]
2022-03-21 14:57:09,080 - INFO - tqdm - f1: 0.9421, accuracy: 0.9422, batch_loss: 0.0675, loss: 0.1690 ||:  24%|##4       | 1751/7188 [05:44<19:18,  4.69it/s]
2022-03-21 14:57:19,243 - INFO - tqdm - f1: 0.9415, accuracy: 0.9416, batch_loss: 0.2734, loss: 0.1705 ||:  25%|##5       | 1799/7188 [05:54<18:30,  4.85it/s]
2022-03-21 14:57:29,392 - INFO - tqdm - f1: 0.9419, accuracy: 0.9420, batch_loss: 0.0179, loss: 0.1698 ||:  26%|##5       | 1847/7188 [06:04<19:12,  4.64it/s]
2022-03-21 14:57:39,613 - INFO - tqdm - f1: 0.9420, accuracy: 0.9420, batch_loss: 0.0738, loss: 0.1701 ||:  26%|##6       | 1899/7188 [06:15<18:10,  4.85it/s]
2022-03-21 14:57:49,827 - INFO - tqdm - f1: 0.9422, accuracy: 0.9422, batch_loss: 0.0764, loss: 0.1696 ||:  27%|##7       | 1947/7188 [06:25<19:07,  4.57it/s]
2022-03-21 14:57:59,916 - INFO - tqdm - f1: 0.9421, accuracy: 0.9422, batch_loss: 0.0426, loss: 0.1693 ||:  28%|##7       | 1994/7188 [06:35<17:39,  4.90it/s]
2022-03-21 14:58:10,095 - INFO - tqdm - f1: 0.9420, accuracy: 0.9420, batch_loss: 0.0524, loss: 0.1699 ||:  28%|##8       | 2043/7188 [06:45<17:53,  4.79it/s]
2022-03-21 14:58:20,272 - INFO - tqdm - f1: 0.9420, accuracy: 0.9421, batch_loss: 0.3416, loss: 0.1696 ||:  29%|##9       | 2090/7188 [06:55<21:07,  4.02it/s]
2022-03-21 14:58:30,308 - INFO - tqdm - f1: 0.9422, accuracy: 0.9423, batch_loss: 0.0413, loss: 0.1691 ||:  30%|##9       | 2137/7188 [07:05<18:33,  4.54it/s]
2022-03-21 14:58:40,492 - INFO - tqdm - f1: 0.9424, accuracy: 0.9425, batch_loss: 0.1112, loss: 0.1682 ||:  30%|###       | 2185/7188 [07:15<18:27,  4.52it/s]
2022-03-21 14:58:50,562 - INFO - tqdm - f1: 0.9423, accuracy: 0.9424, batch_loss: 0.0109, loss: 0.1682 ||:  31%|###1      | 2232/7188 [07:26<16:27,  5.02it/s]
2022-03-21 14:59:00,694 - INFO - tqdm - f1: 0.9423, accuracy: 0.9423, batch_loss: 0.0554, loss: 0.1681 ||:  32%|###1      | 2280/7188 [07:36<18:51,  4.34it/s]
2022-03-21 14:59:10,813 - INFO - tqdm - f1: 0.9422, accuracy: 0.9422, batch_loss: 0.5755, loss: 0.1685 ||:  32%|###2      | 2327/7188 [07:46<16:21,  4.95it/s]
2022-03-21 14:59:20,861 - INFO - tqdm - f1: 0.9421, accuracy: 0.9421, batch_loss: 0.3645, loss: 0.1685 ||:  33%|###3      | 2374/7188 [07:56<17:10,  4.67it/s]
2022-03-21 14:59:31,011 - INFO - tqdm - f1: 0.9418, accuracy: 0.9418, batch_loss: 0.4902, loss: 0.1692 ||:  34%|###3      | 2421/7188 [08:06<16:10,  4.91it/s]
2022-03-21 14:59:41,124 - INFO - tqdm - f1: 0.9418, accuracy: 0.9418, batch_loss: 0.1697, loss: 0.1696 ||:  34%|###4      | 2468/7188 [08:16<17:46,  4.42it/s]
2022-03-21 14:59:51,238 - INFO - tqdm - f1: 0.9415, accuracy: 0.9415, batch_loss: 0.0285, loss: 0.1702 ||:  35%|###5      | 2517/7188 [08:26<18:26,  4.22it/s]
2022-03-21 15:00:01,449 - INFO - tqdm - f1: 0.9415, accuracy: 0.9415, batch_loss: 0.1314, loss: 0.1701 ||:  36%|###5      | 2565/7188 [08:36<16:40,  4.62it/s]
2022-03-21 15:00:11,463 - INFO - tqdm - f1: 0.9415, accuracy: 0.9416, batch_loss: 0.2261, loss: 0.1703 ||:  36%|###6      | 2610/7188 [08:46<17:39,  4.32it/s]
2022-03-21 15:00:21,549 - INFO - tqdm - f1: 0.9416, accuracy: 0.9417, batch_loss: 0.0091, loss: 0.1700 ||:  37%|###6      | 2658/7188 [08:56<16:18,  4.63it/s]
2022-03-21 15:00:31,683 - INFO - tqdm - f1: 0.9414, accuracy: 0.9414, batch_loss: 0.0044, loss: 0.1704 ||:  38%|###7      | 2706/7188 [09:07<16:14,  4.60it/s]
2022-03-21 15:00:41,707 - INFO - tqdm - f1: 0.9412, accuracy: 0.9412, batch_loss: 0.0476, loss: 0.1707 ||:  38%|###8      | 2752/7188 [09:17<15:35,  4.74it/s]
2022-03-21 15:00:51,711 - INFO - tqdm - f1: 0.9411, accuracy: 0.9412, batch_loss: 0.0297, loss: 0.1708 ||:  39%|###8      | 2800/7188 [09:27<15:46,  4.63it/s]
2022-03-21 15:01:01,777 - INFO - tqdm - f1: 0.9410, accuracy: 0.9410, batch_loss: 0.1389, loss: 0.1710 ||:  40%|###9      | 2847/7188 [09:37<16:11,  4.47it/s]
2022-03-21 15:01:11,867 - INFO - tqdm - f1: 0.9408, accuracy: 0.9409, batch_loss: 0.0215, loss: 0.1713 ||:  40%|####      | 2890/7188 [09:47<15:10,  4.72it/s]
2022-03-21 15:01:21,991 - INFO - tqdm - f1: 0.9409, accuracy: 0.9410, batch_loss: 0.1615, loss: 0.1711 ||:  41%|####      | 2937/7188 [09:57<14:46,  4.79it/s]
2022-03-21 15:01:32,181 - INFO - tqdm - f1: 0.9407, accuracy: 0.9408, batch_loss: 0.1075, loss: 0.1717 ||:  42%|####1     | 2986/7188 [10:07<14:41,  4.77it/s]
2022-03-21 15:01:42,293 - INFO - tqdm - f1: 0.9406, accuracy: 0.9406, batch_loss: 0.5901, loss: 0.1718 ||:  42%|####2     | 3032/7188 [10:17<20:08,  3.44it/s]
2022-03-21 15:01:52,343 - INFO - tqdm - f1: 0.9405, accuracy: 0.9406, batch_loss: 0.0917, loss: 0.1720 ||:  43%|####2     | 3080/7188 [10:27<14:44,  4.64it/s]
2022-03-21 15:02:02,440 - INFO - tqdm - f1: 0.9404, accuracy: 0.9405, batch_loss: 0.7639, loss: 0.1720 ||:  43%|####3     | 3126/7188 [10:37<15:51,  4.27it/s]
2022-03-21 15:02:12,559 - INFO - tqdm - f1: 0.9405, accuracy: 0.9406, batch_loss: 0.1065, loss: 0.1717 ||:  44%|####4     | 3174/7188 [10:48<13:47,  4.85it/s]
2022-03-21 15:02:22,722 - INFO - tqdm - f1: 0.9404, accuracy: 0.9405, batch_loss: 0.1644, loss: 0.1716 ||:  45%|####4     | 3221/7188 [10:58<13:56,  4.74it/s]
2022-03-21 15:02:32,879 - INFO - tqdm - f1: 0.9404, accuracy: 0.9405, batch_loss: 0.2154, loss: 0.1712 ||:  45%|####5     | 3269/7188 [11:08<13:13,  4.94it/s]
2022-03-21 15:02:43,054 - INFO - tqdm - f1: 0.9403, accuracy: 0.9404, batch_loss: 0.0582, loss: 0.1712 ||:  46%|####6     | 3318/7188 [11:18<12:59,  4.97it/s]
2022-03-21 15:02:53,244 - INFO - tqdm - f1: 0.9404, accuracy: 0.9405, batch_loss: 0.1872, loss: 0.1710 ||:  47%|####6     | 3365/7188 [11:28<14:43,  4.33it/s]
2022-03-21 15:03:03,277 - INFO - tqdm - f1: 0.9403, accuracy: 0.9404, batch_loss: 0.0272, loss: 0.1712 ||:  47%|####7     | 3409/7188 [11:38<15:53,  3.96it/s]
2022-03-21 15:03:13,361 - INFO - tqdm - f1: 0.9404, accuracy: 0.9406, batch_loss: 0.3204, loss: 0.1707 ||:  48%|####8     | 3452/7188 [11:48<15:20,  4.06it/s]
2022-03-21 15:03:23,597 - INFO - tqdm - f1: 0.9404, accuracy: 0.9406, batch_loss: 0.1605, loss: 0.1706 ||:  49%|####8     | 3499/7188 [11:59<13:42,  4.48it/s]
2022-03-21 15:03:33,616 - INFO - tqdm - f1: 0.9404, accuracy: 0.9406, batch_loss: 0.4638, loss: 0.1707 ||:  49%|####9     | 3547/7188 [12:09<13:46,  4.41it/s]
2022-03-21 15:03:43,671 - INFO - tqdm - f1: 0.9407, accuracy: 0.9408, batch_loss: 0.0297, loss: 0.1702 ||:  50%|#####     | 3594/7188 [12:19<14:47,  4.05it/s]
2022-03-21 15:03:53,900 - INFO - tqdm - f1: 0.9408, accuracy: 0.9409, batch_loss: 0.1629, loss: 0.1701 ||:  51%|#####     | 3639/7188 [12:29<13:44,  4.31it/s]
2022-03-21 15:04:04,030 - INFO - tqdm - f1: 0.9409, accuracy: 0.9410, batch_loss: 0.0373, loss: 0.1700 ||:  51%|#####1    | 3686/7188 [12:39<12:35,  4.64it/s]
2022-03-21 15:04:14,164 - INFO - tqdm - f1: 0.9407, accuracy: 0.9407, batch_loss: 0.0801, loss: 0.1704 ||:  52%|#####1    | 3734/7188 [12:49<13:40,  4.21it/s]
2022-03-21 15:04:24,293 - INFO - tqdm - f1: 0.9407, accuracy: 0.9408, batch_loss: 0.3542, loss: 0.1702 ||:  53%|#####2    | 3774/7188 [12:59<25:43,  2.21it/s]
2022-03-21 15:04:34,519 - INFO - tqdm - f1: 0.9408, accuracy: 0.9409, batch_loss: 0.2638, loss: 0.1700 ||:  53%|#####3    | 3816/7188 [13:09<12:34,  4.47it/s]
2022-03-21 15:04:44,671 - INFO - tqdm - f1: 0.9407, accuracy: 0.9408, batch_loss: 0.5438, loss: 0.1700 ||:  54%|#####3    | 3858/7188 [13:20<11:34,  4.80it/s]
2022-03-21 15:04:54,833 - INFO - tqdm - f1: 0.9407, accuracy: 0.9408, batch_loss: 0.1158, loss: 0.1699 ||:  54%|#####4    | 3906/7188 [13:30<11:30,  4.75it/s]
2022-03-21 15:05:04,845 - INFO - tqdm - f1: 0.9405, accuracy: 0.9406, batch_loss: 0.7387, loss: 0.1709 ||:  55%|#####4    | 3951/7188 [13:40<12:49,  4.21it/s]
2022-03-21 15:05:14,945 - INFO - tqdm - f1: 0.9404, accuracy: 0.9405, batch_loss: 0.4417, loss: 0.1712 ||:  56%|#####5    | 3997/7188 [13:50<11:56,  4.45it/s]
2022-03-21 15:05:24,976 - INFO - tqdm - f1: 0.9405, accuracy: 0.9406, batch_loss: 0.4078, loss: 0.1709 ||:  56%|#####6    | 4046/7188 [14:00<11:48,  4.43it/s]
2022-03-21 15:05:35,147 - INFO - tqdm - f1: 0.9405, accuracy: 0.9406, batch_loss: 0.2966, loss: 0.1713 ||:  57%|#####6    | 4094/7188 [14:10<12:07,  4.25it/s]
2022-03-21 15:05:45,341 - INFO - tqdm - f1: 0.9406, accuracy: 0.9407, batch_loss: 0.0624, loss: 0.1713 ||:  58%|#####7    | 4144/7188 [14:20<10:18,  4.92it/s]
2022-03-21 15:05:55,430 - INFO - tqdm - f1: 0.9406, accuracy: 0.9406, batch_loss: 0.0209, loss: 0.1715 ||:  58%|#####8    | 4191/7188 [14:30<10:08,  4.93it/s]
2022-03-21 15:06:05,451 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.2771, loss: 0.1718 ||:  59%|#####8    | 4237/7188 [14:40<11:03,  4.45it/s]
2022-03-21 15:06:15,478 - INFO - tqdm - f1: 0.9402, accuracy: 0.9403, batch_loss: 0.0887, loss: 0.1721 ||:  60%|#####9    | 4286/7188 [14:50<09:20,  5.18it/s]
2022-03-21 15:06:25,601 - INFO - tqdm - f1: 0.9403, accuracy: 0.9404, batch_loss: 0.0861, loss: 0.1718 ||:  60%|######    | 4333/7188 [15:01<09:31,  4.99it/s]
2022-03-21 15:06:35,621 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.0155, loss: 0.1718 ||:  61%|######    | 4380/7188 [15:11<09:43,  4.81it/s]
2022-03-21 15:06:45,774 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.3709, loss: 0.1717 ||:  62%|######1   | 4427/7188 [15:21<10:04,  4.57it/s]
2022-03-21 15:06:55,838 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.0417, loss: 0.1717 ||:  62%|######2   | 4473/7188 [15:31<10:04,  4.49it/s]
2022-03-21 15:07:06,051 - INFO - tqdm - f1: 0.9404, accuracy: 0.9405, batch_loss: 0.0105, loss: 0.1715 ||:  63%|######2   | 4523/7188 [15:41<09:22,  4.73it/s]
2022-03-21 15:07:16,152 - INFO - tqdm - f1: 0.9402, accuracy: 0.9403, batch_loss: 0.0626, loss: 0.1718 ||:  64%|######3   | 4570/7188 [15:51<08:58,  4.86it/s]
2022-03-21 15:07:26,218 - INFO - tqdm - f1: 0.9402, accuracy: 0.9402, batch_loss: 0.1625, loss: 0.1719 ||:  64%|######4   | 4617/7188 [16:01<09:53,  4.33it/s]
2022-03-21 15:07:36,399 - INFO - tqdm - f1: 0.9403, accuracy: 0.9403, batch_loss: 0.0360, loss: 0.1717 ||:  65%|######4   | 4664/7188 [16:11<08:47,  4.78it/s]
2022-03-21 15:07:46,492 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.0992, loss: 0.1715 ||:  66%|######5   | 4711/7188 [16:21<08:35,  4.81it/s]
2022-03-21 15:07:56,614 - INFO - tqdm - f1: 0.9403, accuracy: 0.9403, batch_loss: 0.0871, loss: 0.1718 ||:  66%|######6   | 4758/7188 [16:32<08:36,  4.71it/s]
2022-03-21 15:08:06,728 - INFO - tqdm - f1: 0.9402, accuracy: 0.9403, batch_loss: 0.3645, loss: 0.1720 ||:  67%|######6   | 4805/7188 [16:42<08:07,  4.88it/s]
2022-03-21 15:08:16,860 - INFO - tqdm - f1: 0.9403, accuracy: 0.9404, batch_loss: 0.0195, loss: 0.1720 ||:  68%|######7   | 4853/7188 [16:52<08:48,  4.42it/s]
2022-03-21 15:08:26,996 - INFO - tqdm - f1: 0.9403, accuracy: 0.9404, batch_loss: 0.2108, loss: 0.1721 ||:  68%|######8   | 4901/7188 [17:02<07:51,  4.85it/s]
2022-03-21 15:08:37,100 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.2517, loss: 0.1719 ||:  69%|######8   | 4948/7188 [17:12<07:55,  4.71it/s]
2022-03-21 15:08:47,232 - INFO - tqdm - f1: 0.9405, accuracy: 0.9406, batch_loss: 0.2749, loss: 0.1716 ||:  70%|######9   | 4996/7188 [17:22<07:37,  4.79it/s]
2022-03-21 15:08:57,366 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0525, loss: 0.1718 ||:  70%|#######   | 5044/7188 [17:32<07:21,  4.86it/s]
2022-03-21 15:09:07,448 - INFO - tqdm - f1: 0.9403, accuracy: 0.9404, batch_loss: 0.0381, loss: 0.1719 ||:  71%|#######   | 5092/7188 [17:42<08:10,  4.27it/s]
2022-03-21 15:09:17,514 - INFO - tqdm - f1: 0.9403, accuracy: 0.9404, batch_loss: 0.1909, loss: 0.1718 ||:  72%|#######1  | 5165/7188 [17:52<02:14, 15.02it/s]
2022-03-21 15:09:27,589 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.2596, loss: 0.1722 ||:  73%|#######3  | 5263/7188 [18:03<04:28,  7.16it/s]
2022-03-21 15:09:37,666 - INFO - tqdm - f1: 0.9402, accuracy: 0.9402, batch_loss: 0.0454, loss: 0.1724 ||:  74%|#######4  | 5341/7188 [18:13<04:21,  7.07it/s]
2022-03-21 15:09:47,723 - INFO - tqdm - f1: 0.9401, accuracy: 0.9401, batch_loss: 0.0290, loss: 0.1729 ||:  75%|#######5  | 5419/7188 [18:23<03:39,  8.05it/s]
2022-03-21 15:09:57,805 - INFO - tqdm - f1: 0.9402, accuracy: 0.9401, batch_loss: 0.2629, loss: 0.1728 ||:  76%|#######6  | 5475/7188 [18:33<06:34,  4.34it/s]
2022-03-21 15:10:07,946 - INFO - tqdm - f1: 0.9402, accuracy: 0.9402, batch_loss: 0.6902, loss: 0.1726 ||:  77%|#######6  | 5522/7188 [18:43<05:57,  4.65it/s]
2022-03-21 15:10:18,127 - INFO - tqdm - f1: 0.9402, accuracy: 0.9402, batch_loss: 0.1909, loss: 0.1728 ||:  77%|#######7  | 5570/7188 [18:53<05:50,  4.62it/s]
2022-03-21 15:10:28,256 - INFO - tqdm - f1: 0.9402, accuracy: 0.9402, batch_loss: 0.1299, loss: 0.1729 ||:  78%|#######8  | 5618/7188 [19:03<05:28,  4.78it/s]
2022-03-21 15:10:38,427 - INFO - tqdm - f1: 0.9403, accuracy: 0.9402, batch_loss: 0.6339, loss: 0.1729 ||:  79%|#######8  | 5667/7188 [19:13<05:14,  4.84it/s]
2022-03-21 15:10:48,591 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.0056, loss: 0.1726 ||:  79%|#######9  | 5714/7188 [19:24<05:06,  4.82it/s]
2022-03-21 15:10:58,677 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.8589, loss: 0.1727 ||:  80%|########  | 5759/7188 [19:34<05:33,  4.29it/s]
2022-03-21 15:11:08,849 - INFO - tqdm - f1: 0.9403, accuracy: 0.9403, batch_loss: 0.0569, loss: 0.1730 ||:  81%|########  | 5806/7188 [19:44<04:49,  4.78it/s]
2022-03-21 15:11:19,028 - INFO - tqdm - f1: 0.9402, accuracy: 0.9402, batch_loss: 0.1061, loss: 0.1732 ||:  81%|########1 | 5854/7188 [19:54<04:38,  4.80it/s]
2022-03-21 15:11:29,147 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0366, loss: 0.1730 ||:  82%|########2 | 5901/7188 [20:04<04:49,  4.45it/s]
2022-03-21 15:11:39,333 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.0175, loss: 0.1728 ||:  83%|########2 | 5949/7188 [20:14<04:30,  4.58it/s]
2022-03-21 15:11:49,437 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0898, loss: 0.1729 ||:  83%|########3 | 5997/7188 [20:24<04:12,  4.72it/s]
2022-03-21 15:11:59,626 - INFO - tqdm - f1: 0.9403, accuracy: 0.9402, batch_loss: 0.1289, loss: 0.1730 ||:  84%|########4 | 6045/7188 [20:35<03:59,  4.77it/s]
2022-03-21 15:12:09,815 - INFO - tqdm - f1: 0.9404, accuracy: 0.9403, batch_loss: 0.0370, loss: 0.1731 ||:  85%|########4 | 6095/7188 [20:45<03:56,  4.63it/s]
2022-03-21 15:12:19,921 - INFO - tqdm - f1: 0.9403, accuracy: 0.9403, batch_loss: 0.1153, loss: 0.1732 ||:  85%|########5 | 6142/7188 [20:55<03:47,  4.60it/s]
2022-03-21 15:12:30,071 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.0352, loss: 0.1729 ||:  86%|########6 | 6188/7188 [21:05<03:30,  4.74it/s]
2022-03-21 15:12:40,349 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.0228, loss: 0.1729 ||:  87%|########6 | 6234/7188 [21:15<03:54,  4.06it/s]
2022-03-21 15:12:50,421 - INFO - tqdm - f1: 0.9404, accuracy: 0.9404, batch_loss: 0.7841, loss: 0.1728 ||:  87%|########7 | 6282/7188 [21:25<03:19,  4.53it/s]
2022-03-21 15:13:00,523 - INFO - tqdm - f1: 0.9405, accuracy: 0.9405, batch_loss: 0.0437, loss: 0.1725 ||:  88%|########8 | 6329/7188 [21:35<03:05,  4.63it/s]
2022-03-21 15:13:10,648 - INFO - tqdm - f1: 0.9406, accuracy: 0.9406, batch_loss: 0.0732, loss: 0.1722 ||:  89%|########8 | 6377/7188 [21:46<02:43,  4.95it/s]
2022-03-21 15:13:20,880 - INFO - tqdm - f1: 0.9407, accuracy: 0.9406, batch_loss: 0.0940, loss: 0.1720 ||:  89%|########9 | 6426/7188 [21:56<02:43,  4.66it/s]
2022-03-21 15:13:30,943 - INFO - tqdm - f1: 0.9406, accuracy: 0.9406, batch_loss: 0.6592, loss: 0.1721 ||:  90%|######### | 6471/7188 [22:06<02:34,  4.65it/s]
2022-03-21 15:13:40,964 - INFO - tqdm - f1: 0.9406, accuracy: 0.9406, batch_loss: 0.0643, loss: 0.1725 ||:  91%|######### | 6518/7188 [22:16<02:33,  4.37it/s]
2022-03-21 15:13:50,968 - INFO - tqdm - f1: 0.9406, accuracy: 0.9406, batch_loss: 0.0133, loss: 0.1724 ||:  91%|#########1| 6565/7188 [22:26<01:59,  5.23it/s]
2022-03-21 15:14:01,011 - INFO - tqdm - f1: 0.9406, accuracy: 0.9406, batch_loss: 0.0595, loss: 0.1724 ||:  92%|#########1| 6612/7188 [22:36<02:10,  4.43it/s]
2022-03-21 15:14:11,194 - INFO - tqdm - f1: 0.9406, accuracy: 0.9406, batch_loss: 0.0621, loss: 0.1724 ||:  93%|#########2| 6661/7188 [22:46<01:48,  4.84it/s]
2022-03-21 15:14:21,362 - INFO - tqdm - f1: 0.9407, accuracy: 0.9407, batch_loss: 0.0792, loss: 0.1720 ||:  93%|#########3| 6708/7188 [22:56<01:43,  4.62it/s]
2022-03-21 15:14:31,534 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0710, loss: 0.1720 ||:  94%|#########3| 6755/7188 [23:06<01:30,  4.77it/s]
2022-03-21 15:14:41,685 - INFO - tqdm - f1: 0.9408, accuracy: 0.9407, batch_loss: 0.1217, loss: 0.1721 ||:  95%|#########4| 6802/7188 [23:17<01:22,  4.66it/s]
2022-03-21 15:14:51,795 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1550, loss: 0.1721 ||:  95%|#########5| 6850/7188 [23:27<01:18,  4.31it/s]
2022-03-21 15:15:01,839 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.2561, loss: 0.1720 ||:  96%|#########5| 6898/7188 [23:37<01:04,  4.48it/s]
2022-03-21 15:15:12,009 - INFO - tqdm - f1: 0.9409, accuracy: 0.9409, batch_loss: 0.0581, loss: 0.1718 ||:  97%|#########6| 6946/7188 [23:47<00:53,  4.50it/s]
2022-03-21 15:15:22,206 - INFO - tqdm - f1: 0.9409, accuracy: 0.9409, batch_loss: 0.0798, loss: 0.1717 ||:  97%|#########7| 6995/7188 [23:57<00:44,  4.36it/s]
2022-03-21 15:15:32,394 - INFO - tqdm - f1: 0.9409, accuracy: 0.9409, batch_loss: 0.3214, loss: 0.1716 ||:  98%|#########7| 7042/7188 [24:07<00:33,  4.42it/s]
2022-03-21 15:15:42,446 - INFO - tqdm - f1: 0.9409, accuracy: 0.9409, batch_loss: 0.1024, loss: 0.1719 ||:  99%|#########8| 7089/7188 [24:17<00:24,  4.07it/s]
2022-03-21 15:15:52,681 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0686, loss: 0.1720 ||:  99%|#########9| 7137/7188 [24:28<00:10,  4.85it/s]
2022-03-21 15:15:55,787 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1013, loss: 0.1721 ||: 100%|#########9| 7153/7188 [24:31<00:07,  4.55it/s]
2022-03-21 15:15:56,015 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1272, loss: 0.1721 ||: 100%|#########9| 7154/7188 [24:31<00:07,  4.50it/s]
2022-03-21 15:15:56,204 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1269, loss: 0.1721 ||: 100%|#########9| 7155/7188 [24:31<00:07,  4.71it/s]
2022-03-21 15:15:56,486 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1701, loss: 0.1721 ||: 100%|#########9| 7156/7188 [24:31<00:07,  4.29it/s]
2022-03-21 15:15:56,721 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.2189, loss: 0.1721 ||: 100%|#########9| 7157/7188 [24:32<00:07,  4.28it/s]
2022-03-21 15:15:56,963 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1957, loss: 0.1721 ||: 100%|#########9| 7158/7188 [24:32<00:07,  4.23it/s]
2022-03-21 15:15:57,199 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0549, loss: 0.1721 ||: 100%|#########9| 7159/7188 [24:32<00:06,  4.24it/s]
2022-03-21 15:15:57,352 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1585, loss: 0.1721 ||: 100%|#########9| 7160/7188 [24:32<00:05,  4.74it/s]
2022-03-21 15:15:57,605 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.5213, loss: 0.1721 ||: 100%|#########9| 7161/7188 [24:33<00:06,  4.47it/s]
2022-03-21 15:15:57,806 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0091, loss: 0.1721 ||: 100%|#########9| 7162/7188 [24:33<00:05,  4.61it/s]
2022-03-21 15:15:57,991 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.2762, loss: 0.1721 ||: 100%|#########9| 7163/7188 [24:33<00:05,  4.82it/s]
2022-03-21 15:15:58,270 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0229, loss: 0.1721 ||: 100%|#########9| 7164/7188 [24:33<00:05,  4.37it/s]
2022-03-21 15:15:58,512 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0257, loss: 0.1721 ||: 100%|#########9| 7165/7188 [24:33<00:05,  4.30it/s]
2022-03-21 15:15:58,794 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1442, loss: 0.1721 ||: 100%|#########9| 7166/7188 [24:34<00:05,  4.04it/s]
2022-03-21 15:15:58,988 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1684, loss: 0.1721 ||: 100%|#########9| 7167/7188 [24:34<00:04,  4.32it/s]
2022-03-21 15:15:59,135 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.3875, loss: 0.1721 ||: 100%|#########9| 7168/7188 [24:34<00:04,  4.85it/s]
2022-03-21 15:15:59,408 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0410, loss: 0.1721 ||: 100%|#########9| 7169/7188 [24:34<00:04,  4.42it/s]
2022-03-21 15:15:59,593 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.4490, loss: 0.1721 ||: 100%|#########9| 7170/7188 [24:35<00:03,  4.68it/s]
2022-03-21 15:15:59,735 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1165, loss: 0.1721 ||: 100%|#########9| 7171/7188 [24:35<00:03,  5.20it/s]
2022-03-21 15:15:59,998 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.4092, loss: 0.1721 ||: 100%|#########9| 7172/7188 [24:35<00:03,  4.72it/s]
2022-03-21 15:16:00,205 - INFO - tqdm - f1: 0.9408, accuracy: 0.9407, batch_loss: 0.4206, loss: 0.1722 ||: 100%|#########9| 7173/7188 [24:35<00:03,  4.72it/s]
2022-03-21 15:16:00,474 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0943, loss: 0.1722 ||: 100%|#########9| 7174/7188 [24:35<00:03,  4.36it/s]
2022-03-21 15:16:00,727 - INFO - tqdm - f1: 0.9408, accuracy: 0.9407, batch_loss: 0.3268, loss: 0.1722 ||: 100%|#########9| 7175/7188 [24:36<00:03,  4.23it/s]
2022-03-21 15:16:00,903 - INFO - tqdm - f1: 0.9408, accuracy: 0.9407, batch_loss: 0.1781, loss: 0.1722 ||: 100%|#########9| 7176/7188 [24:36<00:02,  4.59it/s]
2022-03-21 15:16:01,183 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0591, loss: 0.1722 ||: 100%|#########9| 7177/7188 [24:36<00:02,  4.22it/s]
2022-03-21 15:16:01,390 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1835, loss: 0.1722 ||: 100%|#########9| 7178/7188 [24:36<00:02,  4.39it/s]
2022-03-21 15:16:01,630 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1166, loss: 0.1722 ||: 100%|#########9| 7179/7188 [24:37<00:02,  4.32it/s]
2022-03-21 15:16:01,916 - INFO - tqdm - f1: 0.9408, accuracy: 0.9407, batch_loss: 0.1672, loss: 0.1722 ||: 100%|#########9| 7180/7188 [24:37<00:01,  4.04it/s]
2022-03-21 15:16:02,092 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0786, loss: 0.1722 ||: 100%|#########9| 7181/7188 [24:37<00:01,  4.42it/s]
2022-03-21 15:16:02,349 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0653, loss: 0.1721 ||: 100%|#########9| 7182/7188 [24:37<00:01,  4.24it/s]
2022-03-21 15:16:02,568 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1295, loss: 0.1721 ||: 100%|#########9| 7183/7188 [24:38<00:01,  4.34it/s]
2022-03-21 15:16:02,828 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0573, loss: 0.1721 ||: 100%|#########9| 7184/7188 [24:38<00:00,  4.18it/s]
2022-03-21 15:16:03,105 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0319, loss: 0.1721 ||: 100%|#########9| 7185/7188 [24:38<00:00,  3.99it/s]
2022-03-21 15:16:03,267 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.2150, loss: 0.1721 ||: 100%|#########9| 7186/7188 [24:38<00:00,  4.46it/s]
2022-03-21 15:16:03,520 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.1867, loss: 0.1721 ||: 100%|#########9| 7187/7188 [24:38<00:00,  4.29it/s]
2022-03-21 15:16:03,727 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0812, loss: 0.1721 ||: 100%|##########| 7188/7188 [24:39<00:00,  4.44it/s]
2022-03-21 15:16:03,796 - INFO - tqdm - f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0812, loss: 0.1721 ||: 100%|##########| 7188/7188 [24:39<00:00,  4.86it/s]
2022-03-21 15:16:03,872 - INFO - allennlp.training.trainer - Validating
2022-03-21 15:16:03,876 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 15:16:13,972 - INFO - tqdm - f1: 0.9409, accuracy: 0.9405, batch_loss: 0.2808, loss: 0.1827 ||:  26%|##6       | 82/313 [00:10<00:27,  8.40it/s]
2022-03-21 15:16:24,231 - INFO - tqdm - f1: 0.9384, accuracy: 0.9386, batch_loss: 0.3882, loss: 0.1924 ||:  54%|#####3    | 169/313 [00:20<00:16,  8.49it/s]
2022-03-21 15:16:34,238 - INFO - tqdm - f1: 0.9389, accuracy: 0.9391, batch_loss: 0.1490, loss: 0.1884 ||:  81%|########  | 252/313 [00:30<00:07,  8.20it/s]
2022-03-21 15:16:41,278 - INFO - tqdm - f1: 0.9377, accuracy: 0.9376, batch_loss: 0.0478, loss: 0.1907 ||: 100%|#########9| 312/313 [00:37<00:00,  9.47it/s]
2022-03-21 15:16:41,468 - INFO - tqdm - f1: 0.9375, accuracy: 0.9374, batch_loss: 0.2381, loss: 0.1908 ||: 100%|##########| 313/313 [00:37<00:00,  8.26it/s]
2022-03-21 15:16:41,471 - INFO - tqdm - f1: 0.9375, accuracy: 0.9374, batch_loss: 0.2381, loss: 0.1908 ||: 100%|##########| 313/313 [00:37<00:00,  8.33it/s]
2022-03-21 15:16:41,551 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_base_hyper_small_seed_314/best.th'.
2022-03-21 15:16:44,242 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 15:16:44,249 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.941  |     0.937
2022-03-21 15:16:44,251 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.941  |     0.937
2022-03-21 15:16:44,254 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 15:16:44,256 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.172  |     0.191
2022-03-21 15:16:44,258 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7578.484  |       N/A
2022-03-21 15:16:44,261 - INFO - allennlp.training.trainer - Epoch duration: 0:25:19.729451
2022-03-21 15:16:44,263 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:23:30
2022-03-21 15:16:44,265 - INFO - allennlp.training.trainer - Epoch 2/9
2022-03-21 15:16:44,267 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 15:16:44,270 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 15:16:44,274 - INFO - allennlp.training.trainer - Training
2022-03-21 15:16:44,276 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 15:16:54,354 - INFO - tqdm - f1: 0.9483, accuracy: 0.9486, batch_loss: 0.1365, loss: 0.1545 ||:   1%|          | 45/7188 [00:10<22:50,  5.21it/s]
2022-03-21 15:17:04,478 - INFO - tqdm - f1: 0.9506, accuracy: 0.9511, batch_loss: 0.0056, loss: 0.1401 ||:   1%|1         | 92/7188 [00:20<25:58,  4.55it/s]
2022-03-21 15:17:14,497 - INFO - tqdm - f1: 0.9511, accuracy: 0.9515, batch_loss: 0.0104, loss: 0.1407 ||:   2%|1         | 138/7188 [00:30<25:11,  4.66it/s]
2022-03-21 15:17:24,544 - INFO - tqdm - f1: 0.9502, accuracy: 0.9503, batch_loss: 0.0739, loss: 0.1461 ||:   3%|2         | 186/7188 [00:40<26:27,  4.41it/s]
2022-03-21 15:17:34,558 - INFO - tqdm - f1: 0.9497, accuracy: 0.9496, batch_loss: 0.1149, loss: 0.1454 ||:   3%|3         | 232/7188 [00:50<25:06,  4.62it/s]
2022-03-21 15:17:44,743 - INFO - tqdm - f1: 0.9510, accuracy: 0.9509, batch_loss: 0.0416, loss: 0.1427 ||:   4%|3         | 280/7188 [01:00<24:51,  4.63it/s]
2022-03-21 15:17:54,908 - INFO - tqdm - f1: 0.9518, accuracy: 0.9518, batch_loss: 0.5016, loss: 0.1408 ||:   5%|4         | 328/7188 [01:10<23:21,  4.89it/s]
2022-03-21 15:18:05,010 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0158, loss: 0.1392 ||:   5%|5         | 377/7188 [01:20<21:41,  5.23it/s]
2022-03-21 15:18:15,053 - INFO - tqdm - f1: 0.9543, accuracy: 0.9540, batch_loss: 0.0428, loss: 0.1335 ||:   6%|5         | 424/7188 [01:30<23:41,  4.76it/s]
2022-03-21 15:18:25,201 - INFO - tqdm - f1: 0.9543, accuracy: 0.9541, batch_loss: 0.3035, loss: 0.1362 ||:   7%|6         | 471/7188 [01:40<25:49,  4.34it/s]
2022-03-21 15:18:35,219 - INFO - tqdm - f1: 0.9542, accuracy: 0.9539, batch_loss: 0.0086, loss: 0.1354 ||:   7%|7         | 518/7188 [01:50<24:43,  4.50it/s]
2022-03-21 15:18:45,301 - INFO - tqdm - f1: 0.9543, accuracy: 0.9541, batch_loss: 0.0692, loss: 0.1343 ||:   8%|7         | 564/7188 [02:01<22:51,  4.83it/s]
2022-03-21 15:18:55,445 - INFO - tqdm - f1: 0.9541, accuracy: 0.9539, batch_loss: 0.1508, loss: 0.1347 ||:   9%|8         | 612/7188 [02:11<22:18,  4.91it/s]
2022-03-21 15:19:05,630 - INFO - tqdm - f1: 0.9546, accuracy: 0.9544, batch_loss: 0.0549, loss: 0.1336 ||:   9%|9         | 659/7188 [02:21<22:58,  4.74it/s]
2022-03-21 15:19:15,734 - INFO - tqdm - f1: 0.9548, accuracy: 0.9545, batch_loss: 0.0783, loss: 0.1327 ||:  10%|9         | 707/7188 [02:31<22:11,  4.87it/s]
2022-03-21 15:19:25,931 - INFO - tqdm - f1: 0.9541, accuracy: 0.9538, batch_loss: 0.1013, loss: 0.1352 ||:  11%|#         | 755/7188 [02:41<21:37,  4.96it/s]
2022-03-21 15:19:36,092 - INFO - tqdm - f1: 0.9545, accuracy: 0.9542, batch_loss: 0.0755, loss: 0.1347 ||:  11%|#1        | 805/7188 [02:51<19:33,  5.44it/s]
2022-03-21 15:19:46,314 - INFO - tqdm - f1: 0.9546, accuracy: 0.9544, batch_loss: 0.1199, loss: 0.1341 ||:  12%|#1        | 853/7188 [03:02<22:13,  4.75it/s]
2022-03-21 15:19:56,502 - INFO - tqdm - f1: 0.9546, accuracy: 0.9543, batch_loss: 0.0213, loss: 0.1336 ||:  13%|#2        | 900/7188 [03:12<21:22,  4.90it/s]
2022-03-21 15:20:06,714 - INFO - tqdm - f1: 0.9549, accuracy: 0.9546, batch_loss: 0.1158, loss: 0.1337 ||:  13%|#3        | 946/7188 [03:22<23:32,  4.42it/s]
2022-03-21 15:20:16,834 - INFO - tqdm - f1: 0.9548, accuracy: 0.9546, batch_loss: 0.2028, loss: 0.1342 ||:  14%|#3        | 993/7188 [03:32<22:08,  4.66it/s]
2022-03-21 15:20:26,889 - INFO - tqdm - f1: 0.9553, accuracy: 0.9551, batch_loss: 0.0569, loss: 0.1342 ||:  14%|#4        | 1039/7188 [03:42<20:56,  4.89it/s]
2022-03-21 15:20:37,155 - INFO - tqdm - f1: 0.9556, accuracy: 0.9554, batch_loss: 0.2430, loss: 0.1339 ||:  15%|#5        | 1085/7188 [03:52<23:37,  4.31it/s]
2022-03-21 15:20:47,366 - INFO - tqdm - f1: 0.9555, accuracy: 0.9552, batch_loss: 0.5407, loss: 0.1340 ||:  16%|#5        | 1133/7188 [04:03<21:30,  4.69it/s]
2022-03-21 15:20:57,486 - INFO - tqdm - f1: 0.9548, accuracy: 0.9546, batch_loss: 0.3106, loss: 0.1349 ||:  16%|#6        | 1180/7188 [04:13<23:42,  4.22it/s]
2022-03-21 15:21:07,597 - INFO - tqdm - f1: 0.9545, accuracy: 0.9544, batch_loss: 0.0051, loss: 0.1349 ||:  17%|#7        | 1226/7188 [04:23<23:37,  4.21it/s]
2022-03-21 15:21:17,760 - INFO - tqdm - f1: 0.9549, accuracy: 0.9547, batch_loss: 0.0732, loss: 0.1344 ||:  18%|#7        | 1274/7188 [04:33<20:23,  4.84it/s]
2022-03-21 15:21:27,856 - INFO - tqdm - f1: 0.9542, accuracy: 0.9539, batch_loss: 0.1821, loss: 0.1351 ||:  18%|#8        | 1319/7188 [04:43<21:04,  4.64it/s]
2022-03-21 15:21:37,928 - INFO - tqdm - f1: 0.9543, accuracy: 0.9541, batch_loss: 0.0550, loss: 0.1351 ||:  19%|#9        | 1366/7188 [04:53<21:45,  4.46it/s]
2022-03-21 15:21:48,047 - INFO - tqdm - f1: 0.9542, accuracy: 0.9540, batch_loss: 0.0197, loss: 0.1350 ||:  20%|#9        | 1413/7188 [05:03<21:06,  4.56it/s]
2022-03-21 15:21:58,098 - INFO - tqdm - f1: 0.9544, accuracy: 0.9542, batch_loss: 0.0357, loss: 0.1345 ||:  20%|##        | 1462/7188 [05:13<17:52,  5.34it/s]
2022-03-21 15:22:08,145 - INFO - tqdm - f1: 0.9545, accuracy: 0.9544, batch_loss: 0.0459, loss: 0.1339 ||:  21%|##        | 1509/7188 [05:23<19:54,  4.75it/s]
2022-03-21 15:22:18,302 - INFO - tqdm - f1: 0.9541, accuracy: 0.9540, batch_loss: 0.0498, loss: 0.1355 ||:  22%|##1       | 1556/7188 [05:34<21:16,  4.41it/s]
2022-03-21 15:22:28,414 - INFO - tqdm - f1: 0.9541, accuracy: 0.9539, batch_loss: 0.0494, loss: 0.1359 ||:  22%|##2       | 1602/7188 [05:44<23:38,  3.94it/s]
2022-03-21 15:22:38,553 - INFO - tqdm - f1: 0.9545, accuracy: 0.9543, batch_loss: 0.0177, loss: 0.1352 ||:  23%|##2       | 1649/7188 [05:54<21:15,  4.34it/s]
2022-03-21 15:22:48,692 - INFO - tqdm - f1: 0.9546, accuracy: 0.9543, batch_loss: 0.1005, loss: 0.1350 ||:  24%|##3       | 1697/7188 [06:04<20:56,  4.37it/s]
2022-03-21 15:22:58,841 - INFO - tqdm - f1: 0.9544, accuracy: 0.9541, batch_loss: 0.3036, loss: 0.1352 ||:  24%|##4       | 1744/7188 [06:14<18:59,  4.78it/s]
2022-03-21 15:23:08,862 - INFO - tqdm - f1: 0.9542, accuracy: 0.9539, batch_loss: 0.0785, loss: 0.1356 ||:  25%|##4       | 1792/7188 [06:24<21:02,  4.28it/s]
2022-03-21 15:23:18,980 - INFO - tqdm - f1: 0.9541, accuracy: 0.9538, batch_loss: 0.4104, loss: 0.1358 ||:  26%|##5       | 1840/7188 [06:34<18:55,  4.71it/s]
2022-03-21 15:23:29,192 - INFO - tqdm - f1: 0.9538, accuracy: 0.9536, batch_loss: 0.0195, loss: 0.1365 ||:  26%|##6       | 1888/7188 [06:44<19:12,  4.60it/s]
2022-03-21 15:23:39,204 - INFO - tqdm - f1: 0.9538, accuracy: 0.9535, batch_loss: 0.0333, loss: 0.1360 ||:  27%|##6       | 1933/7188 [06:54<20:25,  4.29it/s]
2022-03-21 15:23:49,316 - INFO - tqdm - f1: 0.9541, accuracy: 0.9538, batch_loss: 0.1227, loss: 0.1353 ||:  28%|##7       | 1979/7188 [07:05<19:21,  4.49it/s]
2022-03-21 15:23:59,538 - INFO - tqdm - f1: 0.9538, accuracy: 0.9535, batch_loss: 0.1985, loss: 0.1361 ||:  28%|##8       | 2026/7188 [07:15<19:50,  4.34it/s]
2022-03-21 15:24:09,565 - INFO - tqdm - f1: 0.9538, accuracy: 0.9535, batch_loss: 0.0261, loss: 0.1356 ||:  29%|##8       | 2076/7188 [07:25<19:19,  4.41it/s]
2022-03-21 15:24:19,589 - INFO - tqdm - f1: 0.9534, accuracy: 0.9532, batch_loss: 0.0218, loss: 0.1368 ||:  30%|##9       | 2124/7188 [07:35<18:29,  4.56it/s]
2022-03-21 15:24:29,867 - INFO - tqdm - f1: 0.9534, accuracy: 0.9531, batch_loss: 0.1134, loss: 0.1366 ||:  30%|###       | 2172/7188 [07:45<20:05,  4.16it/s]
2022-03-21 15:24:39,874 - INFO - tqdm - f1: 0.9536, accuracy: 0.9534, batch_loss: 0.0392, loss: 0.1358 ||:  31%|###       | 2217/7188 [07:55<19:08,  4.33it/s]
2022-03-21 15:24:49,929 - INFO - tqdm - f1: 0.9536, accuracy: 0.9534, batch_loss: 0.2207, loss: 0.1359 ||:  31%|###1      | 2263/7188 [08:05<17:37,  4.66it/s]
2022-03-21 15:25:00,002 - INFO - tqdm - f1: 0.9535, accuracy: 0.9533, batch_loss: 0.0062, loss: 0.1361 ||:  32%|###2      | 2312/7188 [08:15<17:46,  4.57it/s]
2022-03-21 15:25:10,092 - INFO - tqdm - f1: 0.9533, accuracy: 0.9531, batch_loss: 0.1836, loss: 0.1362 ||:  33%|###2      | 2359/7188 [08:25<15:44,  5.11it/s]
2022-03-21 15:25:20,275 - INFO - tqdm - f1: 0.9535, accuracy: 0.9532, batch_loss: 0.3649, loss: 0.1358 ||:  33%|###3      | 2406/7188 [08:35<16:51,  4.73it/s]
2022-03-21 15:25:30,396 - INFO - tqdm - f1: 0.9535, accuracy: 0.9532, batch_loss: 0.7347, loss: 0.1362 ||:  35%|###5      | 2524/7188 [08:46<11:15,  6.91it/s]
2022-03-21 15:25:40,531 - INFO - tqdm - f1: 0.9535, accuracy: 0.9532, batch_loss: 0.1560, loss: 0.1362 ||:  36%|###6      | 2590/7188 [08:56<09:15,  8.28it/s]
2022-03-21 15:25:50,662 - INFO - tqdm - f1: 0.9536, accuracy: 0.9534, batch_loss: 0.0206, loss: 0.1360 ||:  37%|###7      | 2662/7188 [09:06<10:23,  7.26it/s]
2022-03-21 15:26:00,692 - INFO - tqdm - f1: 0.9532, accuracy: 0.9530, batch_loss: 0.2266, loss: 0.1369 ||:  38%|###7      | 2722/7188 [09:16<15:22,  4.84it/s]
2022-03-21 15:26:10,859 - INFO - tqdm - f1: 0.9531, accuracy: 0.9528, batch_loss: 0.2227, loss: 0.1373 ||:  39%|###8      | 2770/7188 [09:26<15:10,  4.85it/s]
2022-03-21 15:26:21,043 - INFO - tqdm - f1: 0.9531, accuracy: 0.9529, batch_loss: 0.0093, loss: 0.1371 ||:  39%|###9      | 2818/7188 [09:36<16:32,  4.40it/s]
2022-03-21 15:26:31,158 - INFO - tqdm - f1: 0.9533, accuracy: 0.9531, batch_loss: 0.0094, loss: 0.1365 ||:  40%|###9      | 2864/7188 [09:46<16:58,  4.24it/s]
2022-03-21 15:26:41,164 - INFO - tqdm - f1: 0.9533, accuracy: 0.9531, batch_loss: 0.1809, loss: 0.1365 ||:  40%|####      | 2911/7188 [09:56<15:09,  4.70it/s]
2022-03-21 15:26:51,301 - INFO - tqdm - f1: 0.9532, accuracy: 0.9530, batch_loss: 0.0404, loss: 0.1367 ||:  41%|####1     | 2959/7188 [10:07<15:03,  4.68it/s]
2022-03-21 15:27:01,488 - INFO - tqdm - f1: 0.9533, accuracy: 0.9531, batch_loss: 0.0242, loss: 0.1365 ||:  42%|####1     | 3008/7188 [10:17<13:52,  5.02it/s]
2022-03-21 15:27:11,726 - INFO - tqdm - f1: 0.9532, accuracy: 0.9530, batch_loss: 0.1429, loss: 0.1368 ||:  43%|####2     | 3057/7188 [10:27<14:32,  4.74it/s]
2022-03-21 15:27:21,814 - INFO - tqdm - f1: 0.9529, accuracy: 0.9528, batch_loss: 0.0593, loss: 0.1376 ||:  43%|####3     | 3107/7188 [10:37<12:47,  5.32it/s]
2022-03-21 15:27:31,856 - INFO - tqdm - f1: 0.9530, accuracy: 0.9528, batch_loss: 0.2966, loss: 0.1378 ||:  44%|####3     | 3154/7188 [10:47<14:09,  4.75it/s]
2022-03-21 15:27:41,935 - INFO - tqdm - f1: 0.9531, accuracy: 0.9529, batch_loss: 0.0457, loss: 0.1376 ||:  45%|####4     | 3199/7188 [10:57<16:17,  4.08it/s]
2022-03-21 15:27:52,129 - INFO - tqdm - f1: 0.9533, accuracy: 0.9531, batch_loss: 0.0057, loss: 0.1370 ||:  45%|####5     | 3246/7188 [11:07<14:12,  4.63it/s]
2022-03-21 15:28:02,277 - INFO - tqdm - f1: 0.9532, accuracy: 0.9530, batch_loss: 0.1069, loss: 0.1376 ||:  46%|####5     | 3294/7188 [11:17<13:24,  4.84it/s]
2022-03-21 15:28:12,402 - INFO - tqdm - f1: 0.9533, accuracy: 0.9531, batch_loss: 0.1120, loss: 0.1372 ||:  46%|####6     | 3340/7188 [11:28<13:33,  4.73it/s]
2022-03-21 15:28:22,427 - INFO - tqdm - f1: 0.9532, accuracy: 0.9531, batch_loss: 0.0435, loss: 0.1370 ||:  47%|####7     | 3388/7188 [11:38<13:27,  4.71it/s]
2022-03-21 15:28:32,480 - INFO - tqdm - f1: 0.9532, accuracy: 0.9530, batch_loss: 0.2077, loss: 0.1372 ||:  48%|####7     | 3435/7188 [11:48<13:20,  4.69it/s]
2022-03-21 15:28:42,592 - INFO - tqdm - f1: 0.9532, accuracy: 0.9530, batch_loss: 0.0218, loss: 0.1372 ||:  48%|####8     | 3482/7188 [11:58<13:54,  4.44it/s]
2022-03-21 15:28:52,832 - INFO - tqdm - f1: 0.9533, accuracy: 0.9532, batch_loss: 0.0257, loss: 0.1371 ||:  49%|####9     | 3531/7188 [12:08<12:55,  4.72it/s]
2022-03-21 15:29:03,000 - INFO - tqdm - f1: 0.9530, accuracy: 0.9529, batch_loss: 0.0465, loss: 0.1374 ||:  50%|####9     | 3578/7188 [12:18<14:02,  4.28it/s]
2022-03-21 15:29:13,084 - INFO - tqdm - f1: 0.9531, accuracy: 0.9530, batch_loss: 0.3730, loss: 0.1373 ||:  50%|#####     | 3627/7188 [12:28<11:41,  5.08it/s]
2022-03-21 15:29:23,313 - INFO - tqdm - f1: 0.9529, accuracy: 0.9527, batch_loss: 0.0568, loss: 0.1381 ||:  51%|#####1    | 3676/7188 [12:39<12:48,  4.57it/s]
2022-03-21 15:29:33,402 - INFO - tqdm - f1: 0.9530, accuracy: 0.9529, batch_loss: 0.0394, loss: 0.1377 ||:  52%|#####1    | 3723/7188 [12:49<13:14,  4.36it/s]
2022-03-21 15:29:43,515 - INFO - tqdm - f1: 0.9530, accuracy: 0.9529, batch_loss: 0.4608, loss: 0.1379 ||:  52%|#####2    | 3770/7188 [12:59<12:20,  4.61it/s]
2022-03-21 15:29:53,736 - INFO - tqdm - f1: 0.9529, accuracy: 0.9528, batch_loss: 0.0382, loss: 0.1379 ||:  53%|#####3    | 3816/7188 [13:09<11:43,  4.80it/s]
2022-03-21 15:30:03,933 - INFO - tqdm - f1: 0.9530, accuracy: 0.9529, batch_loss: 0.0047, loss: 0.1379 ||:  54%|#####3    | 3863/7188 [13:19<13:05,  4.23it/s]
2022-03-21 15:30:14,108 - INFO - tqdm - f1: 0.9529, accuracy: 0.9528, batch_loss: 0.0291, loss: 0.1380 ||:  54%|#####4    | 3909/7188 [13:29<14:03,  3.89it/s]
2022-03-21 15:30:24,246 - INFO - tqdm - f1: 0.9530, accuracy: 0.9529, batch_loss: 0.1795, loss: 0.1379 ||:  55%|#####5    | 3957/7188 [13:39<11:36,  4.64it/s]
2022-03-21 15:30:34,412 - INFO - tqdm - f1: 0.9531, accuracy: 0.9529, batch_loss: 0.1234, loss: 0.1378 ||:  56%|#####5    | 4005/7188 [13:50<10:45,  4.93it/s]
2022-03-21 15:30:44,574 - INFO - tqdm - f1: 0.9531, accuracy: 0.9530, batch_loss: 0.0866, loss: 0.1378 ||:  56%|#####6    | 4052/7188 [14:00<11:32,  4.53it/s]
2022-03-21 15:30:54,669 - INFO - tqdm - f1: 0.9531, accuracy: 0.9530, batch_loss: 0.3695, loss: 0.1379 ||:  57%|#####6    | 4097/7188 [14:10<10:58,  4.70it/s]
2022-03-21 15:31:04,794 - INFO - tqdm - f1: 0.9531, accuracy: 0.9531, batch_loss: 0.2050, loss: 0.1377 ||:  58%|#####7    | 4142/7188 [14:20<12:25,  4.09it/s]
2022-03-21 15:31:15,139 - INFO - tqdm - f1: 0.9531, accuracy: 0.9530, batch_loss: 0.2317, loss: 0.1377 ||:  58%|#####8    | 4187/7188 [14:30<16:52,  2.97it/s]
2022-03-21 15:31:25,535 - INFO - tqdm - f1: 0.9531, accuracy: 0.9531, batch_loss: 0.0207, loss: 0.1376 ||:  59%|#####8    | 4213/7188 [14:41<19:44,  2.51it/s]
2022-03-21 15:31:35,810 - INFO - tqdm - f1: 0.9531, accuracy: 0.9531, batch_loss: 0.3525, loss: 0.1376 ||:  59%|#####8    | 4239/7188 [14:51<20:21,  2.41it/s]
2022-03-21 15:31:46,124 - INFO - tqdm - f1: 0.9530, accuracy: 0.9530, batch_loss: 0.1714, loss: 0.1378 ||:  59%|#####9    | 4267/7188 [15:01<18:47,  2.59it/s]
2022-03-21 15:31:56,475 - INFO - tqdm - f1: 0.9531, accuracy: 0.9530, batch_loss: 0.0885, loss: 0.1376 ||:  60%|#####9    | 4293/7188 [15:12<19:48,  2.44it/s]
2022-03-21 15:32:06,553 - INFO - tqdm - f1: 0.9529, accuracy: 0.9529, batch_loss: 0.0161, loss: 0.1380 ||:  60%|######    | 4319/7188 [15:22<18:35,  2.57it/s]
2022-03-21 15:32:16,652 - INFO - tqdm - f1: 0.9529, accuracy: 0.9529, batch_loss: 0.2033, loss: 0.1380 ||:  60%|######    | 4345/7188 [15:32<17:19,  2.73it/s]
2022-03-21 15:32:26,980 - INFO - tqdm - f1: 0.9529, accuracy: 0.9528, batch_loss: 0.2686, loss: 0.1382 ||:  61%|######    | 4371/7188 [15:42<18:33,  2.53it/s]
2022-03-21 15:32:37,280 - INFO - tqdm - f1: 0.9529, accuracy: 0.9528, batch_loss: 0.0616, loss: 0.1380 ||:  61%|######1   | 4398/7188 [15:53<16:58,  2.74it/s]
2022-03-21 15:32:47,412 - INFO - tqdm - f1: 0.9529, accuracy: 0.9528, batch_loss: 0.1469, loss: 0.1379 ||:  62%|######1   | 4424/7188 [16:03<19:08,  2.41it/s]
2022-03-21 15:32:57,626 - INFO - tqdm - f1: 0.9528, accuracy: 0.9527, batch_loss: 0.2496, loss: 0.1379 ||:  62%|######1   | 4451/7188 [16:13<17:39,  2.58it/s]
2022-03-21 15:33:07,794 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.1919, loss: 0.1380 ||:  62%|######2   | 4477/7188 [16:23<17:09,  2.63it/s]
2022-03-21 15:33:18,114 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.1115, loss: 0.1379 ||:  63%|######2   | 4504/7188 [16:33<14:03,  3.18it/s]
2022-03-21 15:33:28,122 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.1628, loss: 0.1380 ||:  63%|######3   | 4530/7188 [16:43<17:14,  2.57it/s]
2022-03-21 15:33:38,236 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0180, loss: 0.1381 ||:  63%|######3   | 4556/7188 [16:53<16:36,  2.64it/s]
2022-03-21 15:33:48,282 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.1473, loss: 0.1381 ||:  64%|######3   | 4582/7188 [17:04<18:19,  2.37it/s]
2022-03-21 15:33:58,615 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.3360, loss: 0.1381 ||:  64%|######4   | 4608/7188 [17:14<18:03,  2.38it/s]
2022-03-21 15:34:08,871 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0156, loss: 0.1380 ||:  64%|######4   | 4635/7188 [17:24<16:06,  2.64it/s]
2022-03-21 15:34:18,897 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.0303, loss: 0.1377 ||:  65%|######4   | 4661/7188 [17:34<15:58,  2.64it/s]
2022-03-21 15:34:29,170 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.1490, loss: 0.1382 ||:  65%|######5   | 4687/7188 [17:44<17:26,  2.39it/s]
2022-03-21 15:34:39,479 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.0478, loss: 0.1382 ||:  66%|######5   | 4716/7188 [17:55<16:20,  2.52it/s]
2022-03-21 15:34:49,502 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.1372, loss: 0.1380 ||:  66%|######5   | 4741/7188 [18:05<16:12,  2.52it/s]
2022-03-21 15:34:59,652 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.0373, loss: 0.1383 ||:  66%|######6   | 4768/7188 [18:15<15:49,  2.55it/s]
2022-03-21 15:35:10,051 - INFO - tqdm - f1: 0.9528, accuracy: 0.9527, batch_loss: 0.0209, loss: 0.1384 ||:  67%|######6   | 4794/7188 [18:25<16:19,  2.44it/s]
2022-03-21 15:35:20,073 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.0701, loss: 0.1382 ||:  67%|######7   | 4819/7188 [18:35<15:57,  2.47it/s]
2022-03-21 15:35:30,469 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.1168, loss: 0.1384 ||:  67%|######7   | 4847/7188 [18:46<15:55,  2.45it/s]
2022-03-21 15:35:40,617 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.2543, loss: 0.1385 ||:  68%|######7   | 4873/7188 [18:56<14:34,  2.65it/s]
2022-03-21 15:35:50,918 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.1451, loss: 0.1384 ||:  68%|######8   | 4902/7188 [19:06<13:04,  2.91it/s]
2022-03-21 15:36:00,933 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.2778, loss: 0.1385 ||:  69%|######8   | 4939/7188 [19:16<08:29,  4.41it/s]
2022-03-21 15:36:10,977 - INFO - tqdm - f1: 0.9526, accuracy: 0.9526, batch_loss: 0.0215, loss: 0.1388 ||:  69%|######9   | 4986/7188 [19:26<08:46,  4.18it/s]
2022-03-21 15:36:21,146 - INFO - tqdm - f1: 0.9526, accuracy: 0.9526, batch_loss: 0.0805, loss: 0.1387 ||:  70%|#######   | 5034/7188 [19:36<08:40,  4.14it/s]
2022-03-21 15:36:31,340 - INFO - tqdm - f1: 0.9526, accuracy: 0.9526, batch_loss: 0.1782, loss: 0.1387 ||:  71%|#######   | 5081/7188 [19:47<07:42,  4.56it/s]
2022-03-21 15:36:41,463 - INFO - tqdm - f1: 0.9526, accuracy: 0.9526, batch_loss: 0.0264, loss: 0.1387 ||:  71%|#######1  | 5129/7188 [19:57<07:16,  4.72it/s]
2022-03-21 15:36:51,616 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0081, loss: 0.1386 ||:  72%|#######2  | 5177/7188 [20:07<07:38,  4.39it/s]
2022-03-21 15:37:01,665 - INFO - tqdm - f1: 0.9527, accuracy: 0.9528, batch_loss: 0.1138, loss: 0.1386 ||:  73%|#######2  | 5225/7188 [20:17<07:14,  4.52it/s]
2022-03-21 15:37:11,698 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.0309, loss: 0.1387 ||:  73%|#######3  | 5271/7188 [20:27<06:41,  4.78it/s]
2022-03-21 15:37:21,839 - INFO - tqdm - f1: 0.9529, accuracy: 0.9529, batch_loss: 0.1884, loss: 0.1386 ||:  74%|#######3  | 5318/7188 [20:37<05:52,  5.31it/s]
2022-03-21 15:37:32,041 - INFO - tqdm - f1: 0.9529, accuracy: 0.9529, batch_loss: 0.0212, loss: 0.1384 ||:  75%|#######4  | 5364/7188 [20:47<07:03,  4.31it/s]
2022-03-21 15:37:42,084 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.0638, loss: 0.1386 ||:  75%|#######5  | 5412/7188 [20:57<06:23,  4.64it/s]
2022-03-21 15:37:52,194 - INFO - tqdm - f1: 0.9527, accuracy: 0.9528, batch_loss: 0.4135, loss: 0.1387 ||:  76%|#######5  | 5459/7188 [21:07<06:14,  4.61it/s]
2022-03-21 15:38:02,343 - INFO - tqdm - f1: 0.9527, accuracy: 0.9528, batch_loss: 0.0104, loss: 0.1385 ||:  77%|#######6  | 5506/7188 [21:18<05:55,  4.74it/s]
2022-03-21 15:38:12,413 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.1277, loss: 0.1385 ||:  77%|#######7  | 5551/7188 [21:28<05:52,  4.65it/s]
2022-03-21 15:38:22,587 - INFO - tqdm - f1: 0.9526, accuracy: 0.9526, batch_loss: 0.1663, loss: 0.1386 ||:  78%|#######7  | 5598/7188 [21:38<05:40,  4.67it/s]
2022-03-21 15:38:32,619 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0517, loss: 0.1385 ||:  79%|#######8  | 5644/7188 [21:48<06:05,  4.23it/s]
2022-03-21 15:38:42,799 - INFO - tqdm - f1: 0.9526, accuracy: 0.9527, batch_loss: 0.2464, loss: 0.1387 ||:  79%|#######9  | 5692/7188 [21:58<05:34,  4.47it/s]
2022-03-21 15:38:52,831 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.3592, loss: 0.1388 ||:  80%|#######9  | 5742/7188 [22:08<04:11,  5.75it/s]
2022-03-21 15:39:03,062 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0990, loss: 0.1387 ||:  81%|########  | 5791/7188 [22:18<05:05,  4.57it/s]
2022-03-21 15:39:13,256 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.1918, loss: 0.1387 ||:  81%|########1 | 5840/7188 [22:28<04:43,  4.76it/s]
2022-03-21 15:39:23,274 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.0233, loss: 0.1387 ||:  82%|########1 | 5887/7188 [22:38<04:46,  4.55it/s]
2022-03-21 15:39:33,331 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.3874, loss: 0.1385 ||:  83%|########2 | 5933/7188 [22:49<04:37,  4.52it/s]
2022-03-21 15:39:43,604 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.5917, loss: 0.1383 ||:  83%|########3 | 5980/7188 [22:59<04:51,  4.15it/s]
2022-03-21 15:39:53,736 - INFO - tqdm - f1: 0.9527, accuracy: 0.9528, batch_loss: 0.0837, loss: 0.1384 ||:  84%|########3 | 6028/7188 [23:09<04:02,  4.79it/s]
2022-03-21 15:40:03,903 - INFO - tqdm - f1: 0.9527, accuracy: 0.9528, batch_loss: 0.0232, loss: 0.1384 ||:  85%|########4 | 6075/7188 [23:19<04:04,  4.56it/s]
2022-03-21 15:40:14,066 - INFO - tqdm - f1: 0.9527, accuracy: 0.9528, batch_loss: 0.0624, loss: 0.1386 ||:  85%|########5 | 6123/7188 [23:29<03:42,  4.78it/s]
2022-03-21 15:40:24,176 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.2153, loss: 0.1385 ||:  86%|########5 | 6170/7188 [23:39<03:50,  4.43it/s]
2022-03-21 15:40:34,282 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.1038, loss: 0.1385 ||:  87%|########6 | 6218/7188 [23:50<03:21,  4.82it/s]
2022-03-21 15:40:44,313 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.2493, loss: 0.1386 ||:  87%|########7 | 6263/7188 [24:00<03:46,  4.08it/s]
2022-03-21 15:40:54,581 - INFO - tqdm - f1: 0.9529, accuracy: 0.9529, batch_loss: 0.0163, loss: 0.1383 ||:  88%|########7 | 6310/7188 [24:10<03:21,  4.35it/s]
2022-03-21 15:41:04,610 - INFO - tqdm - f1: 0.9528, accuracy: 0.9528, batch_loss: 0.0459, loss: 0.1383 ||:  88%|########8 | 6357/7188 [24:20<02:55,  4.74it/s]
2022-03-21 15:41:14,758 - INFO - tqdm - f1: 0.9528, accuracy: 0.9527, batch_loss: 0.0554, loss: 0.1385 ||:  89%|########9 | 6406/7188 [24:30<03:06,  4.19it/s]
2022-03-21 15:41:24,947 - INFO - tqdm - f1: 0.9527, accuracy: 0.9527, batch_loss: 0.2420, loss: 0.1384 ||:  90%|########9 | 6454/7188 [24:40<02:38,  4.62it/s]
2022-03-21 15:41:34,982 - INFO - tqdm - f1: 0.9527, accuracy: 0.9526, batch_loss: 0.0334, loss: 0.1385 ||:  90%|######### | 6502/7188 [24:50<02:34,  4.44it/s]
2022-03-21 15:41:45,190 - INFO - tqdm - f1: 0.9526, accuracy: 0.9526, batch_loss: 0.2666, loss: 0.1385 ||:  91%|#########1| 6548/7188 [25:00<02:26,  4.37it/s]
2022-03-21 15:41:55,385 - INFO - tqdm - f1: 0.9526, accuracy: 0.9525, batch_loss: 0.0505, loss: 0.1387 ||:  92%|#########1| 6596/7188 [25:11<02:17,  4.29it/s]
2022-03-21 15:42:05,521 - INFO - tqdm - f1: 0.9526, accuracy: 0.9526, batch_loss: 0.1990, loss: 0.1384 ||:  92%|#########2| 6642/7188 [25:21<01:53,  4.79it/s]
2022-03-21 15:42:15,742 - INFO - tqdm - f1: 0.9526, accuracy: 0.9526, batch_loss: 0.2906, loss: 0.1386 ||:  93%|#########3| 6689/7188 [25:31<01:51,  4.46it/s]
2022-03-21 15:42:25,888 - INFO - tqdm - f1: 0.9526, accuracy: 0.9526, batch_loss: 0.0051, loss: 0.1384 ||:  94%|#########3| 6738/7188 [25:41<01:37,  4.63it/s]
2022-03-21 15:42:35,977 - INFO - tqdm - f1: 0.9525, accuracy: 0.9525, batch_loss: 0.3829, loss: 0.1386 ||:  94%|#########4| 6785/7188 [25:51<01:31,  4.42it/s]
2022-03-21 15:42:46,031 - INFO - tqdm - f1: 0.9525, accuracy: 0.9525, batch_loss: 0.2233, loss: 0.1386 ||:  95%|#########5| 6832/7188 [26:01<01:17,  4.60it/s]
2022-03-21 15:42:56,173 - INFO - tqdm - f1: 0.9524, accuracy: 0.9524, batch_loss: 0.0709, loss: 0.1386 ||:  96%|#########5| 6878/7188 [26:11<01:10,  4.37it/s]
2022-03-21 15:43:06,397 - INFO - tqdm - f1: 0.9523, accuracy: 0.9523, batch_loss: 0.0411, loss: 0.1388 ||:  96%|#########6| 6925/7188 [26:22<00:54,  4.83it/s]
2022-03-21 15:43:16,469 - INFO - tqdm - f1: 0.9522, accuracy: 0.9522, batch_loss: 0.1385, loss: 0.1388 ||:  97%|#########7| 6996/7188 [26:32<00:12, 14.89it/s]
2022-03-21 15:43:26,529 - INFO - tqdm - f1: 0.9522, accuracy: 0.9522, batch_loss: 0.2428, loss: 0.1387 ||:  99%|#########8| 7097/7188 [26:42<00:12,  7.04it/s]
2022-03-21 15:43:33,997 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.2144, loss: 0.1387 ||: 100%|#########9| 7153/7188 [26:49<00:04,  7.80it/s]
2022-03-21 15:43:34,124 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0855, loss: 0.1387 ||: 100%|#########9| 7154/7188 [26:49<00:04,  7.82it/s]
2022-03-21 15:43:34,263 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.2880, loss: 0.1387 ||: 100%|#########9| 7155/7188 [26:49<00:04,  7.64it/s]
2022-03-21 15:43:34,404 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0288, loss: 0.1387 ||: 100%|#########9| 7156/7188 [26:50<00:04,  7.45it/s]
2022-03-21 15:43:34,635 - INFO - tqdm - f1: 0.9521, accuracy: 0.9521, batch_loss: 0.0943, loss: 0.1387 ||: 100%|#########9| 7158/7188 [26:50<00:03,  7.96it/s]
2022-03-21 15:43:34,784 - INFO - tqdm - f1: 0.9521, accuracy: 0.9521, batch_loss: 0.1087, loss: 0.1387 ||: 100%|#########9| 7159/7188 [26:50<00:03,  7.61it/s]
2022-03-21 15:43:34,931 - INFO - tqdm - f1: 0.9521, accuracy: 0.9521, batch_loss: 0.0033, loss: 0.1387 ||: 100%|#########9| 7160/7188 [26:50<00:03,  7.39it/s]
2022-03-21 15:43:35,078 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0041, loss: 0.1387 ||: 100%|#########9| 7161/7188 [26:50<00:03,  7.21it/s]
2022-03-21 15:43:35,223 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0336, loss: 0.1387 ||: 100%|#########9| 7162/7188 [26:50<00:03,  7.14it/s]
2022-03-21 15:43:35,366 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0063, loss: 0.1387 ||: 100%|#########9| 7163/7188 [26:51<00:03,  7.08it/s]
2022-03-21 15:43:35,506 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0373, loss: 0.1387 ||: 100%|#########9| 7164/7188 [26:51<00:03,  7.10it/s]
2022-03-21 15:43:35,650 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.1243, loss: 0.1387 ||: 100%|#########9| 7165/7188 [26:51<00:03,  7.06it/s]
2022-03-21 15:43:35,799 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.1000, loss: 0.1387 ||: 100%|#########9| 7166/7188 [26:51<00:03,  6.95it/s]
2022-03-21 15:43:35,939 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0552, loss: 0.1386 ||: 100%|#########9| 7167/7188 [26:51<00:02,  7.01it/s]
2022-03-21 15:43:36,089 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0916, loss: 0.1386 ||: 100%|#########9| 7168/7188 [26:51<00:02,  6.90it/s]
2022-03-21 15:43:36,234 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0157, loss: 0.1386 ||: 100%|#########9| 7169/7188 [26:51<00:02,  6.91it/s]
2022-03-21 15:43:36,381 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0969, loss: 0.1386 ||: 100%|#########9| 7170/7188 [26:52<00:02,  6.88it/s]
2022-03-21 15:43:36,524 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0413, loss: 0.1386 ||: 100%|#########9| 7171/7188 [26:52<00:02,  6.91it/s]
2022-03-21 15:43:36,669 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0973, loss: 0.1386 ||: 100%|#########9| 7172/7188 [26:52<00:02,  6.90it/s]
2022-03-21 15:43:36,813 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.1107, loss: 0.1386 ||: 100%|#########9| 7173/7188 [26:52<00:02,  6.92it/s]
2022-03-21 15:43:36,957 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0789, loss: 0.1386 ||: 100%|#########9| 7174/7188 [26:52<00:02,  6.92it/s]
2022-03-21 15:43:37,102 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0449, loss: 0.1386 ||: 100%|#########9| 7175/7188 [26:52<00:01,  6.92it/s]
2022-03-21 15:43:37,243 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0115, loss: 0.1385 ||: 100%|#########9| 7176/7188 [26:52<00:01,  6.96it/s]
2022-03-21 15:43:37,486 - INFO - tqdm - f1: 0.9522, accuracy: 0.9522, batch_loss: 0.0055, loss: 0.1385 ||: 100%|#########9| 7178/7188 [26:53<00:01,  7.50it/s]
2022-03-21 15:43:37,642 - INFO - tqdm - f1: 0.9522, accuracy: 0.9522, batch_loss: 0.0039, loss: 0.1385 ||: 100%|#########9| 7179/7188 [26:53<00:01,  7.20it/s]
2022-03-21 15:43:37,779 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.6122, loss: 0.1386 ||: 100%|#########9| 7180/7188 [26:53<00:01,  7.22it/s]
2022-03-21 15:43:37,999 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.1718, loss: 0.1386 ||: 100%|#########9| 7182/7188 [26:53<00:00,  7.92it/s]
2022-03-21 15:43:38,144 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.1425, loss: 0.1386 ||: 100%|#########9| 7183/7188 [26:53<00:00,  7.65it/s]
2022-03-21 15:43:38,293 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0045, loss: 0.1386 ||: 100%|#########9| 7184/7188 [26:54<00:00,  7.39it/s]
2022-03-21 15:43:38,442 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0350, loss: 0.1386 ||: 100%|#########9| 7185/7188 [26:54<00:00,  7.20it/s]
2022-03-21 15:43:38,590 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.3622, loss: 0.1386 ||: 100%|#########9| 7186/7188 [26:54<00:00,  7.07it/s]
2022-03-21 15:43:38,733 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.0181, loss: 0.1386 ||: 100%|#########9| 7187/7188 [26:54<00:00,  7.05it/s]
2022-03-21 15:43:38,880 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.1145, loss: 0.1386 ||: 100%|##########| 7188/7188 [26:54<00:00,  6.98it/s]
2022-03-21 15:43:38,920 - INFO - tqdm - f1: 0.9522, accuracy: 0.9521, batch_loss: 0.1145, loss: 0.1386 ||: 100%|##########| 7188/7188 [26:54<00:00,  4.45it/s]
2022-03-21 15:43:38,948 - INFO - allennlp.training.trainer - Validating
2022-03-21 15:43:38,950 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 15:43:49,055 - INFO - tqdm - f1: 0.9358, accuracy: 0.9360, batch_loss: 0.0043, loss: 0.2195 ||:  58%|#####8    | 183/313 [00:10<00:05, 24.72it/s]
2022-03-21 15:43:59,083 - INFO - tqdm - f1: 0.9382, accuracy: 0.9383, batch_loss: 0.0583, loss: 0.2215 ||:  86%|########5 | 268/313 [00:20<00:04, 10.40it/s]
2022-03-21 15:44:04,316 - INFO - tqdm - f1: 0.9379, accuracy: 0.9378, batch_loss: 0.7211, loss: 0.2213 ||: 100%|#########9| 312/313 [00:25<00:00,  8.71it/s]
2022-03-21 15:44:04,473 - INFO - tqdm - f1: 0.9381, accuracy: 0.9380, batch_loss: 0.0071, loss: 0.2206 ||: 100%|##########| 313/313 [00:25<00:00,  8.09it/s]
2022-03-21 15:44:04,477 - INFO - tqdm - f1: 0.9381, accuracy: 0.9380, batch_loss: 0.0071, loss: 0.2206 ||: 100%|##########| 313/313 [00:25<00:00, 12.26it/s]
2022-03-21 15:44:04,491 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_base_hyper_small_seed_314/best.th'.
2022-03-21 15:44:06,846 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 15:44:06,850 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.952  |     0.938
2022-03-21 15:44:06,854 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.952  |     0.938
2022-03-21 15:44:06,857 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 15:44:06,858 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.139  |     0.221
2022-03-21 15:44:06,860 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7579.625  |       N/A
2022-03-21 15:44:06,861 - INFO - allennlp.training.trainer - Epoch duration: 0:27:22.596152
2022-03-21 15:44:06,863 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:02:35
2022-03-21 15:44:06,864 - INFO - allennlp.training.trainer - Epoch 3/9
2022-03-21 15:44:06,866 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 15:44:06,868 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 15:44:06,870 - INFO - allennlp.training.trainer - Training
2022-03-21 15:44:06,872 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 15:44:17,040 - INFO - tqdm - f1: 0.9557, accuracy: 0.9551, batch_loss: 0.0049, loss: 0.1022 ||:   0%|          | 32/7188 [00:10<23:19,  5.11it/s]
2022-03-21 15:44:27,186 - INFO - tqdm - f1: 0.9595, accuracy: 0.9602, batch_loss: 0.2365, loss: 0.1034 ||:   1%|1         | 80/7188 [00:20<25:51,  4.58it/s]
2022-03-21 15:44:37,215 - INFO - tqdm - f1: 0.9595, accuracy: 0.9600, batch_loss: 0.2124, loss: 0.1190 ||:   2%|1         | 128/7188 [00:30<24:29,  4.80it/s]
2022-03-21 15:44:47,392 - INFO - tqdm - f1: 0.9619, accuracy: 0.9624, batch_loss: 0.0151, loss: 0.1157 ||:   2%|2         | 176/7188 [00:40<25:59,  4.50it/s]
2022-03-21 15:44:57,545 - INFO - tqdm - f1: 0.9616, accuracy: 0.9619, batch_loss: 0.1716, loss: 0.1126 ||:   3%|3         | 225/7188 [00:50<27:07,  4.28it/s]
2022-03-21 15:45:07,729 - INFO - tqdm - f1: 0.9619, accuracy: 0.9620, batch_loss: 0.1708, loss: 0.1101 ||:   4%|3         | 273/7188 [01:00<24:15,  4.75it/s]
2022-03-21 15:45:17,925 - INFO - tqdm - f1: 0.9628, accuracy: 0.9628, batch_loss: 0.0356, loss: 0.1123 ||:   4%|4         | 323/7188 [01:11<24:41,  4.63it/s]
2022-03-21 15:45:28,034 - INFO - tqdm - f1: 0.9633, accuracy: 0.9633, batch_loss: 0.0102, loss: 0.1099 ||:   5%|5         | 371/7188 [01:21<25:19,  4.49it/s]
2022-03-21 15:45:38,237 - INFO - tqdm - f1: 0.9618, accuracy: 0.9619, batch_loss: 0.0968, loss: 0.1137 ||:   6%|5         | 420/7188 [01:31<22:49,  4.94it/s]
2022-03-21 15:45:48,453 - INFO - tqdm - f1: 0.9619, accuracy: 0.9619, batch_loss: 0.0308, loss: 0.1129 ||:   7%|6         | 469/7188 [01:41<24:16,  4.61it/s]
2022-03-21 15:45:58,458 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.0274, loss: 0.1131 ||:   7%|7         | 518/7188 [01:51<21:54,  5.07it/s]
2022-03-21 15:46:08,465 - INFO - tqdm - f1: 0.9635, accuracy: 0.9634, batch_loss: 0.0227, loss: 0.1097 ||:   8%|7         | 565/7188 [02:01<23:50,  4.63it/s]
2022-03-21 15:46:18,623 - INFO - tqdm - f1: 0.9635, accuracy: 0.9635, batch_loss: 0.0094, loss: 0.1080 ||:   9%|8         | 613/7188 [02:11<22:53,  4.79it/s]
2022-03-21 15:46:28,666 - INFO - tqdm - f1: 0.9632, accuracy: 0.9633, batch_loss: 0.0613, loss: 0.1090 ||:   9%|9         | 660/7188 [02:21<23:46,  4.57it/s]
2022-03-21 15:46:38,740 - INFO - tqdm - f1: 0.9633, accuracy: 0.9634, batch_loss: 0.3173, loss: 0.1082 ||:  10%|9         | 707/7188 [02:31<22:47,  4.74it/s]
2022-03-21 15:46:48,920 - INFO - tqdm - f1: 0.9634, accuracy: 0.9635, batch_loss: 0.0067, loss: 0.1086 ||:  11%|#         | 755/7188 [02:42<22:53,  4.68it/s]
2022-03-21 15:46:59,096 - INFO - tqdm - f1: 0.9634, accuracy: 0.9634, batch_loss: 0.0292, loss: 0.1092 ||:  11%|#1        | 804/7188 [02:52<22:29,  4.73it/s]
2022-03-21 15:47:09,328 - INFO - tqdm - f1: 0.9634, accuracy: 0.9634, batch_loss: 0.3022, loss: 0.1091 ||:  12%|#1        | 853/7188 [03:02<22:53,  4.61it/s]
2022-03-21 15:47:19,424 - INFO - tqdm - f1: 0.9633, accuracy: 0.9632, batch_loss: 0.0036, loss: 0.1088 ||:  13%|#2        | 900/7188 [03:12<22:06,  4.74it/s]
2022-03-21 15:47:29,435 - INFO - tqdm - f1: 0.9637, accuracy: 0.9636, batch_loss: 0.0430, loss: 0.1074 ||:  13%|#3        | 948/7188 [03:22<20:48,  5.00it/s]
2022-03-21 15:47:39,642 - INFO - tqdm - f1: 0.9636, accuracy: 0.9635, batch_loss: 0.4382, loss: 0.1077 ||:  14%|#3        | 999/7188 [03:32<21:31,  4.79it/s]
2022-03-21 15:47:49,676 - INFO - tqdm - f1: 0.9634, accuracy: 0.9633, batch_loss: 0.0372, loss: 0.1082 ||:  15%|#4        | 1047/7188 [03:42<22:17,  4.59it/s]
2022-03-21 15:47:59,762 - INFO - tqdm - f1: 0.9635, accuracy: 0.9634, batch_loss: 0.0336, loss: 0.1077 ||:  15%|#5        | 1095/7188 [03:52<19:36,  5.18it/s]
2022-03-21 15:48:10,004 - INFO - tqdm - f1: 0.9640, accuracy: 0.9639, batch_loss: 0.0146, loss: 0.1065 ||:  16%|#5        | 1143/7188 [04:03<21:47,  4.63it/s]
2022-03-21 15:48:20,129 - INFO - tqdm - f1: 0.9643, accuracy: 0.9643, batch_loss: 0.0205, loss: 0.1058 ||:  17%|#6        | 1189/7188 [04:13<23:30,  4.25it/s]
2022-03-21 15:48:30,207 - INFO - tqdm - f1: 0.9645, accuracy: 0.9644, batch_loss: 0.1785, loss: 0.1054 ||:  17%|#7        | 1236/7188 [04:23<23:21,  4.25it/s]
2022-03-21 15:48:40,259 - INFO - tqdm - f1: 0.9645, accuracy: 0.9645, batch_loss: 0.0378, loss: 0.1049 ||:  18%|#7        | 1284/7188 [04:33<20:28,  4.81it/s]
2022-03-21 15:48:50,478 - INFO - tqdm - f1: 0.9645, accuracy: 0.9645, batch_loss: 0.1135, loss: 0.1049 ||:  19%|#8        | 1331/7188 [04:43<20:55,  4.67it/s]
2022-03-21 15:49:00,698 - INFO - tqdm - f1: 0.9638, accuracy: 0.9638, batch_loss: 0.2692, loss: 0.1064 ||:  19%|#9        | 1377/7188 [04:53<20:51,  4.64it/s]
2022-03-21 15:49:10,873 - INFO - tqdm - f1: 0.9637, accuracy: 0.9638, batch_loss: 0.0094, loss: 0.1059 ||:  20%|#9        | 1426/7188 [05:03<19:14,  4.99it/s]
2022-03-21 15:49:21,008 - INFO - tqdm - f1: 0.9637, accuracy: 0.9637, batch_loss: 0.0075, loss: 0.1057 ||:  21%|##        | 1474/7188 [05:14<18:02,  5.28it/s]
2022-03-21 15:49:31,013 - INFO - tqdm - f1: 0.9636, accuracy: 0.9637, batch_loss: 0.0484, loss: 0.1049 ||:  21%|##1       | 1522/7188 [05:24<17:49,  5.30it/s]
2022-03-21 15:49:41,154 - INFO - tqdm - f1: 0.9639, accuracy: 0.9640, batch_loss: 0.0057, loss: 0.1037 ||:  22%|##1       | 1568/7188 [05:34<20:47,  4.51it/s]
2022-03-21 15:49:51,350 - INFO - tqdm - f1: 0.9636, accuracy: 0.9638, batch_loss: 0.0145, loss: 0.1042 ||:  22%|##2       | 1614/7188 [05:44<19:41,  4.72it/s]
2022-03-21 15:50:01,477 - INFO - tqdm - f1: 0.9637, accuracy: 0.9638, batch_loss: 0.1381, loss: 0.1043 ||:  23%|##3       | 1663/7188 [05:54<19:27,  4.73it/s]
2022-03-21 15:50:11,525 - INFO - tqdm - f1: 0.9638, accuracy: 0.9639, batch_loss: 0.0125, loss: 0.1039 ||:  24%|##3       | 1711/7188 [06:04<19:03,  4.79it/s]
2022-03-21 15:50:21,650 - INFO - tqdm - f1: 0.9638, accuracy: 0.9639, batch_loss: 0.0137, loss: 0.1038 ||:  24%|##4       | 1757/7188 [06:14<22:33,  4.01it/s]
2022-03-21 15:50:31,823 - INFO - tqdm - f1: 0.9640, accuracy: 0.9641, batch_loss: 0.0655, loss: 0.1036 ||:  25%|##5       | 1804/7188 [06:24<19:37,  4.57it/s]
2022-03-21 15:50:41,972 - INFO - tqdm - f1: 0.9641, accuracy: 0.9642, batch_loss: 0.0640, loss: 0.1035 ||:  26%|##5       | 1851/7188 [06:35<19:24,  4.58it/s]
2022-03-21 15:50:52,124 - INFO - tqdm - f1: 0.9640, accuracy: 0.9640, batch_loss: 0.1037, loss: 0.1040 ||:  26%|##6       | 1900/7188 [06:45<18:09,  4.85it/s]
2022-03-21 15:51:02,332 - INFO - tqdm - f1: 0.9641, accuracy: 0.9642, batch_loss: 0.0593, loss: 0.1035 ||:  27%|##7       | 1948/7188 [06:55<18:08,  4.81it/s]
2022-03-21 15:51:12,447 - INFO - tqdm - f1: 0.9641, accuracy: 0.9643, batch_loss: 0.0272, loss: 0.1033 ||:  28%|##7       | 1995/7188 [07:05<20:28,  4.23it/s]
2022-03-21 15:51:22,643 - INFO - tqdm - f1: 0.9643, accuracy: 0.9644, batch_loss: 0.1790, loss: 0.1028 ||:  28%|##8       | 2044/7188 [07:15<16:06,  5.32it/s]
2022-03-21 15:51:32,849 - INFO - tqdm - f1: 0.9642, accuracy: 0.9643, batch_loss: 0.0758, loss: 0.1028 ||:  29%|##9       | 2092/7188 [07:25<18:25,  4.61it/s]
2022-03-21 15:51:42,946 - INFO - tqdm - f1: 0.9641, accuracy: 0.9642, batch_loss: 0.0913, loss: 0.1031 ||:  30%|##9       | 2138/7188 [07:36<17:49,  4.72it/s]
2022-03-21 15:51:53,161 - INFO - tqdm - f1: 0.9635, accuracy: 0.9636, batch_loss: 0.0353, loss: 0.1048 ||:  30%|###       | 2185/7188 [07:46<17:44,  4.70it/s]
2022-03-21 15:52:03,259 - INFO - tqdm - f1: 0.9636, accuracy: 0.9637, batch_loss: 0.0074, loss: 0.1046 ||:  31%|###1      | 2232/7188 [07:56<18:30,  4.46it/s]
2022-03-21 15:52:13,432 - INFO - tqdm - f1: 0.9636, accuracy: 0.9637, batch_loss: 0.1544, loss: 0.1045 ||:  32%|###1      | 2280/7188 [08:06<18:26,  4.44it/s]
2022-03-21 15:52:23,485 - INFO - tqdm - f1: 0.9635, accuracy: 0.9637, batch_loss: 0.0240, loss: 0.1048 ||:  32%|###2      | 2325/7188 [08:16<19:04,  4.25it/s]
2022-03-21 15:52:33,614 - INFO - tqdm - f1: 0.9636, accuracy: 0.9637, batch_loss: 0.0371, loss: 0.1048 ||:  33%|###2      | 2370/7188 [08:26<17:36,  4.56it/s]
2022-03-21 15:52:43,808 - INFO - tqdm - f1: 0.9634, accuracy: 0.9636, batch_loss: 0.3602, loss: 0.1054 ||:  34%|###3      | 2418/7188 [08:36<16:23,  4.85it/s]
2022-03-21 15:52:53,949 - INFO - tqdm - f1: 0.9632, accuracy: 0.9633, batch_loss: 0.4432, loss: 0.1058 ||:  34%|###4      | 2465/7188 [08:47<17:06,  4.60it/s]
2022-03-21 15:53:04,082 - INFO - tqdm - f1: 0.9634, accuracy: 0.9635, batch_loss: 0.0671, loss: 0.1056 ||:  35%|###4      | 2513/7188 [08:57<15:56,  4.89it/s]
2022-03-21 15:53:14,284 - INFO - tqdm - f1: 0.9632, accuracy: 0.9632, batch_loss: 0.1049, loss: 0.1064 ||:  36%|###5      | 2561/7188 [09:07<18:06,  4.26it/s]
2022-03-21 15:53:24,442 - INFO - tqdm - f1: 0.9631, accuracy: 0.9632, batch_loss: 0.0063, loss: 0.1068 ||:  36%|###6      | 2608/7188 [09:17<18:14,  4.18it/s]
2022-03-21 15:53:34,489 - INFO - tqdm - f1: 0.9632, accuracy: 0.9632, batch_loss: 0.4660, loss: 0.1067 ||:  37%|###6      | 2656/7188 [09:27<16:31,  4.57it/s]
2022-03-21 15:53:44,665 - INFO - tqdm - f1: 0.9632, accuracy: 0.9632, batch_loss: 0.0283, loss: 0.1067 ||:  38%|###7      | 2704/7188 [09:37<16:57,  4.41it/s]
2022-03-21 15:53:54,753 - INFO - tqdm - f1: 0.9632, accuracy: 0.9633, batch_loss: 0.0051, loss: 0.1066 ||:  38%|###8      | 2752/7188 [09:47<15:44,  4.69it/s]
2022-03-21 15:54:04,915 - INFO - tqdm - f1: 0.9633, accuracy: 0.9633, batch_loss: 0.0188, loss: 0.1065 ||:  39%|###8      | 2800/7188 [09:58<15:22,  4.76it/s]
2022-03-21 15:54:14,927 - INFO - tqdm - f1: 0.9632, accuracy: 0.9633, batch_loss: 0.0144, loss: 0.1070 ||:  40%|###9      | 2847/7188 [10:08<15:02,  4.81it/s]
2022-03-21 15:54:25,147 - INFO - tqdm - f1: 0.9628, accuracy: 0.9629, batch_loss: 0.2732, loss: 0.1080 ||:  40%|####      | 2894/7188 [10:18<16:15,  4.40it/s]
2022-03-21 15:54:35,183 - INFO - tqdm - f1: 0.9627, accuracy: 0.9627, batch_loss: 0.1087, loss: 0.1082 ||:  41%|####      | 2941/7188 [10:28<14:50,  4.77it/s]
2022-03-21 15:54:45,204 - INFO - tqdm - f1: 0.9626, accuracy: 0.9627, batch_loss: 0.0076, loss: 0.1086 ||:  42%|####1     | 2988/7188 [10:38<15:58,  4.38it/s]
2022-03-21 15:54:55,223 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.1046, loss: 0.1088 ||:  42%|####2     | 3035/7188 [10:48<15:54,  4.35it/s]
2022-03-21 15:55:05,305 - INFO - tqdm - f1: 0.9625, accuracy: 0.9625, batch_loss: 0.0072, loss: 0.1090 ||:  43%|####2     | 3082/7188 [10:58<15:22,  4.45it/s]
2022-03-21 15:55:15,364 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.0218, loss: 0.1090 ||:  44%|####3     | 3129/7188 [11:08<15:42,  4.31it/s]
2022-03-21 15:55:25,419 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.0159, loss: 0.1091 ||:  44%|####4     | 3176/7188 [11:18<14:38,  4.57it/s]
2022-03-21 15:55:35,522 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.0165, loss: 0.1090 ||:  45%|####4     | 3222/7188 [11:28<14:53,  4.44it/s]
2022-03-21 15:55:45,597 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.0891, loss: 0.1090 ||:  45%|####5     | 3268/7188 [11:38<13:27,  4.85it/s]
2022-03-21 15:55:55,790 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.0357, loss: 0.1089 ||:  46%|####6     | 3316/7188 [11:48<13:16,  4.86it/s]
2022-03-21 15:56:05,993 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.0665, loss: 0.1089 ||:  47%|####6     | 3365/7188 [11:59<13:25,  4.74it/s]
2022-03-21 15:56:16,208 - INFO - tqdm - f1: 0.9625, accuracy: 0.9626, batch_loss: 0.0126, loss: 0.1090 ||:  48%|####7     | 3415/7188 [12:09<13:00,  4.83it/s]
2022-03-21 15:56:26,390 - INFO - tqdm - f1: 0.9624, accuracy: 0.9624, batch_loss: 0.0203, loss: 0.1093 ||:  48%|####8     | 3462/7188 [12:19<13:51,  4.48it/s]
2022-03-21 15:56:36,634 - INFO - tqdm - f1: 0.9625, accuracy: 0.9625, batch_loss: 0.2379, loss: 0.1094 ||:  49%|####8     | 3509/7188 [12:29<14:30,  4.23it/s]
2022-03-21 15:56:46,812 - INFO - tqdm - f1: 0.9624, accuracy: 0.9624, batch_loss: 0.0283, loss: 0.1094 ||:  49%|####9     | 3558/7188 [12:39<14:08,  4.28it/s]
2022-03-21 15:56:56,988 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0562, loss: 0.1098 ||:  50%|#####     | 3604/7188 [12:50<12:34,  4.75it/s]
2022-03-21 15:57:07,170 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0167, loss: 0.1101 ||:  51%|#####     | 3651/7188 [13:00<12:14,  4.81it/s]
2022-03-21 15:57:17,385 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.1548, loss: 0.1102 ||:  51%|#####1    | 3700/7188 [13:10<12:11,  4.77it/s]
2022-03-21 15:57:27,640 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.1689, loss: 0.1101 ||:  52%|#####2    | 3748/7188 [13:20<11:09,  5.14it/s]
2022-03-21 15:57:37,689 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0264, loss: 0.1099 ||:  53%|#####2    | 3793/7188 [13:30<12:38,  4.48it/s]
2022-03-21 15:57:47,794 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0119, loss: 0.1099 ||:  53%|#####3    | 3841/7188 [13:40<11:25,  4.88it/s]
2022-03-21 15:57:57,986 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0419, loss: 0.1100 ||:  54%|#####4    | 3888/7188 [13:51<11:38,  4.73it/s]
2022-03-21 15:58:08,060 - INFO - tqdm - f1: 0.9624, accuracy: 0.9624, batch_loss: 0.2047, loss: 0.1097 ||:  55%|#####4    | 3934/7188 [14:01<10:51,  5.00it/s]
2022-03-21 15:58:18,239 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.1068, loss: 0.1098 ||:  55%|#####5    | 3982/7188 [14:11<12:14,  4.36it/s]
2022-03-21 15:58:28,494 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.1277, loss: 0.1100 ||:  56%|#####6    | 4031/7188 [14:21<11:54,  4.42it/s]
2022-03-21 15:58:38,682 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0599, loss: 0.1100 ||:  57%|#####6    | 4080/7188 [14:31<10:57,  4.73it/s]
2022-03-21 15:58:48,939 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.1536, loss: 0.1099 ||:  57%|#####7    | 4129/7188 [14:42<11:17,  4.52it/s]
2022-03-21 15:58:59,204 - INFO - tqdm - f1: 0.9624, accuracy: 0.9624, batch_loss: 0.0046, loss: 0.1098 ||:  58%|#####8    | 4177/7188 [14:52<12:13,  4.10it/s]
2022-03-21 15:59:09,368 - INFO - tqdm - f1: 0.9624, accuracy: 0.9625, batch_loss: 0.1310, loss: 0.1098 ||:  59%|#####8    | 4225/7188 [15:02<10:10,  4.85it/s]
2022-03-21 15:59:19,456 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.0178, loss: 0.1094 ||:  59%|#####9    | 4270/7188 [15:12<12:01,  4.04it/s]
2022-03-21 15:59:29,549 - INFO - tqdm - f1: 0.9625, accuracy: 0.9626, batch_loss: 0.1045, loss: 0.1095 ||:  61%|######    | 4384/7188 [15:22<06:33,  7.13it/s]
2022-03-21 15:59:39,632 - INFO - tqdm - f1: 0.9624, accuracy: 0.9624, batch_loss: 0.0063, loss: 0.1099 ||:  62%|######2   | 4458/7188 [15:32<06:34,  6.93it/s]
2022-03-21 15:59:49,649 - INFO - tqdm - f1: 0.9624, accuracy: 0.9624, batch_loss: 0.0762, loss: 0.1099 ||:  63%|######3   | 4531/7188 [15:42<06:21,  6.97it/s]
2022-03-21 15:59:59,740 - INFO - tqdm - f1: 0.9624, accuracy: 0.9625, batch_loss: 0.5803, loss: 0.1099 ||:  64%|######3   | 4596/7188 [15:52<08:42,  4.96it/s]
2022-03-21 16:00:09,851 - INFO - tqdm - f1: 0.9624, accuracy: 0.9624, batch_loss: 0.2754, loss: 0.1103 ||:  65%|######4   | 4643/7188 [16:02<09:12,  4.61it/s]
2022-03-21 16:00:20,064 - INFO - tqdm - f1: 0.9625, accuracy: 0.9625, batch_loss: 0.0019, loss: 0.1101 ||:  65%|######5   | 4692/7188 [16:13<08:46,  4.74it/s]
2022-03-21 16:00:30,281 - INFO - tqdm - f1: 0.9626, accuracy: 0.9627, batch_loss: 0.2304, loss: 0.1098 ||:  66%|######5   | 4741/7188 [16:23<08:29,  4.80it/s]
2022-03-21 16:00:40,296 - INFO - tqdm - f1: 0.9626, accuracy: 0.9627, batch_loss: 0.0743, loss: 0.1097 ||:  67%|######6   | 4788/7188 [16:33<08:49,  4.53it/s]
2022-03-21 16:00:50,444 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.1311, loss: 0.1098 ||:  67%|######7   | 4836/7188 [16:43<08:54,  4.40it/s]
2022-03-21 16:01:00,646 - INFO - tqdm - f1: 0.9626, accuracy: 0.9627, batch_loss: 0.0744, loss: 0.1098 ||:  68%|######7   | 4884/7188 [16:53<07:51,  4.88it/s]
2022-03-21 16:01:10,870 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.0832, loss: 0.1099 ||:  69%|######8   | 4932/7188 [17:03<08:05,  4.65it/s]
2022-03-21 16:01:21,119 - INFO - tqdm - f1: 0.9626, accuracy: 0.9627, batch_loss: 0.0648, loss: 0.1099 ||:  69%|######9   | 4979/7188 [17:14<08:31,  4.32it/s]
2022-03-21 16:01:31,324 - INFO - tqdm - f1: 0.9626, accuracy: 0.9626, batch_loss: 0.1009, loss: 0.1100 ||:  70%|######9   | 5028/7188 [17:24<08:30,  4.23it/s]
2022-03-21 16:01:41,501 - INFO - tqdm - f1: 0.9625, accuracy: 0.9625, batch_loss: 0.1050, loss: 0.1100 ||:  71%|#######   | 5075/7188 [17:34<07:27,  4.72it/s]
2022-03-21 16:01:51,561 - INFO - tqdm - f1: 0.9625, accuracy: 0.9626, batch_loss: 0.2315, loss: 0.1101 ||:  71%|#######1  | 5121/7188 [17:44<08:32,  4.04it/s]
2022-03-21 16:02:01,629 - INFO - tqdm - f1: 0.9623, accuracy: 0.9624, batch_loss: 0.0466, loss: 0.1104 ||:  72%|#######1  | 5168/7188 [17:54<08:02,  4.19it/s]
2022-03-21 16:02:11,746 - INFO - tqdm - f1: 0.9623, accuracy: 0.9624, batch_loss: 0.3997, loss: 0.1103 ||:  73%|#######2  | 5216/7188 [18:04<06:54,  4.76it/s]
2022-03-21 16:02:21,877 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0378, loss: 0.1104 ||:  73%|#######3  | 5263/7188 [18:15<07:15,  4.42it/s]
2022-03-21 16:02:32,060 - INFO - tqdm - f1: 0.9623, accuracy: 0.9624, batch_loss: 0.0413, loss: 0.1103 ||:  74%|#######3  | 5311/7188 [18:25<06:32,  4.78it/s]
2022-03-21 16:02:42,086 - INFO - tqdm - f1: 0.9622, accuracy: 0.9623, batch_loss: 0.1092, loss: 0.1105 ||:  75%|#######4  | 5356/7188 [18:35<07:18,  4.17it/s]
2022-03-21 16:02:52,269 - INFO - tqdm - f1: 0.9622, accuracy: 0.9623, batch_loss: 0.0042, loss: 0.1105 ||:  75%|#######5  | 5403/7188 [18:45<07:13,  4.12it/s]
2022-03-21 16:03:02,374 - INFO - tqdm - f1: 0.9622, accuracy: 0.9623, batch_loss: 0.0066, loss: 0.1103 ||:  76%|#######5  | 5449/7188 [18:55<06:29,  4.46it/s]
2022-03-21 16:03:12,519 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.2780, loss: 0.1105 ||:  76%|#######6  | 5497/7188 [19:05<05:53,  4.79it/s]
2022-03-21 16:03:22,720 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0094, loss: 0.1104 ||:  77%|#######7  | 5545/7188 [19:15<05:39,  4.84it/s]
2022-03-21 16:03:32,863 - INFO - tqdm - f1: 0.9622, accuracy: 0.9623, batch_loss: 0.0589, loss: 0.1106 ||:  78%|#######7  | 5593/7188 [19:25<05:19,  4.98it/s]
2022-03-21 16:03:43,065 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0565, loss: 0.1105 ||:  78%|#######8  | 5642/7188 [19:36<05:23,  4.77it/s]
2022-03-21 16:03:53,071 - INFO - tqdm - f1: 0.9624, accuracy: 0.9624, batch_loss: 0.0100, loss: 0.1103 ||:  79%|#######9  | 5691/7188 [19:46<04:43,  5.28it/s]
2022-03-21 16:04:03,141 - INFO - tqdm - f1: 0.9624, accuracy: 0.9624, batch_loss: 0.0147, loss: 0.1105 ||:  80%|#######9  | 5738/7188 [19:56<04:55,  4.91it/s]
2022-03-21 16:04:13,310 - INFO - tqdm - f1: 0.9623, accuracy: 0.9624, batch_loss: 0.0589, loss: 0.1106 ||:  81%|########  | 5789/7188 [20:06<05:08,  4.54it/s]
2022-03-21 16:04:23,321 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0962, loss: 0.1106 ||:  81%|########1 | 5837/7188 [20:16<04:25,  5.09it/s]
2022-03-21 16:04:33,327 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.3532, loss: 0.1104 ||:  82%|########1 | 5884/7188 [20:26<04:41,  4.63it/s]
2022-03-21 16:04:43,436 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0408, loss: 0.1104 ||:  83%|########2 | 5932/7188 [20:36<04:45,  4.39it/s]
2022-03-21 16:04:53,465 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0234, loss: 0.1106 ||:  83%|########3 | 5980/7188 [20:46<04:11,  4.81it/s]
2022-03-21 16:05:03,636 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.1834, loss: 0.1108 ||:  84%|########3 | 6028/7188 [20:56<04:07,  4.69it/s]
2022-03-21 16:05:13,763 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.0457, loss: 0.1109 ||:  85%|########4 | 6075/7188 [21:06<04:03,  4.57it/s]
2022-03-21 16:05:23,963 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.1139, loss: 0.1110 ||:  85%|########5 | 6123/7188 [21:17<03:56,  4.51it/s]
2022-03-21 16:05:34,129 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0216, loss: 0.1110 ||:  86%|########5 | 6173/7188 [21:27<03:22,  5.01it/s]
2022-03-21 16:05:44,359 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.2516, loss: 0.1108 ||:  87%|########6 | 6221/7188 [21:37<03:20,  4.83it/s]
2022-03-21 16:05:54,489 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.2465, loss: 0.1108 ||:  87%|########7 | 6268/7188 [21:47<03:22,  4.55it/s]
2022-03-21 16:06:04,734 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0077, loss: 0.1107 ||:  88%|########7 | 6316/7188 [21:57<03:12,  4.53it/s]
2022-03-21 16:06:14,839 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0880, loss: 0.1107 ||:  89%|########8 | 6363/7188 [22:07<02:57,  4.65it/s]
2022-03-21 16:06:25,065 - INFO - tqdm - f1: 0.9623, accuracy: 0.9623, batch_loss: 0.0062, loss: 0.1107 ||:  89%|########9 | 6413/7188 [22:18<02:57,  4.35it/s]
2022-03-21 16:06:35,293 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.0265, loss: 0.1110 ||:  90%|########9 | 6461/7188 [22:28<02:43,  4.45it/s]
2022-03-21 16:06:45,484 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.1030, loss: 0.1111 ||:  91%|######### | 6509/7188 [22:38<02:32,  4.47it/s]
2022-03-21 16:06:55,645 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.2241, loss: 0.1110 ||:  91%|#########1| 6557/7188 [22:48<02:22,  4.42it/s]
2022-03-21 16:07:05,711 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.1378, loss: 0.1109 ||:  92%|#########1| 6606/7188 [22:58<02:12,  4.39it/s]
2022-03-21 16:07:15,960 - INFO - tqdm - f1: 0.9622, accuracy: 0.9622, batch_loss: 0.0558, loss: 0.1111 ||:  93%|#########2| 6653/7188 [23:09<02:08,  4.15it/s]
2022-03-21 16:07:26,066 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0621, loss: 0.1113 ||:  93%|#########3| 6700/7188 [23:19<01:39,  4.90it/s]
2022-03-21 16:07:36,073 - INFO - tqdm - f1: 0.9622, accuracy: 0.9621, batch_loss: 0.0703, loss: 0.1112 ||:  94%|#########3| 6749/7188 [23:29<01:21,  5.36it/s]
2022-03-21 16:07:46,197 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0657, loss: 0.1114 ||:  95%|#########4| 6796/7188 [23:39<01:13,  5.32it/s]
2022-03-21 16:07:56,242 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0893, loss: 0.1113 ||:  95%|#########5| 6844/7188 [23:49<01:13,  4.71it/s]
2022-03-21 16:08:06,381 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0218, loss: 0.1111 ||:  96%|#########5| 6891/7188 [23:59<01:04,  4.62it/s]
2022-03-21 16:08:16,471 - INFO - tqdm - f1: 0.9621, accuracy: 0.9621, batch_loss: 0.0467, loss: 0.1112 ||:  97%|#########6| 6939/7188 [24:09<00:58,  4.28it/s]
2022-03-21 16:08:26,651 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0523, loss: 0.1113 ||:  97%|#########7| 6988/7188 [24:19<00:44,  4.48it/s]
2022-03-21 16:08:36,670 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0295, loss: 0.1112 ||:  98%|#########7| 7035/7188 [24:29<00:31,  4.79it/s]
2022-03-21 16:08:46,745 - INFO - tqdm - f1: 0.9619, accuracy: 0.9619, batch_loss: 0.2983, loss: 0.1114 ||:  99%|#########8| 7082/7188 [24:39<00:24,  4.32it/s]
2022-03-21 16:08:56,918 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.3451, loss: 0.1112 ||:  99%|#########9| 7128/7188 [24:50<00:12,  4.81it/s]
2022-03-21 16:09:02,254 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0222, loss: 0.1112 ||: 100%|#########9| 7153/7188 [24:55<00:07,  4.81it/s]
2022-03-21 16:09:02,483 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0419, loss: 0.1112 ||: 100%|#########9| 7154/7188 [24:55<00:07,  4.67it/s]
2022-03-21 16:09:02,706 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.1038, loss: 0.1112 ||: 100%|#########9| 7155/7188 [24:55<00:07,  4.61it/s]
2022-03-21 16:09:02,956 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0891, loss: 0.1112 ||: 100%|#########9| 7156/7188 [24:56<00:07,  4.41it/s]
2022-03-21 16:09:03,180 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0906, loss: 0.1112 ||: 100%|#########9| 7157/7188 [24:56<00:07,  4.43it/s]
2022-03-21 16:09:03,427 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0174, loss: 0.1112 ||: 100%|#########9| 7158/7188 [24:56<00:06,  4.30it/s]
2022-03-21 16:09:03,667 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0033, loss: 0.1112 ||: 100%|#########9| 7159/7188 [24:56<00:06,  4.26it/s]
2022-03-21 16:09:03,857 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0378, loss: 0.1112 ||: 100%|#########9| 7160/7188 [24:56<00:06,  4.52it/s]
2022-03-21 16:09:04,091 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.2460, loss: 0.1112 ||: 100%|#########9| 7161/7188 [24:57<00:06,  4.44it/s]
2022-03-21 16:09:04,297 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0912, loss: 0.1112 ||: 100%|#########9| 7162/7188 [24:57<00:05,  4.56it/s]
2022-03-21 16:09:04,555 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.3157, loss: 0.1112 ||: 100%|#########9| 7163/7188 [24:57<00:05,  4.33it/s]
2022-03-21 16:09:04,814 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.3542, loss: 0.1112 ||: 100%|#########9| 7164/7188 [24:57<00:05,  4.18it/s]
2022-03-21 16:09:04,982 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.2042, loss: 0.1113 ||: 100%|#########9| 7165/7188 [24:58<00:05,  4.59it/s]
2022-03-21 16:09:05,252 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0294, loss: 0.1112 ||: 100%|#########9| 7166/7188 [24:58<00:05,  4.28it/s]
2022-03-21 16:09:05,446 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0199, loss: 0.1112 ||: 100%|#########9| 7167/7188 [24:58<00:04,  4.51it/s]
2022-03-21 16:09:05,602 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0183, loss: 0.1112 ||: 100%|#########9| 7168/7188 [24:58<00:04,  4.95it/s]
2022-03-21 16:09:05,851 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0208, loss: 0.1112 ||: 100%|#########9| 7169/7188 [24:58<00:04,  4.63it/s]
2022-03-21 16:09:06,047 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0598, loss: 0.1112 ||: 100%|#########9| 7170/7188 [24:59<00:03,  4.76it/s]
2022-03-21 16:09:06,182 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0015, loss: 0.1112 ||: 100%|#########9| 7171/7188 [24:59<00:03,  5.33it/s]
2022-03-21 16:09:06,417 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0037, loss: 0.1112 ||: 100%|#########9| 7172/7188 [24:59<00:03,  4.96it/s]
2022-03-21 16:09:06,646 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0623, loss: 0.1112 ||: 100%|#########9| 7173/7188 [24:59<00:03,  4.76it/s]
2022-03-21 16:09:06,804 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.1845, loss: 0.1112 ||: 100%|#########9| 7174/7188 [24:59<00:02,  5.15it/s]
2022-03-21 16:09:07,055 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.3166, loss: 0.1112 ||: 100%|#########9| 7175/7188 [25:00<00:02,  4.73it/s]
2022-03-21 16:09:07,252 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0255, loss: 0.1112 ||: 100%|#########9| 7176/7188 [25:00<00:02,  4.83it/s]
2022-03-21 16:09:07,434 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.3194, loss: 0.1112 ||: 100%|#########9| 7177/7188 [25:00<00:02,  5.01it/s]
2022-03-21 16:09:07,676 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.1427, loss: 0.1112 ||: 100%|#########9| 7178/7188 [25:00<00:02,  4.71it/s]
2022-03-21 16:09:07,863 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0682, loss: 0.1112 ||: 100%|#########9| 7179/7188 [25:00<00:01,  4.89it/s]
2022-03-21 16:09:08,041 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0044, loss: 0.1112 ||: 100%|#########9| 7180/7188 [25:01<00:01,  5.08it/s]
2022-03-21 16:09:08,299 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.3587, loss: 0.1112 ||: 100%|#########9| 7181/7188 [25:01<00:01,  4.65it/s]
2022-03-21 16:09:08,478 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.2153, loss: 0.1112 ||: 100%|#########9| 7182/7188 [25:01<00:01,  4.89it/s]
2022-03-21 16:09:08,723 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.1581, loss: 0.1113 ||: 100%|#########9| 7183/7188 [25:01<00:01,  4.62it/s]
2022-03-21 16:09:08,980 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.1045, loss: 0.1113 ||: 100%|#########9| 7184/7188 [25:02<00:00,  4.38it/s]
2022-03-21 16:09:09,173 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0036, loss: 0.1112 ||: 100%|#########9| 7185/7188 [25:02<00:00,  4.59it/s]
2022-03-21 16:09:09,448 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.1938, loss: 0.1113 ||: 100%|#########9| 7186/7188 [25:02<00:00,  4.25it/s]
2022-03-21 16:09:09,639 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0408, loss: 0.1112 ||: 100%|#########9| 7187/7188 [25:02<00:00,  4.51it/s]
2022-03-21 16:09:09,827 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0040, loss: 0.1112 ||: 100%|##########| 7188/7188 [25:02<00:00,  4.72it/s]
2022-03-21 16:09:09,869 - INFO - tqdm - f1: 0.9620, accuracy: 0.9620, batch_loss: 0.0040, loss: 0.1112 ||: 100%|##########| 7188/7188 [25:02<00:00,  4.78it/s]
2022-03-21 16:09:09,922 - INFO - allennlp.training.trainer - Validating
2022-03-21 16:09:09,925 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 16:09:20,081 - INFO - tqdm - f1: 0.9520, accuracy: 0.9518, batch_loss: 0.1567, loss: 0.1729 ||:  27%|##6       | 83/313 [00:10<00:32,  7.17it/s]
2022-03-21 16:09:30,187 - INFO - tqdm - f1: 0.9452, accuracy: 0.9453, batch_loss: 0.4185, loss: 0.1990 ||:  54%|#####3    | 168/313 [00:20<00:15,  9.07it/s]
2022-03-21 16:09:40,352 - INFO - tqdm - f1: 0.9420, accuracy: 0.9416, batch_loss: 0.0403, loss: 0.2168 ||:  80%|#######9  | 250/313 [00:30<00:08,  7.64it/s]
2022-03-21 16:09:47,785 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.5319, loss: 0.2146 ||: 100%|##########| 313/313 [00:37<00:00,  9.19it/s]
2022-03-21 16:09:47,789 - INFO - tqdm - f1: 0.9405, accuracy: 0.9404, batch_loss: 0.5319, loss: 0.2146 ||: 100%|##########| 313/313 [00:37<00:00,  8.27it/s]
2022-03-21 16:09:47,856 - INFO - dont_stop_pretraining.training.roberta_checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_base_hyper_small_seed_314/best.th'.
2022-03-21 16:09:50,307 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 16:09:50,309 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.962  |     0.940
2022-03-21 16:09:50,312 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.962  |     0.940
2022-03-21 16:09:50,314 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 16:09:50,316 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.111  |     0.215
2022-03-21 16:09:50,318 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7579.625  |       N/A
2022-03-21 16:09:50,321 - INFO - allennlp.training.trainer - Epoch duration: 0:25:43.456850
2022-03-21 16:09:50,323 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:35:58
2022-03-21 16:09:50,325 - INFO - allennlp.training.trainer - Epoch 4/9
2022-03-21 16:09:50,328 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 16:09:50,330 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 16:09:50,335 - INFO - allennlp.training.trainer - Training
2022-03-21 16:09:50,338 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 16:10:00,395 - INFO - tqdm - f1: 0.9731, accuracy: 0.9728, batch_loss: 0.0361, loss: 0.0692 ||:   1%|          | 46/7188 [00:10<22:48,  5.22it/s]
2022-03-21 16:10:10,595 - INFO - tqdm - f1: 0.9742, accuracy: 0.9742, batch_loss: 0.0059, loss: 0.0702 ||:   1%|1         | 95/7188 [00:20<20:13,  5.85it/s]
2022-03-21 16:10:20,771 - INFO - tqdm - f1: 0.9734, accuracy: 0.9737, batch_loss: 0.0633, loss: 0.0750 ||:   2%|1         | 143/7188 [00:30<24:23,  4.81it/s]
2022-03-21 16:10:30,916 - INFO - tqdm - f1: 0.9747, accuracy: 0.9749, batch_loss: 0.0177, loss: 0.0726 ||:   3%|2         | 190/7188 [00:40<24:37,  4.74it/s]
2022-03-21 16:10:41,050 - INFO - tqdm - f1: 0.9728, accuracy: 0.9729, batch_loss: 0.0018, loss: 0.0799 ||:   3%|3         | 236/7188 [00:50<24:55,  4.65it/s]
2022-03-21 16:10:51,190 - INFO - tqdm - f1: 0.9735, accuracy: 0.9737, batch_loss: 0.0113, loss: 0.0808 ||:   4%|3         | 283/7188 [01:00<25:48,  4.46it/s]
2022-03-21 16:11:01,362 - INFO - tqdm - f1: 0.9744, accuracy: 0.9745, batch_loss: 0.0295, loss: 0.0781 ||:   5%|4         | 331/7188 [01:11<26:28,  4.32it/s]
2022-03-21 16:11:11,506 - INFO - tqdm - f1: 0.9751, accuracy: 0.9752, batch_loss: 0.0118, loss: 0.0757 ||:   5%|5         | 378/7188 [01:21<27:42,  4.10it/s]
2022-03-21 16:11:21,697 - INFO - tqdm - f1: 0.9747, accuracy: 0.9748, batch_loss: 0.0076, loss: 0.0781 ||:   6%|5         | 427/7188 [01:31<23:04,  4.88it/s]
2022-03-21 16:11:31,868 - INFO - tqdm - f1: 0.9746, accuracy: 0.9747, batch_loss: 0.0032, loss: 0.0784 ||:   7%|6         | 475/7188 [01:41<23:26,  4.77it/s]
2022-03-21 16:11:41,908 - INFO - tqdm - f1: 0.9734, accuracy: 0.9735, batch_loss: 0.0727, loss: 0.0806 ||:   7%|7         | 525/7188 [01:51<23:04,  4.81it/s]
2022-03-21 16:11:51,996 - INFO - tqdm - f1: 0.9739, accuracy: 0.9741, batch_loss: 0.0071, loss: 0.0806 ||:   8%|7         | 571/7188 [02:01<25:09,  4.38it/s]
2022-03-21 16:12:02,139 - INFO - tqdm - f1: 0.9739, accuracy: 0.9741, batch_loss: 0.6348, loss: 0.0813 ||:   9%|8         | 618/7188 [02:11<23:26,  4.67it/s]
2022-03-21 16:12:12,383 - INFO - tqdm - f1: 0.9747, accuracy: 0.9750, batch_loss: 0.0080, loss: 0.0799 ||:   9%|9         | 667/7188 [02:22<23:05,  4.71it/s]
2022-03-21 16:12:22,507 - INFO - tqdm - f1: 0.9750, accuracy: 0.9753, batch_loss: 0.0078, loss: 0.0793 ||:  10%|9         | 714/7188 [02:32<23:00,  4.69it/s]
2022-03-21 16:12:32,658 - INFO - tqdm - f1: 0.9745, accuracy: 0.9747, batch_loss: 0.0877, loss: 0.0797 ||:  11%|#         | 765/7188 [02:42<23:21,  4.58it/s]
2022-03-21 16:12:42,710 - INFO - tqdm - f1: 0.9750, accuracy: 0.9752, batch_loss: 0.2763, loss: 0.0781 ||:  11%|#1        | 811/7188 [02:52<22:03,  4.82it/s]
2022-03-21 16:12:52,865 - INFO - tqdm - f1: 0.9749, accuracy: 0.9751, batch_loss: 0.0999, loss: 0.0779 ||:  12%|#1        | 859/7188 [03:02<21:42,  4.86it/s]
2022-03-21 16:13:03,068 - INFO - tqdm - f1: 0.9745, accuracy: 0.9747, batch_loss: 0.2461, loss: 0.0789 ||:  13%|#2        | 908/7188 [03:12<22:36,  4.63it/s]
2022-03-21 16:13:13,243 - INFO - tqdm - f1: 0.9745, accuracy: 0.9747, batch_loss: 0.0244, loss: 0.0792 ||:  13%|#3        | 956/7188 [03:22<21:46,  4.77it/s]
2022-03-21 16:13:23,281 - INFO - tqdm - f1: 0.9743, accuracy: 0.9745, batch_loss: 0.0213, loss: 0.0792 ||:  14%|#3        | 1001/7188 [03:32<23:06,  4.46it/s]
2022-03-21 16:13:33,323 - INFO - tqdm - f1: 0.9743, accuracy: 0.9744, batch_loss: 0.4523, loss: 0.0789 ||:  15%|#4        | 1047/7188 [03:42<22:49,  4.48it/s]
2022-03-21 16:13:43,515 - INFO - tqdm - f1: 0.9743, accuracy: 0.9745, batch_loss: 0.1631, loss: 0.0791 ||:  15%|#5        | 1095/7188 [03:53<22:24,  4.53it/s]
2022-03-21 16:13:53,702 - INFO - tqdm - f1: 0.9744, accuracy: 0.9746, batch_loss: 0.0077, loss: 0.0787 ||:  16%|#5        | 1143/7188 [04:03<23:33,  4.28it/s]
2022-03-21 16:14:03,757 - INFO - tqdm - f1: 0.9751, accuracy: 0.9752, batch_loss: 0.0381, loss: 0.0776 ||:  17%|#6        | 1189/7188 [04:13<22:40,  4.41it/s]
2022-03-21 16:14:13,825 - INFO - tqdm - f1: 0.9748, accuracy: 0.9750, batch_loss: 0.0044, loss: 0.0784 ||:  17%|#7        | 1236/7188 [04:23<22:36,  4.39it/s]
2022-03-21 16:14:23,849 - INFO - tqdm - f1: 0.9748, accuracy: 0.9749, batch_loss: 0.0247, loss: 0.0790 ||:  18%|#7        | 1284/7188 [04:33<19:43,  4.99it/s]
2022-03-21 16:14:33,871 - INFO - tqdm - f1: 0.9747, accuracy: 0.9747, batch_loss: 0.0722, loss: 0.0792 ||:  19%|#8        | 1331/7188 [04:43<20:06,  4.85it/s]
2022-03-21 16:14:43,949 - INFO - tqdm - f1: 0.9746, accuracy: 0.9747, batch_loss: 0.0153, loss: 0.0795 ||:  19%|#9        | 1378/7188 [04:53<21:53,  4.42it/s]
2022-03-21 16:14:53,999 - INFO - tqdm - f1: 0.9747, accuracy: 0.9747, batch_loss: 0.1381, loss: 0.0792 ||:  20%|#9        | 1425/7188 [05:03<20:31,  4.68it/s]
2022-03-21 16:15:04,171 - INFO - tqdm - f1: 0.9744, accuracy: 0.9745, batch_loss: 0.1462, loss: 0.0792 ||:  20%|##        | 1472/7188 [05:13<21:20,  4.47it/s]
2022-03-21 16:15:14,333 - INFO - tqdm - f1: 0.9741, accuracy: 0.9741, batch_loss: 0.0311, loss: 0.0799 ||:  21%|##1       | 1521/7188 [05:23<19:32,  4.83it/s]
2022-03-21 16:15:24,480 - INFO - tqdm - f1: 0.9739, accuracy: 0.9740, batch_loss: 0.0992, loss: 0.0798 ||:  22%|##1       | 1569/7188 [05:34<18:55,  4.95it/s]
2022-03-21 16:15:34,591 - INFO - tqdm - f1: 0.9738, accuracy: 0.9739, batch_loss: 0.0076, loss: 0.0802 ||:  23%|##3       | 1679/7188 [05:44<12:50,  7.15it/s]
2022-03-21 16:15:44,607 - INFO - tqdm - f1: 0.9739, accuracy: 0.9740, batch_loss: 0.0962, loss: 0.0805 ||:  24%|##4       | 1752/7188 [05:54<12:37,  7.18it/s]
2022-03-21 16:15:54,696 - INFO - tqdm - f1: 0.9734, accuracy: 0.9735, batch_loss: 0.0181, loss: 0.0812 ||:  25%|##5       | 1816/7188 [06:04<13:22,  6.70it/s]
2022-03-21 16:16:04,725 - INFO - tqdm - f1: 0.9734, accuracy: 0.9735, batch_loss: 0.0482, loss: 0.0813 ||:  26%|##6       | 1882/7188 [06:14<18:39,  4.74it/s]
2022-03-21 16:16:14,896 - INFO - tqdm - f1: 0.9733, accuracy: 0.9734, batch_loss: 0.1646, loss: 0.0817 ||:  27%|##6       | 1929/7188 [06:24<18:46,  4.67it/s]
2022-03-21 16:16:25,072 - INFO - tqdm - f1: 0.9734, accuracy: 0.9735, batch_loss: 0.2524, loss: 0.0818 ||:  28%|##7       | 1977/7188 [06:34<19:00,  4.57it/s]
2022-03-21 16:16:35,114 - INFO - tqdm - f1: 0.9732, accuracy: 0.9733, batch_loss: 0.0042, loss: 0.0818 ||:  28%|##8       | 2027/7188 [06:44<18:32,  4.64it/s]
2022-03-21 16:16:45,324 - INFO - tqdm - f1: 0.9733, accuracy: 0.9733, batch_loss: 0.0076, loss: 0.0818 ||:  29%|##8       | 2076/7188 [06:54<18:54,  4.51it/s]
2022-03-21 16:16:55,336 - INFO - tqdm - f1: 0.9732, accuracy: 0.9733, batch_loss: 0.0052, loss: 0.0819 ||:  30%|##9       | 2122/7188 [07:04<18:45,  4.50it/s]
2022-03-21 16:17:05,361 - INFO - tqdm - f1: 0.9730, accuracy: 0.9730, batch_loss: 0.0310, loss: 0.0824 ||:  30%|###       | 2164/7188 [07:15<19:06,  4.38it/s]
2022-03-21 16:17:15,666 - INFO - tqdm - f1: 0.9731, accuracy: 0.9731, batch_loss: 0.0125, loss: 0.0820 ||:  31%|###       | 2204/7188 [07:25<24:08,  3.44it/s]
2022-03-21 16:17:25,751 - INFO - tqdm - f1: 0.9731, accuracy: 0.9732, batch_loss: 0.0018, loss: 0.0820 ||:  31%|###1      | 2238/7188 [07:35<18:27,  4.47it/s]
2022-03-21 16:17:35,922 - INFO - tqdm - f1: 0.9732, accuracy: 0.9732, batch_loss: 0.0016, loss: 0.0817 ||:  32%|###1      | 2280/7188 [07:45<19:06,  4.28it/s]
2022-03-21 16:17:45,945 - INFO - tqdm - f1: 0.9733, accuracy: 0.9733, batch_loss: 0.0076, loss: 0.0817 ||:  32%|###2      | 2318/7188 [07:55<19:53,  4.08it/s]
2022-03-21 16:17:56,220 - INFO - tqdm - f1: 0.9733, accuracy: 0.9734, batch_loss: 0.2364, loss: 0.0818 ||:  33%|###2      | 2353/7188 [08:05<26:26,  3.05it/s]
2022-03-21 16:18:06,457 - INFO - tqdm - f1: 0.9731, accuracy: 0.9731, batch_loss: 0.0098, loss: 0.0822 ||:  33%|###3      | 2390/7188 [08:16<27:57,  2.86it/s]
2022-03-21 16:18:16,698 - INFO - tqdm - f1: 0.9730, accuracy: 0.9730, batch_loss: 0.1908, loss: 0.0824 ||:  34%|###3      | 2429/7188 [08:26<24:39,  3.22it/s]
2022-03-21 16:18:26,850 - INFO - tqdm - f1: 0.9730, accuracy: 0.9730, batch_loss: 0.0065, loss: 0.0824 ||:  34%|###4      | 2462/7188 [08:36<26:31,  2.97it/s]
2022-03-21 16:18:36,884 - INFO - tqdm - f1: 0.9730, accuracy: 0.9730, batch_loss: 0.0063, loss: 0.0826 ||:  35%|###4      | 2502/7188 [08:46<17:57,  4.35it/s]
2022-03-21 16:18:46,965 - INFO - tqdm - f1: 0.9729, accuracy: 0.9729, batch_loss: 0.1313, loss: 0.0825 ||:  35%|###5      | 2547/7188 [08:56<16:53,  4.58it/s]
2022-03-21 16:18:57,116 - INFO - tqdm - f1: 0.9730, accuracy: 0.9730, batch_loss: 0.1615, loss: 0.0824 ||:  36%|###6      | 2594/7188 [09:06<16:18,  4.69it/s]
2022-03-21 16:19:07,288 - INFO - tqdm - f1: 0.9728, accuracy: 0.9728, batch_loss: 0.1044, loss: 0.0828 ||:  37%|###6      | 2641/7188 [09:16<15:44,  4.81it/s]
2022-03-21 16:19:17,449 - INFO - tqdm - f1: 0.9729, accuracy: 0.9729, batch_loss: 0.0096, loss: 0.0825 ||:  37%|###7      | 2689/7188 [09:27<15:22,  4.88it/s]
2022-03-21 16:19:27,630 - INFO - tqdm - f1: 0.9728, accuracy: 0.9728, batch_loss: 0.0081, loss: 0.0827 ||:  38%|###8      | 2737/7188 [09:37<17:06,  4.34it/s]
2022-03-21 16:19:37,718 - INFO - tqdm - f1: 0.9728, accuracy: 0.9728, batch_loss: 0.0306, loss: 0.0828 ||:  39%|###8      | 2784/7188 [09:47<16:41,  4.40it/s]
2022-03-21 16:19:47,938 - INFO - tqdm - f1: 0.9727, accuracy: 0.9727, batch_loss: 0.0023, loss: 0.0828 ||:  39%|###9      | 2833/7188 [09:57<15:19,  4.74it/s]
2022-03-21 16:19:57,945 - INFO - tqdm - f1: 0.9726, accuracy: 0.9726, batch_loss: 0.2755, loss: 0.0831 ||:  40%|####      | 2881/7188 [10:07<15:08,  4.74it/s]
2022-03-21 16:20:08,104 - INFO - tqdm - f1: 0.9726, accuracy: 0.9726, batch_loss: 0.0294, loss: 0.0832 ||:  41%|####      | 2930/7188 [10:17<14:25,  4.92it/s]
2022-03-21 16:20:18,118 - INFO - tqdm - f1: 0.9725, accuracy: 0.9725, batch_loss: 0.1133, loss: 0.0832 ||:  41%|####1     | 2980/7188 [10:27<13:24,  5.23it/s]
2022-03-21 16:20:28,250 - INFO - tqdm - f1: 0.9725, accuracy: 0.9725, batch_loss: 0.0051, loss: 0.0831 ||:  42%|####2     | 3026/7188 [10:37<14:26,  4.80it/s]
2022-03-21 16:20:38,258 - INFO - tqdm - f1: 0.9724, accuracy: 0.9724, batch_loss: 0.2062, loss: 0.0832 ||:  43%|####2     | 3075/7188 [10:47<14:04,  4.87it/s]
2022-03-21 16:20:48,389 - INFO - tqdm - f1: 0.9723, accuracy: 0.9722, batch_loss: 0.1396, loss: 0.0833 ||:  43%|####3     | 3122/7188 [10:58<14:05,  4.81it/s]
2022-03-21 16:20:58,637 - INFO - tqdm - f1: 0.9722, accuracy: 0.9722, batch_loss: 0.0521, loss: 0.0832 ||:  44%|####4     | 3170/7188 [11:08<14:57,  4.47it/s]
2022-03-21 16:21:08,717 - INFO - tqdm - f1: 0.9721, accuracy: 0.9721, batch_loss: 0.0495, loss: 0.0836 ||:  45%|####4     | 3217/7188 [11:18<15:42,  4.21it/s]
2022-03-21 16:21:18,899 - INFO - tqdm - f1: 0.9720, accuracy: 0.9720, batch_loss: 0.0721, loss: 0.0840 ||:  45%|####5     | 3265/7188 [11:28<15:34,  4.20it/s]
2022-03-21 16:21:29,096 - INFO - tqdm - f1: 0.9720, accuracy: 0.9720, batch_loss: 0.1293, loss: 0.0840 ||:  46%|####6     | 3313/7188 [11:38<14:11,  4.55it/s]
2022-03-21 16:21:39,220 - INFO - tqdm - f1: 0.9721, accuracy: 0.9721, batch_loss: 0.0038, loss: 0.0836 ||:  47%|####6     | 3362/7188 [11:48<13:06,  4.87it/s]
2022-03-21 16:21:49,323 - INFO - tqdm - f1: 0.9721, accuracy: 0.9721, batch_loss: 0.3490, loss: 0.0838 ||:  47%|####7     | 3410/7188 [11:58<13:43,  4.59it/s]
2022-03-21 16:21:59,489 - INFO - tqdm - f1: 0.9720, accuracy: 0.9720, batch_loss: 0.0185, loss: 0.0839 ||:  48%|####8     | 3458/7188 [12:09<13:59,  4.44it/s]
2022-03-21 16:22:09,708 - INFO - tqdm - f1: 0.9719, accuracy: 0.9719, batch_loss: 0.0061, loss: 0.0840 ||:  49%|####8     | 3507/7188 [12:19<12:07,  5.06it/s]
2022-03-21 16:22:19,782 - INFO - tqdm - f1: 0.9719, accuracy: 0.9719, batch_loss: 0.0174, loss: 0.0840 ||:  49%|####9     | 3553/7188 [12:29<13:39,  4.44it/s]
2022-03-21 16:22:29,788 - INFO - tqdm - f1: 0.9719, accuracy: 0.9719, batch_loss: 0.0070, loss: 0.0842 ||:  50%|#####     | 3598/7188 [12:39<12:30,  4.78it/s]
2022-03-21 16:22:39,790 - INFO - tqdm - f1: 0.9719, accuracy: 0.9719, batch_loss: 0.0033, loss: 0.0844 ||:  51%|#####     | 3648/7188 [12:49<12:35,  4.69it/s]
2022-03-21 16:22:50,019 - INFO - tqdm - f1: 0.9719, accuracy: 0.9719, batch_loss: 0.0025, loss: 0.0842 ||:  51%|#####1    | 3698/7188 [12:59<12:23,  4.70it/s]
2022-03-21 16:23:00,220 - INFO - tqdm - f1: 0.9718, accuracy: 0.9718, batch_loss: 0.0972, loss: 0.0847 ||:  52%|#####2    | 3745/7188 [13:09<13:00,  4.41it/s]
2022-03-21 16:23:10,299 - INFO - tqdm - f1: 0.9717, accuracy: 0.9717, batch_loss: 0.4567, loss: 0.0850 ||:  53%|#####2    | 3791/7188 [13:19<12:39,  4.47it/s]
2022-03-21 16:23:20,387 - INFO - tqdm - f1: 0.9716, accuracy: 0.9716, batch_loss: 0.0403, loss: 0.0850 ||:  53%|#####3    | 3839/7188 [13:30<12:25,  4.49it/s]
2022-03-21 16:23:30,617 - INFO - tqdm - f1: 0.9717, accuracy: 0.9717, batch_loss: 0.0157, loss: 0.0847 ||:  54%|#####4    | 3887/7188 [13:40<12:41,  4.33it/s]
2022-03-21 16:23:40,745 - INFO - tqdm - f1: 0.9717, accuracy: 0.9717, batch_loss: 0.0161, loss: 0.0847 ||:  55%|#####4    | 3936/7188 [13:50<12:08,  4.46it/s]
2022-03-21 16:23:50,920 - INFO - tqdm - f1: 0.9716, accuracy: 0.9716, batch_loss: 0.0353, loss: 0.0851 ||:  55%|#####5    | 3984/7188 [14:00<10:36,  5.03it/s]
2022-03-21 16:24:01,026 - INFO - tqdm - f1: 0.9716, accuracy: 0.9716, batch_loss: 0.0429, loss: 0.0851 ||:  56%|#####6    | 4030/7188 [14:10<10:55,  4.82it/s]
2022-03-21 16:24:11,230 - INFO - tqdm - f1: 0.9716, accuracy: 0.9716, batch_loss: 0.0075, loss: 0.0851 ||:  57%|#####6    | 4077/7188 [14:20<11:43,  4.42it/s]
2022-03-21 16:24:21,389 - INFO - tqdm - f1: 0.9716, accuracy: 0.9716, batch_loss: 0.0097, loss: 0.0850 ||:  57%|#####7    | 4125/7188 [14:31<10:56,  4.66it/s]
2022-03-21 16:24:31,446 - INFO - tqdm - f1: 0.9715, accuracy: 0.9715, batch_loss: 0.0407, loss: 0.0852 ||:  58%|#####8    | 4171/7188 [14:41<11:29,  4.37it/s]
2022-03-21 16:24:41,512 - INFO - tqdm - f1: 0.9716, accuracy: 0.9715, batch_loss: 0.0105, loss: 0.0852 ||:  59%|#####8    | 4218/7188 [14:51<10:51,  4.56it/s]
2022-03-21 16:24:51,542 - INFO - tqdm - f1: 0.9715, accuracy: 0.9715, batch_loss: 0.3199, loss: 0.0853 ||:  59%|#####9    | 4266/7188 [15:01<10:59,  4.43it/s]
2022-03-21 16:25:01,653 - INFO - tqdm - f1: 0.9715, accuracy: 0.9715, batch_loss: 0.0717, loss: 0.0853 ||:  60%|######    | 4313/7188 [15:11<10:17,  4.66it/s]
2022-03-21 16:25:11,791 - INFO - tqdm - f1: 0.9715, accuracy: 0.9715, batch_loss: 0.0213, loss: 0.0851 ||:  61%|######    | 4361/7188 [15:21<09:34,  4.92it/s]
2022-03-21 16:25:21,798 - INFO - tqdm - f1: 0.9714, accuracy: 0.9714, batch_loss: 0.5103, loss: 0.0853 ||:  61%|######1   | 4408/7188 [15:31<09:38,  4.81it/s]
2022-03-21 16:25:31,998 - INFO - tqdm - f1: 0.9714, accuracy: 0.9714, batch_loss: 0.1407, loss: 0.0853 ||:  62%|######2   | 4457/7188 [15:41<09:18,  4.89it/s]
2022-03-21 16:25:42,131 - INFO - tqdm - f1: 0.9714, accuracy: 0.9714, batch_loss: 0.0771, loss: 0.0851 ||:  63%|######2   | 4503/7188 [15:51<09:20,  4.79it/s]
2022-03-21 16:25:52,271 - INFO - tqdm - f1: 0.9714, accuracy: 0.9714, batch_loss: 0.1767, loss: 0.0854 ||:  63%|######3   | 4552/7188 [16:01<08:52,  4.95it/s]
2022-03-21 16:26:02,326 - INFO - tqdm - f1: 0.9713, accuracy: 0.9712, batch_loss: 0.0139, loss: 0.0857 ||:  64%|######3   | 4600/7188 [16:11<09:18,  4.64it/s]
2022-03-21 16:26:12,470 - INFO - tqdm - f1: 0.9712, accuracy: 0.9711, batch_loss: 0.1895, loss: 0.0858 ||:  65%|######4   | 4648/7188 [16:22<08:57,  4.72it/s]
2022-03-21 16:26:22,578 - INFO - tqdm - f1: 0.9711, accuracy: 0.9711, batch_loss: 0.3909, loss: 0.0860 ||:  65%|######5   | 4696/7188 [16:32<08:13,  5.05it/s]
2022-03-21 16:26:32,599 - INFO - tqdm - f1: 0.9711, accuracy: 0.9711, batch_loss: 0.0654, loss: 0.0861 ||:  66%|######6   | 4746/7188 [16:42<08:46,  4.64it/s]
2022-03-21 16:26:42,731 - INFO - tqdm - f1: 0.9711, accuracy: 0.9711, batch_loss: 0.0510, loss: 0.0859 ||:  67%|######6   | 4794/7188 [16:52<08:03,  4.96it/s]
2022-03-21 16:26:52,803 - INFO - tqdm - f1: 0.9711, accuracy: 0.9711, batch_loss: 0.0426, loss: 0.0863 ||:  67%|######7   | 4840/7188 [17:02<08:36,  4.55it/s]
2022-03-21 16:27:02,953 - INFO - tqdm - f1: 0.9711, accuracy: 0.9711, batch_loss: 0.0338, loss: 0.0863 ||:  68%|######8   | 4889/7188 [17:12<08:25,  4.55it/s]
2022-03-21 16:27:12,972 - INFO - tqdm - f1: 0.9711, accuracy: 0.9711, batch_loss: 0.1803, loss: 0.0864 ||:  69%|######8   | 4937/7188 [17:22<08:20,  4.50it/s]
2022-03-21 16:27:23,040 - INFO - tqdm - f1: 0.9711, accuracy: 0.9710, batch_loss: 0.1033, loss: 0.0865 ||:  69%|######9   | 4985/7188 [17:32<07:36,  4.83it/s]
2022-03-21 16:27:33,168 - INFO - tqdm - f1: 0.9711, accuracy: 0.9711, batch_loss: 0.0423, loss: 0.0866 ||:  70%|#######   | 5032/7188 [17:42<08:36,  4.17it/s]
2022-03-21 16:27:43,374 - INFO - tqdm - f1: 0.9709, accuracy: 0.9709, batch_loss: 0.0203, loss: 0.0869 ||:  71%|#######   | 5081/7188 [17:53<08:13,  4.27it/s]
2022-03-21 16:27:53,593 - INFO - tqdm - f1: 0.9709, accuracy: 0.9709, batch_loss: 0.2060, loss: 0.0870 ||:  71%|#######1  | 5129/7188 [18:03<08:21,  4.11it/s]
2022-03-21 16:28:03,818 - INFO - tqdm - f1: 0.9709, accuracy: 0.9709, batch_loss: 0.0057, loss: 0.0870 ||:  72%|#######2  | 5177/7188 [18:13<07:36,  4.40it/s]
2022-03-21 16:28:13,823 - INFO - tqdm - f1: 0.9710, accuracy: 0.9709, batch_loss: 0.0083, loss: 0.0870 ||:  73%|#######2  | 5225/7188 [18:23<07:35,  4.31it/s]
2022-03-21 16:28:24,010 - INFO - tqdm - f1: 0.9709, accuracy: 0.9709, batch_loss: 0.1316, loss: 0.0870 ||:  73%|#######3  | 5272/7188 [18:33<07:06,  4.49it/s]
2022-03-21 16:28:34,070 - INFO - tqdm - f1: 0.9709, accuracy: 0.9709, batch_loss: 0.0178, loss: 0.0872 ||:  74%|#######3  | 5319/7188 [18:43<06:44,  4.62it/s]
2022-03-21 16:28:44,146 - INFO - tqdm - f1: 0.9710, accuracy: 0.9710, batch_loss: 0.0701, loss: 0.0870 ||:  75%|#######4  | 5368/7188 [18:53<05:22,  5.64it/s]
2022-03-21 16:28:54,250 - INFO - tqdm - f1: 0.9710, accuracy: 0.9710, batch_loss: 0.0322, loss: 0.0869 ||:  75%|#######5  | 5414/7188 [19:03<06:00,  4.92it/s]
2022-03-21 16:29:04,420 - INFO - tqdm - f1: 0.9710, accuracy: 0.9710, batch_loss: 0.0816, loss: 0.0869 ||:  76%|#######5  | 5461/7188 [19:14<06:25,  4.48it/s]
2022-03-21 16:29:14,558 - INFO - tqdm - f1: 0.9710, accuracy: 0.9710, batch_loss: 0.0768, loss: 0.0870 ||:  77%|#######6  | 5509/7188 [19:24<05:20,  5.23it/s]
2022-03-21 16:29:24,574 - INFO - tqdm - f1: 0.9708, accuracy: 0.9708, batch_loss: 0.0197, loss: 0.0873 ||:  77%|#######7  | 5555/7188 [19:34<06:19,  4.30it/s]
2022-03-21 16:29:34,599 - INFO - tqdm - f1: 0.9708, accuracy: 0.9708, batch_loss: 0.0160, loss: 0.0873 ||:  78%|#######7  | 5602/7188 [19:44<06:35,  4.01it/s]
2022-03-21 16:29:44,625 - INFO - tqdm - f1: 0.9708, accuracy: 0.9707, batch_loss: 0.0470, loss: 0.0875 ||:  79%|#######8  | 5649/7188 [19:54<05:18,  4.84it/s]
2022-03-21 16:29:54,796 - INFO - tqdm - f1: 0.9707, accuracy: 0.9707, batch_loss: 0.1245, loss: 0.0876 ||:  79%|#######9  | 5696/7188 [20:04<05:32,  4.49it/s]
2022-03-21 16:30:04,921 - INFO - tqdm - f1: 0.9707, accuracy: 0.9707, batch_loss: 0.0423, loss: 0.0875 ||:  80%|#######9  | 5744/7188 [20:14<04:59,  4.82it/s]
2022-03-21 16:30:15,099 - INFO - tqdm - f1: 0.9707, accuracy: 0.9707, batch_loss: 0.0033, loss: 0.0875 ||:  81%|########  | 5790/7188 [20:24<05:35,  4.16it/s]
2022-03-21 16:30:25,238 - INFO - tqdm - f1: 0.9707, accuracy: 0.9707, batch_loss: 0.0250, loss: 0.0878 ||:  81%|########1 | 5838/7188 [20:34<04:43,  4.77it/s]
2022-03-21 16:30:35,376 - INFO - tqdm - f1: 0.9706, accuracy: 0.9705, batch_loss: 0.0687, loss: 0.0880 ||:  82%|########1 | 5885/7188 [20:45<05:04,  4.28it/s]
2022-03-21 16:30:45,534 - INFO - tqdm - f1: 0.9706, accuracy: 0.9706, batch_loss: 0.0087, loss: 0.0879 ||:  83%|########2 | 5932/7188 [20:55<04:32,  4.61it/s]
2022-03-21 16:30:55,737 - INFO - tqdm - f1: 0.9705, accuracy: 0.9705, batch_loss: 0.0509, loss: 0.0881 ||:  83%|########3 | 5979/7188 [21:05<04:37,  4.35it/s]
2022-03-21 16:31:05,818 - INFO - tqdm - f1: 0.9706, accuracy: 0.9706, batch_loss: 0.1191, loss: 0.0878 ||:  84%|########3 | 6025/7188 [21:15<04:19,  4.48it/s]
2022-03-21 16:31:15,917 - INFO - tqdm - f1: 0.9705, accuracy: 0.9704, batch_loss: 0.0439, loss: 0.0882 ||:  84%|########4 | 6073/7188 [21:25<03:47,  4.91it/s]
2022-03-21 16:31:25,950 - INFO - tqdm - f1: 0.9704, accuracy: 0.9704, batch_loss: 0.1297, loss: 0.0884 ||:  85%|########5 | 6121/7188 [21:35<03:36,  4.92it/s]
2022-03-21 16:31:36,042 - INFO - tqdm - f1: 0.9704, accuracy: 0.9704, batch_loss: 0.0412, loss: 0.0885 ||:  86%|########6 | 6190/7188 [21:45<01:04, 15.37it/s]
2022-03-21 16:31:46,081 - INFO - tqdm - f1: 0.9703, accuracy: 0.9703, batch_loss: 0.4087, loss: 0.0885 ||:  87%|########7 | 6288/7188 [21:55<01:57,  7.63it/s]
2022-03-21 16:31:56,096 - INFO - tqdm - f1: 0.9702, accuracy: 0.9702, batch_loss: 0.0395, loss: 0.0888 ||:  89%|########8 | 6363/7188 [22:05<01:42,  8.02it/s]
2022-03-21 16:32:06,139 - INFO - tqdm - f1: 0.9703, accuracy: 0.9702, batch_loss: 0.0553, loss: 0.0887 ||:  90%|########9 | 6435/7188 [22:15<01:40,  7.52it/s]
2022-03-21 16:32:16,292 - INFO - tqdm - f1: 0.9702, accuracy: 0.9702, batch_loss: 0.0256, loss: 0.0888 ||:  90%|######### | 6491/7188 [22:25<02:28,  4.69it/s]
2022-03-21 16:32:26,437 - INFO - tqdm - f1: 0.9702, accuracy: 0.9702, batch_loss: 0.3665, loss: 0.0888 ||:  91%|######### | 6539/7188 [22:36<02:31,  4.29it/s]
2022-03-21 16:32:36,494 - INFO - tqdm - f1: 0.9702, accuracy: 0.9702, batch_loss: 0.0190, loss: 0.0888 ||:  92%|#########1| 6586/7188 [22:46<02:11,  4.58it/s]
2022-03-21 16:32:46,511 - INFO - tqdm - f1: 0.9701, accuracy: 0.9701, batch_loss: 0.2043, loss: 0.0890 ||:  92%|#########2| 6635/7188 [22:56<01:47,  5.17it/s]
2022-03-21 16:32:56,632 - INFO - tqdm - f1: 0.9701, accuracy: 0.9701, batch_loss: 0.0105, loss: 0.0889 ||:  93%|#########2| 6683/7188 [23:06<01:53,  4.43it/s]
2022-03-21 16:33:06,693 - INFO - tqdm - f1: 0.9701, accuracy: 0.9701, batch_loss: 0.0919, loss: 0.0891 ||:  94%|#########3| 6730/7188 [23:16<01:34,  4.85it/s]
2022-03-21 16:33:16,758 - INFO - tqdm - f1: 0.9701, accuracy: 0.9701, batch_loss: 0.0067, loss: 0.0892 ||:  94%|#########4| 6776/7188 [23:26<01:40,  4.11it/s]
2022-03-21 16:33:26,836 - INFO - tqdm - f1: 0.9700, accuracy: 0.9700, batch_loss: 0.0241, loss: 0.0893 ||:  95%|#########4| 6825/7188 [23:36<01:18,  4.64it/s]
2022-03-21 16:33:37,003 - INFO - tqdm - f1: 0.9700, accuracy: 0.9700, batch_loss: 0.0063, loss: 0.0893 ||:  96%|#########5| 6872/7188 [23:46<01:11,  4.44it/s]
2022-03-21 16:33:47,196 - INFO - tqdm - f1: 0.9700, accuracy: 0.9700, batch_loss: 0.0550, loss: 0.0894 ||:  96%|#########6| 6918/7188 [23:56<01:08,  3.92it/s]
2022-03-21 16:33:57,368 - INFO - tqdm - f1: 0.9700, accuracy: 0.9700, batch_loss: 0.0058, loss: 0.0894 ||:  97%|#########6| 6962/7188 [24:07<00:52,  4.33it/s]
2022-03-21 16:34:07,528 - INFO - tqdm - f1: 0.9699, accuracy: 0.9699, batch_loss: 0.1192, loss: 0.0895 ||:  97%|#########7| 7002/7188 [24:17<00:53,  3.49it/s]
2022-03-21 16:34:17,707 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0921, loss: 0.0898 ||:  98%|#########7| 7036/7188 [24:27<00:40,  3.79it/s]
2022-03-21 16:34:27,858 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.1268, loss: 0.0898 ||:  98%|#########8| 7078/7188 [24:37<00:22,  4.80it/s]
2022-03-21 16:34:37,917 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.3612, loss: 0.0899 ||:  99%|#########9| 7124/7188 [24:47<00:12,  5.04it/s]
2022-03-21 16:34:44,124 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0266, loss: 0.0899 ||: 100%|#########9| 7153/7188 [24:53<00:07,  4.68it/s]
2022-03-21 16:34:44,311 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0086, loss: 0.0898 ||: 100%|#########9| 7154/7188 [24:53<00:06,  4.86it/s]
2022-03-21 16:34:44,495 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0030, loss: 0.0898 ||: 100%|#########9| 7155/7188 [24:54<00:06,  5.02it/s]
2022-03-21 16:34:44,750 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.2255, loss: 0.0899 ||: 100%|#########9| 7156/7188 [24:54<00:06,  4.63it/s]
2022-03-21 16:34:44,926 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0341, loss: 0.0898 ||: 100%|#########9| 7157/7188 [24:54<00:06,  4.90it/s]
2022-03-21 16:34:45,164 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0391, loss: 0.0898 ||: 100%|#########9| 7158/7188 [24:54<00:06,  4.67it/s]
2022-03-21 16:34:45,422 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.1096, loss: 0.0898 ||: 100%|#########9| 7159/7188 [24:55<00:06,  4.40it/s]
2022-03-21 16:34:45,616 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0967, loss: 0.0898 ||: 100%|#########9| 7160/7188 [24:55<00:06,  4.60it/s]
2022-03-21 16:34:45,852 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0207, loss: 0.0898 ||: 100%|#########9| 7161/7188 [24:55<00:06,  4.48it/s]
2022-03-21 16:34:46,087 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0044, loss: 0.0898 ||: 100%|#########9| 7162/7188 [24:55<00:05,  4.42it/s]
2022-03-21 16:34:46,233 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0895, loss: 0.0898 ||: 100%|#########9| 7163/7188 [24:55<00:05,  4.94it/s]
2022-03-21 16:34:46,509 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0162, loss: 0.0898 ||: 100%|#########9| 7164/7188 [24:56<00:05,  4.46it/s]
2022-03-21 16:34:46,696 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0411, loss: 0.0898 ||: 100%|#########9| 7165/7188 [24:56<00:04,  4.69it/s]
2022-03-21 16:34:46,872 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.4999, loss: 0.0899 ||: 100%|#########9| 7166/7188 [24:56<00:04,  4.95it/s]
2022-03-21 16:34:47,144 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0143, loss: 0.0898 ||: 100%|#########9| 7167/7188 [24:56<00:04,  4.48it/s]
2022-03-21 16:34:47,383 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0227, loss: 0.0898 ||: 100%|#########9| 7168/7188 [24:57<00:04,  4.39it/s]
2022-03-21 16:34:47,626 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0703, loss: 0.0898 ||: 100%|#########9| 7169/7188 [24:57<00:04,  4.30it/s]
2022-03-21 16:34:47,865 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0548, loss: 0.0898 ||: 100%|#########9| 7170/7188 [24:57<00:04,  4.26it/s]
2022-03-21 16:34:48,008 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.3315, loss: 0.0899 ||: 100%|#########9| 7171/7188 [24:57<00:03,  4.83it/s]
2022-03-21 16:34:48,246 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.3108, loss: 0.0899 ||: 100%|#########9| 7172/7188 [24:57<00:03,  4.62it/s]
2022-03-21 16:34:48,470 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0681, loss: 0.0899 ||: 100%|#########9| 7173/7188 [24:58<00:03,  4.57it/s]
2022-03-21 16:34:48,625 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.1499, loss: 0.0899 ||: 100%|#########9| 7174/7188 [24:58<00:02,  5.02it/s]
2022-03-21 16:34:48,876 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.2678, loss: 0.0899 ||: 100%|#########9| 7175/7188 [24:58<00:02,  4.65it/s]
2022-03-21 16:34:49,071 - INFO - tqdm - f1: 0.9698, accuracy: 0.9698, batch_loss: 0.0152, loss: 0.0899 ||: 100%|#########9| 7176/7188 [24:58<00:02,  4.78it/s]
2022-03-21 16:34:49,220 - INFO - tqdm - f1: 0.9698, accuracy: 0.9697, batch_loss: 0.3993, loss: 0.0900 ||: 100%|#########9| 7177/7188 [24:58<00:02,  5.24it/s]
2022-03-21 16:34:49,464 - INFO - tqdm - f1: 0.9698, accuracy: 0.9697, batch_loss: 0.1534, loss: 0.0900 ||: 100%|#########9| 7178/7188 [24:59<00:02,  4.83it/s]
2022-03-21 16:34:49,676 - INFO - tqdm - f1: 0.9698, accuracy: 0.9697, batch_loss: 0.0581, loss: 0.0900 ||: 100%|#########9| 7179/7188 [24:59<00:01,  4.80it/s]
2022-03-21 16:34:49,820 - INFO - tqdm - f1: 0.9697, accuracy: 0.9697, batch_loss: 0.1658, loss: 0.0900 ||: 100%|#########9| 7180/7188 [24:59<00:01,  5.29it/s]
2022-03-21 16:34:50,055 - INFO - tqdm - f1: 0.9697, accuracy: 0.9697, batch_loss: 0.2609, loss: 0.0900 ||: 100%|#########9| 7181/7188 [24:59<00:01,  4.93it/s]
2022-03-21 16:34:50,281 - INFO - tqdm - f1: 0.9697, accuracy: 0.9697, batch_loss: 0.0505, loss: 0.0900 ||: 100%|#########9| 7182/7188 [24:59<00:01,  4.77it/s]
2022-03-21 16:34:50,429 - INFO - tqdm - f1: 0.9697, accuracy: 0.9697, batch_loss: 0.1326, loss: 0.0900 ||: 100%|#########9| 7183/7188 [25:00<00:00,  5.22it/s]
2022-03-21 16:34:50,711 - INFO - tqdm - f1: 0.9697, accuracy: 0.9697, batch_loss: 0.0907, loss: 0.0900 ||: 100%|#########9| 7184/7188 [25:00<00:00,  4.58it/s]
2022-03-21 16:34:50,908 - INFO - tqdm - f1: 0.9697, accuracy: 0.9697, batch_loss: 0.1163, loss: 0.0900 ||: 100%|#########9| 7185/7188 [25:00<00:00,  4.72it/s]
2022-03-21 16:34:51,177 - INFO - tqdm - f1: 0.9697, accuracy: 0.9697, batch_loss: 0.0813, loss: 0.0900 ||: 100%|#########9| 7186/7188 [25:00<00:00,  4.37it/s]
2022-03-21 16:34:51,433 - INFO - tqdm - f1: 0.9697, accuracy: 0.9697, batch_loss: 0.0250, loss: 0.0900 ||: 100%|#########9| 7187/7188 [25:01<00:00,  4.21it/s]
2022-03-21 16:34:51,597 - INFO - tqdm - f1: 0.9697, accuracy: 0.9697, batch_loss: 0.0367, loss: 0.0900 ||: 100%|##########| 7188/7188 [25:01<00:00,  4.64it/s]
2022-03-21 16:34:51,639 - INFO - tqdm - f1: 0.9697, accuracy: 0.9697, batch_loss: 0.0367, loss: 0.0900 ||: 100%|##########| 7188/7188 [25:01<00:00,  4.79it/s]
2022-03-21 16:34:51,710 - INFO - allennlp.training.trainer - Validating
2022-03-21 16:34:51,713 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 16:35:01,766 - INFO - tqdm - f1: 0.9218, accuracy: 0.9207, batch_loss: 0.1430, loss: 0.2752 ||:  26%|##6       | 82/313 [00:10<00:30,  7.49it/s]
2022-03-21 16:35:11,810 - INFO - tqdm - f1: 0.9308, accuracy: 0.9310, batch_loss: 0.0249, loss: 0.2445 ||:  52%|#####2    | 164/313 [00:20<00:19,  7.81it/s]
2022-03-21 16:35:22,071 - INFO - tqdm - f1: 0.9365, accuracy: 0.9365, batch_loss: 0.0450, loss: 0.2326 ||:  78%|#######7  | 243/313 [00:30<00:10,  6.78it/s]
2022-03-21 16:35:31,274 - INFO - tqdm - f1: 0.9359, accuracy: 0.9360, batch_loss: 0.1988, loss: 0.2341 ||: 100%|#########9| 312/313 [00:39<00:00,  6.53it/s]
2022-03-21 16:35:31,303 - INFO - tqdm - f1: 0.9359, accuracy: 0.9360, batch_loss: 0.0998, loss: 0.2337 ||: 100%|##########| 313/313 [00:39<00:00,  7.91it/s]
2022-03-21 16:35:31,315 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 16:35:31,317 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.970  |     0.936
2022-03-21 16:35:31,318 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.970  |     0.936
2022-03-21 16:35:31,319 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 16:35:31,321 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.090  |     0.234
2022-03-21 16:35:31,322 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7579.625  |       N/A
2022-03-21 16:35:31,323 - INFO - allennlp.training.trainer - Epoch duration: 0:25:40.997985
2022-03-21 16:35:31,325 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:09:39
2022-03-21 16:35:31,326 - INFO - allennlp.training.trainer - Epoch 5/9
2022-03-21 16:35:31,327 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 16:35:31,329 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 16:35:31,331 - INFO - allennlp.training.trainer - Training
2022-03-21 16:35:31,333 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 16:35:41,449 - INFO - tqdm - f1: 0.9764, accuracy: 0.9777, batch_loss: 0.0403, loss: 0.0658 ||:   1%|          | 42/7188 [00:10<23:35,  5.05it/s]
2022-03-21 16:35:51,555 - INFO - tqdm - f1: 0.9783, accuracy: 0.9785, batch_loss: 0.1261, loss: 0.0628 ||:   1%|1         | 90/7188 [00:20<29:27,  4.02it/s]
2022-03-21 16:36:01,689 - INFO - tqdm - f1: 0.9789, accuracy: 0.9793, batch_loss: 0.0456, loss: 0.0574 ||:   2%|1         | 136/7188 [00:30<23:56,  4.91it/s]
2022-03-21 16:36:11,725 - INFO - tqdm - f1: 0.9792, accuracy: 0.9796, batch_loss: 0.0019, loss: 0.0568 ||:   3%|2         | 181/7188 [00:40<25:46,  4.53it/s]
2022-03-21 16:36:21,860 - INFO - tqdm - f1: 0.9795, accuracy: 0.9799, batch_loss: 0.0351, loss: 0.0588 ||:   3%|3         | 227/7188 [00:50<23:00,  5.04it/s]
2022-03-21 16:36:31,877 - INFO - tqdm - f1: 0.9799, accuracy: 0.9801, batch_loss: 0.0309, loss: 0.0591 ||:   4%|3         | 277/7188 [01:00<18:37,  6.18it/s]
2022-03-21 16:36:41,950 - INFO - tqdm - f1: 0.9802, accuracy: 0.9803, batch_loss: 0.0119, loss: 0.0587 ||:   4%|4         | 321/7188 [01:10<27:02,  4.23it/s]
2022-03-21 16:36:52,098 - INFO - tqdm - f1: 0.9798, accuracy: 0.9799, batch_loss: 0.0831, loss: 0.0597 ||:   5%|5         | 367/7188 [01:20<30:40,  3.71it/s]
2022-03-21 16:37:02,165 - INFO - tqdm - f1: 0.9797, accuracy: 0.9798, batch_loss: 0.0044, loss: 0.0593 ||:   6%|5         | 408/7188 [01:30<26:24,  4.28it/s]
2022-03-21 16:37:12,173 - INFO - tqdm - f1: 0.9794, accuracy: 0.9794, batch_loss: 0.0086, loss: 0.0620 ||:   6%|6         | 456/7188 [01:40<24:02,  4.67it/s]
2022-03-21 16:37:22,229 - INFO - tqdm - f1: 0.9808, accuracy: 0.9808, batch_loss: 0.1665, loss: 0.0594 ||:   7%|7         | 504/7188 [01:50<24:55,  4.47it/s]
2022-03-21 16:37:32,480 - INFO - tqdm - f1: 0.9804, accuracy: 0.9804, batch_loss: 0.0042, loss: 0.0606 ||:   8%|7         | 552/7188 [02:01<22:39,  4.88it/s]
2022-03-21 16:37:42,695 - INFO - tqdm - f1: 0.9802, accuracy: 0.9802, batch_loss: 0.0242, loss: 0.0630 ||:   8%|8         | 600/7188 [02:11<24:06,  4.55it/s]
2022-03-21 16:37:52,919 - INFO - tqdm - f1: 0.9800, accuracy: 0.9800, batch_loss: 0.0696, loss: 0.0636 ||:   9%|9         | 649/7188 [02:21<23:18,  4.68it/s]
2022-03-21 16:38:03,057 - INFO - tqdm - f1: 0.9794, accuracy: 0.9794, batch_loss: 0.0376, loss: 0.0653 ||:  10%|9         | 695/7188 [02:31<24:20,  4.45it/s]
2022-03-21 16:38:13,244 - INFO - tqdm - f1: 0.9795, accuracy: 0.9795, batch_loss: 0.0018, loss: 0.0651 ||:  10%|#         | 736/7188 [02:41<24:41,  4.35it/s]
2022-03-21 16:38:23,281 - INFO - tqdm - f1: 0.9794, accuracy: 0.9794, batch_loss: 0.0269, loss: 0.0656 ||:  11%|#         | 781/7188 [02:51<23:09,  4.61it/s]
2022-03-21 16:38:33,493 - INFO - tqdm - f1: 0.9789, accuracy: 0.9789, batch_loss: 0.0347, loss: 0.0670 ||:  11%|#1        | 822/7188 [03:02<24:17,  4.37it/s]
2022-03-21 16:38:43,802 - INFO - tqdm - f1: 0.9784, accuracy: 0.9783, batch_loss: 0.0098, loss: 0.0684 ||:  12%|#2        | 865/7188 [03:12<22:39,  4.65it/s]
2022-03-21 16:38:53,967 - INFO - tqdm - f1: 0.9785, accuracy: 0.9785, batch_loss: 0.0188, loss: 0.0682 ||:  13%|#2        | 908/7188 [03:22<24:44,  4.23it/s]
2022-03-21 16:39:03,979 - INFO - tqdm - f1: 0.9781, accuracy: 0.9781, batch_loss: 0.1340, loss: 0.0685 ||:  13%|#3        | 947/7188 [03:32<26:39,  3.90it/s]
2022-03-21 16:39:14,049 - INFO - tqdm - f1: 0.9784, accuracy: 0.9784, batch_loss: 0.0038, loss: 0.0678 ||:  14%|#3        | 989/7188 [03:42<23:05,  4.48it/s]
2022-03-21 16:39:24,068 - INFO - tqdm - f1: 0.9782, accuracy: 0.9781, batch_loss: 0.0713, loss: 0.0679 ||:  14%|#4        | 1029/7188 [03:52<27:02,  3.80it/s]
2022-03-21 16:39:34,324 - INFO - tqdm - f1: 0.9782, accuracy: 0.9781, batch_loss: 0.1668, loss: 0.0679 ||:  15%|#4        | 1070/7188 [04:02<28:08,  3.62it/s]
2022-03-21 16:39:44,595 - INFO - tqdm - f1: 0.9783, accuracy: 0.9782, batch_loss: 0.0335, loss: 0.0674 ||:  15%|#5        | 1111/7188 [04:13<25:46,  3.93it/s]
2022-03-21 16:39:54,767 - INFO - tqdm - f1: 0.9781, accuracy: 0.9780, batch_loss: 0.0843, loss: 0.0679 ||:  16%|#5        | 1150/7188 [04:23<23:41,  4.25it/s]
2022-03-21 16:40:04,991 - INFO - tqdm - f1: 0.9778, accuracy: 0.9777, batch_loss: 0.0417, loss: 0.0687 ||:  17%|#6        | 1193/7188 [04:33<23:12,  4.31it/s]
2022-03-21 16:40:15,073 - INFO - tqdm - f1: 0.9778, accuracy: 0.9778, batch_loss: 0.0383, loss: 0.0681 ||:  17%|#7        | 1234/7188 [04:43<25:30,  3.89it/s]
2022-03-21 16:40:25,363 - INFO - tqdm - f1: 0.9779, accuracy: 0.9778, batch_loss: 0.0092, loss: 0.0677 ||:  18%|#7        | 1276/7188 [04:54<24:43,  3.99it/s]
2022-03-21 16:40:35,371 - INFO - tqdm - f1: 0.9775, accuracy: 0.9775, batch_loss: 0.0075, loss: 0.0686 ||:  18%|#8        | 1317/7188 [05:04<25:43,  3.80it/s]
2022-03-21 16:40:45,537 - INFO - tqdm - f1: 0.9775, accuracy: 0.9775, batch_loss: 0.2938, loss: 0.0688 ||:  19%|#8        | 1361/7188 [05:14<22:45,  4.27it/s]
2022-03-21 16:40:55,692 - INFO - tqdm - f1: 0.9779, accuracy: 0.9779, batch_loss: 0.0022, loss: 0.0678 ||:  20%|#9        | 1403/7188 [05:24<22:55,  4.21it/s]
2022-03-21 16:41:05,851 - INFO - tqdm - f1: 0.9776, accuracy: 0.9775, batch_loss: 0.0152, loss: 0.0686 ||:  20%|##        | 1449/7188 [05:34<22:57,  4.17it/s]
2022-03-21 16:41:15,857 - INFO - tqdm - f1: 0.9774, accuracy: 0.9774, batch_loss: 0.2302, loss: 0.0694 ||:  21%|##        | 1493/7188 [05:44<19:16,  4.93it/s]
2022-03-21 16:41:25,993 - INFO - tqdm - f1: 0.9774, accuracy: 0.9773, batch_loss: 0.1271, loss: 0.0691 ||:  21%|##1       | 1533/7188 [05:54<21:31,  4.38it/s]
2022-03-21 16:41:36,146 - INFO - tqdm - f1: 0.9772, accuracy: 0.9771, batch_loss: 0.0089, loss: 0.0697 ||:  22%|##1       | 1575/7188 [06:04<23:11,  4.03it/s]
2022-03-21 16:41:46,247 - INFO - tqdm - f1: 0.9771, accuracy: 0.9771, batch_loss: 0.0181, loss: 0.0696 ||:  23%|##2       | 1618/7188 [06:14<22:03,  4.21it/s]
2022-03-21 16:41:56,478 - INFO - tqdm - f1: 0.9772, accuracy: 0.9772, batch_loss: 0.0180, loss: 0.0688 ||:  23%|##3       | 1659/7188 [06:25<25:36,  3.60it/s]
2022-03-21 16:42:06,669 - INFO - tqdm - f1: 0.9772, accuracy: 0.9771, batch_loss: 0.0418, loss: 0.0692 ||:  24%|##3       | 1700/7188 [06:35<22:58,  3.98it/s]
2022-03-21 16:42:16,784 - INFO - tqdm - f1: 0.9773, accuracy: 0.9773, batch_loss: 0.0114, loss: 0.0689 ||:  24%|##4       | 1743/7188 [06:45<22:10,  4.09it/s]
2022-03-21 16:42:26,932 - INFO - tqdm - f1: 0.9774, accuracy: 0.9774, batch_loss: 0.0046, loss: 0.0685 ||:  25%|##4       | 1783/7188 [06:55<22:42,  3.97it/s]
2022-03-21 16:42:37,040 - INFO - tqdm - f1: 0.9775, accuracy: 0.9775, batch_loss: 0.0306, loss: 0.0687 ||:  25%|##5       | 1824/7188 [07:05<20:00,  4.47it/s]
2022-03-21 16:42:47,162 - INFO - tqdm - f1: 0.9774, accuracy: 0.9774, batch_loss: 0.0151, loss: 0.0687 ||:  26%|##6       | 1872/7188 [07:15<19:27,  4.55it/s]
2022-03-21 16:42:57,300 - INFO - tqdm - f1: 0.9774, accuracy: 0.9774, batch_loss: 0.0022, loss: 0.0690 ||:  27%|##6       | 1920/7188 [07:25<19:33,  4.49it/s]
2022-03-21 16:43:07,350 - INFO - tqdm - f1: 0.9773, accuracy: 0.9772, batch_loss: 0.0324, loss: 0.0693 ||:  27%|##7       | 1968/7188 [07:36<16:51,  5.16it/s]
2022-03-21 16:43:17,360 - INFO - tqdm - f1: 0.9772, accuracy: 0.9771, batch_loss: 0.0129, loss: 0.0695 ||:  28%|##8       | 2013/7188 [07:46<18:34,  4.64it/s]
2022-03-21 16:43:27,554 - INFO - tqdm - f1: 0.9771, accuracy: 0.9770, batch_loss: 0.2766, loss: 0.0695 ||:  29%|##8       | 2061/7188 [07:56<20:03,  4.26it/s]
2022-03-21 16:43:37,753 - INFO - tqdm - f1: 0.9770, accuracy: 0.9769, batch_loss: 0.0171, loss: 0.0695 ||:  29%|##9       | 2110/7188 [08:06<18:12,  4.65it/s]
2022-03-21 16:43:47,871 - INFO - tqdm - f1: 0.9772, accuracy: 0.9771, batch_loss: 0.0121, loss: 0.0690 ||:  30%|###       | 2157/7188 [08:16<18:04,  4.64it/s]
2022-03-21 16:43:58,065 - INFO - tqdm - f1: 0.9770, accuracy: 0.9770, batch_loss: 0.0027, loss: 0.0691 ||:  31%|###       | 2205/7188 [08:26<17:21,  4.79it/s]
2022-03-21 16:44:08,242 - INFO - tqdm - f1: 0.9770, accuracy: 0.9770, batch_loss: 0.1166, loss: 0.0693 ||:  31%|###1      | 2252/7188 [08:36<17:25,  4.72it/s]
2022-03-21 16:44:18,353 - INFO - tqdm - f1: 0.9770, accuracy: 0.9769, batch_loss: 0.0584, loss: 0.0694 ||:  32%|###1      | 2294/7188 [08:47<17:13,  4.73it/s]
2022-03-21 16:44:28,549 - INFO - tqdm - f1: 0.9770, accuracy: 0.9769, batch_loss: 0.0040, loss: 0.0695 ||:  32%|###2      | 2336/7188 [08:57<19:30,  4.15it/s]
2022-03-21 16:44:38,692 - INFO - tqdm - f1: 0.9768, accuracy: 0.9768, batch_loss: 0.0065, loss: 0.0698 ||:  33%|###3      | 2378/7188 [09:07<20:16,  3.95it/s]
2022-03-21 16:44:48,971 - INFO - tqdm - f1: 0.9770, accuracy: 0.9770, batch_loss: 0.0155, loss: 0.0693 ||:  34%|###3      | 2418/7188 [09:17<20:24,  3.89it/s]
2022-03-21 16:44:59,089 - INFO - tqdm - f1: 0.9771, accuracy: 0.9771, batch_loss: 0.1257, loss: 0.0693 ||:  34%|###4      | 2461/7188 [09:27<21:12,  3.71it/s]
2022-03-21 16:45:09,195 - INFO - tqdm - f1: 0.9770, accuracy: 0.9769, batch_loss: 0.0029, loss: 0.0694 ||:  35%|###4      | 2505/7188 [09:37<15:42,  4.97it/s]
2022-03-21 16:45:19,325 - INFO - tqdm - f1: 0.9771, accuracy: 0.9770, batch_loss: 0.0196, loss: 0.0691 ||:  35%|###5      | 2544/7188 [09:47<24:42,  3.13it/s]
2022-03-21 16:45:29,531 - INFO - tqdm - f1: 0.9769, accuracy: 0.9769, batch_loss: 0.0776, loss: 0.0693 ||:  36%|###5      | 2587/7188 [09:58<22:43,  3.37it/s]
2022-03-21 16:45:39,705 - INFO - tqdm - f1: 0.9768, accuracy: 0.9767, batch_loss: 0.1916, loss: 0.0697 ||:  37%|###6      | 2628/7188 [10:08<19:08,  3.97it/s]
2022-03-21 16:45:49,957 - INFO - tqdm - f1: 0.9768, accuracy: 0.9768, batch_loss: 0.0057, loss: 0.0698 ||:  37%|###7      | 2671/7188 [10:18<18:46,  4.01it/s]
2022-03-21 16:46:00,040 - INFO - tqdm - f1: 0.9766, accuracy: 0.9766, batch_loss: 0.0360, loss: 0.0705 ||:  38%|###7      | 2714/7188 [10:28<16:46,  4.45it/s]
2022-03-21 16:46:10,213 - INFO - tqdm - f1: 0.9766, accuracy: 0.9766, batch_loss: 0.0446, loss: 0.0703 ||:  38%|###8      | 2756/7188 [10:38<20:06,  3.67it/s]
2022-03-21 16:46:20,252 - INFO - tqdm - f1: 0.9763, accuracy: 0.9763, batch_loss: 0.3411, loss: 0.0711 ||:  39%|###8      | 2800/7188 [10:48<15:17,  4.78it/s]
2022-03-21 16:46:30,468 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0029, loss: 0.0708 ||:  40%|###9      | 2843/7188 [10:59<17:21,  4.17it/s]
2022-03-21 16:46:40,635 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0635, loss: 0.0710 ||:  40%|####      | 2887/7188 [11:09<19:55,  3.60it/s]
2022-03-21 16:46:50,807 - INFO - tqdm - f1: 0.9765, accuracy: 0.9765, batch_loss: 0.0110, loss: 0.0707 ||:  41%|####      | 2927/7188 [11:19<17:58,  3.95it/s]
2022-03-21 16:47:00,827 - INFO - tqdm - f1: 0.9765, accuracy: 0.9765, batch_loss: 0.3963, loss: 0.0705 ||:  41%|####1     | 2970/7188 [11:29<14:49,  4.74it/s]
2022-03-21 16:47:10,884 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0659, loss: 0.0708 ||:  42%|####1     | 3011/7188 [11:39<17:02,  4.09it/s]
2022-03-21 16:47:20,987 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0270, loss: 0.0708 ||:  42%|####2     | 3054/7188 [11:49<15:34,  4.43it/s]
2022-03-21 16:47:31,011 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.1508, loss: 0.0708 ||:  44%|####3     | 3151/7188 [11:59<06:53,  9.77it/s]
2022-03-21 16:47:41,042 - INFO - tqdm - f1: 0.9765, accuracy: 0.9765, batch_loss: 0.0202, loss: 0.0711 ||:  45%|####4     | 3220/7188 [12:09<09:08,  7.23it/s]
2022-03-21 16:47:51,183 - INFO - tqdm - f1: 0.9765, accuracy: 0.9765, batch_loss: 0.0035, loss: 0.0714 ||:  46%|####5     | 3294/7188 [12:19<08:09,  7.95it/s]
2022-03-21 16:48:01,255 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0070, loss: 0.0715 ||:  47%|####6     | 3360/7188 [12:29<13:23,  4.77it/s]
2022-03-21 16:48:11,539 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0063, loss: 0.0716 ||:  47%|####7     | 3401/7188 [12:40<17:10,  3.67it/s]
2022-03-21 16:48:21,628 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0343, loss: 0.0717 ||:  48%|####7     | 3444/7188 [12:50<13:28,  4.63it/s]
2022-03-21 16:48:31,841 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0118, loss: 0.0716 ||:  49%|####8     | 3488/7188 [13:00<14:12,  4.34it/s]
2022-03-21 16:48:41,872 - INFO - tqdm - f1: 0.9765, accuracy: 0.9765, batch_loss: 0.0085, loss: 0.0715 ||:  49%|####9     | 3530/7188 [13:10<14:56,  4.08it/s]
2022-03-21 16:48:51,990 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0136, loss: 0.0714 ||:  50%|####9     | 3570/7188 [13:20<16:31,  3.65it/s]
2022-03-21 16:49:02,102 - INFO - tqdm - f1: 0.9763, accuracy: 0.9763, batch_loss: 0.0991, loss: 0.0717 ||:  50%|#####     | 3610/7188 [13:30<17:24,  3.42it/s]
2022-03-21 16:49:12,115 - INFO - tqdm - f1: 0.9762, accuracy: 0.9762, batch_loss: 0.0978, loss: 0.0719 ||:  51%|#####     | 3654/7188 [13:40<13:03,  4.51it/s]
2022-03-21 16:49:22,183 - INFO - tqdm - f1: 0.9763, accuracy: 0.9763, batch_loss: 0.0133, loss: 0.0717 ||:  51%|#####1    | 3695/7188 [13:50<14:51,  3.92it/s]
2022-03-21 16:49:32,197 - INFO - tqdm - f1: 0.9763, accuracy: 0.9763, batch_loss: 0.0035, loss: 0.0717 ||:  52%|#####1    | 3736/7188 [14:00<15:07,  3.80it/s]
2022-03-21 16:49:42,340 - INFO - tqdm - f1: 0.9764, accuracy: 0.9764, batch_loss: 0.0041, loss: 0.0716 ||:  53%|#####2    | 3777/7188 [14:11<14:18,  3.97it/s]
2022-03-21 16:49:52,405 - INFO - tqdm - f1: 0.9763, accuracy: 0.9763, batch_loss: 0.1140, loss: 0.0717 ||:  53%|#####3    | 3819/7188 [14:21<13:30,  4.16it/s]
2022-03-21 16:50:02,674 - INFO - tqdm - f1: 0.9763, accuracy: 0.9763, batch_loss: 0.0037, loss: 0.0715 ||:  54%|#####3    | 3859/7188 [14:31<15:14,  3.64it/s]
2022-03-21 16:50:12,732 - INFO - tqdm - f1: 0.9763, accuracy: 0.9762, batch_loss: 0.0141, loss: 0.0715 ||:  54%|#####4    | 3900/7188 [14:41<14:07,  3.88it/s]
2022-03-21 16:50:22,972 - INFO - tqdm - f1: 0.9763, accuracy: 0.9762, batch_loss: 0.0206, loss: 0.0714 ||:  55%|#####4    | 3942/7188 [14:51<13:44,  3.94it/s]
2022-03-21 16:50:33,065 - INFO - tqdm - f1: 0.9763, accuracy: 0.9762, batch_loss: 0.0244, loss: 0.0715 ||:  55%|#####5    | 3984/7188 [15:01<12:15,  4.35it/s]
2022-03-21 16:50:43,204 - INFO - tqdm - f1: 0.9762, accuracy: 0.9762, batch_loss: 0.1035, loss: 0.0716 ||:  56%|#####6    | 4026/7188 [15:11<11:49,  4.46it/s]
2022-03-21 16:50:53,328 - INFO - tqdm - f1: 0.9762, accuracy: 0.9761, batch_loss: 0.0397, loss: 0.0717 ||:  57%|#####6    | 4068/7188 [15:21<12:08,  4.28it/s]
2022-03-21 16:51:03,422 - INFO - tqdm - f1: 0.9762, accuracy: 0.9761, batch_loss: 0.2485, loss: 0.0717 ||:  57%|#####7    | 4111/7188 [15:32<13:12,  3.88it/s]
2022-03-21 16:51:13,478 - INFO - tqdm - f1: 0.9762, accuracy: 0.9761, batch_loss: 0.0144, loss: 0.0717 ||:  58%|#####7    | 4154/7188 [15:42<13:46,  3.67it/s]
2022-03-21 16:51:23,687 - INFO - tqdm - f1: 0.9759, accuracy: 0.9759, batch_loss: 0.0596, loss: 0.0722 ||:  58%|#####8    | 4198/7188 [15:52<13:32,  3.68it/s]
2022-03-21 16:51:33,692 - INFO - tqdm - f1: 0.9759, accuracy: 0.9759, batch_loss: 0.0142, loss: 0.0725 ||:  59%|#####8    | 4240/7188 [16:02<10:19,  4.75it/s]
2022-03-21 16:51:43,756 - INFO - tqdm - f1: 0.9760, accuracy: 0.9759, batch_loss: 0.2455, loss: 0.0723 ||:  60%|#####9    | 4279/7188 [16:12<12:58,  3.74it/s]
2022-03-21 16:51:53,822 - INFO - tqdm - f1: 0.9759, accuracy: 0.9759, batch_loss: 0.0099, loss: 0.0725 ||:  60%|######    | 4322/7188 [16:22<10:36,  4.50it/s]
2022-03-21 16:52:03,945 - INFO - tqdm - f1: 0.9759, accuracy: 0.9758, batch_loss: 0.0103, loss: 0.0727 ||:  61%|######    | 4368/7188 [16:32<10:09,  4.62it/s]
2022-03-21 16:52:14,071 - INFO - tqdm - f1: 0.9758, accuracy: 0.9758, batch_loss: 0.0252, loss: 0.0730 ||:  61%|######1   | 4416/7188 [16:42<10:52,  4.25it/s]
2022-03-21 16:52:24,230 - INFO - tqdm - f1: 0.9758, accuracy: 0.9758, batch_loss: 0.0520, loss: 0.0730 ||:  62%|######2   | 4464/7188 [16:52<10:43,  4.23it/s]
2022-03-21 16:52:34,432 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.1042, loss: 0.0730 ||:  63%|######2   | 4512/7188 [17:03<09:34,  4.66it/s]
2022-03-21 16:52:44,437 - INFO - tqdm - f1: 0.9757, accuracy: 0.9756, batch_loss: 0.5069, loss: 0.0731 ||:  63%|######3   | 4560/7188 [17:13<09:01,  4.86it/s]
2022-03-21 16:52:54,694 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.0249, loss: 0.0731 ||:  64%|######4   | 4608/7188 [17:23<09:46,  4.40it/s]
2022-03-21 16:53:04,759 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.1723, loss: 0.0731 ||:  65%|######4   | 4655/7188 [17:33<08:31,  4.96it/s]
2022-03-21 16:53:14,844 - INFO - tqdm - f1: 0.9756, accuracy: 0.9756, batch_loss: 0.0041, loss: 0.0731 ||:  65%|######5   | 4703/7188 [17:43<09:26,  4.38it/s]
2022-03-21 16:53:24,957 - INFO - tqdm - f1: 0.9757, accuracy: 0.9756, batch_loss: 0.0955, loss: 0.0730 ||:  66%|######6   | 4752/7188 [17:53<09:06,  4.46it/s]
2022-03-21 16:53:34,971 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.0038, loss: 0.0730 ||:  67%|######6   | 4799/7188 [18:03<08:22,  4.75it/s]
2022-03-21 16:53:45,147 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.0237, loss: 0.0730 ||:  67%|######7   | 4847/7188 [18:13<08:04,  4.83it/s]
2022-03-21 16:53:55,193 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.0056, loss: 0.0728 ||:  68%|######8   | 4893/7188 [18:23<08:58,  4.26it/s]
2022-03-21 16:54:05,387 - INFO - tqdm - f1: 0.9757, accuracy: 0.9756, batch_loss: 0.0601, loss: 0.0732 ||:  69%|######8   | 4942/7188 [18:34<07:45,  4.82it/s]
2022-03-21 16:54:15,483 - INFO - tqdm - f1: 0.9757, accuracy: 0.9756, batch_loss: 0.0684, loss: 0.0733 ||:  69%|######9   | 4990/7188 [18:44<08:19,  4.40it/s]
2022-03-21 16:54:25,502 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.0169, loss: 0.0733 ||:  70%|#######   | 5037/7188 [18:54<07:40,  4.67it/s]
2022-03-21 16:54:35,707 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.0184, loss: 0.0733 ||:  71%|#######   | 5086/7188 [19:04<07:40,  4.56it/s]
2022-03-21 16:54:45,850 - INFO - tqdm - f1: 0.9758, accuracy: 0.9757, batch_loss: 0.0081, loss: 0.0731 ||:  71%|#######1  | 5134/7188 [19:14<07:20,  4.66it/s]
2022-03-21 16:54:56,024 - INFO - tqdm - f1: 0.9758, accuracy: 0.9758, batch_loss: 0.1124, loss: 0.0729 ||:  72%|#######2  | 5182/7188 [19:24<07:00,  4.77it/s]
2022-03-21 16:55:06,178 - INFO - tqdm - f1: 0.9758, accuracy: 0.9757, batch_loss: 0.2378, loss: 0.0732 ||:  73%|#######2  | 5230/7188 [19:34<06:54,  4.72it/s]
2022-03-21 16:55:16,353 - INFO - tqdm - f1: 0.9758, accuracy: 0.9758, batch_loss: 0.0134, loss: 0.0731 ||:  73%|#######3  | 5280/7188 [19:45<06:22,  4.99it/s]
2022-03-21 16:55:26,478 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.0071, loss: 0.0734 ||:  74%|#######4  | 5326/7188 [19:55<06:41,  4.63it/s]
2022-03-21 16:55:36,536 - INFO - tqdm - f1: 0.9757, accuracy: 0.9756, batch_loss: 0.1218, loss: 0.0735 ||:  75%|#######4  | 5375/7188 [20:05<06:17,  4.80it/s]
2022-03-21 16:55:46,683 - INFO - tqdm - f1: 0.9757, accuracy: 0.9756, batch_loss: 0.0053, loss: 0.0735 ||:  75%|#######5  | 5422/7188 [20:15<06:11,  4.75it/s]
2022-03-21 16:55:56,915 - INFO - tqdm - f1: 0.9757, accuracy: 0.9756, batch_loss: 0.0212, loss: 0.0735 ||:  76%|#######6  | 5472/7188 [20:25<06:02,  4.73it/s]
2022-03-21 16:56:07,097 - INFO - tqdm - f1: 0.9757, accuracy: 0.9757, batch_loss: 0.0064, loss: 0.0734 ||:  77%|#######6  | 5519/7188 [20:35<05:44,  4.85it/s]
2022-03-21 16:56:17,107 - INFO - tqdm - f1: 0.9758, accuracy: 0.9757, batch_loss: 0.0680, loss: 0.0732 ||:  77%|#######7  | 5568/7188 [20:45<05:49,  4.63it/s]
2022-03-21 16:56:27,202 - INFO - tqdm - f1: 0.9758, accuracy: 0.9757, batch_loss: 0.2869, loss: 0.0735 ||:  78%|#######8  | 5615/7188 [20:55<06:07,  4.28it/s]
2022-03-21 16:56:37,420 - INFO - tqdm - f1: 0.9756, accuracy: 0.9756, batch_loss: 0.1624, loss: 0.0739 ||:  79%|#######8  | 5663/7188 [21:06<05:57,  4.27it/s]
2022-03-21 16:56:47,609 - INFO - tqdm - f1: 0.9756, accuracy: 0.9755, batch_loss: 0.1919, loss: 0.0742 ||:  79%|#######9  | 5712/7188 [21:16<05:09,  4.77it/s]
2022-03-21 16:56:57,807 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.0212, loss: 0.0745 ||:  80%|########  | 5760/7188 [21:26<05:46,  4.12it/s]
2022-03-21 16:57:07,987 - INFO - tqdm - f1: 0.9754, accuracy: 0.9754, batch_loss: 0.0362, loss: 0.0745 ||:  81%|########  | 5808/7188 [21:36<05:29,  4.19it/s]
2022-03-21 16:57:18,145 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.2188, loss: 0.0749 ||:  81%|########1 | 5856/7188 [21:46<04:46,  4.65it/s]
2022-03-21 16:57:28,309 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.0235, loss: 0.0748 ||:  82%|########2 | 5903/7188 [21:56<04:43,  4.54it/s]
2022-03-21 16:57:38,419 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0234, loss: 0.0751 ||:  83%|########2 | 5954/7188 [22:07<03:50,  5.36it/s]
2022-03-21 16:57:48,445 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.0776, loss: 0.0750 ||:  83%|########3 | 6001/7188 [22:17<04:26,  4.46it/s]
2022-03-21 16:57:58,609 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0842, loss: 0.0751 ||:  84%|########4 | 6049/7188 [22:27<03:56,  4.82it/s]
2022-03-21 16:58:08,765 - INFO - tqdm - f1: 0.9753, accuracy: 0.9752, batch_loss: 0.0054, loss: 0.0750 ||:  85%|########4 | 6096/7188 [22:37<03:58,  4.58it/s]
2022-03-21 16:58:18,939 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0083, loss: 0.0750 ||:  85%|########5 | 6144/7188 [22:47<03:38,  4.77it/s]
2022-03-21 16:58:29,079 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0498, loss: 0.0750 ||:  86%|########6 | 6191/7188 [22:57<03:36,  4.60it/s]
2022-03-21 16:58:39,246 - INFO - tqdm - f1: 0.9753, accuracy: 0.9753, batch_loss: 0.0110, loss: 0.0748 ||:  87%|########6 | 6239/7188 [23:07<03:18,  4.78it/s]
2022-03-21 16:58:49,425 - INFO - tqdm - f1: 0.9752, accuracy: 0.9752, batch_loss: 0.0239, loss: 0.0751 ||:  87%|########7 | 6287/7188 [23:18<03:25,  4.38it/s]
2022-03-21 16:58:59,545 - INFO - tqdm - f1: 0.9752, accuracy: 0.9751, batch_loss: 0.0029, loss: 0.0752 ||:  88%|########8 | 6334/7188 [23:28<03:22,  4.21it/s]
2022-03-21 16:59:09,587 - INFO - tqdm - f1: 0.9751, accuracy: 0.9751, batch_loss: 0.0538, loss: 0.0754 ||:  89%|########8 | 6382/7188 [23:38<02:55,  4.58it/s]
2022-03-21 16:59:19,614 - INFO - tqdm - f1: 0.9751, accuracy: 0.9751, batch_loss: 0.0259, loss: 0.0754 ||:  89%|########9 | 6431/7188 [23:48<02:41,  4.69it/s]
2022-03-21 16:59:29,802 - INFO - tqdm - f1: 0.9751, accuracy: 0.9751, batch_loss: 0.0095, loss: 0.0754 ||:  90%|######### | 6478/7188 [23:58<02:46,  4.28it/s]
2022-03-21 16:59:39,825 - INFO - tqdm - f1: 0.9750, accuracy: 0.9750, batch_loss: 0.2675, loss: 0.0756 ||:  91%|######### | 6525/7188 [24:08<02:27,  4.50it/s]
2022-03-21 16:59:49,994 - INFO - tqdm - f1: 0.9750, accuracy: 0.9750, batch_loss: 0.0733, loss: 0.0757 ||:  91%|#########1| 6573/7188 [24:18<02:20,  4.39it/s]
2022-03-21 17:00:00,142 - INFO - tqdm - f1: 0.9750, accuracy: 0.9750, batch_loss: 0.0046, loss: 0.0755 ||:  92%|#########2| 6619/7188 [24:28<02:06,  4.51it/s]
2022-03-21 17:00:10,276 - INFO - tqdm - f1: 0.9750, accuracy: 0.9750, batch_loss: 0.0070, loss: 0.0757 ||:  93%|#########2| 6665/7188 [24:38<01:46,  4.90it/s]
2022-03-21 17:00:20,316 - INFO - tqdm - f1: 0.9750, accuracy: 0.9750, batch_loss: 0.0166, loss: 0.0758 ||:  93%|#########3| 6712/7188 [24:48<01:50,  4.31it/s]
2022-03-21 17:00:30,459 - INFO - tqdm - f1: 0.9750, accuracy: 0.9749, batch_loss: 0.0303, loss: 0.0760 ||:  94%|#########4| 6761/7188 [24:59<01:28,  4.84it/s]
2022-03-21 17:00:40,584 - INFO - tqdm - f1: 0.9749, accuracy: 0.9749, batch_loss: 0.0046, loss: 0.0761 ||:  95%|#########4| 6806/7188 [25:09<01:21,  4.67it/s]
2022-03-21 17:00:50,686 - INFO - tqdm - f1: 0.9750, accuracy: 0.9749, batch_loss: 0.0080, loss: 0.0759 ||:  95%|#########5| 6853/7188 [25:19<01:09,  4.83it/s]
2022-03-21 17:01:00,839 - INFO - tqdm - f1: 0.9749, accuracy: 0.9749, batch_loss: 0.2699, loss: 0.0761 ||:  96%|#########5| 6900/7188 [25:29<01:02,  4.64it/s]
2022-03-21 17:01:11,020 - INFO - tqdm - f1: 0.9749, accuracy: 0.9749, batch_loss: 0.0058, loss: 0.0760 ||:  97%|#########6| 6948/7188 [25:39<00:49,  4.84it/s]
2022-03-21 17:01:21,100 - INFO - tqdm - f1: 0.9749, accuracy: 0.9748, batch_loss: 0.0740, loss: 0.0762 ||:  97%|#########7| 6997/7188 [25:49<00:41,  4.65it/s]
2022-03-21 17:01:31,170 - INFO - tqdm - f1: 0.9749, accuracy: 0.9749, batch_loss: 0.1970, loss: 0.0762 ||:  98%|#########8| 7047/7188 [25:59<00:26,  5.34it/s]
2022-03-21 17:01:41,205 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0056, loss: 0.0763 ||:  99%|#########8| 7094/7188 [26:09<00:19,  4.93it/s]
2022-03-21 17:01:51,347 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.1608, loss: 0.0762 ||:  99%|#########9| 7142/7188 [26:20<00:10,  4.47it/s]
2022-03-21 17:01:53,583 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0031, loss: 0.0762 ||: 100%|#########9| 7153/7188 [26:22<00:07,  4.62it/s]
2022-03-21 17:01:53,775 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.2798, loss: 0.0762 ||: 100%|#########9| 7154/7188 [26:22<00:07,  4.78it/s]
2022-03-21 17:01:54,015 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0061, loss: 0.0762 ||: 100%|#########9| 7155/7188 [26:22<00:07,  4.58it/s]
2022-03-21 17:01:54,263 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0731, loss: 0.0762 ||: 100%|#########9| 7156/7188 [26:22<00:07,  4.40it/s]
2022-03-21 17:01:54,460 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0023, loss: 0.0762 ||: 100%|#########9| 7157/7188 [26:23<00:06,  4.58it/s]
2022-03-21 17:01:54,741 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0120, loss: 0.0762 ||: 100%|#########9| 7158/7188 [26:23<00:07,  4.22it/s]
2022-03-21 17:01:54,958 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0028, loss: 0.0762 ||: 100%|#########9| 7159/7188 [26:23<00:06,  4.33it/s]
2022-03-21 17:01:55,199 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0165, loss: 0.0761 ||: 100%|#########9| 7160/7188 [26:23<00:06,  4.27it/s]
2022-03-21 17:01:55,493 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0109, loss: 0.0761 ||: 100%|#########9| 7161/7188 [26:24<00:06,  3.97it/s]
2022-03-21 17:01:55,662 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0099, loss: 0.0761 ||: 100%|#########9| 7162/7188 [26:24<00:05,  4.41it/s]
2022-03-21 17:01:55,914 - INFO - tqdm - f1: 0.9749, accuracy: 0.9748, batch_loss: 0.0472, loss: 0.0761 ||: 100%|#########9| 7163/7188 [26:24<00:05,  4.26it/s]
2022-03-21 17:01:56,122 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.3559, loss: 0.0762 ||: 100%|#########9| 7164/7188 [26:24<00:05,  4.41it/s]
2022-03-21 17:01:56,261 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.3558, loss: 0.0762 ||: 100%|#########9| 7165/7188 [26:24<00:04,  4.99it/s]
2022-03-21 17:01:56,511 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.3035, loss: 0.0762 ||: 100%|#########9| 7166/7188 [26:25<00:04,  4.65it/s]
2022-03-21 17:01:56,723 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.1015, loss: 0.0762 ||: 100%|#########9| 7167/7188 [26:25<00:04,  4.67it/s]
2022-03-21 17:01:56,933 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.3186, loss: 0.0763 ||: 100%|#########9| 7168/7188 [26:25<00:04,  4.70it/s]
2022-03-21 17:01:57,161 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0095, loss: 0.0763 ||: 100%|#########9| 7169/7188 [26:25<00:04,  4.60it/s]
2022-03-21 17:01:57,338 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0347, loss: 0.0763 ||: 100%|#########9| 7170/7188 [26:26<00:03,  4.87it/s]
2022-03-21 17:01:57,577 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.1945, loss: 0.0763 ||: 100%|#########9| 7171/7188 [26:26<00:03,  4.64it/s]
2022-03-21 17:01:57,837 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0214, loss: 0.0763 ||: 100%|#########9| 7172/7188 [26:26<00:03,  4.37it/s]
2022-03-21 17:01:58,026 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0162, loss: 0.0763 ||: 100%|#########9| 7173/7188 [26:26<00:03,  4.61it/s]
2022-03-21 17:01:58,263 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0095, loss: 0.0762 ||: 100%|#########9| 7174/7188 [26:26<00:03,  4.49it/s]
2022-03-21 17:01:58,496 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0071, loss: 0.0762 ||: 100%|#########9| 7175/7188 [26:27<00:02,  4.43it/s]
2022-03-21 17:01:58,708 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0675, loss: 0.0762 ||: 100%|#########9| 7176/7188 [26:27<00:02,  4.51it/s]
2022-03-21 17:01:58,977 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.1605, loss: 0.0763 ||: 100%|#########9| 7177/7188 [26:27<00:02,  4.24it/s]
2022-03-21 17:01:59,212 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.2936, loss: 0.0763 ||: 100%|#########9| 7178/7188 [26:27<00:02,  4.24it/s]
2022-03-21 17:01:59,452 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0079, loss: 0.0763 ||: 100%|#########9| 7179/7188 [26:28<00:02,  4.22it/s]
2022-03-21 17:01:59,680 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0331, loss: 0.0763 ||: 100%|#########9| 7180/7188 [26:28<00:01,  4.27it/s]
2022-03-21 17:01:59,825 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0140, loss: 0.0763 ||: 100%|#########9| 7181/7188 [26:28<00:01,  4.82it/s]
2022-03-21 17:02:00,107 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0086, loss: 0.0762 ||: 100%|#########9| 7182/7188 [26:28<00:01,  4.35it/s]
2022-03-21 17:02:00,288 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0332, loss: 0.0762 ||: 100%|#########9| 7183/7188 [26:28<00:01,  4.65it/s]
2022-03-21 17:02:00,464 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0052, loss: 0.0762 ||: 100%|#########9| 7184/7188 [26:29<00:00,  4.91it/s]
2022-03-21 17:02:00,716 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0266, loss: 0.0762 ||: 100%|#########9| 7185/7188 [26:29<00:00,  4.59it/s]
2022-03-21 17:02:00,902 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0153, loss: 0.0762 ||: 100%|#########9| 7186/7188 [26:29<00:00,  4.79it/s]
2022-03-21 17:02:01,173 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.0124, loss: 0.0762 ||: 100%|#########9| 7187/7188 [26:29<00:00,  4.40it/s]
2022-03-21 17:02:01,427 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.1064, loss: 0.0762 ||: 100%|##########| 7188/7188 [26:30<00:00,  4.25it/s]
2022-03-21 17:02:01,467 - INFO - tqdm - f1: 0.9748, accuracy: 0.9748, batch_loss: 0.1064, loss: 0.0762 ||: 100%|##########| 7188/7188 [26:30<00:00,  4.52it/s]
2022-03-21 17:02:01,473 - INFO - allennlp.training.trainer - Validating
2022-03-21 17:02:01,475 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 17:02:11,577 - INFO - tqdm - f1: 0.9400, accuracy: 0.9398, batch_loss: 0.4872, loss: 0.2338 ||:  27%|##6       | 83/313 [00:10<00:23,  9.89it/s]
2022-03-21 17:02:21,658 - INFO - tqdm - f1: 0.9393, accuracy: 0.9392, batch_loss: 1.2383, loss: 0.2591 ||:  53%|#####3    | 166/313 [00:20<00:17,  8.28it/s]
2022-03-21 17:02:31,683 - INFO - tqdm - f1: 0.9367, accuracy: 0.9369, batch_loss: 0.1649, loss: 0.2634 ||:  80%|#######9  | 249/313 [00:30<00:08,  7.64it/s]
2022-03-21 17:02:39,078 - INFO - tqdm - f1: 0.9399, accuracy: 0.9400, batch_loss: 0.3576, loss: 0.2497 ||: 100%|#########9| 312/313 [00:37<00:00,  9.60it/s]
2022-03-21 17:02:39,275 - INFO - tqdm - f1: 0.9401, accuracy: 0.9402, batch_loss: 0.0277, loss: 0.2490 ||: 100%|##########| 313/313 [00:37<00:00,  8.23it/s]
2022-03-21 17:02:39,279 - INFO - tqdm - f1: 0.9401, accuracy: 0.9402, batch_loss: 0.0277, loss: 0.2490 ||: 100%|##########| 313/313 [00:37<00:00,  8.28it/s]
2022-03-21 17:02:39,355 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-03-21 17:02:39,357 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.975  |     0.940
2022-03-21 17:02:39,359 - INFO - allennlp.training.callbacks.console_logger - f1                 |     0.975  |     0.940
2022-03-21 17:02:39,360 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |     0.000  |       N/A
2022-03-21 17:02:39,362 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.076  |     0.249
2022-03-21 17:02:39,364 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7579.625  |       N/A
2022-03-21 17:02:39,365 - INFO - allennlp.training.trainer - Epoch duration: 0:27:08.038893
2022-03-21 17:02:39,367 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:44:31
2022-03-21 17:02:39,368 - INFO - allennlp.training.trainer - Epoch 6/9
2022-03-21 17:02:39,370 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-03-21 17:02:39,372 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2022-03-21 17:02:39,374 - INFO - allennlp.training.trainer - Training
2022-03-21 17:02:39,376 - INFO - tqdm - 0%|          | 0/7188 [00:00<?, ?it/s]
2022-03-21 17:02:49,443 - INFO - tqdm - f1: 0.9832, accuracy: 0.9837, batch_loss: 0.0088, loss: 0.0511 ||:   1%|          | 46/7188 [00:10<24:26,  4.87it/s]
2022-03-21 17:02:59,621 - INFO - tqdm - f1: 0.9838, accuracy: 0.9844, batch_loss: 0.2753, loss: 0.0561 ||:   1%|1         | 92/7188 [00:20<26:16,  4.50it/s]
2022-03-21 17:03:09,809 - INFO - tqdm - f1: 0.9828, accuracy: 0.9832, batch_loss: 0.0142, loss: 0.0539 ||:   2%|1         | 141/7188 [00:30<25:03,  4.69it/s]
2022-03-21 17:03:19,998 - INFO - tqdm - f1: 0.9819, accuracy: 0.9825, batch_loss: 0.0880, loss: 0.0557 ||:   3%|2         | 189/7188 [00:40<24:52,  4.69it/s]
2022-03-21 17:03:30,050 - INFO - tqdm - f1: 0.9814, accuracy: 0.9818, batch_loss: 0.0128, loss: 0.0534 ||:   4%|4         | 298/7188 [00:50<13:38,  8.41it/s]
2022-03-21 17:03:40,160 - INFO - tqdm - f1: 0.9812, accuracy: 0.9815, batch_loss: 0.0036, loss: 0.0561 ||:   5%|5         | 371/7188 [01:00<16:06,  7.05it/s]
2022-03-21 17:03:50,257 - INFO - tqdm - f1: 0.9812, accuracy: 0.9815, batch_loss: 0.3873, loss: 0.0549 ||:   6%|6         | 446/7188 [01:10<15:41,  7.16it/s]
2022-03-21 17:04:00,336 - INFO - tqdm - f1: 0.9822, accuracy: 0.9825, batch_loss: 0.0099, loss: 0.0512 ||:   7%|7         | 515/7188 [01:20<25:15,  4.40it/s]
2022-03-21 17:04:10,544 - INFO - tqdm - f1: 0.9823, accuracy: 0.9826, batch_loss: 0.3074, loss: 0.0516 ||:   8%|7         | 563/7188 [01:31<23:54,  4.62it/s]
2022-03-21 17:04:20,750 - INFO - tqdm - f1: 0.9818, accuracy: 0.9820, batch_loss: 0.1741, loss: 0.0541 ||:   9%|8         | 615/7188 [01:41<22:19,  4.91it/s]
2022-03-21 17:04:30,928 - INFO - tqdm - f1: 0.9815, accuracy: 0.9816, batch_loss: 0.0027, loss: 0.0553 ||:   9%|9         | 663/7188 [01:51<22:30,  4.83it/s]
2022-03-21 17:04:41,097 - INFO - tqdm - f1: 0.9810, accuracy: 0.9812, batch_loss: 0.0131, loss: 0.0583 ||:  10%|9         | 710/7188 [02:01<23:07,  4.67it/s]
2022-03-21 17:04:51,265 - INFO - tqdm - f1: 0.9813, accuracy: 0.9814, batch_loss: 0.1564, loss: 0.0575 ||:  11%|#         | 757/7188 [02:11<25:00,  4.29it/s]
2022-03-21 17:05:01,421 - INFO - tqdm - f1: 0.9816, accuracy: 0.9817, batch_loss: 0.3276, loss: 0.0569 ||:  11%|#1        | 805/7188 [02:22<22:55,  4.64it/s]
2022-03-21 17:05:11,526 - INFO - tqdm - f1: 0.9815, accuracy: 0.9816, batch_loss: 0.0048, loss: 0.0570 ||:  12%|#1        | 852/7188 [02:32<23:39,  4.46it/s]
2022-03-21 17:05:21,708 - INFO - tqdm - f1: 0.9820, accuracy: 0.9821, batch_loss: 0.3083, loss: 0.0565 ||:  13%|#2        | 899/7188 [02:42<22:40,  4.62it/s]
2022-03-21 17:05:31,767 - INFO - tqdm - f1: 0.9818, accuracy: 0.9819, batch_loss: 0.0099, loss: 0.0562 ||:  13%|#3        | 947/7188 [02:52<24:18,  4.28it/s]
2022-03-21 17:05:41,880 - INFO - tqdm - f1: 0.9819, accuracy: 0.9819, batch_loss: 0.0014, loss: 0.0550 ||:  14%|#3        | 996/7188 [03:02<20:58,  4.92it/s]
2022-03-21 17:05:51,998 - INFO - tqdm - f1: 0.9821, accuracy: 0.9821, batch_loss: 0.0011, loss: 0.0541 ||:  14%|#4        | 1042/7188 [03:12<21:11,  4.83it/s]
2022-03-21 17:06:02,045 - INFO - tqdm - f1: 0.9819, accuracy: 0.9820, batch_loss: 0.0038, loss: 0.0543 ||:  15%|#5        | 1089/7188 [03:22<23:26,  4.34it/s]
2022-03-21 17:06:12,221 - INFO - tqdm - f1: 0.9819, accuracy: 0.9819, batch_loss: 0.3330, loss: 0.0551 ||:  16%|#5        | 1136/7188 [03:32<21:25,  4.71it/s]
2022-03-21 17:06:22,335 - INFO - tqdm - f1: 0.9816, accuracy: 0.9817, batch_loss: 0.1682, loss: 0.0562 ||:  16%|#6        | 1183/7188 [03:42<21:03,  4.75it/s]
2022-03-21 17:06:32,476 - INFO - tqdm - f1: 0.9817, accuracy: 0.9817, batch_loss: 0.0024, loss: 0.0565 ||:  17%|#7        | 1230/7188 [03:53<20:31,  4.84it/s]
2022-03-21 17:06:42,631 - INFO - tqdm - f1: 0.9812, accuracy: 0.9813, batch_loss: 0.0307, loss: 0.0576 ||:  18%|#7        | 1277/7188 [04:03<20:57,  4.70it/s]
2022-03-21 17:06:52,773 - INFO - tqdm - f1: 0.9814, accuracy: 0.9815, batch_loss: 0.0306, loss: 0.0572 ||:  18%|#8        | 1323/7188 [04:13<22:45,  4.30it/s]
2022-03-21 17:07:02,812 - INFO - tqdm - f1: 0.9816, accuracy: 0.9817, batch_loss: 0.0063, loss: 0.0567 ||:  19%|#9        | 1370/7188 [04:23<20:13,  4.79it/s]
2022-03-21 17:07:12,879 - INFO - tqdm - f1: 0.9815, accuracy: 0.9816, batch_loss: 0.0041, loss: 0.0571 ||:  20%|#9        | 1416/7188 [04:33<20:34,  4.67it/s]
2022-03-21 17:07:23,049 - INFO - tqdm - f1: 0.9814, accuracy: 0.9815, batch_loss: 0.0647, loss: 0.0570 ||:  20%|##        | 1464/7188 [04:43<19:52,  4.80it/s]
2022-03-21 17:07:33,234 - INFO - tqdm - f1: 0.9811, accuracy: 0.9812, batch_loss: 0.0013, loss: 0.0571 ||:  21%|##1       | 1512/7188 [04:53<20:57,  4.51it/s]
2022-03-21 17:07:43,397 - INFO - tqdm - f1: 0.9811, accuracy: 0.9812, batch_loss: 0.1177, loss: 0.0569 ||:  22%|##1       | 1561/7188 [05:04<18:53,  4.96it/s]
2022-03-21 17:07:53,525 - INFO - tqdm - f1: 0.9813, accuracy: 0.9814, batch_loss: 0.0204, loss: 0.0565 ||:  22%|##2       | 1608/7188 [05:14<19:58,  4.65it/s]
2022-03-21 17:08:03,720 - INFO - tqdm - f1: 0.9812, accuracy: 0.9813, batch_loss: 0.2813, loss: 0.0571 ||:  23%|##3       | 1657/7188 [05:24<18:27,  4.99it/s]
2022-03-21 17:08:13,871 - INFO - tqdm - f1: 0.9812, accuracy: 0.9813, batch_loss: 0.1511, loss: 0.0570 ||:  24%|##3       | 1708/7188 [05:34<20:03,  4.55it/s]
2022-03-21 17:08:23,896 - INFO - tqdm - f1: 0.9811, accuracy: 0.9812, batch_loss: 0.0022, loss: 0.0574 ||:  24%|##4       | 1755/7188 [05:44<19:11,  4.72it/s]
2022-03-21 17:08:34,062 - INFO - tqdm - f1: 0.9814, accuracy: 0.9814, batch_loss: 0.0016, loss: 0.0566 ||:  25%|##5       | 1802/7188 [05:54<20:43,  4.33it/s]
2022-03-21 17:08:44,209 - INFO - tqdm - f1: 0.9813, accuracy: 0.9814, batch_loss: 0.0358, loss: 0.0570 ||:  26%|##5       | 1851/7188 [06:04<18:23,  4.84it/s]
2022-03-21 17:08:54,405 - INFO - tqdm - f1: 0.9813, accuracy: 0.9813, batch_loss: 0.0022, loss: 0.0569 ||:  26%|##6       | 1900/7188 [06:15<20:22,  4.32it/s]
2022-03-21 17:09:04,551 - INFO - tqdm - f1: 0.9814, accuracy: 0.9815, batch_loss: 0.0014, loss: 0.0569 ||:  27%|##7       | 1948/7188 [06:25<19:30,  4.48it/s]
2022-03-21 17:09:14,572 - INFO - tqdm - f1: 0.9815, accuracy: 0.9816, batch_loss: 0.1134, loss: 0.0561 ||:  28%|##7       | 1995/7188 [06:35<18:31,  4.67it/s]
2022-03-21 17:09:24,607 - INFO - tqdm - f1: 0.9814, accuracy: 0.9815, batch_loss: 0.0233, loss: 0.0563 ||:  28%|##8       | 2043/7188 [06:45<18:48,  4.56it/s]
2022-03-21 17:09:34,683 - INFO - tqdm - f1: 0.9812, accuracy: 0.9813, batch_loss: 0.0025, loss: 0.0569 ||:  29%|##9       | 2092/7188 [06:55<15:53,  5.35it/s]
2022-03-21 17:09:44,813 - INFO - tqdm - f1: 0.9812, accuracy: 0.9813, batch_loss: 0.0618, loss: 0.0565 ||:  30%|##9       | 2138/7188 [07:05<18:40,  4.51it/s]
2022-03-21 17:09:54,960 - INFO - tqdm - f1: 0.9812, accuracy: 0.9812, batch_loss: 0.0014, loss: 0.0562 ||:  30%|###       | 2186/7188 [07:15<18:57,  4.40it/s]
2022-03-21 17:10:05,098 - INFO - tqdm - f1: 0.9812, accuracy: 0.9813, batch_loss: 0.0028, loss: 0.0564 ||:  31%|###1      | 2233/7188 [07:25<18:36,  4.44it/s]
2022-03-21 17:10:15,117 - INFO - tqdm - f1: 0.9811, accuracy: 0.9811, batch_loss: 0.0176, loss: 0.0569 ||:  32%|###1      | 2280/7188 [07:35<18:14,  4.48it/s]
2022-03-21 17:10:25,119 - INFO - tqdm - f1: 0.9812, accuracy: 0.9812, batch_loss: 0.0015, loss: 0.0568 ||:  32%|###2      | 2328/7188 [07:45<17:32,  4.62it/s]
2022-03-21 17:10:35,124 - INFO - tqdm - f1: 0.9810, accuracy: 0.9811, batch_loss: 0.1610, loss: 0.0572 ||:  33%|###3      | 2378/7188 [07:55<16:37,  4.82it/s]
2022-03-21 17:10:45,192 - INFO - tqdm - f1: 0.9810, accuracy: 0.9810, batch_loss: 0.0845, loss: 0.0573 ||:  34%|###3      | 2423/7188 [08:05<19:11,  4.14it/s]
2022-03-21 17:10:55,230 - INFO - tqdm - f1: 0.9808, accuracy: 0.9808, batch_loss: 0.0136, loss: 0.0575 ||:  34%|###4      | 2470/7188 [08:15<17:05,  4.60it/s]
2022-03-21 17:11:05,369 - INFO - tqdm - f1: 0.9808, accuracy: 0.9809, batch_loss: 0.0047, loss: 0.0574 ||:  35%|###5      | 2518/7188 [08:25<15:39,  4.97it/s]
2022-03-21 17:11:15,581 - INFO - tqdm - f1: 0.9808, accuracy: 0.9809, batch_loss: 0.0098, loss: 0.0574 ||:  36%|###5      | 2567/7188 [08:36<16:50,  4.57it/s]
2022-03-21 17:11:25,710 - INFO - tqdm - f1: 0.9808, accuracy: 0.9808, batch_loss: 0.0398, loss: 0.0575 ||:  36%|###6      | 2614/7188 [08:46<15:56,  4.78it/s]
2022-03-21 17:11:35,890 - INFO - tqdm - f1: 0.9807, accuracy: 0.9807, batch_loss: 0.0104, loss: 0.0577 ||:  37%|###7      | 2662/7188 [08:56<16:07,  4.68it/s]
2022-03-21 17:11:45,922 - INFO - tqdm - f1: 0.9808, accuracy: 0.9808, batch_loss: 0.1346, loss: 0.0573 ||:  38%|###7      | 2708/7188 [09:06<17:04,  4.37it/s]
2022-03-21 17:11:55,927 - INFO - tqdm - f1: 0.9807, accuracy: 0.9807, batch_loss: 0.0025, loss: 0.0576 ||:  38%|###8      | 2755/7188 [09:16<14:24,  5.13it/s]
2022-03-21 17:12:05,944 - INFO - tqdm - f1: 0.9807, accuracy: 0.9807, batch_loss: 0.0018, loss: 0.0575 ||:  39%|###8      | 2801/7188 [09:26<16:25,  4.45it/s]
2022-03-21 17:12:16,138 - INFO - tqdm - f1: 0.9807, accuracy: 0.9807, batch_loss: 0.0338, loss: 0.0574 ||:  40%|###9      | 2850/7188 [09:36<15:12,  4.75it/s]
2022-03-21 17:12:26,236 - INFO - tqdm - f1: 0.9807, accuracy: 0.9807, batch_loss: 0.1670, loss: 0.0573 ||:  40%|####      | 2897/7188 [09:46<15:26,  4.63it/s]
2022-03-21 17:12:36,303 - INFO - tqdm - f1: 0.9806, accuracy: 0.9806, batch_loss: 0.0042, loss: 0.0577 ||:  41%|####      | 2943/7188 [09:56<16:43,  4.23it/s]
2022-03-21 17:12:46,409 - INFO - tqdm - f1: 0.9807, accuracy: 0.9807, batch_loss: 0.0016, loss: 0.0577 ||:  42%|####1     | 2991/7188 [10:07<15:12,  4.60it/s]
2022-03-21 17:12:56,533 - INFO - tqdm - f1: 0.9807, accuracy: 0.9807, batch_loss: 0.0270, loss: 0.0576 ||:  42%|####2     | 3038/7188 [10:17<14:07,  4.90it/s]
2022-03-21 17:13:06,749 - INFO - tqdm - f1: 0.9807, accuracy: 0.9807, batch_loss: 0.0186, loss: 0.0576 ||:  43%|####2     | 3085/7188 [10:27<14:54,  4.59it/s]
2022-03-21 17:13:16,866 - INFO - tqdm - f1: 0.9807, accuracy: 0.9807, batch_loss: 0.3039, loss: 0.0579 ||:  44%|####3     | 3132/7188 [10:37<15:05,  4.48it/s]
2022-03-21 17:13:26,978 - INFO - tqdm - f1: 0.9807, accuracy: 0.9807, batch_loss: 0.0233, loss: 0.0578 ||:  44%|####4     | 3180/7188 [10:47<14:27,  4.62it/s]
2022-03-21 17:13:37,146 - INFO - tqdm - f1: 0.9806, accuracy: 0.9806, batch_loss: 0.3015, loss: 0.0582 ||:  45%|####4     | 3227/7188 [10:57<14:05,  4.68it/s]
2022-03-21 17:13:47,269 - INFO - tqdm - f1: 0.9806, accuracy: 0.9806, batch_loss: 0.1619, loss: 0.0583 ||:  46%|####5     | 3275/7188 [11:07<15:13,  4.28it/s]
2022-03-21 17:13:57,521 - INFO - tqdm - f1: 0.9806, accuracy: 0.9806, batch_loss: 0.0020, loss: 0.0581 ||:  46%|####6     | 3323/7188 [11:18<14:16,  4.51it/s]
2022-03-21 17:14:07,626 - INFO - tqdm - f1: 0.9806, accuracy: 0.9806, batch_loss: 0.0878, loss: 0.0583 ||:  47%|####6     | 3371/7188 [11:28<12:41,  5.01it/s]
2022-03-21 17:14:17,778 - INFO - tqdm - f1: 0.9807, accuracy: 0.9807, batch_loss: 0.0246, loss: 0.0584 ||:  48%|####7     | 3417/7188 [11:38<13:25,  4.68it/s]
2022-03-21 17:14:27,791 - INFO - tqdm - f1: 0.9806, accuracy: 0.9806, batch_loss: 0.0223, loss: 0.0585 ||:  48%|####8     | 3467/7188 [11:48<14:26,  4.29it/s]
2022-03-21 17:14:37,984 - INFO - tqdm - f1: 0.9806, accuracy: 0.9806, batch_loss: 0.0336, loss: 0.0585 ||:  49%|####8     | 3515/7188 [11:58<12:41,  4.82it/s]
2022-03-21 17:14:48,129 - INFO - tqdm - f1: 0.9806, accuracy: 0.9806, batch_loss: 0.2854, loss: 0.0587 ||:  50%|####9     | 3562/7188 [12:08<14:08,  4.27it/s]
2022-03-21 17:14:58,177 - INFO - tqdm - f1: 0.9805, accuracy: 0.9806, batch_loss: 0.0293, loss: 0.0587 ||:  50%|#####     | 3610/7188 [12:18<14:18,  4.17it/s]
2022-03-21 17:15:08,185 - INFO - tqdm - f1: 0.9804, accuracy: 0.9804, batch_loss: 0.0422, loss: 0.0592 ||:  51%|#####     | 3656/7188 [12:28<12:47,  4.60it/s]
2022-03-21 17:15:18,225 - INFO - tqdm - f1: 0.9804, accuracy: 0.9804, batch_loss: 0.0445, loss: 0.0593 ||:  52%|#####1    | 3702/7188 [12:38<12:15,  4.74it/s]
2022-03-21 17:15:28,266 - INFO - tqdm - f1: 0.9803, accuracy: 0.9803, batch_loss: 0.0049, loss: 0.0593 ||:  52%|#####2    | 3750/7188 [12:48<11:54,  4.81it/s]
2022-03-21 17:15:38,439 - INFO - tqdm - f1: 0.9803, accuracy: 0.9803, batch_loss: 0.1685, loss: 0.0594 ||:  53%|#####2    | 3798/7188 [12:59<12:06,  4.66it/s]
2022-03-21 17:15:48,476 - INFO - tqdm - f1: 0.9803, accuracy: 0.9803, batch_loss: 0.0021, loss: 0.0593 ||:  53%|#####3    | 3845/7188 [13:09<12:32,  4.44it/s]
2022-03-21 17:15:58,559 - INFO - tqdm - f1: 0.9802, accuracy: 0.9802, batch_loss: 0.0658, loss: 0.0595 ||:  54%|#####4    | 3891/7188 [13:19<11:47,  4.66it/s]
2022-03-21 17:16:08,775 - INFO - tqdm - f1: 0.9803, accuracy: 0.9802, batch_loss: 0.0338, loss: 0.0595 ||:  55%|#####4    | 3939/7188 [13:29<11:44,  4.61it/s]
2022-03-21 17:16:18,908 - INFO - tqdm - f1: 0.9802, accuracy: 0.9802, batch_loss: 0.0514, loss: 0.0594 ||:  55%|#####5    | 3985/7188 [13:39<11:22,  4.69it/s]
2022-03-21 17:16:29,007 - INFO - tqdm - f1: 0.9801, accuracy: 0.9801, batch_loss: 0.4273, loss: 0.0594 ||:  56%|#####6    | 4033/7188 [13:49<10:20,  5.09it/s]
2022-03-21 17:16:39,109 - INFO - tqdm - f1: 0.9801, accuracy: 0.9801, batch_loss: 0.0071, loss: 0.0596 ||:  57%|#####6    | 4081/7188 [13:59<11:21,  4.56it/s]
2022-03-21 17:16:49,223 - INFO - tqdm - f1: 0.9800, accuracy: 0.9800, batch_loss: 0.0136, loss: 0.0597 ||:  57%|#####7    | 4130/7188 [14:09<11:41,  4.36it/s]
2022-03-21 17:16:59,356 - INFO - tqdm - f1: 0.9800, accuracy: 0.9800, batch_loss: 0.3496, loss: 0.0599 ||:  58%|#####8    | 4176/7188 [14:19<11:06,  4.52it/s]
2022-03-21 17:17:09,454 - INFO - tqdm - f1: 0.9800, accuracy: 0.9800, batch_loss: 0.0225, loss: 0.0601 ||:  59%|#####8    | 4224/7188 [14:30<11:18,  4.37it/s]
2022-03-21 17:17:19,632 - INFO - tqdm - f1: 0.9800, accuracy: 0.9800, batch_loss: 0.0976, loss: 0.0601 ||:  59%|#####9    | 4272/7188 [14:40<11:09,  4.35it/s]
2022-03-21 17:17:29,706 - INFO - tqdm - f1: 0.9800, accuracy: 0.9800, batch_loss: 0.0051, loss: 0.0601 ||:  60%|######    | 4320/7188 [14:50<10:30,  4.55it/s]
2022-03-21 17:17:39,753 - INFO - tqdm - f1: 0.9800, accuracy: 0.9800, batch_loss: 0.0030, loss: 0.0603 ||:  61%|######    | 4366/7188 [15:00<10:24,  4.52it/s]
2022-03-21 17:17:49,974 - INFO - tqdm - f1: 0.9800, accuracy: 0.9800, batch_loss: 0.0021, loss: 0.0604 ||:  61%|######1   | 4416/7188 [15:10<09:20,  4.95it/s]
2022-03-21 17:18:00,166 - INFO - tqdm - f1: 0.9800, accuracy: 0.9800, batch_loss: 0.0029, loss: 0.0605 ||:  62%|######2   | 4464/7188 [15:20<10:42,  4.24it/s]
2022-03-21 17:18:10,345 - INFO - tqdm - f1: 0.9799, accuracy: 0.9800, batch_loss: 0.0254, loss: 0.0606 ||:  63%|######2   | 4512/7188 [15:30<09:40,  4.61it/s]
2022-03-21 17:18:20,595 - INFO - tqdm - f1: 0.9798, accuracy: 0.9799, batch_loss: 0.0371, loss: 0.0608 ||:  63%|######3   | 4559/7188 [15:41<10:11,  4.30it/s]
2022-03-21 17:18:30,663 - INFO - tqdm - f1: 0.9799, accuracy: 0.9799, batch_loss: 0.0056, loss: 0.0608 ||:  64%|######4   | 4606/7188 [15:51<09:12,  4.67it/s]
2022-03-21 17:18:40,731 - INFO - tqdm - f1: 0.9797, accuracy: 0.9797, batch_loss: 0.0391, loss: 0.0613 ||:  65%|######4   | 4652/7188 [16:01<09:37,  4.39it/s]
2022-03-21 17:18:50,802 - INFO - tqdm - f1: 0.9797, accuracy: 0.9797, batch_loss: 0.0048, loss: 0.0614 ||:  65%|######5   | 4699/7188 [16:11<08:36,  4.82it/s]
2022-03-21 17:19:01,019 - INFO - tqdm - f1: 0.9796, accuracy: 0.9796, batch_loss: 0.0048, loss: 0.0615 ||:  66%|######6   | 4747/7188 [16:21<09:08,  4.45it/s]
2022-03-21 17:19:11,248 - INFO - tqdm - f1: 0.9796, accuracy: 0.9796, batch_loss: 0.0758, loss: 0.0618 ||:  67%|######6   | 4796/7188 [16:31<09:06,  4.38it/s]
2022-03-21 17:19:21,482 - INFO - tqdm - f1: 0.9796, accuracy: 0.9796, batch_loss: 0.0287, loss: 0.0619 ||:  67%|######7   | 4845/7188 [16:42<08:16,  4.72it/s]
2022-03-21 17:19:31,659 - INFO - tqdm - f1: 0.9797, accuracy: 0.9797, batch_loss: 0.2005, loss: 0.0616 ||:  68%|######8   | 4892/7188 [16:52<07:57,  4.81it/s]
2022-03-21 17:19:41,768 - INFO - tqdm - f1: 0.9795, accuracy: 0.9795, batch_loss: 0.0223, loss: 0.0620 ||:  70%|######9   | 5002/7188 [17:02<05:07,  7.10it/s]
2022-03-21 17:19:51,939 - INFO - tqdm - f1: 0.9796, accuracy: 0.9796, batch_loss: 0.0068, loss: 0.0618 ||:  71%|#######   | 5075/7188 [17:12<04:39,  7.56it/s]
2022-03-21 17:20:02,073 - INFO - tqdm - f1: 0.9796, accuracy: 0.9796, batch_loss: 0.0103, loss: 0.0617 ||:  72%|#######1  | 5147/7188 [17:22<04:33,  7.47it/s]
2022-03-21 17:20:12,204 - INFO - tqdm - f1: 0.9796, accuracy: 0.9796, batch_loss: 0.0145, loss: 0.0618 ||:  73%|#######2  | 5213/7188 [17:32<07:02,  4.67it/s]
2022-03-21 17:20:22,440 - INFO - tqdm - f1: 0.9794, accuracy: 0.9794, batch_loss: 0.0718, loss: 0.0620 ||:  73%|#######3  | 5263/7188 [17:43<06:47,  4.72it/s]
2022-03-21 17:20:32,557 - INFO - tqdm - f1: 0.9793, accuracy: 0.9793, batch_loss: 0.0742, loss: 0.0624 ||:  74%|#######3  | 5310/7188 [17:53<06:50,  4.57it/s]
2022-03-21 17:20:42,770 - INFO - tqdm - f1: 0.9794, accuracy: 0.9794, batch_loss: 0.0842, loss: 0.0624 ||:  75%|#######4  | 5358/7188 [18:03<06:19,  4.83it/s]
2022-03-21 17:20:52,978 - INFO - tqdm - f1: 0.9794, accuracy: 0.9793, batch_loss: 0.0206, loss: 0.0625 ||:  75%|#######5  | 5406/7188 [18:13<06:22,  4.66it/s]
2022-03-21 17:21:03,052 - INFO - tqdm - f1: 0.9794, accuracy: 0.9794, batch_loss: 0.2003, loss: 0.0624 ||:  76%|#######5  | 5453/7188 [18:23<06:16,  4.61it/s]
2022-03-21 17:21:13,140 - INFO - tqdm - f1: 0.9793, accuracy: 0.9792, batch_loss: 0.0179, loss: 0.0626 ||:  77%|#######6  | 5502/7188 [18:33<05:53,  4.77it/s]
2022-03-21 17:21:23,254 - INFO - tqdm - f1: 0.9793, accuracy: 0.9793, batch_loss: 0.0064, loss: 0.0625 ||:  77%|#######7  | 5549/7188 [18:43<05:40,  4.81it/s]
2022-03-21 17:21:33,431 - INFO - tqdm - f1: 0.9793, accuracy: 0.9793, batch_loss: 0.0994, loss: 0.0624 ||:  78%|#######7  | 5597/7188 [18:54<05:43,  4.64it/s]
2022-03-21 17:21:43,483 - INFO - tqdm - f1: 0.9794, accuracy: 0.9794, batch_loss: 0.0044, loss: 0.0623 ||:  79%|#######8  | 5647/7188 [19:04<05:13,  4.92it/s]
2022-03-21 17:21:53,674 - INFO - tqdm - f1: 0.9794, accuracy: 0.9794, batch_loss: 0.0384, loss: 0.0623 ||:  79%|#######9  | 5695/7188 [19:14<05:05,  4.89it/s]
2022-03-21 17:22:03,749 - INFO - tqdm - f1: 0.9794, accuracy: 0.9794, batch_loss: 0.8026, loss: 0.0624 ||:  80%|#######9  | 5741/7188 [19:24<05:07,  4.71it/s]
2022-03-21 17:22:13,984 - INFO - tqdm - f1: 0.9794, accuracy: 0.9794, batch_loss: 0.0168, loss: 0.0624 ||:  81%|########  | 5789/7188 [19:34<05:15,  4.44it/s]
2022-03-21 17:22:24,070 - INFO - tqdm - f1: 0.9793, accuracy: 0.9793, batch_loss: 0.0416, loss: 0.0627 ||:  81%|########1 | 5836/7188 [19:44<05:14,  4.30it/s]
2022-03-21 17:22:34,286 - INFO - tqdm - f1: 0.9793, accuracy: 0.9793, batch_loss: 0.4334, loss: 0.0627 ||:  82%|########1 | 5885/7188 [19:54<04:22,  4.96it/s]
2022-03-21 17:22:44,462 - INFO - tqdm - f1: 0.9793, accuracy: 0.9793, batch_loss: 0.0193, loss: 0.0628 ||:  83%|########2 | 5935/7188 [20:05<04:12,  4.96it/s]
2022-03-21 17:22:54,668 - INFO - tqdm - f1: 0.9793, accuracy: 0.9792, batch_loss: 0.0185, loss: 0.0631 ||:  83%|########3 | 5983/7188 [20:15<04:25,  4.54it/s]
2022-03-21 17:23:04,882 - INFO - tqdm - f1: 0.9793, accuracy: 0.9793, batch_loss: 0.0030, loss: 0.0630 ||:  84%|########3 | 6032/7188 [20:25<04:07,  4.68it/s]
2022-03-21 17:23:15,077 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0816, loss: 0.0632 ||:  85%|########4 | 6081/7188 [20:35<04:36,  4.00it/s]
2022-03-21 17:23:25,277 - INFO - tqdm - f1: 0.9792, accuracy: 0.9791, batch_loss: 0.0308, loss: 0.0632 ||:  85%|########5 | 6129/7188 [20:45<03:47,  4.65it/s]
2022-03-21 17:23:35,279 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0080, loss: 0.0631 ||:  86%|########5 | 6180/7188 [20:55<03:27,  4.86it/s]
2022-03-21 17:23:45,459 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.5361, loss: 0.0633 ||:  87%|########6 | 6228/7188 [21:06<03:29,  4.58it/s]
2022-03-21 17:23:55,647 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0056, loss: 0.0634 ||:  87%|########7 | 6277/7188 [21:16<03:10,  4.77it/s]
2022-03-21 17:24:05,813 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0450, loss: 0.0634 ||:  88%|########7 | 6324/7188 [21:26<03:07,  4.60it/s]
2022-03-21 17:24:15,943 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0546, loss: 0.0632 ||:  89%|########8 | 6371/7188 [21:36<02:50,  4.80it/s]
2022-03-21 17:24:26,112 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0204, loss: 0.0634 ||:  89%|########9 | 6419/7188 [21:46<02:45,  4.66it/s]
2022-03-21 17:24:36,291 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0770, loss: 0.0634 ||:  90%|########9 | 6466/7188 [21:56<02:31,  4.76it/s]
2022-03-21 17:24:46,489 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0341, loss: 0.0635 ||:  91%|######### | 6515/7188 [22:07<02:43,  4.12it/s]
2022-03-21 17:24:56,490 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0023, loss: 0.0636 ||:  91%|#########1| 6561/7188 [22:17<02:18,  4.52it/s]
2022-03-21 17:25:06,696 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0079, loss: 0.0636 ||:  92%|#########1| 6610/7188 [22:27<02:01,  4.75it/s]
2022-03-21 17:25:16,910 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0032, loss: 0.0636 ||:  93%|#########2| 6658/7188 [22:37<01:59,  4.42it/s]
2022-03-21 17:25:26,914 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0019, loss: 0.0634 ||:  93%|#########3| 6705/7188 [22:47<01:43,  4.65it/s]
2022-03-21 17:25:36,917 - INFO - tqdm - f1: 0.9793, accuracy: 0.9793, batch_loss: 0.0254, loss: 0.0634 ||:  94%|#########3| 6751/7188 [22:57<01:27,  5.01it/s]
2022-03-21 17:25:47,049 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0224, loss: 0.0636 ||:  95%|#########4| 6798/7188 [23:07<01:25,  4.56it/s]
2022-03-21 17:25:57,156 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0235, loss: 0.0636 ||:  95%|#########5| 6846/7188 [23:17<01:12,  4.71it/s]
2022-03-21 17:26:07,327 - INFO - tqdm - f1: 0.9793, accuracy: 0.9792, batch_loss: 0.0073, loss: 0.0637 ||:  96%|#########5| 6894/7188 [23:27<01:01,  4.75it/s]
2022-03-21 17:26:17,498 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0990, loss: 0.0639 ||:  97%|#########6| 6942/7188 [23:38<00:50,  4.85it/s]
2022-03-21 17:26:27,629 - INFO - tqdm - f1: 0.9792, accuracy: 0.9792, batch_loss: 0.0086, loss: 0.0640 ||:  97%|#########7| 6989/7188 [23:48<00:44,  4.46it/s]
2022-03-21 17:26:37,857 - INFO - tqdm - f1: 0.9791, accuracy: 0.9791, batch_loss: 0.0496, loss: 0.0640 ||:  98%|#########7| 7038/7188 [23:58<00:35,  4.28it/s]
2022-03-21 17:26:47,869 - INFO - tqdm - f1: 0.9791, accuracy: 0.9791, batch_loss: 0.2407, loss: 0.0642 ||:  99%|#########8| 7084/7188 [24:08<00:23,  4.46it/s]
2022-03-21 17:26:57,965 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0222, loss: 0.0643 ||:  99%|#########9| 7131/7188 [24:18<00:11,  4.92it/s]
2022-03-21 17:27:02,929 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0106, loss: 0.0642 ||: 100%|#########9| 7153/7188 [24:23<00:08,  4.25it/s]
2022-03-21 17:27:03,077 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0310, loss: 0.0642 ||: 100%|#########9| 7154/7188 [24:23<00:07,  4.78it/s]
2022-03-21 17:27:03,334 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.7302, loss: 0.0643 ||: 100%|#########9| 7155/7188 [24:23<00:07,  4.47it/s]
2022-03-21 17:27:03,550 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0104, loss: 0.0643 ||: 100%|#########9| 7156/7188 [24:24<00:07,  4.52it/s]
2022-03-21 17:27:03,797 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.2823, loss: 0.0643 ||: 100%|#########9| 7157/7188 [24:24<00:07,  4.37it/s]
2022-03-21 17:27:04,046 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0085, loss: 0.0643 ||: 100%|#########9| 7158/7188 [24:24<00:07,  4.26it/s]
2022-03-21 17:27:04,224 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.3198, loss: 0.0643 ||: 100%|#########9| 7159/7188 [24:24<00:06,  4.59it/s]
2022-03-21 17:27:04,469 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0402, loss: 0.0643 ||: 100%|#########9| 7160/7188 [24:25<00:06,  4.42it/s]
2022-03-21 17:27:04,703 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0121, loss: 0.0643 ||: 100%|#########9| 7161/7188 [24:25<00:06,  4.38it/s]
2022-03-21 17:27:04,845 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0138, loss: 0.0643 ||: 100%|#########9| 7162/7188 [24:25<00:05,  4.94it/s]
2022-03-21 17:27:05,094 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.3624, loss: 0.0644 ||: 100%|#########9| 7163/7188 [24:25<00:05,  4.62it/s]
2022-03-21 17:27:05,306 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0908, loss: 0.0644 ||: 100%|#########9| 7164/7188 [24:25<00:05,  4.65it/s]
2022-03-21 17:27:05,452 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0113, loss: 0.0644 ||: 100%|#########9| 7165/7188 [24:26<00:04,  5.15it/s]
2022-03-21 17:27:05,710 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0394, loss: 0.0644 ||: 100%|#########9| 7166/7188 [24:26<00:04,  4.68it/s]
2022-03-21 17:27:05,909 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0123, loss: 0.0643 ||: 100%|#########9| 7167/7188 [24:26<00:04,  4.78it/s]
2022-03-21 17:27:06,091 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0208, loss: 0.0643 ||: 100%|#########9| 7168/7188 [24:26<00:04,  4.98it/s]
2022-03-21 17:27:06,331 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0492, loss: 0.0643 ||: 100%|#########9| 7169/7188 [24:26<00:04,  4.70it/s]
2022-03-21 17:27:06,516 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0029, loss: 0.0643 ||: 100%|#########9| 7170/7188 [24:27<00:03,  4.89it/s]
2022-03-21 17:27:06,700 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.1356, loss: 0.0643 ||: 100%|#########9| 7171/7188 [24:27<00:03,  5.04it/s]
2022-03-21 17:27:06,980 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.3580, loss: 0.0644 ||: 100%|#########9| 7172/7188 [24:27<00:03,  4.49it/s]
2022-03-21 17:27:07,229 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0036, loss: 0.0644 ||: 100%|#########9| 7173/7188 [24:27<00:03,  4.34it/s]
2022-03-21 17:27:07,506 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.1381, loss: 0.0644 ||: 100%|#########9| 7174/7188 [24:28<00:03,  4.09it/s]
2022-03-21 17:27:07,697 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0829, loss: 0.0644 ||: 100%|#########9| 7175/7188 [24:28<00:02,  4.38it/s]
2022-03-21 17:27:07,850 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0067, loss: 0.0644 ||: 100%|#########9| 7176/7188 [24:28<00:02,  4.86it/s]
2022-03-21 17:27:08,106 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.1061, loss: 0.0644 ||: 100%|#########9| 7177/7188 [24:28<00:02,  4.53it/s]
2022-03-21 17:27:08,302 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0877, loss: 0.0644 ||: 100%|#########9| 7178/7188 [24:28<00:02,  4.69it/s]
2022-03-21 17:27:08,487 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0045, loss: 0.0644 ||: 100%|#########9| 7179/7188 [24:29<00:01,  4.88it/s]
2022-03-21 17:27:08,736 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0053, loss: 0.0644 ||: 100%|#########9| 7180/7188 [24:29<00:01,  4.58it/s]
2022-03-21 17:27:08,912 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0082, loss: 0.0644 ||: 100%|#########9| 7181/7188 [24:29<00:01,  4.87it/s]
2022-03-21 17:27:09,158 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0107, loss: 0.0644 ||: 100%|#########9| 7182/7188 [24:29<00:01,  4.59it/s]
2022-03-21 17:27:09,417 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0364, loss: 0.0644 ||: 100%|#########9| 7183/7188 [24:30<00:01,  4.35it/s]
2022-03-21 17:27:09,601 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.2357, loss: 0.0644 ||: 100%|#########9| 7184/7188 [24:30<00:00,  4.62it/s]
2022-03-21 17:27:09,845 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.2297, loss: 0.0644 ||: 100%|#########9| 7185/7188 [24:30<00:00,  4.46it/s]
2022-03-21 17:27:10,072 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0189, loss: 0.0644 ||: 100%|#########9| 7186/7188 [24:30<00:00,  4.44it/s]
2022-03-21 17:27:10,217 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0497, loss: 0.0644 ||: 100%|#########9| 7187/7188 [24:30<00:00,  4.97it/s]
2022-03-21 17:27:10,466 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0092, loss: 0.0644 ||: 100%|##########| 7188/7188 [24:31<00:00,  4.64it/s]
2022-03-21 17:27:10,509 - INFO - tqdm - f1: 0.9790, accuracy: 0.9790, batch_loss: 0.0092, loss: 0.0644 ||: 100%|##########| 7188/7188 [24:31<00:00,  4.89it/s]
2022-03-21 17:27:10,585 - INFO - allennlp.training.trainer - Validating
2022-03-21 17:27:10,591 - INFO - tqdm - 0%|          | 0/313 [00:00<?, ?it/s]
2022-03-21 17:27:20,759 - INFO - tqdm - f1: 0.9144, accuracy: 0.9146, batch_loss: 0.1740, loss: 0.3309 ||:  26%|##6       | 82/313 [00:10<00:30,  7.58it/s]
2022-03-21 17:27:30,859 - INFO - tqdm - f1: 0.9220, accuracy: 0.9216, batch_loss: 0.3451, loss: 0.2959 ||:  55%|#####4    | 172/313 [00:20<00:16,  8.61it/s]
2022-03-21 17:27:40,896 - INFO - tqdm - f1: 0.9264, accuracy: 0.9264, batch_loss: 0.0093, loss: 0.2768 ||:  79%|#######8  | 246/313 [00:30<00:08,  7.46it/s]
2022-03-21 17:27:48,978 - INFO - tqdm - f1: 0.9267, accuracy: 0.9268, batch_loss: 0.3605, loss: 0.2813 ||: 100%|#########9| 312/313 [00:38<00:00,  8.22it/s]
2022-03-21 17:27:49,117 - INFO - tqdm - f1: 0.9270, accuracy: 0.9270, batch_loss: 0.0129, loss: 0.2805 ||: 100%|##########| 313/313 [00:38<00:00,  7.96it/s]
2022-03-21 17:27:49,123 - INFO - tqdm - f1: 0.9270, accuracy: 0.9270, batch_loss: 0.0129, loss: 0.2805 ||: 100%|##########| 313/313 [00:38<00:00,  8.12it/s]
2022-03-21 17:27:49,127 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-03-21 17:27:49,130 - INFO - dont_stop_pretraining.training.roberta_checkpointer - loading best weights
2022-03-21 17:27:49,630 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-03-21 17:27:49,637 - INFO - allennlp.training.util - Iterating over dataset
2022-03-21 17:27:49,640 - INFO - tqdm - 0it [00:00, ?it/s]
2022-03-21 17:27:49,654 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-21 17:27:49,657 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
2022-03-21 17:27:59,778 - INFO - tqdm - f1: 0.93, accuracy: 0.93, loss: 0.22 ||: : 82it [00:10,  8.06it/s]
2022-03-21 17:28:09,792 - INFO - tqdm - f1: 0.93, accuracy: 0.93, loss: 0.22 ||: : 166it [00:20,  7.89it/s]
2022-03-21 17:28:19,936 - INFO - tqdm - f1: 0.94, accuracy: 0.94, loss: 0.21 ||: : 251it [00:30,  9.27it/s]
2022-03-21 17:28:30,095 - INFO - tqdm - f1: 0.93, accuracy: 0.93, loss: 0.23 ||: : 338it [00:40,  8.18it/s]
2022-03-21 17:28:40,131 - INFO - tqdm - f1: 0.94, accuracy: 0.94, loss: 0.23 ||: : 423it [00:50,  7.97it/s]
2022-03-21 17:28:46,191 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 3,
  "peak_worker_0_memory_MB": 7579.625,
  "peak_gpu_0_memory_MB": 0,
  "training_duration": "2:36:47.771729",
  "training_start_epoch": 0,
  "training_epochs": 5,
  "epoch": 5,
  "training_f1": 0.9748233407735825,
  "training_accuracy": 0.9748086956521739,
  "training_loss": 0.07621078600229157,
  "training_worker_0_memory_MB": 7579.625,
  "training_gpu_0_memory_MB": 0.0,
  "validation_f1": 0.9401298761367798,
  "validation_accuracy": 0.9402,
  "validation_loss": 0.24898629076555728,
  "best_validation_f1": 0.9404686391353607,
  "best_validation_accuracy": 0.9404,
  "best_validation_loss": 0.21464091743983793,
  "test_f1": 0.935231626033783,
  "test_accuracy": 0.9352631578947368,
  "test_loss": 0.2283249031232768
}
2022-03-21 17:28:46,255 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/ag_base_hyper_small_seed_314/model.tar.gz
